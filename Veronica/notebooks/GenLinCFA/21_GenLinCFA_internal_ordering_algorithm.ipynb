{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18093,"status":"ok","timestamp":1690351142930,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"},"user_tz":-120},"id":"_Q-9-_Ldoy_t","outputId":"03a6f6f4-da7f-445b-b2be-2ada16451eed"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"id":"_Q-9-_Ldoy_t"},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2094,"status":"ok","timestamp":1690351145017,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"},"user_tz":-120},"id":"N4mlPbfnozfO","outputId":"1481a739-e6bb-467e-eb93-9eae8bd91340"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/scripts\n"]}],"source":["cd drive/MyDrive/Colab\\ Notebooks/scripts"],"id":"N4mlPbfnozfO"},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":1112,"status":"ok","timestamp":1690351146108,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"},"user_tz":-120},"id":"87a19403"},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import matplotlib.cm as cm\n","import numpy as np\n","import sys\n","from sklearn.linear_model import LinearRegression\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import r2_score\n","import os"],"id":"87a19403"},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":1344,"status":"ok","timestamp":1690351147450,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"},"user_tz":-120},"id":"t4O3GfTbop-R"},"outputs":[],"source":["from feature_selection import forwardFeatureSelection\n","\n","from GenLinCFA import GenLinCFA\n","\n","from aux_GenLinCFA import standardize,unfold_dataset,compute_r2,prepare_target,prepare_features,aggregate_unfolded_data,aggregate_unfolded_data_onlyTrain,FS_with_linearWrapper,FS_with_logisticWrapper,compare_methods,compare_methods_class,compute_r2,prepare_target_binary"],"id":"t4O3GfTbop-R"},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1690351147451,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"},"user_tz":-120},"id":"tkkdaNmFRP4N","outputId":"d268a2d8-5499-4524-a95e-489f68788c22"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks\n"]}],"source":["cd .."],"id":"tkkdaNmFRP4N"},{"cell_type":"markdown","metadata":{"id":"PqNz4kWf-tga"},"source":["## GenLinCFA aggregations standardized target\n","\n"],"id":"PqNz4kWf-tga"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2449881,"status":"ok","timestamp":1690206599484,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"},"user_tz":-120},"id":"Dd_c8fjYuJ9h","outputId":"1271cdc0-6e29-4c4a-e0e2-4def2d24f4e4"},"outputs":[{"output_type":"stream","name":"stdout","text":["####################Emiliani1####################\n","target samples:            date      mean  median  year  week  mean_std\n","0    2001-01-05  0.379890    0.50  2001     1         0\n","1    2001-01-13  0.482679    0.58  2001     2         1\n","2    2001-01-21  0.516259    0.59  2001     3         1\n","3    2001-01-29  0.434421    0.50  2001     5         0\n","4    2001-02-06  0.494805    0.54  2001     6         1\n","..          ...       ...     ...   ...   ...       ...\n","406  2009-11-27  0.427085    0.43  2009    48         0\n","407  2009-12-05  0.547380    0.57  2009    49         1\n","408  2009-12-13  0.531070    0.58  2009    50         1\n","409  2009-12-21  0.295704    0.00  2009    52         0\n","410  2009-12-29  0.027861    0.00  2009    53         0\n","\n","[411 rows x 6 columns]\n"," target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n","Feature: cyclostationary_mean_tg\n","\n","Number of features: 172\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_1w\n","\n","Number of features: 172\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_tg_4w\n","\n","Number of features: 172\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_8w\n","\n","Number of features: 172\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_12w\n","\n","Number of features: 172\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_tg_16w\n","\n","Number of features: 172\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_24w\n","\n","Number of features: 172\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr\n","\n","Number of features: 172\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_1w\n","\n","Number of features: 172\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_4w\n","\n","Number of features: 172\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_rr_8w\n","\n","Number of features: 172\n","\n","Number of aggregated features: 7\n","\n","Feature: cyclostationary_mean_rr_12w\n","\n","Number of features: 172\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_rr_16w\n","\n","Number of features: 172\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_rr_24w\n","\n","Number of features: 172\n","\n","Number of aggregated features: 5\n","\n","\n","\n","selected columns: ['cyclostationary_mean_rr_8w_2', 'cyclostationary_mean_tg_1w_4', 'cyclostationary_mean_rr_8w_0', 'cyclostationary_mean_rr_24w_4', 'cyclostationary_mean_rr_12w_2', 'cyclostationary_mean_tg_24w_2', 'cyclostationary_mean_rr_8w_4', 'cyclostationary_mean_rr_16w_0', 'cyclostationary_mean_rr_16w_3', 'cyclostationary_mean_tg_24w_0', 'cyclostationary_mean_rr_16w_2'], \n","\n","validation score: 0.38335921266625517, \n","\n","number of selected features: 11\n","\n","Full model and selected features with wrapper\n","\n","Full aggregate regression train score: 0.34377787472529076, test score: -0.010614176706756462\n","Aggregate regression train score with FS: 0.24159481457039644, test score: 0.15758921622571176\n","\n","Full model and best 5 selected features with wrapper\n","\n","Full aggregate regression train score: 0.34377787472529076, test score: -0.010614176706756462\n","Aggregate regression train score with FS: 0.2314536779623716, test score: 0.14904206144346976\n","----- MI Scores -----\n","[(39, 0.11356367810937015), (40, 0.11128266914743393), (32, 0.10140017513644295), (34, 0.0926421853245166), (41, 0.09253444417618098), (1, 0.08866146459627064), (36, 0.08723405703339025), (28, 0.08537594148378816), (35, 0.08510061764151326), (38, 0.08491866701609256), (26, 0.08343023190494907), (55, 0.08082407130969377), (2, 0.0802269359067934), (37, 0.07958048742599162), (30, 0.07195528198806332), (44, 0.07047592758378993), (31, 0.07038889675094881), (27, 0.0702200321563645), (53, 0.06947024251949149), (7, 0.0686828185330803), (33, 0.06746863816194472), (47, 0.0648524597452632), (42, 0.06479240071050071), (43, 0.06423743240450719), (5, 0.0639836540217453), (50, 0.060053332648494294), (54, 0.05691552931003472), (51, 0.05669437235400927), (46, 0.05640672357577389), (25, 0.056098082191255866), (52, 0.054888385454732506), (29, 0.054028412951695026), (0, 0.053315507612018816), (49, 0.04869083691229801), (24, 0.04854332813218871), (48, 0.04760180695581325), (45, 0.0467385767109005), (6, 0.04478467748271026), (4, 0.044460065452626873), (3, 0.03893157144107195), (12, 0.03698581976583691), (19, 0.03390393714847367), (21, 0.028129140871695768), (13, 0.025099051413211178), (9, 0.02494511688048449), (11, 0.018896241845012863), (22, 0.018545003241104103), (23, 0.01782448808658934), (8, 0.015892245841503123), (10, 0.011620267425034025), (16, 0.011104114549030894), (14, 0.009000108715688654), (17, 0.007975967120675824), (20, 0.00014571755462942292), (18, -0.0015906002615947656), (15, -0.01361101829242338)]\n","Best MI score: 0.11356367810937015\n","Adding first best original feature: 39\n","CMI: 0.02876154707131723\n","CMI: 0.05215664780483789\n","CMI: 0.04992616223892196\n","CMI: 0.015118077916647016\n","CMI: 0.008461871849269692\n","CMI: 0.006833529412399966\n","CMI: 0.022991277926157322\n","CMI: 0.0010197759523711825\n","CMI: 0.012214927977787365\n","CMI: 0.0026854265627763163\n","CMI: 0.012659608958585172\n","CMI: 0.012415379938888998\n","CMI: 0.01223498727096431\n","CMI: 0.008689717521774304\n","CMI: 0.031125274111614726\n","CMI: 0.013564001439128281\n","CMI: 0.010715985698721134\n","CMI: 0.013373999125472963\n","CMI: 0.000822415676783872\n","CMI: 0.0095759449334656\n","CMI: 0.009934133679783505\n","CMI: 0.014816595791583648\n","CMI: 0.0009551346122987775\n","CMI: 0.008334730782438085\n","CMI: 0.009626469642105132\n","CMI: 0.018726398984230425\n","CMI: 0.013552324853126602\n","CMI: 0.008002548150965724\n","CMI: 0.008919667751859886\n","CMI: 1.3275047681782226e-05\n","CMI: 0.0033403106799517607\n","CMI: 0.002893843367635679\n","CMI: 0.012413076347341956\n","CMI: 0.004242546503528372\n","CMI: 0.01517321630074514\n","CMI: 0.014445008914691998\n","CMI: 0.005720523222561558\n","CMI: 0.006223899026961188\n","CMI: 0.010961942981174894\n","CMI: 0.006893075441730456\n","CMI: 0.012040243097622444\n","CMI: 0.004543691215772652\n","CMI: 0.002906436740160792\n","CMI: 0.023681723507057495\n","Highest CMI score: 0.05215664780483789\n","Adding original feature: 1\n","CMI: 0.0059285322733391155\n","CMI: 0.0011085553935996084\n","CMI: 0.00884114381837861\n","CMI: 0.004711597171081661\n","CMI: 0.0005227747518126158\n","CMI: 0.010170180340633383\n","CMI: 0.016449437898790942\n","CMI: 0.004808056541147576\n","CMI: 0.01671380011173504\n","CMI: 0.013139480153220445\n","CMI: 0.012788024094976397\n","CMI: 0.01322051737691543\n","CMI: 0.016358406507602702\n","CMI: 0.018780642356185484\n","CMI: 0.005228757998538891\n","CMI: 0.005103870683497047\n","CMI: 0.006616765158494464\n","CMI: 0.0019400879700428586\n","CMI: 0.018757770713591332\n","CMI: 0.002467540918895589\n","CMI: 0.0016493583512939003\n","CMI: 0.00833619425530499\n","CMI: 0.0034586371003497707\n","CMI: 0.013125535092104013\n","CMI: 0.0029625624253359906\n","CMI: 0.023395167049281823\n","CMI: 0.0064042707592950054\n","CMI: 0.004971151544624436\n","CMI: 0.00583656285283507\n","CMI: 0.007829723258526156\n","CMI: 0.01707280316431606\n","Highest CMI score: 0.023395167049281823\n","Adding original feature: 48\n","CMI: 0.00959661708077661\n","CMI: 0.007158757254304177\n","CMI: 0.005025503934033393\n","CMI: 0.0026773365154958706\n","CMI: 0.004178577054036348\n","CMI: 0.005774465182137395\n","CMI: 0.006823991301477095\n","CMI: 0.004940793333809035\n","CMI: 0.004281017398830439\n","CMI: 0.004130494433311371\n","CMI: 0.015075279163727945\n","CMI: 0.02199864398481538\n","CMI: 0.012774908095373988\n","CMI: 0.02126534730099247\n","CMI: 0.01768706692534508\n","CMI: 0.017481489697065006\n","CMI: 0.00018204765699103564\n","CMI: 0.0023587542048018606\n","CMI: 0.00030715638493877817\n","CMI: 0.0065608573587351005\n","CMI: 0.0038244162956309613\n","CMI: 0.0013624048863999372\n","CMI: 0.0054458788377446665\n","CMI: 0.007894586214611088\n","CMI: 0.010151155611704515\n","CMI: 0.0030685537319493916\n","CMI: 0.008109169264607946\n","CMI: 0.01049919338056432\n","Highest CMI score: 0.02199864398481538\n","Adding original feature: 19\n","CMI: 0.005096136232815018\n","CMI: 0.0029239028430031733\n","CMI: 0.0007476555028620158\n","CMI: 0.009968776854095918\n","CMI: 0.010958246252242287\n","CMI: 0.0038931480651474837\n","CMI: 0.0009301911577458133\n","CMI: 0.001151097528846956\n","CMI: 0.00035324196660305174\n","CMI: 0.008071477739694383\n","CMI: 0.0023429067220670508\n","CMI: 0.0020956751369339555\n","CMI: 0.004090837598634933\n","CMI: 0.010273757203196038\n","Highest CMI score: 0.010958246252242287\n","Adding original feature: 21\n","CMI: 0.005901905209672403\n","CMI: 0.0024631220251774555\n","CMI: 0.00012434126835822457\n","CMI: 0.0034099109167252117\n","CMI: 0.00442884937846913\n","CMI: 0.009707515300692526\n","CMI: 0.0023259198437791395\n","CMI: 0.003714512677276488\n","CMI: 0.009678504048327013\n","Highest CMI score: 0.009707515300692526\n","Adding original feature: 40\n","CMI: 0.0017106377924153426\n","Highest CMI score: 0.0017106377924153426\n","Adding original feature: 18\n","Highest CMI score: -0.0020612968487475625\n","\n","[39, 1, 48, 19, 21, 40, 18]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.34377787472529076, test score: -0.010614176706756462\n","Aggregate regression train score with FS: 0.2427867429195496, test score: 0.05294517663003295\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.34377787472529076, test score: -0.010614176706756462\n","Aggregate regression train score with FS: 0.22594943829797076, test score: 0.11082839185928628\n","###### Binary Classification ######\n","Train accuracy logistic regression CMI:  0.734\n","Test accuracy logistic regression CMI:  0.649 \n","\n","Train accuracy logistic regression CMI best 5:  0.721\n","Test accuracy logistic regression CMI best 5:  0.697 \n","\n","Train accuracy logistic regression wrapper:  0.692\n","Test accuracy logistic regression wrapper:  0.693 \n","\n","####################Emiliani2####################\n","target samples:            date      mean  median  year  week  mean_std\n","0    2001-01-05  0.214281    0.00  2001     1         0\n","1    2001-01-13  0.484737    0.52  2001     2         1\n","2    2001-01-21  0.466071    0.47  2001     3         1\n","3    2001-01-29  0.417470    0.44  2001     5         0\n","4    2001-02-06  0.492202    0.53  2001     6         1\n","..          ...       ...     ...   ...   ...       ...\n","406  2009-11-27  0.436464    0.46  2009    48         1\n","407  2009-12-05  0.466152    0.49  2009    49         1\n","408  2009-12-13  0.553659    0.59  2009    50         1\n","409  2009-12-21  0.507978    0.65  2009    52         1\n","410  2009-12-29  0.083046    0.00  2009    53         0\n","\n","[411 rows x 6 columns]\n"," target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n","Feature: cyclostationary_mean_tg\n","\n","Number of features: 130\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_1w\n","\n","Number of features: 130\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_4w\n","\n","Number of features: 130\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_8w\n","\n","Number of features: 130\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_12w\n","\n","Number of features: 130\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_16w\n","\n","Number of features: 130\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_tg_24w\n","\n","Number of features: 130\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_rr\n","\n","Number of features: 130\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_rr_1w\n","\n","Number of features: 130\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_rr_4w\n","\n","Number of features: 130\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_rr_8w\n","\n","Number of features: 130\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_rr_12w\n","\n","Number of features: 130\n","\n","Number of aggregated features: 7\n","\n","Feature: cyclostationary_mean_rr_16w\n","\n","Number of features: 130\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_24w\n","\n","Number of features: 130\n","\n","Number of aggregated features: 4\n","\n","\n","\n","selected columns: ['cyclostationary_mean_rr_8w_3', 'cyclostationary_mean_tg_1w_1', 'cyclostationary_mean_tg_8w_0', 'cyclostationary_mean_rr_12w_1', 'cyclostationary_mean_rr_12w_0', 'cyclostationary_mean_tg_24w_1', 'cyclostationary_mean_tg_16w_4', 'cyclostationary_mean_rr_24w_3', 'cyclostationary_mean_tg_4w_0', 'cyclostationary_mean_rr_4w_3', 'cyclostationary_mean_rr_4w_0', 'cyclostationary_mean_tg_8w_1', 'cyclostationary_mean_rr_24w_2', 'cyclostationary_mean_tg_24w_0', 'cyclostationary_mean_tg_8w_2', 'cyclostationary_mean_rr_16w_2', 'cyclostationary_mean_tg_4w_2', 'cyclostationary_mean_tg_12w_0'], \n","\n","validation score: 0.369848677384676, \n","\n","number of selected features: 18\n","\n","Full model and selected features with wrapper\n","\n","Full aggregate regression train score: 0.3070556469269027, test score: 0.09150288555387776\n","Aggregate regression train score with FS: 0.23348788683573574, test score: 0.25328243707503806\n","\n","Full model and best 5 selected features with wrapper\n","\n","Full aggregate regression train score: 0.3070556469269027, test score: 0.09150288555387776\n","Aggregate regression train score with FS: 0.21819604660873604, test score: 0.2665137097072551\n","----- MI Scores -----\n","[(27, 0.09683751312728613), (26, 0.09262636479245587), (40, 0.086598513597551), (25, 0.08015706027626637), (35, 0.07826481385901023), (34, 0.07733805147543484), (1, 0.0704607761026192), (33, 0.06686186233507427), (38, 0.06683909701141881), (2, 0.06434874959596322), (32, 0.0629669024882549), (30, 0.06278556593604985), (44, 0.06221628298553507), (39, 0.06160975382563289), (29, 0.060371191533181774), (45, 0.06036887180800342), (31, 0.05833637232071515), (8, 0.05813265186871324), (5, 0.058117835828464484), (37, 0.055197481189190226), (4, 0.05513032797721548), (47, 0.054804322889574424), (49, 0.05273476077875141), (36, 0.05267847653919426), (28, 0.05037116379687575), (43, 0.049442783197925055), (50, 0.04861634447730702), (46, 0.0480105024336942), (42, 0.047688572206663185), (0, 0.04454712903503171), (48, 0.04095170422490763), (52, 0.04059622813464456), (41, 0.04008803369087768), (54, 0.035461611006337226), (3, 0.03510887073401208), (18, 0.03407751424916151), (7, 0.03355950257241446), (10, 0.027584076956403608), (17, 0.027576703392089483), (51, 0.027570293645397998), (21, 0.024370568831594476), (19, 0.0232315082634643), (24, 0.019538320354759508), (14, 0.01805903077066855), (12, 0.01639416011902365), (53, 0.015423396300907645), (23, 0.01438062751825508), (6, 0.013376431927000528), (11, 0.01221538985465791), (22, 0.011458287664703205), (15, 0.01091833060442679), (20, 0.00713324749715151), (16, 0.0052243027699305855), (9, 0.002155022309364073), (13, 0.0016504191534057714)]\n","Best MI score: 0.09683751312728613\n","Adding first best original feature: 27\n","CMI: 0.0066895975043477635\n","CMI: 0.015190130611613714\n","CMI: 0.011503515043325724\n","CMI: 0.004472093076214587\n","CMI: 0.013888573604859164\n","CMI: 0.01028283874735171\n","CMI: 0.005792139119779521\n","CMI: 0.0023443487325671974\n","CMI: 0.006634656459638746\n","Highest CMI score: 0.015190130611613714\n","Adding original feature: 26\n","Highest CMI score: -0.004976697459948512\n","\n","[27, 26]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.3070556469269027, test score: 0.09150288555387776\n","Aggregate regression train score with FS: 0.06012440331257518, test score: 0.03488815259064271\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.3070556469269027, test score: 0.09150288555387776\n","Aggregate regression train score with FS: 0.06012440331257518, test score: 0.03488815259064271\n","###### Binary Classification ######\n","Train accuracy logistic regression CMI:  0.609\n","Test accuracy logistic regression CMI:  0.583 \n","\n","Train accuracy logistic regression CMI best 5:  0.609\n","Test accuracy logistic regression CMI best 5:  0.583 \n","\n","Train accuracy logistic regression wrapper:  0.723\n","Test accuracy logistic regression wrapper:  0.763 \n","\n","####################Garda_Mincio####################\n","target samples:            date      mean  median  year  week  mean_std\n","0    2001-01-05  0.102270    0.00  2001     1         0\n","1    2001-01-13  0.454431    0.53  2001     2         1\n","2    2001-01-21  0.323514    0.32  2001     3         0\n","3    2001-01-29  0.301661    0.31  2001     5         0\n","4    2001-02-06  0.394733    0.44  2001     6         1\n","..          ...       ...     ...   ...   ...       ...\n","406  2009-11-27  0.388573    0.44  2009    48         1\n","407  2009-12-05  0.402760    0.47  2009    49         1\n","408  2009-12-13  0.353782    0.44  2009    50         0\n","409  2009-12-21  0.043947    0.00  2009    52         0\n","410  2009-12-29  0.006670    0.00  2009    53         0\n","\n","[411 rows x 6 columns]\n"," target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n","Feature: cyclostationary_mean_tg\n","\n","Number of features: 67\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_tg_1w\n","\n","Number of features: 67\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_tg_4w\n","\n","Number of features: 67\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_8w\n","\n","Number of features: 67\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_12w\n","\n","Number of features: 67\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_16w\n","\n","Number of features: 67\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_24w\n","\n","Number of features: 67\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr\n","\n","Number of features: 67\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_rr_1w\n","\n","Number of features: 67\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_rr_4w\n","\n","Number of features: 67\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_rr_8w\n","\n","Number of features: 67\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_rr_12w\n","\n","Number of features: 67\n","\n","Number of aggregated features: 7\n","\n","Feature: cyclostationary_mean_rr_16w\n","\n","Number of features: 67\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_24w\n","\n","Number of features: 67\n","\n","Number of aggregated features: 3\n","\n","\n","\n","selected columns: ['cyclostationary_mean_rr_8w_3', 'cyclostationary_mean_rr_8w_0', 'cyclostationary_mean_tg_1w_2', 'cyclostationary_mean_tg_8w_0', 'cyclostationary_mean_rr_24w_2', 'cyclostationary_mean_rr_24w_0', 'cyclostationary_mean_rr_4w_0', 'cyclostationary_mean_rr_12w_0', 'cyclostationary_mean_rr_8w_1', 'cyclostationary_mean_rr_12w_3', 'cyclostationary_mean_rr_24w_1', 'cyclostationary_mean_rr_12w_4', 'cyclostationary_mean_rr_4w_4', 'cyclostationary_mean_rr_1w_0', 'cyclostationary_mean_rr_12w_1', 'cyclostationary_mean_rr_12w_2', 'cyclostationary_mean_tg_12w_1', 'cyclostationary_mean_tg_12w_2', 'cyclostationary_mean_rr_12w_6', 'cyclostationary_mean_rr_4w_1', 'cyclostationary_mean_rr_16w_1', 'cyclostationary_mean_rr_16w_2', 'cyclostationary_mean_tg_4w_0'], \n","\n","validation score: 0.3834652777239139, \n","\n","number of selected features: 23\n","\n","Full model and selected features with wrapper\n","\n","Full aggregate regression train score: 0.3179348722097767, test score: 0.011243487646285466\n","Aggregate regression train score with FS: 0.24886558002312986, test score: 0.10347313509462919\n","\n","Full model and best 5 selected features with wrapper\n","\n","Full aggregate regression train score: 0.3179348722097767, test score: 0.011243487646285466\n","Aggregate regression train score with FS: 0.20438045144696315, test score: 0.24568065414816853\n","----- MI Scores -----\n","[(27, 0.10120120873518604), (28, 0.09847360720403904), (26, 0.09577781540695063), (36, 0.08906610807365067), (25, 0.07762163862077565), (41, 0.0760516883839209), (34, 0.0726303792532838), (37, 0.0712188639085985), (32, 0.06675514098465735), (53, 0.06650976736398012), (47, 0.0617214643918033), (35, 0.05961651410926053), (43, 0.05938726922623028), (50, 0.05700080768292917), (40, 0.05565976384110034), (4, 0.05507008163723792), (39, 0.05453475502056454), (46, 0.05414155706317305), (2, 0.05228997151473636), (1, 0.051161520648532806), (45, 0.05043518149134133), (44, 0.05019073547089066), (30, 0.049590967857862565), (48, 0.04947666583509019), (29, 0.04899865670986281), (0, 0.04897551676888965), (51, 0.046955254929749904), (33, 0.045121307270243466), (38, 0.042488940360242394), (31, 0.042033873307388614), (11, 0.04056034234666896), (3, 0.04034787810715557), (54, 0.04010550383549827), (7, 0.039595285502935826), (49, 0.039381757877798206), (24, 0.0385144101244638), (6, 0.036987478678081706), (8, 0.035883379217022296), (5, 0.03396915159379253), (22, 0.03278791017063735), (10, 0.03169004062001849), (42, 0.029081581433145307), (15, 0.02886611601079409), (17, 0.027742012348708666), (21, 0.02549595943796735), (20, 0.025201858245687183), (18, 0.02495649365908097), (52, 0.02191937869882306), (16, 0.018637124981036583), (19, 0.013535169575084233), (12, 0.011152351149563996), (23, 0.00943613524882361), (13, 0.008644140313508906), (9, 0.006779517607379959), (14, -0.00181220901330698)]\n","Best MI score: 0.10120120873518604\n","Adding first best original feature: 27\n","CMI: 0.0024121834685421756\n","CMI: 0.005608213393878098\n","CMI: 0.007109824102917786\n","CMI: 0.0057754941013818395\n","CMI: 0.007991558444450958\n","Highest CMI score: 0.007991558444450958\n","Adding original feature: 47\n","CMI: 0.0001716175230303124\n","CMI: 0.0003082582011416646\n","CMI: 0.001778384968182667\n","CMI: 0.004476137923047227\n","CMI: 0.02049029182775075\n","CMI: 0.003222112619913148\n","CMI: 0.007005021675533157\n","CMI: 0.006656161448133663\n","Highest CMI score: 0.02049029182775075\n","Adding original feature: 36\n","CMI: 0.040489153261304256\n","CMI: 0.02852159181335115\n","CMI: 0.03162919902514014\n","CMI: 0.024488596746187807\n","CMI: 0.023730497139037937\n","CMI: 0.013853270757942404\n","CMI: 0.03216739318239531\n","CMI: 0.02628599129829806\n","CMI: 0.03308932782787491\n","CMI: 0.030493458764162734\n","CMI: 0.02750374934785549\n","CMI: 0.02511087708514137\n","CMI: 0.018831577809372085\n","CMI: 0.014451670458582228\n","CMI: 0.016271806202363126\n","CMI: 0.014142964588612222\n","CMI: 0.007933268055422299\n","CMI: 0.004967691204328328\n","CMI: 0.00990026202013708\n","CMI: 0.0007768185483225942\n","CMI: 0.00479419939907369\n","CMI: 0.01315100542451239\n","CMI: 0.006901277653218102\n","CMI: 0.012334761180588294\n","CMI: 0.008788638977065\n","CMI: 0.0021075405244702916\n","CMI: 0.01364365913394222\n","CMI: 0.0015119704706904324\n","CMI: 0.0009502405285688742\n","CMI: 0.013380590629281569\n","CMI: 0.006423518827058522\n","CMI: 0.012406285971431369\n","CMI: 0.008070803784731878\n","CMI: 0.01118841957872882\n","CMI: 0.00620107299635933\n","CMI: 0.007220850822290181\n","CMI: 0.005788208469640316\n","CMI: 0.005395347847871046\n","CMI: 0.01342201305896798\n","CMI: 0.0011169311278593774\n","CMI: 0.004540006307300032\n","Highest CMI score: 0.040489153261304256\n","Adding original feature: 0\n","CMI: 0.004657514709184962\n","CMI: 0.0003468819204679452\n","CMI: 0.005336676639188159\n","CMI: 0.0006291780858785345\n","Highest CMI score: 0.005336676639188159\n","Adding original feature: 37\n","CMI: 0.0036497586779469515\n","Highest CMI score: 0.0036497586779469515\n","Adding original feature: 28\n","CMI: 0.0018539914922586775\n","CMI: 0.0003924051637404502\n","Highest CMI score: 0.0018539914922586775\n","Adding original feature: 43\n","CMI: 0.00024430297948010993\n","CMI: 0.002911928375247591\n","Highest CMI score: 0.002911928375247591\n","Adding original feature: 46\n","Highest CMI score: -0.0004410045481477165\n","\n","[27, 47, 36, 0, 37, 28, 43, 46]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.3179348722097767, test score: 0.011243487646285466\n","Aggregate regression train score with FS: 0.214916687028894, test score: 0.15594998361054913\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.3179348722097767, test score: 0.011243487646285466\n","Aggregate regression train score with FS: 0.2077007340525414, test score: 0.14017159461154827\n","###### Binary Classification ######\n","Train accuracy logistic regression CMI:  0.717\n","Test accuracy logistic regression CMI:  0.737 \n","\n","Train accuracy logistic regression CMI best 5:  0.718\n","Test accuracy logistic regression CMI best 5:  0.732 \n","\n","Train accuracy logistic regression wrapper:  0.696\n","Test accuracy logistic regression wrapper:  0.763 \n","\n"]}],"source":["basins = ['Emiliani1', 'Emiliani2', 'Garda_Mincio']\n","\n","path_target = \"./csv/\"\n","path_features = './features_allvalues/'\n","destination_folder = './GenLinCFA/temp_prec/internal_ordering/'\n","#plots_folder = './GenLinCFA/for_plots/internal_ordering/'\n","\n","for basin in basins:\n","  selected_colnames_CMI5 = []\n","  print('####################' + basin + '####################')\n","  target_df_train, target_df_val, target_df_test, target_df_trainVal = prepare_target_binary('',max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01',\n","      path=path_target+basin+'.csv', window_size = 1)\n","  eps = 0.37\n","  actual_path = path_features+basin+'_aggreg.csv'\n","  output, aggregate_trainVal, aggregate_test = aggregate_unfolded_data(actual_path,['cyclostationary_mean_tg',\n","                                                                            'cyclostationary_mean_tg_1w',\n","                                                                            'cyclostationary_mean_tg_4w',\n","                                                                            'cyclostationary_mean_tg_8w',\n","                                                                            'cyclostationary_mean_tg_12w',\n","                                                                            'cyclostationary_mean_tg_16w',\n","                                                                            'cyclostationary_mean_tg_24w',\n","                                                                            'cyclostationary_mean_rr',\n","                                                                            'cyclostationary_mean_rr_1w',\n","                                                                            'cyclostationary_mean_rr_4w',\n","                                                                            'cyclostationary_mean_rr_8w',\n","                                                                            'cyclostationary_mean_rr_12w',\n","                                                                            'cyclostationary_mean_rr_16w',\n","                                                                            'cyclostationary_mean_rr_24w'\n","                                                                            ],\n","                                                                      target_df_trainVal, eps=eps,\n","                                                                      max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01')\n","\n","  #agg_trainVal_string = plots_folder + basin + \"_trainVal_aggreg\"\n","  #agg_test_string = plots_folder + basin + \"_test_aggreg\"\n","  #aggregate_trainVal.to_csv(agg_trainVal_string, index = False)\n","  #aggregate_test.to_csv(agg_test_string, index = False)\n","\n","  selected_colnames = FS_with_linearWrapper(aggregate_trainVal, target_df_train, target_df_val, min(50,aggregate_trainVal.shape[1]-1), 228)\n","\n","  print('\\nFull model and selected features with wrapper\\n')\n","  compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n","\n","  print('\\nFull model and best 5 selected features with wrapper\\n')\n","  compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames[0:5])\n","\n","  train_string = destination_folder + basin + '_genLinCFA_wrapper_best5_train.csv'\n","  val_string = destination_folder + basin + '_genLinCFA_wrapper_best5_val.csv'\n","  test_string = destination_folder + basin + '_genLinCFA_wrapper_best5_test.csv'\n","  X_train_wrapper = aggregate_trainVal.loc[:410,selected_colnames[0:5]]\n","  X_validation_wrapper = aggregate_trainVal.loc[411:,selected_colnames[0:5]]\n","  X_train_validation_wrapper = pd.concat([X_train_wrapper, X_validation_wrapper])\n","  X_test_wrapper = aggregate_test.loc[:,selected_colnames[0:5]]\n","  X_train_wrapper.to_csv(train_string, index=False)\n","  X_validation_wrapper.to_csv(val_string, index=False)\n","  X_test_wrapper.to_csv(test_string, index=False)\n","\n","  res = {\n","          \"delta\" : [],\n","          \"numSelected\" : [],\n","          \"selectedFeatures\" : []\n","      }\n","\n","  res['selectedFeatures'] = forwardFeatureSelection(10,np.array(aggregate_trainVal),\n","                                                    np.array(target_df_trainVal.mean_std),res,10,1)\n","\n","  selectedFeatures='selectedFeatures'\n","  print(f'\\n{res[selectedFeatures]}\\n')\n","\n","  selected_colnames = aggregate_trainVal.columns[res['selectedFeatures']]\n","\n","  print('\\nFull model and selected features with CMI\\n')\n","  compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n","\n","  print('\\nFull model and best 5 selected features with CMI\\n')\n","  compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames[0:5])\n","\n","  train_string = destination_folder + basin + '_genLinCFA_best5_CMI_train.csv'\n","  val_string = destination_folder + basin + '_genLinCFA_best5_CMI_val.csv'\n","  test_string = destination_folder + basin + '_genLinCFA_best5_CMI_test.csv'\n","\n","  X_train_CMI5 = aggregate_trainVal.loc[:410,selected_colnames[0:5]]\n","  X_validation_CMI5 = aggregate_trainVal.loc[411:,selected_colnames[0:5]]\n","  X_train_validation_CMI5 = pd.concat([X_train_CMI5, X_validation_CMI5])\n","  X_test_CMI5 = aggregate_test.loc[:,selected_colnames[0:5]]\n","\n","  selected_colnames_CMI5.append(aggregate_trainVal.loc[:,selected_colnames[0:5]].columns.values)\n","\n","  X_train_CMI5.to_csv(train_string, index=False)\n","  X_validation_CMI5.to_csv(val_string, index=False)\n","  X_test_CMI5.to_csv(test_string, index=False)\n","\n","  train_string = destination_folder + basin + '_genLinCFA_CMI_train.csv'\n","  val_string = destination_folder + basin + '_genLinCFA_CMI_val.csv'\n","  test_string = destination_folder + basin + '_genLinCFA_CMI_test.csv'\n","\n","  X_train_CMI = aggregate_trainVal.loc[:410,selected_colnames]\n","  X_validation_CMI = aggregate_trainVal.loc[411:,selected_colnames]\n","  X_train_validation_CMI = pd.concat([X_train_CMI, X_validation_CMI])\n","  X_test_CMI = aggregate_test.loc[:,selected_colnames]\n","\n","  X_train_CMI.to_csv(train_string, index=False)\n","  X_validation_CMI.to_csv(val_string, index=False)\n","  X_test_CMI.to_csv(test_string, index=False)\n","\n","  print('###### Binary Classification ######')\n","\n","  target_df_train = target_df_train.apply(lambda x: np.sign(x.mean_std), axis=1)\n","  target_df_val = target_df_val.apply(lambda x: np.sign(x.mean_std), axis=1)\n","  target_df_test = target_df_test.apply(lambda x: np.sign(x.mean_std), axis=1)\n","  target_df_trainVal = target_df_trainVal.apply(lambda x: np.sign(x.mean_std), axis=1)\n","\n","  log_regr = LogisticRegression(solver='lbfgs', random_state = 42)\n","\n","  # CMI\n","  log_regr.fit(X_train_validation_CMI, target_df_trainVal)\n","  print(\"Train accuracy logistic regression CMI: \", round(log_regr.score(X_train_validation_CMI, target_df_trainVal),3))\n","  print(\"Test accuracy logistic regression CMI: \", round(log_regr.score(X_test_CMI, target_df_test),3), \"\\n\")\n","\n","  # CMI best 5\n","  log_regr.fit(X_train_validation_CMI5, target_df_trainVal)\n","  print(\"Train accuracy logistic regression CMI best 5: \", round(log_regr.score(X_train_validation_CMI5, target_df_trainVal),3))\n","  print(\"Test accuracy logistic regression CMI best 5: \", round(log_regr.score(X_test_CMI5, target_df_test),3), \"\\n\")\n","\n","  # wrapper\n","  log_regr.fit(X_train_validation_wrapper, target_df_trainVal)\n","  print(\"Train accuracy logistic regression wrapper: \", round(log_regr.score(X_train_validation_wrapper, target_df_trainVal),3))\n","  print(\"Test accuracy logistic regression wrapper: \", round(log_regr.score(X_test_wrapper, target_df_test),3), \"\\n\")\n","\n","  #output_string = plots_folder + basin + '_aggregations.npy'\n","  #sel_col_string = plots_folder + basin + '_chosen_features.npy'\n","  #np.save(sel_col_string, selected_colnames_CMI5)\n","  #np.save(output_string, outputs)"],"id":"Dd_c8fjYuJ9h"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3461429,"status":"ok","timestamp":1690210062103,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"},"user_tz":-120},"id":"-0Byf2H5wzXe","outputId":"e9733d6f-452c-4bff-f4c6-9911dda77dfd"},"outputs":[{"output_type":"stream","name":"stdout","text":["####################Adda####################\n","target samples:            date      mean  median  year  week  mean_std\n","0    2001-01-05  0.039373    0.00  2001     1         0\n","1    2001-01-13  0.380618    0.43  2001     2         0\n","2    2001-01-21  0.341985    0.38  2001     3         0\n","3    2001-01-29  0.322044    0.35  2001     5         0\n","4    2001-02-06  0.354954    0.40  2001     6         0\n","..          ...       ...     ...   ...   ...       ...\n","406  2009-11-27  0.382706    0.40  2009    48         0\n","407  2009-12-05  0.409921    0.46  2009    49         0\n","408  2009-12-13  0.472087    0.53  2009    50         1\n","409  2009-12-21  0.324728    0.00  2009    52         0\n","410  2009-12-29  0.086512    0.00  2009    53         0\n","\n","[411 rows x 6 columns]\n"," target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n","Feature: cyclostationary_mean_tg\n","\n","Number of features: 92\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_1w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_4w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_8w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_tg_12w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_tg_16w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_tg_24w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr\n","\n","Number of features: 92\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_rr_1w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_4w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 8\n","\n","Feature: cyclostationary_mean_rr_8w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 15\n","\n","Feature: cyclostationary_mean_rr_12w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 10\n","\n","Feature: cyclostationary_mean_rr_16w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_rr_24w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 8\n","\n","\n","\n","selected columns: ['cyclostationary_mean_tg_1w_2', 'cyclostationary_mean_tg_4w_1', 'cyclostationary_mean_tg_4w_2', 'cyclostationary_mean_rr_4w_0', 'cyclostationary_mean_tg_8w_0', 'cyclostationary_mean_tg_1w_1', 'cyclostationary_mean_rr_24w_0', 'cyclostationary_mean_tg_8w_3', 'cyclostationary_mean_rr_24w_2', 'cyclostationary_mean_rr_4w_1', 'cyclostationary_mean_rr_4w_2', 'cyclostationary_mean_rr_24w_7', 'cyclostationary_mean_rr_1w_2', 'cyclostationary_mean_rr_8w_1', 'cyclostationary_mean_rr_16w_1', 'cyclostationary_mean_rr_8w_2'], \n","\n","validation score: 0.25419295533550834, \n","\n","number of selected features: 16\n","\n","Full model and selected features with wrapper\n","\n","Full aggregate regression train score: 0.2944190222970554, test score: -0.39811195035533586\n","Aggregate regression train score with FS: 0.1609399007182657, test score: 0.0579062244394517\n","\n","Full model and best 5 selected features with wrapper\n","\n","Full aggregate regression train score: 0.2944190222970554, test score: -0.39811195035533586\n","Aggregate regression train score with FS: 0.1440759008299486, test score: 0.12691405710657577\n","----- MI Scores -----\n","[(27, 0.07426394053968663), (28, 0.07064861805559879), (25, 0.06565546799993426), (0, 0.06341479218878367), (2, 0.06154924722054746), (40, 0.05510860013342701), (5, 0.05440200218511999), (1, 0.052295701741671315), (73, 0.045870559453819085), (13, 0.04579323938165829), (4, 0.045444831860808665), (75, 0.04535367294037398), (32, 0.039086985624180705), (3, 0.03650096311365742), (51, 0.03324540115322162), (58, 0.03275917614350123), (47, 0.032577077971148886), (56, 0.03084453721106745), (8, 0.030586261903864025), (64, 0.029611836862427774), (70, 0.0278595981612805), (30, 0.027764938391219938), (62, 0.02720404690290137), (35, 0.027189588143225814), (50, 0.026191401818913468), (49, 0.026002494184630114), (11, 0.025727701206068217), (29, 0.025516049769112304), (42, 0.023483649557416362), (59, 0.02335650617324098), (45, 0.02332618662134555), (57, 0.021451787817284945), (31, 0.020999521676169145), (61, 0.020663857674686176), (26, 0.02040861179732287), (12, 0.02028949015860065), (37, 0.020228344285874483), (34, 0.02021443888370932), (44, 0.019643425089019274), (41, 0.01963966321546049), (46, 0.018534812391315932), (36, 0.018520579030288857), (48, 0.017371321530923627), (68, 0.017209004411155988), (52, 0.016619201984015), (22, 0.015454867938594054), (18, 0.014914468037684805), (76, 0.013818848510319547), (54, 0.013415109005516285), (65, 0.013245503955702701), (60, 0.01270934222084833), (43, 0.012184060456771631), (15, 0.011836122999913939), (66, 0.01163139222608697), (16, 0.011571229176405162), (17, 0.010781106563733473), (14, 0.010647987721316315), (39, 0.010010675134999591), (71, 0.009549049764006053), (38, 0.008984038334623107), (6, 0.00887362630340825), (10, 0.008562180462303266), (74, 0.008419358279822648), (53, 0.0080311309911059), (7, 0.007804641996140892), (55, 0.0075468002363079136), (72, 0.006327896925066662), (63, 0.006084547625136577), (67, 0.005760536401420191), (20, 0.0048664149034964325), (23, 0.0038647986716313963), (24, 0.001825460653871919), (19, 0.00024254615223875844), (33, 0.00012455591369065681), (21, -6.77000813182088e-05), (9, -0.0012235647650569005), (69, -0.008506724931865599)]\n","Best MI score: 0.07426394053968663\n","Adding first best original feature: 27\n","CMI: 0.00110146852490417\n","Highest CMI score: 0.00110146852490417\n","Adding original feature: 4\n","CMI: 0.024179021953894056\n","CMI: 0.027885315293686777\n","CMI: 0.0043558223893157555\n","CMI: 0.017099389355395733\n","CMI: 0.014446933564411124\n","CMI: 0.0119267762260057\n","CMI: 0.003962478114350729\n","CMI: 0.007613461575034938\n","CMI: 0.008915608522389942\n","CMI: 0.0011632237060585776\n","CMI: 0.0015518168369192398\n","CMI: 0.008070416789498741\n","CMI: 0.015366476092236361\n","CMI: 0.009887183486721823\n","CMI: 5.496150763788232e-05\n","CMI: 0.0014737419675734664\n","CMI: 0.0008134820798345876\n","CMI: 0.011417982412920302\n","CMI: 0.01885508832474679\n","CMI: 0.010162153509656546\n","CMI: 0.007648186648775396\n","CMI: 0.0024221246781024053\n","CMI: 0.015125321466193234\n","CMI: 0.01869916877744493\n","CMI: 0.006998423850410662\n","CMI: 0.013897904479875559\n","CMI: 0.02482401190879685\n","CMI: 0.01472630266986677\n","CMI: 0.014843775422630559\n","CMI: 0.0010598234058027262\n","CMI: 0.018042981676934827\n","CMI: 0.022329151731552713\n","CMI: 0.019223546380822965\n","CMI: 0.02356751511944727\n","CMI: 0.014274148385525959\n","CMI: 0.01998478619647366\n","CMI: 0.014202887908341594\n","CMI: 0.012426444864373179\n","CMI: 0.018118590545125088\n","CMI: 0.011069352691879863\n","CMI: 0.014535011063198044\n","CMI: 0.021116721689810145\n","CMI: 0.009620030155823828\n","CMI: 0.012868801698609017\n","CMI: 0.010398425812355588\n","CMI: 0.026361391564840894\n","CMI: 0.020612120965950165\n","CMI: 0.020591873432789926\n","CMI: 0.01588104604946733\n","CMI: 0.013474646982820221\n","CMI: 0.020776898241602226\n","CMI: 0.015305715552680774\n","CMI: 0.011193931587658537\n","CMI: 0.01049925692633373\n","CMI: 0.0168597736523403\n","CMI: 0.016141072597388312\n","CMI: 0.019457070348213715\n","CMI: 0.02062777296568788\n","CMI: 0.0018198934585394733\n","CMI: 0.005774407349513552\n","CMI: 0.014668363083205876\n","CMI: 0.011359265963735335\n","CMI: 0.0048058687492288366\n","Highest CMI score: 0.027885315293686777\n","Adding original feature: 7\n","CMI: 0.007590401699762564\n","CMI: 0.013829243029108554\n","CMI: 0.014191125563979876\n","CMI: 0.007340714575368154\n","CMI: 0.011562955146779408\n","CMI: 0.005656787006049102\n","CMI: 0.00919085090787343\n","CMI: 0.013273836073897344\n","CMI: 0.012129024919944484\n","CMI: 0.007079489860839491\n","CMI: 0.0012443095344394361\n","CMI: 0.0164856433289661\n","CMI: 0.005468863649833497\n","CMI: 7.845581357177056e-05\n","CMI: 0.007683174626146191\n","CMI: 0.003950896599568168\n","CMI: 0.007511177346825826\n","CMI: 0.009855585039946782\n","CMI: 0.010740621155500577\n","CMI: 0.008634322187651242\n","CMI: 0.013099294771768799\n","CMI: 0.0023616183798273876\n","CMI: 0.003023857280282094\n","CMI: 0.011833168874100936\n","CMI: 0.0034397629824569897\n","CMI: 0.003454776003953844\n","CMI: 0.0037683091452113543\n","CMI: 0.014950324029549683\n","CMI: 0.020064035610312475\n","CMI: 0.010838688798935875\n","CMI: 0.005787488522363576\n","CMI: 0.018145001744268294\n","CMI: 0.005611286972077287\n","CMI: 0.004905161419502341\n","CMI: 0.013897148407249149\n","CMI: 0.013688347079393523\n","CMI: 0.010443858063000966\n","CMI: 0.011020181011675137\n","CMI: 0.009411599767594717\n","CMI: 0.014853177957392827\n","CMI: 0.020137539840591412\n","CMI: 0.01140475646494779\n","CMI: 0.004390906833796102\n","CMI: 0.004864210123866994\n","CMI: 0.0008272386136801285\n","CMI: 0.006128892150131127\n","CMI: 0.005136239252926528\n","CMI: 0.005077521832847209\n","CMI: 0.004064825265996885\n","CMI: 0.00639792309567469\n","CMI: 0.0069492811001179156\n","CMI: 0.0004610759759796773\n","CMI: 0.005168032978233081\n","CMI: 0.016772921198837498\n","Highest CMI score: 0.020137539840591412\n","Adding original feature: 54\n","CMI: 0.006442909897942481\n","CMI: 0.006634947476856626\n","CMI: 0.006963010557805058\n","CMI: 0.0013229468931584276\n","CMI: 0.00023977945808409395\n","CMI: 0.004399363442594659\n","CMI: 0.0022756200217268624\n","CMI: 0.0010378090445414961\n","Highest CMI score: 0.006963010557805058\n","Adding original feature: 2\n","CMI: 0.002986347381077531\n","CMI: 0.0030305866519636515\n","CMI: 0.0012982243696831874\n","CMI: 0.006093929154828037\n","CMI: 0.00899045282278546\n","CMI: 0.004535919839473629\n","CMI: 0.0001268955512774006\n","CMI: 0.008521716699102733\n","CMI: 0.0011483919949813182\n","CMI: 0.004354161521533201\n","CMI: 0.0002479222691079419\n","CMI: 0.004143452942227482\n","CMI: 0.00596500491869964\n","CMI: 0.0015554443856538591\n","CMI: 0.0033092607249292083\n","CMI: 0.007073127180425798\n","CMI: 0.0010185897376340236\n","CMI: 0.0019494699599391097\n","CMI: 9.9785840270733e-05\n","CMI: 0.0026562373872819067\n","CMI: 0.002316280544844729\n","CMI: 0.0010383883585131648\n","CMI: 0.002471717602019724\n","CMI: 0.0011185178516622818\n","CMI: 0.001175444799431935\n","CMI: 0.0023213366553427317\n","Highest CMI score: 0.00899045282278546\n","Adding original feature: 11\n","CMI: 0.0017350957960594604\n","CMI: 0.003938576493812296\n","CMI: 0.0009827340563951792\n","CMI: 0.00034362867554074694\n","Highest CMI score: 0.003938576493812296\n","Adding original feature: 13\n","CMI: 0.0032512088074911905\n","CMI: 0.0020246028059884014\n","CMI: 0.000977717942207884\n","CMI: 0.006583248667479447\n","CMI: 0.0019101546205865239\n","CMI: 0.003548888772634179\n","CMI: 0.00016768669513286816\n","CMI: 0.0005726710537726776\n","CMI: 0.0013166126613197993\n","Highest CMI score: 0.006583248667479447\n","Adding original feature: 8\n","CMI: 0.0061185163597458625\n","CMI: 0.0007093461832830827\n","Highest CMI score: 0.0061185163597458625\n","Adding original feature: 3\n","CMI: 0.0024298266928625134\n","Highest CMI score: 0.0024298266928625134\n","Adding original feature: 6\n","Highest CMI score: -0.002561594600789807\n","\n","[27, 4, 7, 54, 2, 11, 13, 8, 3, 6]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.2944190222970554, test score: -0.39811195035533586\n","Aggregate regression train score with FS: 0.17092121236548963, test score: 0.1495767874922883\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.2944190222970554, test score: -0.39811195035533586\n","Aggregate regression train score with FS: 0.14682003272450028, test score: 0.14193754127186964\n","###### Binary Classification ######\n","Train accuracy logistic regression CMI:  0.671\n","Test accuracy logistic regression CMI:  0.684 \n","\n","Train accuracy logistic regression CMI best 5:  0.649\n","Test accuracy logistic regression CMI best 5:  0.671 \n","\n","Train accuracy logistic regression wrapper:  0.664\n","Test accuracy logistic regression wrapper:  0.654 \n","\n","####################Lambro_Olona####################\n","target samples:            date      mean  median  year  week  mean_std\n","0    2001-01-05  0.369625    0.45  2001     1         0\n","1    2001-01-13  0.429563    0.43  2001     2         0\n","2    2001-01-21  0.470784    0.48  2001     3         1\n","3    2001-01-29  0.370358    0.37  2001     5         0\n","4    2001-02-06  0.372263    0.37  2001     6         0\n","..          ...       ...     ...   ...   ...       ...\n","406  2009-11-27  0.402059    0.40  2009    48         0\n","407  2009-12-05  0.389658    0.39  2009    49         0\n","408  2009-12-13  0.545184    0.56  2009    50         1\n","409  2009-12-21  0.447916    0.55  2009    52         1\n","410  2009-12-29  0.277300    0.32  2009    53         0\n","\n","[411 rows x 6 columns]\n"," target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n","Feature: cyclostationary_mean_tg\n","\n","Number of features: 55\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_1w\n","\n","Number of features: 55\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_tg_4w\n","\n","Number of features: 55\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_8w\n","\n","Number of features: 55\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_12w\n","\n","Number of features: 55\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_16w\n","\n","Number of features: 55\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_24w\n","\n","Number of features: 55\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr\n","\n","Number of features: 55\n","\n","Number of aggregated features: 10\n","\n","Feature: cyclostationary_mean_rr_1w\n","\n","Number of features: 55\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_rr_4w\n","\n","Number of features: 55\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_8w\n","\n","Number of features: 55\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_rr_12w\n","\n","Number of features: 55\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_16w\n","\n","Number of features: 55\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_24w\n","\n","Number of features: 55\n","\n","Number of aggregated features: 4\n","\n","\n","\n","selected columns: ['cyclostationary_mean_tg_1w_2', 'cyclostationary_mean_rr_1w_3', 'cyclostationary_mean_tg_4w_0', 'cyclostationary_mean_tg_4w_1', 'cyclostationary_mean_tg_1w_1', 'cyclostationary_mean_tg_12w_1', 'cyclostationary_mean_tg_1w_3', 'cyclostationary_mean_tg_8w_0', 'cyclostationary_mean_tg_16w_0', 'cyclostationary_mean_tg_24w_2', 'cyclostationary_mean_rr_24w_0', 'cyclostationary_mean_rr_1w_0', 'cyclostationary_mean_tg_12w_0', 'cyclostationary_mean_rr_4w_2', 'cyclostationary_mean_rr_8w_0', 'cyclostationary_mean_rr_5', 'cyclostationary_mean_rr_9', 'cyclostationary_mean_rr_1w_1', 'cyclostationary_mean_rr_8w_2', 'cyclostationary_mean_rr_1w_2', 'cyclostationary_mean_rr_16w_0', 'cyclostationary_mean_tg_8w_1', 'cyclostationary_mean_rr_24w_3', 'cyclostationary_mean_rr_24w_1', 'cyclostationary_mean_tg_8w_2', 'cyclostationary_mean_tg_16w_1', 'cyclostationary_mean_tg_12w_2', 'cyclostationary_mean_rr_1w_4', 'cyclostationary_mean_rr_2', 'cyclostationary_mean_rr_24w_2'], \n","\n","validation score: 0.321774158767128, \n","\n","number of selected features: 30\n","\n","Full model and selected features with wrapper\n","\n","Full aggregate regression train score: 0.2937000928866733, test score: -0.08405552446287201\n","Aggregate regression train score with FS: 0.24286307126868134, test score: 0.07123323871515497\n","\n","Full model and best 5 selected features with wrapper\n","\n","Full aggregate regression train score: 0.2937000928866733, test score: -0.08405552446287201\n","Aggregate regression train score with FS: 0.20230402434800432, test score: 0.15742143625187954\n","----- MI Scores -----\n","[(2, 0.10311237594322889), (30, 0.08694055862422356), (6, 0.07787449780492389), (5, 0.0720556273975069), (4, 0.06271940274776804), (1, 0.05969851375994328), (0, 0.058615519682940466), (26, 0.05704881315212915), (24, 0.05615915813598699), (21, 0.05393686673739326), (3, 0.05380567359210118), (38, 0.05345305452513542), (27, 0.05267297026538407), (29, 0.051144208554795664), (23, 0.05055095121462613), (53, 0.047185591023697696), (35, 0.04693658472524337), (31, 0.0465436240413615), (46, 0.04651849360064755), (28, 0.04501512298905702), (25, 0.044926568876657684), (33, 0.04277868513284016), (18, 0.042162102301100596), (32, 0.040918301260301944), (40, 0.04008731139316782), (42, 0.038113383674919864), (36, 0.03710392870689569), (52, 0.03628263881103373), (8, 0.033303195927396965), (45, 0.03258875160090288), (49, 0.03248373283764401), (47, 0.031679257584269385), (44, 0.03157562444939338), (22, 0.030455639118998203), (12, 0.029520357273300466), (51, 0.028767735547091812), (34, 0.027182443723691697), (48, 0.02512263853446698), (43, 0.02509895039439464), (37, 0.024380766265139128), (16, 0.023407327887554345), (50, 0.02306568405963686), (15, 0.021334021556279722), (41, 0.02130448756816888), (39, 0.02038992648341171), (9, 0.018202566293218255), (20, 0.014095838920602384), (17, 0.010732624300741215), (7, 0.010018841740640603), (10, 0.0022736893816504558), (11, 0.002195746901207309), (14, -0.0033559326713758692), (13, -0.00432838043126416), (19, -0.008838850181010214)]\n","Best MI score: 0.10311237594322889\n","Adding first best original feature: 2\n","CMI: 0.002013487496476049\n","CMI: 0.00011502134019777954\n","CMI: 0.012223931793437143\n","CMI: 0.014982764992296782\n","CMI: 0.017386600913983113\n","CMI: 0.008207904870655564\n","CMI: 0.006139409310800981\n","CMI: 0.010084556910882447\n","CMI: 0.02248063122534877\n","CMI: 0.006927584044450846\n","CMI: 0.023243671269399413\n","CMI: 0.03595715955716364\n","CMI: 0.013780004332222179\n","CMI: 0.034886205067099385\n","CMI: 0.00967630580886622\n","CMI: 0.0038534831493395733\n","CMI: 0.008314456313505414\n","CMI: 0.014944163277839387\n","CMI: 0.018547292630679307\n","CMI: 0.007007556987304736\n","CMI: 0.02457582978159184\n","CMI: 0.0011202128695848024\n","CMI: 0.004387842624327801\n","CMI: 0.02887898063392616\n","CMI: 0.012111723038186209\n","CMI: 0.01631957387584583\n","CMI: 0.02538525156117688\n","Highest CMI score: 0.03595715955716364\n","Adding original feature: 36\n","CMI: 0.007362389770202399\n","CMI: 0.0017608783024769536\n","CMI: 0.006080544377404906\n","CMI: 0.00422167911591137\n","CMI: 0.010647910688400403\n","CMI: 0.0009188974756970392\n","CMI: 0.004120795630297547\n","CMI: 0.0033043122566122907\n","CMI: 0.003575726137253321\n","CMI: 0.0010244928673134035\n","CMI: 0.004002298439620189\n","CMI: 0.007125215714473693\n","CMI: 0.001161424487114593\n","CMI: 0.01215855021261747\n","CMI: 0.01883223767964734\n","CMI: 0.010469420061577472\n","CMI: 0.021412086719137857\n","CMI: 0.005604803082300103\n","CMI: 0.014033641821741466\n","CMI: 0.0038732571877992394\n","CMI: 0.00363638485705986\n","CMI: 0.016951529287763195\n","CMI: 0.0029021050261523185\n","CMI: 0.0023347636976822628\n","CMI: 0.014314015756665799\n","CMI: 0.007699433010078194\n","Highest CMI score: 0.021412086719137857\n","Adding original feature: 43\n","CMI: 0.003914885939832968\n","CMI: 0.0005279697039194675\n","CMI: 0.0035989416108800076\n","CMI: 0.005609967117480769\n","CMI: 0.0016226592139165774\n","CMI: 0.005179319843684249\n","CMI: 0.007968505002537984\n","CMI: 0.012905553928318714\n","CMI: 0.018779950696649977\n","CMI: 0.0011768657265124605\n","CMI: 0.017106601450045278\n","CMI: 0.0051918079246902615\n","CMI: 0.004282507314682549\n","CMI: 0.005539225971022577\n","CMI: 0.0035097504052587214\n","CMI: 0.003581404003191624\n","CMI: 0.0012615864379158515\n","CMI: 0.008428293330236425\n","CMI: 0.004989720919502366\n","CMI: 0.00655031701171932\n","CMI: 0.015534496314542512\n","CMI: 0.021347006207390634\n","Highest CMI score: 0.021347006207390634\n","Adding original feature: 48\n","Highest CMI score: -0.005662207079336262\n","\n","[2, 36, 43, 48]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.2937000928866733, test score: -0.08405552446287201\n","Aggregate regression train score with FS: 0.18341356406592668, test score: 0.18708064011810854\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.2937000928866733, test score: -0.08405552446287201\n","Aggregate regression train score with FS: 0.18341356406592668, test score: 0.18708064011810854\n","###### Binary Classification ######\n","Train accuracy logistic regression CMI:  0.69\n","Test accuracy logistic regression CMI:  0.693 \n","\n","Train accuracy logistic regression CMI best 5:  0.69\n","Test accuracy logistic regression CMI best 5:  0.693 \n","\n","Train accuracy logistic regression wrapper:  0.684\n","Test accuracy logistic regression wrapper:  0.667 \n","\n","####################Ticino####################\n","target samples:            date      mean  median  year  week  mean_std\n","0    2001-01-05  0.264043    0.00  2001     1         0\n","1    2001-01-13  0.354618    0.39  2001     2         0\n","2    2001-01-21  0.427990    0.47  2001     3         1\n","3    2001-01-29  0.339495    0.35  2001     5         0\n","4    2001-02-06  0.324134    0.34  2001     6         0\n","..          ...       ...     ...   ...   ...       ...\n","406  2009-11-27  0.332713    0.35  2009    48         0\n","407  2009-12-05  0.370253    0.40  2009    49         0\n","408  2009-12-13  0.517201    0.57  2009    50         1\n","409  2009-12-21  0.353636    0.45  2009    52         0\n","410  2009-12-29  0.261079    0.00  2009    53         0\n","\n","[411 rows x 6 columns]\n"," target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n","Feature: cyclostationary_mean_tg\n","\n","Number of features: 92\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_tg_1w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_4w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_8w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_tg_12w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 6\n","\n","Feature: cyclostationary_mean_tg_16w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 6\n","\n","Feature: cyclostationary_mean_tg_24w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_rr\n","\n","Number of features: 92\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_1w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_rr_4w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_8w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_12w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_16w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_rr_24w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 8\n","\n","\n","\n","selected columns: ['cyclostationary_mean_tg_1w_1', 'cyclostationary_mean_rr_24w_2', 'cyclostationary_mean_tg_4w_0', 'cyclostationary_mean_tg_8w_1', 'cyclostationary_mean_tg_8w_0', 'cyclostationary_mean_tg_12w_5', 'cyclostationary_mean_tg_16w_5'], \n","\n","validation score: 0.19946316786618112, \n","\n","number of selected features: 7\n","\n","Full model and selected features with wrapper\n","\n","Full aggregate regression train score: 0.25190662010996845, test score: -1.0688355356833177\n","Aggregate regression train score with FS: 0.1348639215226458, test score: 0.1925767665788306\n","\n","Full model and best 5 selected features with wrapper\n","\n","Full aggregate regression train score: 0.25190662010996845, test score: -1.0688355356833177\n","Aggregate regression train score with FS: 0.13317966594737796, test score: 0.19193133272207696\n","----- MI Scores -----\n","[(1, 0.07619436851140222), (2, 0.06906896931200217), (6, 0.06852056802960067), (4, 0.06660455307361404), (3, 0.06088807942810209), (5, 0.05824310484330773), (0, 0.05522297523167413), (47, 0.054295157155189296), (9, 0.04657151971199622), (18, 0.04529046878737617), (17, 0.044000308482937525), (7, 0.0427709935947236), (35, 0.04202737177106451), (46, 0.04190789459252143), (36, 0.041818526764121115), (34, 0.038827653046544175), (38, 0.03455350135826824), (50, 0.03243262035231984), (41, 0.032002396320943746), (10, 0.030877908471773914), (57, 0.03015489995525939), (52, 0.029096993004445224), (16, 0.0287590274396903), (39, 0.0261434086834642), (51, 0.024707407342511152), (40, 0.024333897539835253), (53, 0.023793929211500614), (12, 0.023326683582522715), (49, 0.022787553903856228), (37, 0.02253515338620965), (58, 0.02185642353004048), (55, 0.021201045477643902), (24, 0.019683674697863963), (28, 0.019401056144409373), (59, 0.019311135066338005), (48, 0.018781723381094045), (42, 0.017045569016774356), (13, 0.016828879265827934), (14, 0.015451812824777122), (15, 0.015049707608688807), (21, 0.014917791231975104), (31, 0.014679133520503993), (26, 0.013936453922602928), (8, 0.01384838851225433), (22, 0.012832363091462967), (45, 0.012682459160006404), (23, 0.012641765001735271), (33, 0.012114109290322368), (25, 0.010825060037588714), (29, 0.009671990696651625), (56, 0.008418213346720669), (54, 0.008294665702062911), (43, 0.008282081820316934), (32, 0.0071560037046853875), (11, 0.007091986352875644), (19, 0.004483391034735937), (30, 0.003241891707893248), (27, 0.0012844786940756298), (60, 0.0010400024002533803), (44, 0.0003457871689164371), (20, -0.007011565293243101)]\n","Best MI score: 0.07619436851140222\n","Adding first best original feature: 1\n","CMI: 0.00784749952241108\n","CMI: 0.013624819098180724\n","CMI: 0.0024070241981222484\n","CMI: 0.01096956243228181\n","CMI: 0.00204696544792983\n","CMI: 0.003927566539001892\n","CMI: 0.001407862232270643\n","CMI: 0.0009120306323470301\n","CMI: 0.0030631925499413487\n","CMI: 0.002637055565816629\n","CMI: 0.018046360346559306\n","CMI: 0.0014556706061218394\n","CMI: 0.013220938789374567\n","CMI: 0.013776169253487042\n","CMI: 0.01304102841356708\n","CMI: 0.0027315178852214544\n","CMI: 0.017453087007609086\n","CMI: 0.007181260541283985\n","CMI: 0.023217874671034144\n","CMI: 0.010756090479374522\n","CMI: 0.020791192106256393\n","CMI: 0.000614257354135353\n","CMI: 0.011231497019055625\n","CMI: 0.035245872115852867\n","CMI: 0.02743734432527563\n","CMI: 0.031068821063846244\n","CMI: 0.005821446583474527\n","CMI: 0.003199939712128397\n","CMI: 0.012861191773261352\n","CMI: 0.004954082178859065\n","CMI: 0.012409545659913701\n","CMI: 0.02216986812888805\n","CMI: 0.001491152662443443\n","CMI: 0.012320150079380296\n","CMI: 0.014394868486600584\n","CMI: 0.015710572519931423\n","CMI: 0.008449297219921423\n","CMI: 0.005359375209194328\n","CMI: 0.0015980427824700966\n","CMI: 0.004729961990848297\n","CMI: 0.0016334117291859074\n","Highest CMI score: 0.035245872115852867\n","Adding original feature: 41\n","CMI: 0.003693252489567228\n","CMI: 0.0048038450262221505\n","CMI: 0.004736229343969209\n","CMI: 0.0001241487355630455\n","CMI: 0.001473555853213418\n","CMI: 0.0011685882672663045\n","CMI: 0.015113793634872155\n","CMI: 0.0036636215759606183\n","Highest CMI score: 0.015113793634872155\n","Adding original feature: 39\n","CMI: 0.009355893362717471\n","CMI: 0.005877675760361939\n","CMI: 0.006906111017951938\n","CMI: 0.0005169234036183634\n","CMI: 0.001963778801625765\n","CMI: 0.00981480778183108\n","CMI: 0.004467597228877823\n","CMI: 0.01542047217959358\n","CMI: 0.011865661261097504\n","CMI: 0.008722557772385897\n","CMI: 0.0009222302905255719\n","CMI: 0.0013078224740834254\n","Highest CMI score: 0.01542047217959358\n","Adding original feature: 48\n","CMI: 0.0026871752517424463\n","CMI: 0.002145762844831728\n","CMI: 0.004046044079835581\n","CMI: 0.0004985656781826553\n","CMI: 0.002529191465826225\n","CMI: 0.0013954612682396672\n","CMI: 0.0019298531260283636\n","CMI: 0.0008239312578782465\n","CMI: 0.008282616475169757\n","CMI: 0.007011754764043893\n","CMI: 0.010866677039828354\n","CMI: 0.0017711126657534992\n","CMI: 0.0002362453476817128\n","CMI: 0.00039917126641947354\n","Highest CMI score: 0.010866677039828354\n","Adding original feature: 50\n","CMI: 0.0054587043345442066\n","CMI: 0.0029561697460439296\n","CMI: 0.0025415825594409525\n","CMI: 0.0040278212830853755\n","CMI: 0.000271183871973002\n","Highest CMI score: 0.0054587043345442066\n","Adding original feature: 0\n","CMI: 0.003572828807856865\n","Highest CMI score: 0.003572828807856865\n","Adding original feature: 2\n","Highest CMI score: -0.00025891312091749774\n","\n","[1, 41, 39, 48, 50, 0, 2]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.25190662010996845, test score: -1.0688355356833177\n","Aggregate regression train score with FS: 0.1499244671091835, test score: 0.10696475093570834\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.25190662010996845, test score: -1.0688355356833177\n","Aggregate regression train score with FS: 0.1490439776611815, test score: 0.10086857140775107\n","###### Binary Classification ######\n","Train accuracy logistic regression CMI:  0.682\n","Test accuracy logistic regression CMI:  0.627 \n","\n","Train accuracy logistic regression CMI best 5:  0.679\n","Test accuracy logistic regression CMI best 5:  0.645 \n","\n","Train accuracy logistic regression wrapper:  0.64\n","Test accuracy logistic regression wrapper:  0.693 \n","\n","####################Oglio_Iseo####################\n","target samples:            date      mean  median  year  week  mean_std\n","0    2001-01-05  0.243674    0.26  2001     1         0\n","1    2001-01-13  0.424116    0.44  2001     2         0\n","2    2001-01-21  0.393786    0.39  2001     3         0\n","3    2001-01-29  0.314939    0.31  2001     5         0\n","4    2001-02-06  0.464902    0.48  2001     6         1\n","..          ...       ...     ...   ...   ...       ...\n","406  2009-11-27  0.465734    0.48  2009    48         1\n","407  2009-12-05  0.447390    0.47  2009    49         1\n","408  2009-12-13  0.556760    0.59  2009    50         1\n","409  2009-12-21  0.307880    0.00  2009    52         0\n","410  2009-12-29  0.034211    0.00  2009    53         0\n","\n","[411 rows x 6 columns]\n"," target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n","Feature: cyclostationary_mean_tg\n","\n","Number of features: 74\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_tg_1w\n","\n","Number of features: 74\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_tg_4w\n","\n","Number of features: 74\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_tg_8w\n","\n","Number of features: 74\n","\n","Number of aggregated features: 6\n","\n","Feature: cyclostationary_mean_tg_12w\n","\n","Number of features: 74\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_tg_16w\n","\n","Number of features: 74\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_tg_24w\n","\n","Number of features: 74\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr\n","\n","Number of features: 74\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_rr_1w\n","\n","Number of features: 74\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_4w\n","\n","Number of features: 74\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_rr_8w\n","\n","Number of features: 74\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_12w\n","\n","Number of features: 74\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_rr_16w\n","\n","Number of features: 74\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_rr_24w\n","\n","Number of features: 74\n","\n","Number of aggregated features: 3\n","\n","\n","\n","selected columns: ['cyclostationary_mean_tg_3', 'cyclostationary_mean_rr_4w_2', 'cyclostationary_mean_rr_16w_0', 'cyclostationary_mean_rr_8w_2', 'cyclostationary_mean_rr_1w_0', 'cyclostationary_mean_tg_16w_0', 'cyclostationary_mean_tg_24w_1', 'cyclostationary_mean_tg_24w_0', 'cyclostationary_mean_rr_16w_1', 'cyclostationary_mean_rr_12w_0', 'cyclostationary_mean_rr_12w_3', 'cyclostationary_mean_tg_1', 'cyclostationary_mean_rr_8w_1'], \n","\n","validation score: 0.27002838409520724, \n","\n","number of selected features: 13\n","\n","Full model and selected features with wrapper\n","\n","Full aggregate regression train score: 0.2823734754834698, test score: 0.0013652487432773697\n","Aggregate regression train score with FS: 0.1855105742372234, test score: 0.1521569282931482\n","\n","Full model and best 5 selected features with wrapper\n","\n","Full aggregate regression train score: 0.2823734754834698, test score: 0.0013652487432773697\n","Aggregate regression train score with FS: 0.1747698865420727, test score: 0.16318212071197047\n","----- MI Scores -----\n","[(35, 0.07266497221224631), (7, 0.06615760823187876), (3, 0.06568966212252096), (8, 0.06384561451534691), (1, 0.059837919207322246), (34, 0.05516701885465093), (2, 0.054194147706084196), (6, 0.05316938841480197), (33, 0.05188683317206092), (42, 0.05102256986157405), (0, 0.05038893484353032), (38, 0.0502229974523168), (30, 0.04780120789141581), (5, 0.04622827544494628), (40, 0.04508211551080975), (36, 0.04159780446439129), (9, 0.040986056148187996), (41, 0.03961272489309636), (4, 0.03918759230332868), (39, 0.03729185253073095), (24, 0.03722712311744739), (31, 0.035770550084311264), (11, 0.033037162005768485), (32, 0.03268846003151463), (22, 0.031017172889424172), (12, 0.030810121632042577), (37, 0.026720121249542005), (45, 0.026496469444884787), (46, 0.024982155243445634), (13, 0.024922595674756905), (49, 0.023335142398340007), (10, 0.022941433175940145), (17, 0.022547904723786396), (56, 0.021867964151221792), (18, 0.021239915455380284), (27, 0.021186874053272537), (53, 0.020726845524726454), (15, 0.020108930352637118), (44, 0.019998338566571308), (48, 0.018850919705713926), (43, 0.01789038139075917), (54, 0.01779064829322368), (57, 0.017061945803314417), (50, 0.015829477313208728), (21, 0.014333768190424102), (16, 0.012204813013872957), (23, 0.011854501593770255), (19, 0.011526702628185462), (25, 0.011263322315825358), (28, 0.00927545270063909), (14, 0.009265213312162771), (47, 0.008824703184477731), (26, 0.007772738037063627), (52, 0.002868876816380014), (29, 0.001949206939100508), (20, -0.0006906301575006161), (51, -0.008845519408810386), (55, -0.009153097178596354)]\n","Best MI score: 0.07266497221224631\n","Adding first best original feature: 35\n","CMI: 0.013208739738871003\n","CMI: 0.0034278416537357193\n","CMI: 0.008132553382395616\n","CMI: 0.016038351090150116\n","CMI: 0.008742505027631728\n","CMI: 0.004887440062089313\n","CMI: 0.005286079170286326\n","Highest CMI score: 0.016038351090150116\n","Adding original feature: 3\n","CMI: 0.00016767144390061883\n","CMI: 0.0014278413097622983\n","CMI: 0.005796685935339482\n","CMI: 0.008043439849722764\n","CMI: 0.013325781768727576\n","CMI: 0.0015527015770253894\n","CMI: 0.0005614034555537634\n","CMI: 0.022683885305643872\n","CMI: 0.025294146851021035\n","CMI: 0.007253521924919404\n","CMI: 0.011240657396009865\n","CMI: 0.00629291764404688\n","CMI: 0.017518268267665518\n","CMI: 0.006716585429390409\n","CMI: 0.011536589366889186\n","CMI: 0.017736830735114145\n","CMI: 0.015318100407343493\n","CMI: 0.009543390852298092\n","CMI: 0.0015545601715618723\n","CMI: 0.01348135170075275\n","CMI: 0.024453260794891962\n","CMI: 0.0027444014184881543\n","CMI: 0.00833101938921936\n","CMI: 0.010700149392712216\n","CMI: 0.008831589643017362\n","CMI: 0.007995011162808291\n","CMI: 0.023929241761756398\n","CMI: 0.03363324875366312\n","CMI: 0.02447798642226949\n","CMI: 0.005433592694048667\n","CMI: 0.0022122152547232876\n","CMI: 0.00396220956221939\n","CMI: 0.0032048723171742427\n","CMI: 0.005620812336174466\n","CMI: 0.005146082512092351\n","CMI: 0.005680724779830421\n","CMI: 0.005569276090266431\n","CMI: 0.014608868657533913\n","CMI: 0.0031388940911528107\n","Highest CMI score: 0.03363324875366312\n","Adding original feature: 41\n","CMI: 0.010997153821097672\n","CMI: 0.004292626767096158\n","CMI: 0.001904382836113383\n","CMI: 0.0005701387813767667\n","CMI: 0.0003622864197883602\n","CMI: 0.0019100549110343257\n","CMI: 0.0036209826525863964\n","CMI: 0.002428468456120672\n","CMI: 0.0006825496284218607\n","CMI: 0.00044755527847842314\n","CMI: 0.0002660772905336839\n","CMI: 0.008062196382835868\n","Highest CMI score: 0.010997153821097672\n","Adding original feature: 0\n","CMI: 0.0018585827794809773\n","CMI: 0.004358148397266948\n","CMI: 0.004148225886856732\n","CMI: 0.006409718478225163\n","CMI: 5.4480134721340834e-05\n","Highest CMI score: 0.006409718478225163\n","Adding original feature: 23\n","CMI: 0.000948623918951591\n","CMI: 0.0035503119164002894\n","CMI: 0.000846542235959924\n","CMI: 0.010246616780951623\n","CMI: 0.008187892735718127\n","CMI: 0.0021665897323839556\n","CMI: 0.0009441639837614868\n","CMI: 0.005839208820063335\n","CMI: 0.0032668192076464597\n","CMI: 0.0002734936139110189\n","CMI: 0.003515948528210411\n","CMI: 0.001086519966185917\n","CMI: 0.0020746962367916844\n","Highest CMI score: 0.010246616780951623\n","Adding original feature: 19\n","CMI: 0.005136213491951036\n","CMI: 0.0016045314685357026\n","CMI: 0.0019259127745774318\n","CMI: 0.0027459671513677952\n","CMI: 0.012180466593337103\n","CMI: 0.005760271218664376\n","CMI: 0.00497014627577147\n","CMI: 0.006908415568300352\n","CMI: 0.00966600023544481\n","CMI: 0.008243622287799957\n","CMI: 0.0018116530631072936\n","CMI: 0.0017952865191959433\n","CMI: 0.000268808905614204\n","CMI: 0.0005357526654131695\n","Highest CMI score: 0.012180466593337103\n","Adding original feature: 20\n","CMI: 0.00019274525257670372\n","CMI: 0.0006941865966804406\n","Highest CMI score: 0.0006941865966804406\n","Adding original feature: 22\n","CMI: 0.00038721304782848853\n","Highest CMI score: 0.00038721304782848853\n","Adding original feature: 21\n","CMI: 0.00126972982795176\n","CMI: 0.00037882525372306963\n","Highest CMI score: 0.00126972982795176\n","Adding original feature: 40\n","Highest CMI score: -0.0005697092058949138\n","\n","[35, 3, 41, 0, 23, 19, 20, 22, 21, 40]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.2823734754834698, test score: 0.0013652487432773697\n","Aggregate regression train score with FS: 0.16401401106717928, test score: 0.1854923680298719\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.2823734754834698, test score: 0.0013652487432773697\n","Aggregate regression train score with FS: 0.16030886229459207, test score: 0.18089697974528562\n","###### Binary Classification ######\n","Train accuracy logistic regression CMI:  0.678\n","Test accuracy logistic regression CMI:  0.724 \n","\n","Train accuracy logistic regression CMI best 5:  0.678\n","Test accuracy logistic regression CMI best 5:  0.711 \n","\n","Train accuracy logistic regression wrapper:  0.693\n","Test accuracy logistic regression wrapper:  0.684 \n","\n"]}],"source":["basins = ['Adda', 'Lambro_Olona', 'Ticino', 'Oglio_Iseo']\n","\n","path_target = \"./csv/\"\n","path_features = './features_allvalues/'\n","destination_folder = './GenLinCFA/temp_prec/internal_ordering/'\n","#plots_folder = './GenLinCFA/for_plots/internal_ordering/'\n","\n","for basin in basins:\n","  selected_colnames_CMI5 = []\n","  outputs = []\n","  print('####################' + basin + '####################')\n","  target_df_train, target_df_val, target_df_test, target_df_trainVal = prepare_target_binary('',max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01',\n","      path=path_target+basin+'.csv', window_size = 1)\n","  eps = 0.37\n","  actual_path = path_features+basin+'_aggreg.csv'\n","  output, aggregate_trainVal, aggregate_test = aggregate_unfolded_data(actual_path,['cyclostationary_mean_tg',\n","                                                                            'cyclostationary_mean_tg_1w',\n","                                                                            'cyclostationary_mean_tg_4w',\n","                                                                            'cyclostationary_mean_tg_8w',\n","                                                                            'cyclostationary_mean_tg_12w',\n","                                                                            'cyclostationary_mean_tg_16w',\n","                                                                            'cyclostationary_mean_tg_24w',\n","                                                                            'cyclostationary_mean_rr',\n","                                                                            'cyclostationary_mean_rr_1w',\n","                                                                            'cyclostationary_mean_rr_4w',\n","                                                                            'cyclostationary_mean_rr_8w',\n","                                                                            'cyclostationary_mean_rr_12w',\n","                                                                            'cyclostationary_mean_rr_16w',\n","                                                                            'cyclostationary_mean_rr_24w'\n","                                                                            ],\n","                                                                      target_df_trainVal, eps=eps,\n","                                                                      max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01')\n","\n","  #agg_trainVal_string = plots_folder + basin + \"_trainVal_aggreg\"\n","  #agg_test_string = plots_folder + basin + \"_test_aggreg\"\n","  #aggregate_trainVal.to_csv(agg_trainVal_string, index = False)\n","  #aggregate_test.to_csv(agg_test_string, index = False)\n","\n","  selected_colnames = FS_with_linearWrapper(aggregate_trainVal, target_df_train, target_df_val, min(50,aggregate_trainVal.shape[1]-1), 228)\n","\n","  print('\\nFull model and selected features with wrapper\\n')\n","  compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n","\n","  print('\\nFull model and best 5 selected features with wrapper\\n')\n","  compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames[0:5])\n","\n","  train_string = destination_folder + basin + '_genLinCFA_wrapper_best5_train.csv'\n","  val_string = destination_folder + basin + '_genLinCFA_wrapper_best5_val.csv'\n","  test_string = destination_folder + basin + '_genLinCFA_wrapper_best5_test.csv'\n","  X_train_wrapper = aggregate_trainVal.loc[:410,selected_colnames[0:5]]\n","  X_validation_wrapper = aggregate_trainVal.loc[411:,selected_colnames[0:5]]\n","  X_train_validation_wrapper = pd.concat([X_train_wrapper, X_validation_wrapper])\n","  X_test_wrapper = aggregate_test.loc[:,selected_colnames[0:5]]\n","  X_train_wrapper.to_csv(train_string, index=False)\n","  X_validation_wrapper.to_csv(val_string, index=False)\n","  X_test_wrapper.to_csv(test_string, index=False)\n","\n","  res = {\n","          \"delta\" : [],\n","          \"numSelected\" : [],\n","          \"selectedFeatures\" : []\n","      }\n","\n","  res['selectedFeatures'] = forwardFeatureSelection(10,np.array(aggregate_trainVal),\n","                                                    np.array(target_df_trainVal.mean_std),res,10,1)\n","\n","  selectedFeatures='selectedFeatures'\n","  print(f'\\n{res[selectedFeatures]}\\n')\n","\n","  selected_colnames = aggregate_trainVal.columns[res['selectedFeatures']]\n","\n","  print('\\nFull model and selected features with CMI\\n')\n","  compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n","\n","  print('\\nFull model and best 5 selected features with CMI\\n')\n","  compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames[0:5])\n","\n","  train_string = destination_folder + basin + '_genLinCFA_best5_CMI_train.csv'\n","  val_string = destination_folder + basin + '_genLinCFA_best5_CMI_val.csv'\n","  test_string = destination_folder + basin + '_genLinCFA_best5_CMI_test.csv'\n","\n","  X_train_CMI5 = aggregate_trainVal.loc[:410,selected_colnames[0:5]]\n","  X_validation_CMI5 = aggregate_trainVal.loc[411:,selected_colnames[0:5]]\n","  X_train_validation_CMI5 = pd.concat([X_train_CMI5, X_validation_CMI5])\n","  X_test_CMI5 = aggregate_test.loc[:,selected_colnames[0:5]]\n","\n","  selected_colnames_CMI5.append(aggregate_trainVal.loc[:,selected_colnames[0:5]].columns.values)\n","\n","  X_train_CMI5.to_csv(train_string, index=False)\n","  X_validation_CMI5.to_csv(val_string, index=False)\n","  X_test_CMI5.to_csv(test_string, index=False)\n","\n","  train_string = destination_folder + basin + '_genLinCFA_CMI_train.csv'\n","  val_string = destination_folder + basin + '_genLinCFA_CMI_val.csv'\n","  test_string = destination_folder + basin + '_genLinCFA_CMI_test.csv'\n","\n","  X_train_CMI = aggregate_trainVal.loc[:410,selected_colnames]\n","  X_validation_CMI = aggregate_trainVal.loc[411:,selected_colnames]\n","  X_train_validation_CMI = pd.concat([X_train_CMI, X_validation_CMI])\n","  X_test_CMI = aggregate_test.loc[:,selected_colnames]\n","\n","  X_train_CMI.to_csv(train_string, index=False)\n","  X_validation_CMI.to_csv(val_string, index=False)\n","  X_test_CMI.to_csv(test_string, index=False)\n","\n","  print('###### Binary Classification ######')\n","\n","  target_df_train = target_df_train.apply(lambda x: np.sign(x.mean_std), axis=1)\n","  target_df_val = target_df_val.apply(lambda x: np.sign(x.mean_std), axis=1)\n","  target_df_test = target_df_test.apply(lambda x: np.sign(x.mean_std), axis=1)\n","  target_df_trainVal = target_df_trainVal.apply(lambda x: np.sign(x.mean_std), axis=1)\n","\n","  log_regr = LogisticRegression(solver='lbfgs', random_state = 42)\n","\n","  # CMI\n","  log_regr.fit(X_train_validation_CMI, target_df_trainVal)\n","  print(\"Train accuracy logistic regression CMI: \", round(log_regr.score(X_train_validation_CMI, target_df_trainVal),3))\n","  print(\"Test accuracy logistic regression CMI: \", round(log_regr.score(X_test_CMI, target_df_test),3), \"\\n\")\n","\n","  # CMI best 5\n","  log_regr.fit(X_train_validation_CMI5, target_df_trainVal)\n","  print(\"Train accuracy logistic regression CMI best 5: \", round(log_regr.score(X_train_validation_CMI5, target_df_trainVal),3))\n","  print(\"Test accuracy logistic regression CMI best 5: \", round(log_regr.score(X_test_CMI5, target_df_test),3), \"\\n\")\n","\n","  # wrapper\n","  log_regr.fit(X_train_validation_wrapper, target_df_trainVal)\n","  print(\"Train accuracy logistic regression wrapper: \", round(log_regr.score(X_train_validation_wrapper, target_df_trainVal),3))\n","  print(\"Test accuracy logistic regression wrapper: \", round(log_regr.score(X_test_wrapper, target_df_test),3), \"\\n\")\n","\n","  #output_string = plots_folder + basin + '_aggregations.npy'\n","  #sel_col_string = plots_folder + basin + '_chosen_features.npy'\n","  #np.save(sel_col_string, selected_colnames_CMI5)\n","  #np.save(output_string, outputs)"],"id":"-0Byf2H5wzXe"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3450506,"status":"ok","timestamp":1690213512586,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"},"user_tz":-120},"id":"FtNcJZiLG1ZG","outputId":"8c19c6a6-15d0-4960-b515-787b91afdbd5"},"outputs":[{"output_type":"stream","name":"stdout","text":["####################Dora####################\n","target samples:            date      mean  median  year  week  mean_std\n","0    2001-01-05  0.010645    0.00  2001     1         0\n","1    2001-01-13  0.206769    0.00  2001     2         0\n","2    2001-01-21  0.267313    0.00  2001     3         0\n","3    2001-01-29  0.240836    0.20  2001     5         0\n","4    2001-02-06  0.193417    0.15  2001     6         0\n","..          ...       ...     ...   ...   ...       ...\n","406  2009-11-27  0.230073    0.25  2009    48         0\n","407  2009-12-05  0.243632    0.24  2009    49         0\n","408  2009-12-13  0.251111    0.00  2009    50         0\n","409  2009-12-21  0.099246    0.00  2009    52         0\n","410  2009-12-29  0.064990    0.00  2009    53         0\n","\n","[411 rows x 6 columns]\n"," target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n","Feature: cyclostationary_mean_tg\n","\n","Number of features: 44\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_tg_1w\n","\n","Number of features: 44\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_tg_4w\n","\n","Number of features: 44\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_tg_8w\n","\n","Number of features: 44\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_tg_12w\n","\n","Number of features: 44\n","\n","Number of aggregated features: 6\n","\n","Feature: cyclostationary_mean_tg_16w\n","\n","Number of features: 44\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_tg_24w\n","\n","Number of features: 44\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr\n","\n","Number of features: 44\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_1w\n","\n","Number of features: 44\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_4w\n","\n","Number of features: 44\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_8w\n","\n","Number of features: 44\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_12w\n","\n","Number of features: 44\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_16w\n","\n","Number of features: 44\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_24w\n","\n","Number of features: 44\n","\n","Number of aggregated features: 3\n","\n","\n","\n","selected columns: ['cyclostationary_mean_tg_1w_4', 'cyclostationary_mean_rr_12w_2', 'cyclostationary_mean_tg_4w_0', 'cyclostationary_mean_rr_1w_2', 'cyclostationary_mean_rr_0', 'cyclostationary_mean_tg_8w_1', 'cyclostationary_mean_tg_12w_0', 'cyclostationary_mean_rr_4w_0', 'cyclostationary_mean_rr_4w_1', 'cyclostationary_mean_rr_24w_1', 'cyclostationary_mean_rr_12w_0', 'cyclostationary_mean_rr_24w_0'], \n","\n","validation score: 0.12940287518142135, \n","\n","number of selected features: 12\n","\n","Full model and selected features with wrapper\n","\n","Full aggregate regression train score: 0.17077707478849613, test score: -0.8325671659563418\n","Aggregate regression train score with FS: 0.09806007727667831, test score: -0.4389781356073186\n","\n","Full model and best 5 selected features with wrapper\n","\n","Full aggregate regression train score: 0.17077707478849613, test score: -0.8325671659563418\n","Aggregate regression train score with FS: 0.08246687866339308, test score: -0.24996600110709344\n","----- MI Scores -----\n","[(0, 0.06788901569201063), (32, 0.04990915725225257), (38, 0.04817953164084569), (6, 0.0474929156334804), (46, 0.04576572935672787), (4, 0.04526697694913859), (5, 0.044978063622270754), (34, 0.044638409652222495), (51, 0.040013009531334486), (40, 0.03902777761495003), (54, 0.032156004226739365), (48, 0.0320336185683358), (49, 0.031418432072367455), (15, 0.029549681293401773), (10, 0.02954834667827062), (42, 0.028777286998935715), (16, 0.028326394246474734), (1, 0.027913058818284833), (47, 0.027878165786693037), (20, 0.02776512268163746), (52, 0.02370900879087618), (8, 0.023521509017530574), (43, 0.023049780840283415), (2, 0.02226106711458348), (3, 0.021965825768889394), (7, 0.021017040655454865), (45, 0.02100425696465217), (50, 0.020904796017072607), (53, 0.020793035403324684), (9, 0.01921761243595824), (37, 0.018821569318340888), (19, 0.018717958288988874), (35, 0.016706360989220445), (12, 0.01646519847260676), (17, 0.01605334293115042), (33, 0.015981056288371636), (18, 0.014653816570735457), (21, 0.011991242128002124), (13, 0.010934726206818943), (26, 0.010585074919523076), (14, 0.009601308832296694), (44, 0.008700893323262172), (23, 0.00786912914848228), (31, 0.007098720689944789), (36, 0.007033078187994072), (24, 0.006382847771990269), (27, 0.006237484405082845), (11, 0.0040804060085533845), (28, 0.0008615961910830387), (25, -2.310112055216437e-05), (41, -0.0001162422686535043), (29, -0.0005926272163619646), (39, -0.004126398699118372), (22, -0.008919001229446466), (30, -0.019058200333735925)]\n","Best MI score: 0.06788901569201063\n","Adding first best original feature: 0\n","CMI: 0.023373301475508812\n","CMI: 0.02127264369941384\n","CMI: 0.018003481394186477\n","CMI: 0.019829115475863135\n","CMI: 0.0004642351171555009\n","CMI: 0.0033959508825463086\n","CMI: 0.017926289416153124\n","CMI: 0.023014812418053518\n","CMI: 0.012995132524688077\n","CMI: 0.0004428845050116065\n","Highest CMI score: 0.023373301475508812\n","Adding original feature: 1\n","CMI: 0.005531197587777759\n","CMI: 0.01688028001750483\n","CMI: 0.016523105897842685\n","CMI: 0.00580761982091639\n","CMI: 0.008876773253412296\n","CMI: 0.0032106057162413493\n","Highest CMI score: 0.01688028001750483\n","Adding original feature: 32\n","CMI: 0.000121699254441901\n","CMI: 0.006503456624103399\n","CMI: 0.0018631857441533395\n","CMI: 0.00938138588712055\n","CMI: 0.0019865411707077896\n","CMI: 0.024407721167496746\n","CMI: 0.008292396919059308\n","CMI: 0.023069014946157942\n","CMI: 0.004897810894706825\n","CMI: 0.008323872199973797\n","CMI: 0.005386853865655558\n","Highest CMI score: 0.024407721167496746\n","Adding original feature: 46\n","CMI: 0.00485702789224679\n","CMI: 0.0026016776794251795\n","CMI: 0.0017800330947388976\n","CMI: 0.007518636080403013\n","CMI: 0.01021392293928991\n","CMI: 0.014969941463779057\n","CMI: 0.013319500362376502\n","CMI: 0.012144032239326863\n","CMI: 0.017397983253601285\n","CMI: 0.0167358338048659\n","CMI: 0.012131864303927625\n","CMI: 0.018307355496227307\n","CMI: 0.014485527523433128\n","CMI: 0.01987107203120203\n","CMI: 0.015103309345446514\n","CMI: 0.018242840362511226\n","CMI: 0.001306617198185006\n","CMI: 0.0050930925191336185\n","CMI: 0.0013822997001363135\n","CMI: 0.0013008900808724189\n","CMI: 0.014136919204868148\n","CMI: 0.0070444067396700505\n","Highest CMI score: 0.01987107203120203\n","Adding original feature: 23\n","Highest CMI score: -1.2275538813277809e-05\n","\n","[0, 1, 32, 46, 23]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.17077707478849613, test score: -0.8325671659563418\n","Aggregate regression train score with FS: 0.07206893764887923, test score: -0.06235575213666267\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.17077707478849613, test score: -0.8325671659563418\n","Aggregate regression train score with FS: 0.07206893764887923, test score: -0.06235575213666267\n","###### Binary Classification ######\n","Train accuracy logistic regression CMI:  0.617\n","Test accuracy logistic regression CMI:  0.548 \n","\n","Train accuracy logistic regression CMI best 5:  0.617\n","Test accuracy logistic regression CMI best 5:  0.548 \n","\n","Train accuracy logistic regression wrapper:  0.606\n","Test accuracy logistic regression wrapper:  0.561 \n","\n","####################Piemonte_Sud####################\n","target samples:            date      mean  median  year  week  mean_std\n","0    2001-01-05  0.278060    0.09  2001     1         0\n","1    2001-01-13  0.445159    0.48  2001     2         1\n","2    2001-01-21  0.488982    0.52  2001     3         1\n","3    2001-01-29  0.362487    0.37  2001     5         0\n","4    2001-02-06  0.430732    0.45  2001     6         0\n","..          ...       ...     ...   ...   ...       ...\n","406  2009-11-27  0.430379    0.44  2009    48         0\n","407  2009-12-05  0.419919    0.43  2009    49         0\n","408  2009-12-13  0.526648    0.55  2009    50         1\n","409  2009-12-21  0.457440    0.61  2009    52         1\n","410  2009-12-29  0.301938    0.38  2009    53         0\n","\n","[411 rows x 6 columns]\n"," target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n","Feature: cyclostationary_mean_tg\n","\n","Number of features: 176\n","\n","Number of aggregated features: 9\n","\n","Feature: cyclostationary_mean_tg_1w\n","\n","Number of features: 176\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_4w\n","\n","Number of features: 176\n","\n","Number of aggregated features: 11\n","\n","Feature: cyclostationary_mean_tg_8w\n","\n","Number of features: 176\n","\n","Number of aggregated features: 6\n","\n","Feature: cyclostationary_mean_tg_12w\n","\n","Number of features: 176\n","\n","Number of aggregated features: 7\n","\n","Feature: cyclostationary_mean_tg_16w\n","\n","Number of features: 176\n","\n","Number of aggregated features: 7\n","\n","Feature: cyclostationary_mean_tg_24w\n","\n","Number of features: 176\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_rr\n","\n","Number of features: 176\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_1w\n","\n","Number of features: 176\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_rr_4w\n","\n","Number of features: 176\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_rr_8w\n","\n","Number of features: 176\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_rr_12w\n","\n","Number of features: 176\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_16w\n","\n","Number of features: 176\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_rr_24w\n","\n","Number of features: 176\n","\n","Number of aggregated features: 10\n","\n","\n","\n","selected columns: ['cyclostationary_mean_rr_24w_9', 'cyclostationary_mean_tg_1w_0', 'cyclostationary_mean_tg_4w_0', 'cyclostationary_mean_rr_1w_1', 'cyclostationary_mean_rr_8w_3', 'cyclostationary_mean_rr_8w_1', 'cyclostationary_mean_tg_4w_4', 'cyclostationary_mean_rr_8w_4', 'cyclostationary_mean_tg_1w_1', 'cyclostationary_mean_tg_4w_3', 'cyclostationary_mean_tg_4w_6', 'cyclostationary_mean_tg_4w_5', 'cyclostationary_mean_tg_8w_3', 'cyclostationary_mean_tg_8w_0', 'cyclostationary_mean_rr_0', 'cyclostationary_mean_tg_4w_2', 'cyclostationary_mean_rr_4w_0', 'cyclostationary_mean_tg_12w_2', 'cyclostationary_mean_rr_1w_2', 'cyclostationary_mean_rr_2', 'cyclostationary_mean_rr_1', 'cyclostationary_mean_tg_8w_2', 'cyclostationary_mean_tg_12w_0', 'cyclostationary_mean_tg_4w_7', 'cyclostationary_mean_tg_4w_8', 'cyclostationary_mean_tg_12w_1', 'cyclostationary_mean_tg_4w_9', 'cyclostationary_mean_rr_24w_0', 'cyclostationary_mean_rr_24w_2', 'cyclostationary_mean_rr_4w_4'], \n","\n","validation score: 0.16798765100752566, \n","\n","number of selected features: 30\n","\n","Full model and selected features with wrapper\n","\n","Full aggregate regression train score: 0.33775566063096285, test score: -0.024973353796928555\n","Aggregate regression train score with FS: 0.1774356211367284, test score: 0.10774587701600535\n","\n","Full model and best 5 selected features with wrapper\n","\n","Full aggregate regression train score: 0.33775566063096285, test score: -0.024973353796928555\n","Aggregate regression train score with FS: 0.1275591874656118, test score: 0.14139515454534912\n","----- MI Scores -----\n","[(73, 0.08200850856608967), (60, 0.08154690581958109), (64, 0.08023291869911069), (67, 0.0629908421980839), (4, 0.06212115034027274), (75, 0.061744893447564855), (66, 0.060099051123127654), (0, 0.05956983162587209), (65, 0.05894765826363212), (70, 0.057934959502322275), (1, 0.057602292145096025), (7, 0.05464496889320559), (74, 0.05431411137050112), (53, 0.05367877612604142), (77, 0.05319540609544913), (59, 0.050732545342190835), (69, 0.050465614323542025), (76, 0.04916063735953679), (8, 0.04681517469213911), (63, 0.04617336978819419), (80, 0.04543222563947015), (78, 0.04533310176074148), (6, 0.045052269889246904), (72, 0.04477870197126896), (9, 0.044769537363075436), (79, 0.04355459180251414), (2, 0.04343289365811805), (3, 0.0417868472724813), (10, 0.041773617585347846), (68, 0.03887120823527717), (71, 0.037631651462370214), (50, 0.036966773820623695), (54, 0.03634273304006359), (24, 0.03502389592772381), (46, 0.0347736205648071), (44, 0.03460667316162251), (19, 0.03427092270734588), (16, 0.03348380724484556), (55, 0.03320277797598067), (15, 0.03239698796363692), (5, 0.032051172621270434), (43, 0.03180796687499343), (58, 0.030782641465693376), (62, 0.03006359949514149), (61, 0.02980769319572087), (11, 0.02838688411780525), (35, 0.027349240770115694), (18, 0.026311389289508137), (48, 0.02610067202470866), (34, 0.025828952248301024), (52, 0.024446883185316477), (28, 0.024348715025695498), (21, 0.02232512958228674), (57, 0.020025867145619183), (36, 0.018619517261129467), (41, 0.018377963109651525), (56, 0.017263718767361245), (45, 0.016777702848484313), (23, 0.015651398778694942), (14, 0.01523262046234758), (13, 0.015074381202541402), (51, 0.013401794249678295), (31, 0.011131724639962518), (17, 0.010399524382419865), (47, 0.010040067145444122), (27, 0.00980393028895221), (49, 0.008946433298220462), (33, 0.007574430769672911), (20, 0.007156607895982135), (30, 0.006391187205660978), (38, 0.005526506549551533), (26, 0.004050619326110653), (40, 0.0030768024456542297), (25, 0.003003511969135791), (22, -0.0013640603849972674), (42, -0.0016723470124216284), (12, -0.0018746298011408358), (32, -0.004719378225670808), (29, -0.005267540018887923), (39, -0.010559100607039443), (37, -0.021472999624162267)]\n","Best MI score: 0.08200850856608967\n","Adding first best original feature: 73\n","CMI: 0.012075486062356228\n","CMI: 0.006760793206960269\n","CMI: 0.020340108597431156\n","CMI: 0.01728042198760106\n","CMI: 0.020026250946691554\n","CMI: 0.018402778477970713\n","CMI: 0.014069264469830478\n","CMI: 0.022153245280966127\n","CMI: 0.01638239625515929\n","CMI: 0.018409304687934003\n","CMI: 0.002021290916385199\n","CMI: 0.004386666947164511\n","CMI: 0.0024468115142960295\n","CMI: 0.002628841466481638\n","CMI: 0.007908632607036892\n","CMI: 0.016361521069507473\n","Highest CMI score: 0.022153245280966127\n","Adding original feature: 8\n","CMI: 0.0008801323184481347\n","CMI: 0.00782671744653754\n","CMI: 0.01614920001818662\n","CMI: 0.007997505924532425\n","CMI: 0.009058989964003741\n","CMI: 0.014454932052933009\n","CMI: 0.013032754174572198\n","CMI: 0.0042819349797973\n","CMI: 0.010556433189257655\n","CMI: 0.012639284505254325\n","CMI: 0.007959128270797172\n","CMI: 0.011002232591357838\n","CMI: 0.023816038134976528\n","CMI: 0.030896675647073726\n","CMI: 0.018067682157519555\n","CMI: 0.015316322522739845\n","CMI: 0.021009894695009898\n","CMI: 0.01865570246836079\n","CMI: 0.03183776786897248\n","CMI: 0.010916179025468264\n","CMI: 0.029029581343793867\n","CMI: 0.025215224290211377\n","CMI: 0.029430771552990634\n","CMI: 0.02238196400347371\n","CMI: 0.02539806279052713\n","CMI: 0.02602746756163858\n","CMI: 0.017748422833551894\n","CMI: 0.020028898849143884\n","CMI: 0.018277879767027605\n","CMI: 0.024573039257620263\n","CMI: 0.011735356612289666\n","CMI: 0.018926567719399254\n","CMI: 0.014965249382213788\n","CMI: 0.017231556929256292\n","CMI: 0.007644336994052356\n","CMI: 0.00814903129051843\n","CMI: 2.7183570712088767e-05\n","CMI: 0.0049163510724074405\n","CMI: 0.011863658604320648\n","CMI: 0.006981029605797676\n","CMI: 0.004300701104824833\n","CMI: 0.005986785405450862\n","CMI: 0.0045921563380392355\n","CMI: 0.043449466841484305\n","CMI: 0.033444371654725205\n","CMI: 0.023635620899161894\n","CMI: 0.022823849558581896\n","CMI: 0.022392333996007693\n","CMI: 0.04053338634869218\n","CMI: 0.012252393795759889\n","CMI: 0.029521394630436196\n","CMI: 0.0288146681330579\n","CMI: 0.006969159122046917\n","CMI: 0.016594680610940285\n","CMI: 0.013438698020505208\n","CMI: 0.021638005294008125\n","CMI: 0.009417246915841823\n","CMI: 0.0038050535328647828\n","CMI: 0.0018559063673357218\n","CMI: 0.013004902952777897\n","CMI: 0.011939934636636146\n","Highest CMI score: 0.043449466841484305\n","Adding original feature: 59\n","CMI: 0.0011400915051872074\n","CMI: 0.0003154282828415067\n","CMI: 0.004754386813195094\n","CMI: 0.007325076849410417\n","CMI: 0.002387113951995784\n","CMI: 0.0018858120241410647\n","CMI: 0.009237120623498213\n","CMI: 0.0037723585390602166\n","CMI: 0.018689755491245047\n","CMI: 0.014765434417278706\n","CMI: 0.013836404843150713\n","CMI: 0.01664181386031474\n","CMI: 0.014411145618624777\n","CMI: 0.012129248835797607\n","CMI: 0.015840888258225633\n","CMI: 0.013589775607177057\n","CMI: 0.00896684241897619\n","CMI: 0.007237852627298036\n","CMI: 0.019402451538592713\n","CMI: 0.010807480920473483\n","CMI: 0.013844429523238472\n","CMI: 0.010248039521043167\n","CMI: 0.018509648658429273\n","CMI: 0.008855707063176343\n","CMI: 0.019519129375032918\n","CMI: 0.012499613755159122\n","CMI: 0.020033103116910478\n","CMI: 0.0116300831361425\n","CMI: 0.012277217741564483\n","CMI: 0.019653350318304535\n","CMI: 0.023433731157368298\n","CMI: 0.023322080017717073\n","CMI: 0.008106566580432545\n","CMI: 0.027418432502370554\n","CMI: 0.016274601772969688\n","CMI: 0.016779293446848892\n","CMI: 0.019808193616333875\n","CMI: 0.03437179025336956\n","CMI: 0.025162918977339105\n","CMI: 0.006518215700727525\n","CMI: 0.0017823992833650992\n","CMI: 0.010668905723488192\n","CMI: 0.004399618588109444\n","CMI: 0.002519814966199796\n","CMI: 0.016962576617680775\n","CMI: 0.00659706353742151\n","CMI: 0.012675135364707157\n","CMI: 0.015645430501416036\n","CMI: 0.017478971503398277\n","CMI: 0.013216839125945429\n","CMI: 0.0066932685101993294\n","CMI: 0.003156463816491817\n","CMI: 0.0013021102952602281\n","Highest CMI score: 0.03437179025336956\n","Adding original feature: 45\n","CMI: 0.004541818018083815\n","CMI: 0.007673324591061931\n","CMI: 0.004835567300481208\n","CMI: 0.009542639192355706\n","CMI: 0.007670443847293651\n","CMI: 0.004516526768942819\n","CMI: 0.005514831789518032\n","CMI: 0.005900091876553992\n","CMI: 0.007447587408068335\n","CMI: 0.0007817228803531917\n","CMI: 0.009295796033983839\n","CMI: 0.004447486143203644\n","CMI: 0.0002562307111496631\n","CMI: 0.0009132141168545771\n","CMI: 0.002484013705556315\n","CMI: 0.0005707738884683233\n","CMI: 0.0011684263637112557\n","CMI: 0.0007007062305627865\n","CMI: 0.006245192365959468\n","CMI: 0.02079342488864777\n","CMI: 0.001963264362819128\n","CMI: 0.01194673874702365\n","CMI: 0.016364873855601536\n","CMI: 0.018369515840167994\n","CMI: 0.007544881615004884\n","CMI: 0.007891050295559338\n","CMI: 0.002317834349447906\n","CMI: 0.003150586053267984\n","CMI: 0.00418637594953436\n","CMI: 0.008311931527839767\n","CMI: 0.006449010067476557\n","CMI: 0.004479181699532209\n","Highest CMI score: 0.02079342488864777\n","Adding original feature: 64\n","CMI: 0.0005749853844007891\n","CMI: 0.0020061094065343954\n","CMI: 0.006119693740591153\n","CMI: 0.002284346572869328\n","CMI: 0.0028587710614200457\n","CMI: 0.0016540328195075449\n","CMI: 0.0019392531999006812\n","CMI: 0.0003208041075559165\n","CMI: 0.0020348587728615253\n","CMI: 0.0030652228731546105\n","CMI: 0.0004532624163469945\n","CMI: 0.00284978173979622\n","CMI: 0.002963060145650759\n","CMI: 0.0013704810438830983\n","CMI: 0.0017024068017879868\n","CMI: 0.0022827159820924536\n","Highest CMI score: 0.006119693740591153\n","Adding original feature: 4\n","CMI: 0.0005664937662011038\n","CMI: 0.0026086473307339875\n","Highest CMI score: 0.0026086473307339875\n","Adding original feature: 75\n","Highest CMI score: -0.0015475213751219297\n","\n","[73, 8, 59, 45, 64, 4, 75]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.33775566063096285, test score: -0.024973353796928555\n","Aggregate regression train score with FS: 0.14556601368978217, test score: 0.0560392510781651\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.33775566063096285, test score: -0.024973353796928555\n","Aggregate regression train score with FS: 0.14523038597415527, test score: 0.049872688327812775\n","###### Binary Classification ######\n","Train accuracy logistic regression CMI:  0.667\n","Test accuracy logistic regression CMI:  0.636 \n","\n","Train accuracy logistic regression CMI best 5:  0.673\n","Test accuracy logistic regression CMI best 5:  0.632 \n","\n","Train accuracy logistic regression wrapper:  0.649\n","Test accuracy logistic regression wrapper:  0.68 \n","\n","####################Piemonte_Nord####################\n","target samples:            date      mean  median  year  week  mean_std\n","0    2001-01-05  0.278983    0.00  2001     1         0\n","1    2001-01-13  0.494910    0.51  2001     2         1\n","2    2001-01-21  0.496092    0.51  2001     3         1\n","3    2001-01-29  0.427992    0.43  2001     5         0\n","4    2001-02-06  0.400512    0.41  2001     6         0\n","..          ...       ...     ...   ...   ...       ...\n","406  2009-11-27  0.363952    0.37  2009    48         0\n","407  2009-12-05  0.400487    0.40  2009    49         0\n","408  2009-12-13  0.506771    0.52  2009    50         1\n","409  2009-12-21  0.387530    0.53  2009    52         0\n","410  2009-12-29  0.279894    0.27  2009    53         0\n","\n","[411 rows x 6 columns]\n"," target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n","Feature: cyclostationary_mean_tg\n","\n","Number of features: 89\n","\n","Number of aggregated features: 9\n","\n","Feature: cyclostationary_mean_tg_1w\n","\n","Number of features: 89\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_4w\n","\n","Number of features: 89\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_tg_8w\n","\n","Number of features: 89\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_tg_12w\n","\n","Number of features: 89\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_tg_16w\n","\n","Number of features: 89\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_tg_24w\n","\n","Number of features: 89\n","\n","Number of aggregated features: 10\n","\n","Feature: cyclostationary_mean_rr\n","\n","Number of features: 89\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_1w\n","\n","Number of features: 89\n","\n","Number of aggregated features: 9\n","\n","Feature: cyclostationary_mean_rr_4w\n","\n","Number of features: 89\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_8w\n","\n","Number of features: 89\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_rr_12w\n","\n","Number of features: 89\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_16w\n","\n","Number of features: 89\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_24w\n","\n","Number of features: 89\n","\n","Number of aggregated features: 3\n","\n","\n","\n","selected columns: ['cyclostationary_mean_tg_1w_2', 'cyclostationary_mean_rr_1w_3', 'cyclostationary_mean_rr_24w_0', 'cyclostationary_mean_rr_1w_0', 'cyclostationary_mean_tg_8w_0', 'cyclostationary_mean_tg_12w_1', 'cyclostationary_mean_tg_12w_2', 'cyclostationary_mean_tg_8w_4', 'cyclostationary_mean_tg_1w_1', 'cyclostationary_mean_tg_16w_1', 'cyclostationary_mean_tg_4w_2', 'cyclostationary_mean_tg_4w_4', 'cyclostationary_mean_tg_16w_2', 'cyclostationary_mean_tg_16w_4', 'cyclostationary_mean_tg_16w_0', 'cyclostationary_mean_rr_1w_5', 'cyclostationary_mean_rr_1w_8', 'cyclostationary_mean_tg_16w_3', 'cyclostationary_mean_rr_1w_4', 'cyclostationary_mean_rr_1w_6', 'cyclostationary_mean_rr_1w_2', 'cyclostationary_mean_rr_4w_1', 'cyclostationary_mean_rr_8w_0', 'cyclostationary_mean_rr_16w_0', 'cyclostationary_mean_rr_1w_1', 'cyclostationary_mean_rr_0', 'cyclostationary_mean_rr_2'], \n","\n","validation score: 0.24657132543862614, \n","\n","number of selected features: 27\n","\n","Full model and selected features with wrapper\n","\n","Full aggregate regression train score: 0.2819959740677105, test score: -0.08014058572383065\n","Aggregate regression train score with FS: 0.2060172844768745, test score: 0.002395221100925604\n","\n","Full model and best 5 selected features with wrapper\n","\n","Full aggregate regression train score: 0.2819959740677105, test score: -0.08014058572383065\n","Aggregate regression train score with FS: 0.15562896151895877, test score: 0.17438153915285837\n","----- MI Scores -----\n","[(4, 0.0856030770608996), (3, 0.07778501965167361), (5, 0.07319672077776422), (6, 0.07262113696636864), (47, 0.06793234317478616), (10, 0.06741274674314679), (42, 0.06597280298995706), (48, 0.0629846428854022), (0, 0.06009994985107116), (46, 0.05967618772387418), (50, 0.05898180227829219), (61, 0.057756303290887594), (2, 0.057626666410608075), (8, 0.05725671760119304), (1, 0.05461847350228548), (9, 0.0537549709167328), (43, 0.0516324218493014), (11, 0.04932062236712692), (7, 0.048867891860529124), (15, 0.04868301255783514), (68, 0.04616663408351521), (52, 0.04581078216678413), (49, 0.04365360590094661), (13, 0.04335584933447547), (65, 0.042811571469987604), (51, 0.04256784715636918), (64, 0.040812988232880494), (18, 0.0405066150024381), (69, 0.03923028420236608), (34, 0.039103317967859624), (14, 0.03868230085680102), (67, 0.03865679927018229), (54, 0.03826151367429518), (58, 0.03676070735347134), (12, 0.03571754251976584), (66, 0.034134108883332626), (44, 0.033988631208898605), (60, 0.030542273778759673), (56, 0.029484438048305247), (62, 0.028203347396219262), (41, 0.026952174746556343), (17, 0.026196595476859912), (59, 0.025749102689878196), (16, 0.02519741699553711), (27, 0.023412172650995662), (21, 0.023120288807236423), (19, 0.022624233366763703), (23, 0.022078625229650862), (53, 0.021955456491820586), (37, 0.021832984727761764), (25, 0.021117435263182393), (63, 0.020847191965022), (20, 0.020108224310386506), (35, 0.019452809581483144), (39, 0.016959691435882877), (45, 0.01690311684506159), (36, 0.016468781873920105), (29, 0.015664275496812093), (30, 0.011698234259527575), (31, 0.011654387250583759), (57, 0.011445009266239786), (55, 0.011412191251826019), (38, 0.011093931850562457), (40, 0.009507422983900919), (33, 0.008751913817516553), (24, 0.007804981016983812), (28, 0.005938892729732087), (22, 0.005038304324926465), (32, 0.0027217070388068014), (26, -0.004516942177767232)]\n","Best MI score: 0.0856030770608996\n","Adding first best original feature: 4\n","CMI: 0.003949058871936001\n","CMI: 0.018078810110051385\n","CMI: 0.009513208943416965\n","CMI: 0.009366306377758066\n","CMI: 0.011669366432506184\n","CMI: 0.0014344304444158379\n","CMI: 0.02952957355155149\n","CMI: 0.017925572300977938\n","CMI: 0.006747332365100403\n","CMI: 0.024592418821630463\n","CMI: 0.025479649690396358\n","CMI: 0.01925848402712356\n","CMI: 0.020098674276592177\n","CMI: 0.018266566519242425\n","CMI: 0.01493581906193879\n","CMI: 0.015205725247408\n","CMI: 0.00786042853582787\n","CMI: 0.006894825730911047\n","CMI: 0.04468386529285891\n","CMI: 0.001780903288228039\n","CMI: 0.004237734929130821\n","CMI: 0.008929580858622388\n","CMI: 0.014105420024513177\n","CMI: 0.02020443757369461\n","CMI: 0.0073818394404271265\n","CMI: 0.015445617298004685\n","CMI: 0.007718834964867846\n","CMI: 0.01425576570437144\n","Highest CMI score: 0.04468386529285891\n","Adding original feature: 56\n","CMI: 0.0016341047899179617\n","CMI: 0.008024418916452086\n","CMI: 0.007023318132856088\n","CMI: 0.01197197684424206\n","CMI: 0.0005899429891237096\n","CMI: 0.003700491997266492\n","CMI: 0.00276192376049636\n","CMI: 0.00033918628978138465\n","CMI: 0.006895965508869034\n","Highest CMI score: 0.01197197684424206\n","Adding original feature: 47\n","CMI: 0.00453802374310458\n","CMI: 0.011167611581883535\n","CMI: 0.00864332184021191\n","CMI: 0.003908789322340067\n","CMI: 0.008121500520362812\n","CMI: 0.002286309451788038\n","CMI: 0.00013738440758398474\n","CMI: 0.009239575164450925\n","CMI: 0.0023132589835726525\n","CMI: 0.0008815171946431055\n","CMI: 0.0008157613394215446\n","Highest CMI score: 0.011167611581883535\n","Adding original feature: 1\n","CMI: 0.004964858720532234\n","CMI: 0.0019186843803333797\n","CMI: 0.0039010985102742035\n","CMI: 0.0030432737344059935\n","Highest CMI score: 0.004964858720532234\n","Adding original feature: 14\n","CMI: 0.002805425067914896\n","CMI: 0.0007879873747800026\n","CMI: 0.0017519441900752386\n","CMI: 0.0013474946771286078\n","CMI: 0.006333899233753326\n","CMI: 0.0008434682511453406\n","CMI: 0.005970050006156663\n","CMI: 0.0031860699411980498\n","Highest CMI score: 0.006333899233753326\n","Adding original feature: 63\n","CMI: 0.0003773576282609936\n","CMI: 0.0008771885823764813\n","CMI: 0.0006015639271350071\n","CMI: 0.007707230381101909\n","Highest CMI score: 0.007707230381101909\n","Adding original feature: 61\n","CMI: 0.00675432663538128\n","CMI: 0.0013256896603040524\n","CMI: 0.001899845999231431\n","CMI: 0.0014335738682285382\n","CMI: 0.0006624785956276802\n","CMI: 0.0028989291847731913\n","CMI: 0.0007304139630395223\n","Highest CMI score: 0.00675432663538128\n","Adding original feature: 0\n","Highest CMI score: -0.0010291635977237035\n","\n","[4, 56, 47, 1, 14, 63, 61, 0]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.2819959740677105, test score: -0.08014058572383065\n","Aggregate regression train score with FS: 0.1730440049734875, test score: 0.07902918415618443\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.2819959740677105, test score: -0.08014058572383065\n","Aggregate regression train score with FS: 0.15364793821407408, test score: 0.09729224363059741\n","###### Binary Classification ######\n","Train accuracy logistic regression CMI:  0.696\n","Test accuracy logistic regression CMI:  0.649 \n","\n","Train accuracy logistic regression CMI best 5:  0.678\n","Test accuracy logistic regression CMI best 5:  0.614 \n","\n","Train accuracy logistic regression wrapper:  0.679\n","Test accuracy logistic regression wrapper:  0.684 \n","\n"]}],"source":["basins = ['Dora', 'Piemonte_Sud', 'Piemonte_Nord']\n","\n","path_target = \"./csv/\"\n","path_features = './features_allvalues/'\n","destination_folder = './GenLinCFA/temp_prec/internal_ordering/'\n","#plots_folder = './GenLinCFA/for_plots/internal_ordering/'\n","\n","for basin in basins:\n","  selected_colnames_CMI5 = []\n","  print('####################' + basin + '####################')\n","  target_df_train, target_df_val, target_df_test, target_df_trainVal = prepare_target_binary('',max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01',\n","      path=path_target+basin+'.csv', window_size = 1)\n","  eps = 0.37\n","  actual_path = path_features+basin+'_aggreg.csv'\n","  output, aggregate_trainVal, aggregate_test = aggregate_unfolded_data(actual_path,['cyclostationary_mean_tg',\n","                                                                            'cyclostationary_mean_tg_1w',\n","                                                                            'cyclostationary_mean_tg_4w',\n","                                                                            'cyclostationary_mean_tg_8w',\n","                                                                            'cyclostationary_mean_tg_12w',\n","                                                                            'cyclostationary_mean_tg_16w',\n","                                                                            'cyclostationary_mean_tg_24w',\n","                                                                            'cyclostationary_mean_rr',\n","                                                                            'cyclostationary_mean_rr_1w',\n","                                                                            'cyclostationary_mean_rr_4w',\n","                                                                            'cyclostationary_mean_rr_8w',\n","                                                                            'cyclostationary_mean_rr_12w',\n","                                                                            'cyclostationary_mean_rr_16w',\n","                                                                            'cyclostationary_mean_rr_24w'\n","                                                                            ],\n","                                                                      target_df_trainVal, eps=eps,\n","                                                                      max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01')\n","\n","  #agg_trainVal_string = plots_folder + basin + \"_trainVal_aggreg\"\n","  #agg_test_string = plots_folder + basin + \"_test_aggreg\"\n","  #aggregate_trainVal.to_csv(agg_trainVal_string, index = False)\n","  #aggregate_test.to_csv(agg_test_string, index = False)\n","\n","  selected_colnames = FS_with_linearWrapper(aggregate_trainVal, target_df_train, target_df_val, min(50,aggregate_trainVal.shape[1]-1), 228)\n","\n","  print('\\nFull model and selected features with wrapper\\n')\n","  compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n","\n","  print('\\nFull model and best 5 selected features with wrapper\\n')\n","  compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames[0:5])\n","\n","  train_string = destination_folder + basin + '_genLinCFA_wrapper_best5_train.csv'\n","  val_string = destination_folder + basin + '_genLinCFA_wrapper_best5_val.csv'\n","  test_string = destination_folder + basin + '_genLinCFA_wrapper_best5_test.csv'\n","  X_train_wrapper = aggregate_trainVal.loc[:410,selected_colnames[0:5]]\n","  X_validation_wrapper = aggregate_trainVal.loc[411:,selected_colnames[0:5]]\n","  X_train_validation_wrapper = pd.concat([X_train_wrapper, X_validation_wrapper])\n","  X_test_wrapper = aggregate_test.loc[:,selected_colnames[0:5]]\n","  X_train_wrapper.to_csv(train_string, index=False)\n","  X_validation_wrapper.to_csv(val_string, index=False)\n","  X_test_wrapper.to_csv(test_string, index=False)\n","\n","  res = {\n","          \"delta\" : [],\n","          \"numSelected\" : [],\n","          \"selectedFeatures\" : []\n","      }\n","\n","  res['selectedFeatures'] = forwardFeatureSelection(10,np.array(aggregate_trainVal),\n","                                                    np.array(target_df_trainVal.mean_std),res,10,1)\n","\n","  selectedFeatures='selectedFeatures'\n","  print(f'\\n{res[selectedFeatures]}\\n')\n","\n","  selected_colnames = aggregate_trainVal.columns[res['selectedFeatures']]\n","\n","  print('\\nFull model and selected features with CMI\\n')\n","  compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n","\n","  print('\\nFull model and best 5 selected features with CMI\\n')\n","  compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames[0:5])\n","\n","  train_string = destination_folder + basin + '_genLinCFA_best5_CMI_train.csv'\n","  val_string = destination_folder + basin + '_genLinCFA_best5_CMI_val.csv'\n","  test_string = destination_folder + basin + '_genLinCFA_best5_CMI_test.csv'\n","\n","  X_train_CMI5 = aggregate_trainVal.loc[:410,selected_colnames[0:5]]\n","  X_validation_CMI5 = aggregate_trainVal.loc[411:,selected_colnames[0:5]]\n","  X_train_validation_CMI5 = pd.concat([X_train_CMI5, X_validation_CMI5])\n","  X_test_CMI5 = aggregate_test.loc[:,selected_colnames[0:5]]\n","\n","  selected_colnames_CMI5.append(aggregate_trainVal.loc[:,selected_colnames[0:5]].columns.values)\n","\n","  X_train_CMI5.to_csv(train_string, index=False)\n","  X_validation_CMI5.to_csv(val_string, index=False)\n","  X_test_CMI5.to_csv(test_string, index=False)\n","\n","  train_string = destination_folder + basin + '_genLinCFA_CMI_train.csv'\n","  val_string = destination_folder + basin + '_genLinCFA_CMI_val.csv'\n","  test_string = destination_folder + basin + '_genLinCFA_CMI_test.csv'\n","\n","  X_train_CMI = aggregate_trainVal.loc[:410,selected_colnames]\n","  X_validation_CMI = aggregate_trainVal.loc[411:,selected_colnames]\n","  X_train_validation_CMI = pd.concat([X_train_CMI, X_validation_CMI])\n","  X_test_CMI = aggregate_test.loc[:,selected_colnames]\n","\n","  X_train_CMI.to_csv(train_string, index=False)\n","  X_validation_CMI.to_csv(val_string, index=False)\n","  X_test_CMI.to_csv(test_string, index=False)\n","\n","  print('###### Binary Classification ######')\n","\n","  target_df_train = target_df_train.apply(lambda x: np.sign(x.mean_std), axis=1)\n","  target_df_val = target_df_val.apply(lambda x: np.sign(x.mean_std), axis=1)\n","  target_df_test = target_df_test.apply(lambda x: np.sign(x.mean_std), axis=1)\n","  target_df_trainVal = target_df_trainVal.apply(lambda x: np.sign(x.mean_std), axis=1)\n","\n","  log_regr = LogisticRegression(solver='lbfgs', random_state = 42)\n","\n","  # CMI\n","  log_regr.fit(X_train_validation_CMI, target_df_trainVal)\n","  print(\"Train accuracy logistic regression CMI: \", round(log_regr.score(X_train_validation_CMI, target_df_trainVal),3))\n","  print(\"Test accuracy logistic regression CMI: \", round(log_regr.score(X_test_CMI, target_df_test),3), \"\\n\")\n","\n","  # CMI best 5\n","  log_regr.fit(X_train_validation_CMI5, target_df_trainVal)\n","  print(\"Train accuracy logistic regression CMI best 5: \", round(log_regr.score(X_train_validation_CMI5, target_df_trainVal),3))\n","  print(\"Test accuracy logistic regression CMI best 5: \", round(log_regr.score(X_test_CMI5, target_df_test),3), \"\\n\")\n","\n","  # wrapper\n","  log_regr.fit(X_train_validation_wrapper, target_df_trainVal)\n","  print(\"Train accuracy logistic regression wrapper: \", round(log_regr.score(X_train_validation_wrapper, target_df_trainVal),3))\n","  print(\"Test accuracy logistic regression wrapper: \", round(log_regr.score(X_test_wrapper, target_df_test),3), \"\\n\")\n","\n","  #output_string = plots_folder + basin + '_aggregations.npy'\n","  #sel_col_string = plots_folder + basin + '_chosen_features.npy'\n","  #np.save(sel_col_string, selected_colnames_CMI5)\n","  #np.save(output_string, outputs)"],"id":"FtNcJZiLG1ZG"},{"cell_type":"markdown","metadata":{"id":"5CH3HZkKIweQ"},"source":["## Temp Prec Snow"],"id":"5CH3HZkKIweQ"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5885919,"status":"ok","timestamp":1690239029049,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"},"user_tz":-120},"id":"_gV8G4C6Iyaz","outputId":"5a084355-1742-44ae-b0e7-dfe8d2309349"},"outputs":[{"output_type":"stream","name":"stdout","text":["####################Ticino####################\n","target samples:            date      mean  median  year  week  mean_std\n","0    2001-01-05  0.264043    0.00  2001     1         0\n","1    2001-01-13  0.354618    0.39  2001     2         0\n","2    2001-01-21  0.427990    0.47  2001     3         1\n","3    2001-01-29  0.339495    0.35  2001     5         0\n","4    2001-02-06  0.324134    0.34  2001     6         0\n","..          ...       ...     ...   ...   ...       ...\n","406  2009-11-27  0.332713    0.35  2009    48         0\n","407  2009-12-05  0.370253    0.40  2009    49         0\n","408  2009-12-13  0.517201    0.57  2009    50         1\n","409  2009-12-21  0.353636    0.45  2009    52         0\n","410  2009-12-29  0.261079    0.00  2009    53         0\n","\n","[411 rows x 6 columns]\n"," target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n","Feature: cyclostationary_mean_tg\n","\n","Number of features: 92\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_tg_1w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_4w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_8w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_tg_12w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 6\n","\n","Feature: cyclostationary_mean_tg_16w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 6\n","\n","Feature: cyclostationary_mean_tg_24w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_rr\n","\n","Number of features: 92\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_1w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_rr_4w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_8w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_12w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_16w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_rr_24w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 8\n","\n","Feature: cyclostationary_mean_HS\n","\n","Number of features: 11\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_HS_1w\n","\n","Number of features: 11\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_HS_4w\n","\n","Number of features: 11\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_HS_8w\n","\n","Number of features: 11\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_HS_12w\n","\n","Number of features: 11\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_HS_16w\n","\n","Number of features: 11\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_HS_24w\n","\n","Number of features: 11\n","\n","Number of aggregated features: 3\n","\n","\n","\n","selected columns: ['cyclostationary_mean_tg_1w_1', 'cyclostationary_mean_rr_24w_2', 'cyclostationary_mean_HS_2', 'cyclostationary_mean_tg_4w_0', 'cyclostationary_mean_HS_4w_0', 'cyclostationary_mean_HS_24w_1', 'cyclostationary_mean_HS_16w_0', 'cyclostationary_mean_HS_4w_1', 'cyclostationary_mean_tg_12w_1', 'cyclostationary_mean_tg_16w_0', 'cyclostationary_mean_tg_16w_3', 'cyclostationary_mean_tg_16w_4', 'cyclostationary_mean_tg_24w_1', 'cyclostationary_mean_tg_12w_3', 'cyclostationary_mean_tg_24w_0', 'cyclostationary_mean_tg_8w_0', 'cyclostationary_mean_tg_12w_0', 'cyclostationary_mean_tg_1w_2', 'cyclostationary_mean_HS_16w_2'], \n","\n","validation score: 0.25082318538589865, \n","\n","number of selected features: 19\n","\n","Full model and selected features with wrapper\n","\n","Full aggregate regression train score: 0.28769677188228115, test score: -2.4586030139107975\n","Aggregate regression train score with FS: 0.1667328231054912, test score: -0.060515324227101264\n","\n","Full model and best 5 selected features with wrapper\n","\n","Full aggregate regression train score: 0.28769677188228115, test score: -2.4586030139107975\n","Aggregate regression train score with FS: 0.13730080872886263, test score: 0.17334215588575708\n","----- MI Scores -----\n","[(23, 0.07619436851140222), (24, 0.06906896931200217), (28, 0.06852056802960067), (26, 0.06660455307361404), (25, 0.06088807942810209), (2, 0.05929109833866007), (5, 0.05928214829064438), (27, 0.05824310484330773), (10, 0.05762123797478628), (22, 0.05522297523167413), (69, 0.054295157155189296), (14, 0.05294538750989553), (7, 0.05008060155676763), (12, 0.048115163751890434), (3, 0.047662862897362934), (6, 0.047488824285564515), (31, 0.04657151971199622), (4, 0.04646357249807251), (40, 0.04529046878737617), (39, 0.044000308482937525), (1, 0.04325127304478813), (29, 0.0427709935947236), (0, 0.042035023528088925), (57, 0.04202737177106451), (68, 0.04190789459252143), (58, 0.041818526764121115), (56, 0.038827653046544175), (9, 0.03635488670481026), (17, 0.03604253869034865), (60, 0.03455350135826824), (72, 0.03243262035231984), (63, 0.032002396320943746), (11, 0.031306399567740555), (32, 0.030877908471773914), (79, 0.03015489995525939), (74, 0.029096993004445224), (8, 0.02885205461310632), (38, 0.0287590274396903), (13, 0.026425347803298162), (61, 0.0261434086834642), (73, 0.024707407342511152), (18, 0.024689691981805942), (62, 0.024333897539835253), (15, 0.023846899449943507), (75, 0.023793929211500614), (34, 0.023326683582522715), (20, 0.023058379432511877), (71, 0.022787553903856228), (59, 0.02253515338620965), (80, 0.02185642353004048), (77, 0.021201045477643902), (46, 0.019683674697863963), (50, 0.019401056144409373), (81, 0.019311135066338005), (70, 0.018781723381094045), (19, 0.017471507039664946), (64, 0.017045569016774356), (35, 0.016828879265827934), (36, 0.015451812824777122), (37, 0.015049707608688807), (43, 0.014917791231975104), (53, 0.014679133520503993), (48, 0.013936453922602928), (30, 0.01384838851225433), (44, 0.012832363091462967), (67, 0.012682459160006404), (45, 0.012641765001735271), (55, 0.012114109290322368), (47, 0.010825060037588714), (51, 0.009671990696651625), (78, 0.008418213346720669), (76, 0.008294665702062911), (65, 0.008282081820316934), (54, 0.0071560037046853875), (33, 0.007091986352875644), (21, 0.00583643818913481), (41, 0.004483391034735937), (52, 0.003241891707893248), (49, 0.0012844786940756298), (82, 0.0010400024002533803), (66, 0.0003457871689164371), (16, -0.0060867750361585805), (42, -0.007011565293243101)]\n","Best MI score: 0.07619436851140222\n","Adding first best original feature: 23\n","CMI: 0.0424885078417675\n","CMI: 0.033656431636816586\n","CMI: 0.032995623999975174\n","CMI: 0.03665754204703467\n","CMI: 0.035430390353333244\n","CMI: 0.03878228559118106\n","CMI: 0.029578745769049203\n","CMI: 0.04339112873729373\n","CMI: 0.03114974838495596\n","CMI: 0.0331602511970205\n","CMI: 0.018507389058177087\n","CMI: 0.01590100703986909\n","CMI: 0.007376007147363597\n","CMI: 0.019837781635328178\n","CMI: 0.030006971090245027\n","CMI: 0.014536629137015283\n","CMI: 0.030459934079421686\n","CMI: 0.0167277515023172\n","CMI: 0.024202491141198365\n","CMI: 0.005177922485420358\n","CMI: 0.00784749952241108\n","CMI: 0.013624819098180724\n","CMI: 0.0024070241981222484\n","CMI: 0.01096956243228181\n","CMI: 0.00204696544792983\n","CMI: 0.003927566539001892\n","CMI: 0.001407862232270643\n","CMI: 0.0009120306323470301\n","CMI: 0.0030631925499413487\n","CMI: 0.002637055565816629\n","CMI: 0.018046360346559306\n","CMI: 0.0014556706061218394\n","CMI: 0.013220938789374567\n","CMI: 0.013776169253487042\n","CMI: 0.01304102841356708\n","CMI: 0.0027315178852214544\n","CMI: 0.017453087007609086\n","CMI: 0.007181260541283985\n","CMI: 0.023217874671034144\n","CMI: 0.010756090479374522\n","CMI: 0.020791192106256393\n","CMI: 0.000614257354135353\n","CMI: 0.011231497019055625\n","CMI: 0.035245872115852867\n","CMI: 0.02743734432527563\n","CMI: 0.031068821063846244\n","CMI: 0.005821446583474527\n","CMI: 0.003199939712128397\n","CMI: 0.012861191773261352\n","CMI: 0.004954082178859065\n","CMI: 0.012409545659913701\n","CMI: 0.02216986812888805\n","CMI: 0.001491152662443443\n","CMI: 0.012320150079380296\n","CMI: 0.014394868486600584\n","CMI: 0.015710572519931423\n","CMI: 0.008449297219921423\n","CMI: 0.005359375209194328\n","CMI: 0.0015980427824700966\n","CMI: 0.004729961990848297\n","CMI: 0.0016334117291859074\n","Highest CMI score: 0.04339112873729373\n","Adding original feature: 7\n","CMI: 0.006790101116471561\n","CMI: 0.012018561201505393\n","CMI: 0.004078222458141892\n","CMI: 0.00030717126709851883\n","CMI: 0.012241814349839716\n","CMI: 0.009991046393799871\n","CMI: 7.160887319096476e-05\n","CMI: 0.002515071046019085\n","CMI: 0.0012112895408397523\n","CMI: 0.01927242793043525\n","CMI: 0.002755368662222271\n","CMI: 0.02131110044620478\n","CMI: 0.003882064511963143\n","CMI: 0.016516555326820878\n","CMI: 0.008176465012099801\n","CMI: 0.008945125139148927\n","CMI: 0.0036632302548631757\n","CMI: 0.009977357407745094\n","CMI: 0.015416037187063317\n","CMI: 0.009914724450448623\n","CMI: 0.012502969520587146\n","CMI: 0.013851084983083836\n","CMI: 0.009405701939929692\n","CMI: 0.009632911646201794\n","CMI: 0.010229307772621474\n","CMI: 0.009734417074358306\n","CMI: 0.0007191090272093553\n","CMI: 0.0021056892974366803\n","CMI: 0.015827099075263598\n","CMI: 0.0042890521150004135\n","CMI: 0.007530372794743348\n","CMI: 0.0005221382686952658\n","CMI: 0.006734951750900428\n","CMI: 0.010522030714035333\n","CMI: 0.006259708411856538\n","CMI: 0.005680754177350686\n","CMI: 0.024544929033202836\n","CMI: 0.030435293865682042\n","CMI: 0.021609428423147906\n","CMI: 0.017870433048132697\n","CMI: 0.000643761650903435\n","CMI: 0.005809556971972121\n","CMI: 0.0018593879377038353\n","CMI: 3.9041339646425643e-05\n","CMI: 0.01379916998422527\n","CMI: 0.00755742942272504\n","CMI: 0.02319586471907016\n","CMI: 0.00943511905270751\n","CMI: 0.01465453726924508\n","CMI: 0.01166270947470728\n","CMI: 0.005873705876744892\n","CMI: 0.002152675678576327\n","CMI: 0.0014321824886229656\n","CMI: 0.0006099936478608098\n","CMI: 0.004881539196358614\n","Highest CMI score: 0.030435293865682042\n","Adding original feature: 52\n","CMI: 0.018176213532674845\n","CMI: 0.011568032925290322\n","CMI: 0.004083728595677433\n","CMI: 0.0017454691898152186\n","CMI: 0.0017265875764844174\n","CMI: 0.006758022831573868\n","CMI: 0.005265355869507743\n","CMI: 0.0038159041588904374\n","Highest CMI score: 0.018176213532674845\n","Adding original feature: 0\n","CMI: 0.0006450339942452588\n","Highest CMI score: 0.0006450339942452588\n","Adding original feature: 24\n","CMI: 0.00037738380878640787\n","CMI: 0.0008681726569741421\n","Highest CMI score: 0.0008681726569741421\n","Adding original feature: 49\n","CMI: 0.00044820152730815077\n","CMI: 0.004777552511759348\n","Highest CMI score: 0.004777552511759348\n","Adding original feature: 25\n","Highest CMI score: -0.001420617723373957\n","\n","[23, 7, 52, 0, 24, 49, 25]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.28769677188228115, test score: -2.4586030139107975\n","Aggregate regression train score with FS: 0.13037371541227816, test score: 0.13742502971670223\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.28769677188228115, test score: -2.4586030139107975\n","Aggregate regression train score with FS: 0.1295175453233991, test score: 0.1262125505631737\n","###### Binary Classification ######\n","Train accuracy logistic regression CMI:  0.657\n","Test accuracy logistic regression CMI:  0.658 \n","\n","Train accuracy logistic regression CMI best 5:  0.66\n","Test accuracy logistic regression CMI best 5:  0.658 \n","\n","Train accuracy logistic regression wrapper:  0.659\n","Test accuracy logistic regression wrapper:  0.706 \n","\n","####################Adda####################\n","target samples:            date      mean  median  year  week  mean_std\n","0    2001-01-05  0.039373    0.00  2001     1         0\n","1    2001-01-13  0.380618    0.43  2001     2         0\n","2    2001-01-21  0.341985    0.38  2001     3         0\n","3    2001-01-29  0.322044    0.35  2001     5         0\n","4    2001-02-06  0.354954    0.40  2001     6         0\n","..          ...       ...     ...   ...   ...       ...\n","406  2009-11-27  0.382706    0.40  2009    48         0\n","407  2009-12-05  0.409921    0.46  2009    49         0\n","408  2009-12-13  0.472087    0.53  2009    50         1\n","409  2009-12-21  0.324728    0.00  2009    52         0\n","410  2009-12-29  0.086512    0.00  2009    53         0\n","\n","[411 rows x 6 columns]\n"," target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n","Feature: cyclostationary_mean_tg\n","\n","Number of features: 92\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_1w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_4w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_8w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_tg_12w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_tg_16w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_tg_24w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr\n","\n","Number of features: 92\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_rr_1w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_4w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 8\n","\n","Feature: cyclostationary_mean_rr_8w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 15\n","\n","Feature: cyclostationary_mean_rr_12w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 10\n","\n","Feature: cyclostationary_mean_rr_16w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_rr_24w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 8\n","\n","Feature: cyclostationary_mean_HS\n","\n","Number of features: 7\n","\n","Number of aggregated features: 2\n","\n","Feature: cyclostationary_mean_HS_1w\n","\n","Number of features: 7\n","\n","Number of aggregated features: 2\n","\n","Feature: cyclostationary_mean_HS_4w\n","\n","Number of features: 7\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_HS_8w\n","\n","Number of features: 7\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_HS_12w\n","\n","Number of features: 7\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_HS_16w\n","\n","Number of features: 7\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_HS_24w\n","\n","Number of features: 7\n","\n","Number of aggregated features: 2\n","\n","\n","\n","selected columns: ['cyclostationary_mean_tg_1w_2', 'cyclostationary_mean_tg_4w_1', 'cyclostationary_mean_tg_4w_2', 'cyclostationary_mean_rr_4w_0', 'cyclostationary_mean_tg_8w_0', 'cyclostationary_mean_HS_24w_1', 'cyclostationary_mean_HS_8w_0', 'cyclostationary_mean_tg_1w_1', 'cyclostationary_mean_HS_8w_1', 'cyclostationary_mean_HS_4w_0', 'cyclostationary_mean_rr_24w_1', 'cyclostationary_mean_rr_1w_2', 'cyclostationary_mean_rr_4w_1', 'cyclostationary_mean_rr_4w_2', 'cyclostationary_mean_rr_4w_3', 'cyclostationary_mean_tg_8w_3', 'cyclostationary_mean_rr_2', 'cyclostationary_mean_rr_0'], \n","\n","validation score: 0.27148658932814795, \n","\n","number of selected features: 18\n","\n","Full model and selected features with wrapper\n","\n","Full aggregate regression train score: 0.3454934876306852, test score: -0.48594074863701886\n","Aggregate regression train score with FS: 0.16840704209882884, test score: 0.08661310788998822\n","\n","Full model and best 5 selected features with wrapper\n","\n","Full aggregate regression train score: 0.3454934876306852, test score: -0.48594074863701886\n","Aggregate regression train score with FS: 0.1440759008299486, test score: 0.12691405710657577\n","----- MI Scores -----\n","[(3, 0.13060303043884083), (5, 0.12928941517574324), (1, 0.12530110884243456), (6, 0.1165339682816214), (48, 0.07426394053968663), (49, 0.07064861805559879), (46, 0.06565546799993426), (21, 0.06341479218878367), (23, 0.06154924722054746), (0, 0.06125353666858077), (2, 0.05750978377173043), (61, 0.05510860013342701), (26, 0.05440200218511999), (22, 0.052295701741671315), (10, 0.050138004158179074), (11, 0.045934853812424695), (94, 0.045870559453819085), (34, 0.04579323938165829), (25, 0.045444831860808665), (96, 0.04535367294037398), (7, 0.040638703972186066), (53, 0.039086985624180705), (24, 0.03650096311365742), (4, 0.03519218038788573), (72, 0.03324540115322162), (18, 0.03296326799206061), (79, 0.03275917614350123), (68, 0.032577077971148886), (77, 0.03084453721106745), (19, 0.030678973937076377), (29, 0.030586261903864025), (85, 0.029611836862427774), (14, 0.029482408688126432), (91, 0.0278595981612805), (51, 0.027764938391219938), (15, 0.027293941324075137), (83, 0.02720404690290137), (56, 0.027189588143225814), (71, 0.026191401818913468), (70, 0.026002494184630114), (32, 0.025727701206068217), (50, 0.025516049769112304), (9, 0.024475819293184167), (63, 0.023483649557416362), (80, 0.02335650617324098), (66, 0.02332618662134555), (20, 0.023169131379861395), (78, 0.021451787817284945), (52, 0.020999521676169145), (82, 0.020663857674686176), (47, 0.02040861179732287), (33, 0.02028949015860065), (58, 0.020228344285874483), (55, 0.02021443888370932), (65, 0.019643425089019274), (62, 0.01963966321546049), (8, 0.01955726848339617), (67, 0.018534812391315932), (57, 0.018520579030288857), (17, 0.01762803092043631), (69, 0.017371321530923627), (89, 0.017209004411155988), (73, 0.016619201984015), (43, 0.015454867938594054), (39, 0.014914468037684805), (12, 0.014883411360459892), (97, 0.013818848510319547), (75, 0.013415109005516285), (86, 0.013245503955702701), (81, 0.01270934222084833), (64, 0.012184060456771631), (36, 0.011836122999913939), (87, 0.01163139222608697), (37, 0.011571229176405162), (16, 0.010966811032947577), (38, 0.010781106563733473), (35, 0.010647987721316315), (60, 0.010010675134999591), (92, 0.009549049764006053), (59, 0.008984038334623107), (27, 0.00887362630340825), (13, 0.008597690603685664), (31, 0.008562180462303266), (95, 0.008419358279822648), (74, 0.0080311309911059), (28, 0.007804641996140892), (76, 0.0075468002363079136), (93, 0.006327896925066662), (84, 0.006084547625136577), (88, 0.005760536401420191), (41, 0.0048664149034964325), (44, 0.0038647986716313963), (45, 0.001825460653871919), (40, 0.00024254615223875844), (54, 0.00012455591369065681), (42, -6.77000813182088e-05), (30, -0.0012235647650569005), (90, -0.008506724931865599)]\n","Best MI score: 0.13060303043884083\n","Adding first best original feature: 3\n","CMI: 0.038231122999317385\n","CMI: 0.04387939871938956\n","CMI: 0.04845046886731966\n","CMI: 0.0020991782744532728\n","Highest CMI score: 0.04845046886731966\n","Adding original feature: 6\n","Highest CMI score: -0.006982111369828903\n","\n","[3, 6]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.3454934876306852, test score: -0.48594074863701886\n","Aggregate regression train score with FS: 0.0008731476090410029, test score: -0.024232074469372034\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.3454934876306852, test score: -0.48594074863701886\n","Aggregate regression train score with FS: 0.0008731476090410029, test score: -0.024232074469372034\n","###### Binary Classification ######\n","Train accuracy logistic regression CMI:  0.545\n","Test accuracy logistic regression CMI:  0.583 \n","\n","Train accuracy logistic regression CMI best 5:  0.545\n","Test accuracy logistic regression CMI best 5:  0.583 \n","\n","Train accuracy logistic regression wrapper:  0.664\n","Test accuracy logistic regression wrapper:  0.654 \n","\n","####################Oglio_Iseo####################\n","target samples:            date      mean  median  year  week  mean_std\n","0    2001-01-05  0.243674    0.26  2001     1         0\n","1    2001-01-13  0.424116    0.44  2001     2         0\n","2    2001-01-21  0.393786    0.39  2001     3         0\n","3    2001-01-29  0.314939    0.31  2001     5         0\n","4    2001-02-06  0.464902    0.48  2001     6         1\n","..          ...       ...     ...   ...   ...       ...\n","406  2009-11-27  0.465734    0.48  2009    48         1\n","407  2009-12-05  0.447390    0.47  2009    49         1\n","408  2009-12-13  0.556760    0.59  2009    50         1\n","409  2009-12-21  0.307880    0.00  2009    52         0\n","410  2009-12-29  0.034211    0.00  2009    53         0\n","\n","[411 rows x 6 columns]\n"," target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n","Feature: cyclostationary_mean_tg\n","\n","Number of features: 74\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_tg_1w\n","\n","Number of features: 74\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_tg_4w\n","\n","Number of features: 74\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_tg_8w\n","\n","Number of features: 74\n","\n","Number of aggregated features: 6\n","\n","Feature: cyclostationary_mean_tg_12w\n","\n","Number of features: 74\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_tg_16w\n","\n","Number of features: 74\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_tg_24w\n","\n","Number of features: 74\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr\n","\n","Number of features: 74\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_rr_1w\n","\n","Number of features: 74\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_4w\n","\n","Number of features: 74\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_rr_8w\n","\n","Number of features: 74\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_12w\n","\n","Number of features: 74\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_rr_16w\n","\n","Number of features: 74\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_rr_24w\n","\n","Number of features: 74\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_HS\n","\n","Number of features: 2\n","\n","Number of aggregated features: 2\n","\n","Feature: cyclostationary_mean_HS_1w\n","\n","Number of features: 2\n","\n","Number of aggregated features: 2\n","\n","Feature: cyclostationary_mean_HS_4w\n","\n","Number of features: 2\n","\n","Number of aggregated features: 2\n","\n","Feature: cyclostationary_mean_HS_8w\n","\n","Number of features: 2\n","\n","Number of aggregated features: 2\n","\n","Feature: cyclostationary_mean_HS_12w\n","\n","Number of features: 2\n","\n","Number of aggregated features: 2\n","\n","Feature: cyclostationary_mean_HS_16w\n","\n","Number of features: 2\n","\n","Number of aggregated features: 2\n","\n","Feature: cyclostationary_mean_HS_24w\n","\n","Number of features: 2\n","\n","Number of aggregated features: 2\n","\n","\n","\n","selected columns: ['cyclostationary_mean_tg_3', 'cyclostationary_mean_rr_4w_2', 'cyclostationary_mean_rr_16w_0', 'cyclostationary_mean_rr_8w_2', 'cyclostationary_mean_HS_1w_0', 'cyclostationary_mean_rr_16w_3', 'cyclostationary_mean_rr_1w_0', 'cyclostationary_mean_tg_16w_0', 'cyclostationary_mean_tg_16w_2', 'cyclostationary_mean_tg_1', 'cyclostationary_mean_tg_24w_0', 'cyclostationary_mean_rr_12w_0', 'cyclostationary_mean_rr_8w_1', 'cyclostationary_mean_HS_0', 'cyclostationary_mean_HS_1', 'cyclostationary_mean_rr_8w_0', 'cyclostationary_mean_HS_24w_1', 'cyclostationary_mean_tg_24w_2', 'cyclostationary_mean_HS_12w_1', 'cyclostationary_mean_rr_12w_1', 'cyclostationary_mean_HS_24w_0', 'cyclostationary_mean_HS_8w_0', 'cyclostationary_mean_HS_4w_0', 'cyclostationary_mean_HS_4w_1'], \n","\n","validation score: 0.2758095451359788, \n","\n","number of selected features: 24\n","\n","Full model and selected features with wrapper\n","\n","Full aggregate regression train score: 0.3047095108872906, test score: -0.07362394027206864\n","Aggregate regression train score with FS: 0.19737962869654302, test score: 0.13494064000705275\n","\n","Full model and best 5 selected features with wrapper\n","\n","Full aggregate regression train score: 0.3047095108872906, test score: -0.07362394027206864\n","Aggregate regression train score with FS: 0.17471707925256197, test score: 0.16138171142972368\n","----- MI Scores -----\n","[(0, 0.10019667024592005), (5, 0.09504421377394884), (1, 0.08934697709940029), (4, 0.08801547051787159), (3, 0.07997990485674795), (49, 0.07266497221224631), (21, 0.06615760823187876), (17, 0.06568966212252096), (22, 0.06384561451534691), (15, 0.059837919207322246), (2, 0.05837089474517893), (48, 0.05516701885465093), (16, 0.054194147706084196), (20, 0.05316938841480197), (47, 0.05188683317206092), (56, 0.05102256986157405), (14, 0.05038893484353032), (52, 0.0502229974523168), (44, 0.04780120789141581), (19, 0.04622827544494628), (54, 0.04508211551080975), (7, 0.043968936004471826), (6, 0.043727267677661), (50, 0.04159780446439129), (23, 0.040986056148187996), (12, 0.040474176352505734), (55, 0.03961272489309636), (18, 0.03918759230332868), (53, 0.03729185253073095), (38, 0.03722712311744739), (45, 0.035770550084311264), (25, 0.033037162005768485), (46, 0.03268846003151463), (13, 0.03169973750573079), (36, 0.031017172889424172), (26, 0.030810121632042577), (51, 0.026720121249542005), (59, 0.026496469444884787), (60, 0.024982155243445634), (27, 0.024922595674756905), (63, 0.023335142398340007), (24, 0.022941433175940145), (31, 0.022547904723786396), (70, 0.021867964151221792), (32, 0.021239915455380284), (41, 0.021186874053272537), (67, 0.020726845524726454), (29, 0.020108930352637118), (58, 0.019998338566571308), (62, 0.018850919705713926), (57, 0.01789038139075917), (68, 0.01779064829322368), (71, 0.017061945803314417), (64, 0.015829477313208728), (35, 0.014333768190424102), (9, 0.01240549710470327), (30, 0.012204813013872957), (37, 0.011854501593770255), (33, 0.011526702628185462), (39, 0.011263322315825358), (8, 0.01096447883901458), (42, 0.00927545270063909), (28, 0.009265213312162771), (61, 0.008824703184477731), (40, 0.007772738037063627), (10, 0.005466381671924328), (11, 0.003861715984564276), (66, 0.002868876816380014), (43, 0.001949206939100508), (34, -0.0006906301575006161), (65, -0.008845519408810386), (69, -0.009153097178596354)]\n","Best MI score: 0.10019667024592005\n","Adding first best original feature: 0\n","CMI: 0.015577634730918916\n","CMI: 0.0063744071346331505\n","CMI: 0.006424443785220335\n","CMI: 0.009183981930664914\n","CMI: 0.0025557286713276256\n","CMI: 0.010161325336619481\n","CMI: 0.013865688676343677\n","CMI: 0.0032105004120239616\n","Highest CMI score: 0.015577634730918916\n","Adding original feature: 1\n","CMI: 0.003560736029985398\n","CMI: 0.010415603730469236\n","CMI: 0.009773043339973142\n","CMI: 0.00023017985256044982\n","Highest CMI score: 0.010415603730469236\n","Adding original feature: 50\n","CMI: 0.0014064226215530495\n","CMI: 0.004898687267437446\n","CMI: 0.025671413623415296\n","CMI: 0.030940116562339914\n","CMI: 0.01770894808087567\n","CMI: 0.023304116429676447\n","CMI: 0.006045322157991584\n","CMI: 0.00202237166862429\n","CMI: 0.011959079859264754\n","CMI: 0.009725943082238342\n","CMI: 0.00719196430801497\n","CMI: 0.0035600535353299823\n","CMI: 0.003250755397580768\n","CMI: 0.013799187984516681\n","CMI: 0.0032376153839712984\n","CMI: 0.0005725582418399378\n","CMI: 0.004739092904747333\n","CMI: 0.0012429576332505798\n","CMI: 0.00048615307666655116\n","CMI: 0.004460554107262482\n","CMI: 0.01382383709401791\n","Highest CMI score: 0.030940116562339914\n","Adding original feature: 15\n","CMI: 0.001372111602350845\n","Highest CMI score: 0.001372111602350845\n","Adding original feature: 56\n","CMI: 0.0021868024898187566\n","Highest CMI score: 0.0021868024898187566\n","Adding original feature: 36\n","Highest CMI score: -0.00038934508430377157\n","\n","[0, 1, 50, 15, 56, 36]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.3047095108872906, test score: -0.07362394027206864\n","Aggregate regression train score with FS: 0.14499183318902165, test score: 0.14260145218450127\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.3047095108872906, test score: -0.07362394027206864\n","Aggregate regression train score with FS: 0.14479747278388988, test score: 0.13892975316395706\n","###### Binary Classification ######\n","Train accuracy logistic regression CMI:  0.679\n","Test accuracy logistic regression CMI:  0.671 \n","\n","Train accuracy logistic regression CMI best 5:  0.681\n","Test accuracy logistic regression CMI best 5:  0.662 \n","\n","Train accuracy logistic regression wrapper:  0.693\n","Test accuracy logistic regression wrapper:  0.697 \n","\n","####################Dora####################\n","target samples:            date      mean  median  year  week  mean_std\n","0    2001-01-05  0.010645    0.00  2001     1         0\n","1    2001-01-13  0.206769    0.00  2001     2         0\n","2    2001-01-21  0.267313    0.00  2001     3         0\n","3    2001-01-29  0.240836    0.20  2001     5         0\n","4    2001-02-06  0.193417    0.15  2001     6         0\n","..          ...       ...     ...   ...   ...       ...\n","406  2009-11-27  0.230073    0.25  2009    48         0\n","407  2009-12-05  0.243632    0.24  2009    49         0\n","408  2009-12-13  0.251111    0.00  2009    50         0\n","409  2009-12-21  0.099246    0.00  2009    52         0\n","410  2009-12-29  0.064990    0.00  2009    53         0\n","\n","[411 rows x 6 columns]\n"," target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n","Feature: cyclostationary_mean_tg\n","\n","Number of features: 44\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_tg_1w\n","\n","Number of features: 44\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_tg_4w\n","\n","Number of features: 44\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_tg_8w\n","\n","Number of features: 44\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_tg_12w\n","\n","Number of features: 44\n","\n","Number of aggregated features: 6\n","\n","Feature: cyclostationary_mean_tg_16w\n","\n","Number of features: 44\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_tg_24w\n","\n","Number of features: 44\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr\n","\n","Number of features: 44\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_1w\n","\n","Number of features: 44\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_4w\n","\n","Number of features: 44\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_8w\n","\n","Number of features: 44\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_12w\n","\n","Number of features: 44\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_16w\n","\n","Number of features: 44\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_24w\n","\n","Number of features: 44\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_HS\n","\n","Number of features: 6\n","\n","Number of aggregated features: 2\n","\n","Feature: cyclostationary_mean_HS_1w\n","\n","Number of features: 6\n","\n","Number of aggregated features: 2\n","\n","Feature: cyclostationary_mean_HS_4w\n","\n","Number of features: 6\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_HS_8w\n","\n","Number of features: 6\n","\n","Number of aggregated features: 2\n","\n","Feature: cyclostationary_mean_HS_12w\n","\n","Number of features: 6\n","\n","Number of aggregated features: 2\n","\n","Feature: cyclostationary_mean_HS_16w\n","\n","Number of features: 6\n","\n","Number of aggregated features: 2\n","\n","Feature: cyclostationary_mean_HS_24w\n","\n","Number of features: 6\n","\n","Number of aggregated features: 2\n","\n","\n","\n","selected columns: ['cyclostationary_mean_tg_1w_4', 'cyclostationary_mean_rr_12w_2', 'cyclostationary_mean_tg_4w_0', 'cyclostationary_mean_rr_1w_2', 'cyclostationary_mean_rr_0', 'cyclostationary_mean_tg_8w_1', 'cyclostationary_mean_tg_12w_0', 'cyclostationary_mean_HS_24w_0', 'cyclostationary_mean_rr_4w_0', 'cyclostationary_mean_rr_4w_1', 'cyclostationary_mean_rr_24w_1', 'cyclostationary_mean_rr_12w_0', 'cyclostationary_mean_HS_12w_1', 'cyclostationary_mean_rr_4w_2', 'cyclostationary_mean_tg_8w_4', 'cyclostationary_mean_tg_1w_1', 'cyclostationary_mean_tg_12w_3', 'cyclostationary_mean_rr_2'], \n","\n","validation score: 0.13870667439485196, \n","\n","number of selected features: 18\n","\n","Full model and selected features with wrapper\n","\n","Full aggregate regression train score: 0.22796476490753992, test score: -0.7781113218050475\n","Aggregate regression train score with FS: 0.10200275833015526, test score: -0.42246581383917703\n","\n","Full model and best 5 selected features with wrapper\n","\n","Full aggregate regression train score: 0.22796476490753992, test score: -0.7781113218050475\n","Aggregate regression train score with FS: 0.08246687866339308, test score: -0.24996600110709344\n","----- MI Scores -----\n","[(1, 0.18311008543787263), (15, 0.15029486602168668), (3, 0.14251347397063163), (7, 0.13967902513995895), (0, 0.13610046518260246), (4, 0.12941582479221564), (2, 0.12029784219588677), (5, 0.11764740153841033), (6, 0.10873212507287427), (8, 0.07942198634167491), (16, 0.06788901569201063), (9, 0.06211487625030295), (48, 0.04990915725225257), (10, 0.049761698643724046), (14, 0.049223250869534406), (11, 0.048487681933389266), (54, 0.04817953164084569), (22, 0.0474929156334804), (62, 0.04576572935672787), (20, 0.04526697694913859), (21, 0.044978063622270754), (50, 0.044638409652222495), (12, 0.04260893931764306), (67, 0.040013009531334486), (56, 0.03902777761495003), (70, 0.032156004226739365), (64, 0.0320336185683358), (65, 0.031418432072367455), (31, 0.029549681293401773), (26, 0.02954834667827062), (58, 0.028777286998935715), (32, 0.028326394246474734), (17, 0.027913058818284833), (63, 0.027878165786693037), (36, 0.02776512268163746), (13, 0.02523913641330281), (68, 0.02370900879087618), (24, 0.023521509017530574), (59, 0.023049780840283415), (18, 0.02226106711458348), (19, 0.021965825768889394), (23, 0.021017040655454865), (61, 0.02100425696465217), (66, 0.020904796017072607), (69, 0.020793035403324684), (25, 0.01921761243595824), (53, 0.018821569318340888), (35, 0.018717958288988874), (51, 0.016706360989220445), (28, 0.01646519847260676), (33, 0.01605334293115042), (49, 0.015981056288371636), (34, 0.014653816570735457), (37, 0.011991242128002124), (29, 0.010934726206818943), (42, 0.010585074919523076), (30, 0.009601308832296694), (60, 0.008700893323262172), (39, 0.00786912914848228), (47, 0.007098720689944789), (52, 0.007033078187994072), (40, 0.006382847771990269), (43, 0.006237484405082845), (27, 0.0040804060085533845), (44, 0.0008615961910830387), (41, -2.310112055216437e-05), (57, -0.0001162422686535043), (45, -0.0005926272163619646), (55, -0.004126398699118372), (38, -0.008919001229446466), (46, -0.019058200333735925)]\n","Best MI score: 0.18311008543787263\n","Adding first best original feature: 1\n","CMI: 0.02754234023778776\n","CMI: 0.024950492642210775\n","CMI: 0.03334636325794693\n","CMI: 0.00908205676033394\n","CMI: 0.017440615699949313\n","CMI: 0.022438290090526253\n","CMI: 0.004074242471447803\n","CMI: 0.008306540775305737\n","CMI: 0.014496838669481843\n","CMI: 0.018551836178399922\n","CMI: 0.03175436193093481\n","CMI: 0.004635608054105789\n","CMI: 0.03846398235700976\n","CMI: 0.012107003487148243\n","CMI: 0.10913730101759075\n","CMI: 0.0004938596879730528\n","CMI: 0.02428972930570006\n","CMI: 0.0172861447399075\n","Highest CMI score: 0.10913730101759075\n","Adding original feature: 15\n","CMI: 0.0031885730795429557\n","CMI: 0.00031244089051168933\n","CMI: 0.008033430261150387\n","CMI: 0.0056530063125205254\n","CMI: 0.001444449582500118\n","CMI: 0.007642534940285051\n","CMI: 0.004258680246978119\n","CMI: 0.002574976467939416\n","CMI: 0.00044502152288100616\n","CMI: 0.002217802256509138\n","CMI: 0.004234706031833235\n","CMI: 0.020591857908598132\n","CMI: 0.01520747121512922\n","CMI: 0.02026948768808734\n","CMI: 0.016667522950552405\n","CMI: 0.02183473246733031\n","CMI: 0.019432307929527104\n","CMI: 0.009688931271327805\n","CMI: 0.002842373873215509\n","CMI: 0.0015883225271845491\n","CMI: 0.000673251720344048\n","CMI: 0.006623180485203217\n","CMI: 0.0063510554103394234\n","CMI: 0.006225229031613655\n","Highest CMI score: 0.02183473246733031\n","Adding original feature: 48\n","CMI: 0.00659433093427092\n","CMI: 0.0015525442278380708\n","CMI: 0.015493970815520564\n","CMI: 0.025363134497306206\n","CMI: 0.02141957196281541\n","CMI: 0.022190966689282166\n","CMI: 0.02614363725667679\n","CMI: 0.011353634467797469\n","CMI: 0.02560020842826799\n","CMI: 0.017854321153618513\n","CMI: 0.02322387161291306\n","CMI: 0.006974067221921176\n","CMI: 0.0015714015739785037\n","CMI: 0.00050100059494812\n","CMI: 0.002513299119436596\n","CMI: 0.0027747455167842494\n","CMI: 0.0031399987263641127\n","CMI: 0.007546395765595071\n","CMI: 0.007485646206162155\n","CMI: 0.010830981548995977\n","CMI: 0.011200986422193138\n","CMI: 0.012992823901610329\n","CMI: 0.00978799266108088\n","CMI: 0.0007218015453692161\n","CMI: 0.0030263771948499385\n","CMI: 0.009468151100254785\n","CMI: 0.0037726047613392266\n","CMI: 0.008970767241929856\n","CMI: 0.004015439489484018\n","CMI: 0.009627346145193894\n","CMI: 0.007324789009284127\n","CMI: 0.005210993379599682\n","CMI: 0.0028378685486903366\n","Highest CMI score: 0.02614363725667679\n","Adding original feature: 8\n","CMI: 0.00018119181555525943\n","CMI: 0.004033795075493729\n","CMI: 0.004534130671569214\n","CMI: 0.0029613947423788867\n","CMI: 0.0018441632890855986\n","CMI: 0.008436728700276841\n","CMI: 0.008043151773767465\n","CMI: 0.002735231085771228\n","CMI: 0.000995546130059366\n","CMI: 0.005419532424020879\n","CMI: 0.0026836394424171184\n","CMI: 0.0007930235810225672\n","CMI: 0.016746660136933544\n","CMI: 0.01608892617001223\n","CMI: 0.016586312584682905\n","CMI: 0.01533954235824908\n","CMI: 0.004190282097711939\n","CMI: 0.007045639738961662\n","CMI: 0.000788917061206762\n","CMI: 0.0043079545750586146\n","CMI: 0.011319344342260673\n","Highest CMI score: 0.016746660136933544\n","Adding original feature: 43\n","CMI: 0.0005786124505348655\n","CMI: 0.0029289352211221975\n","CMI: 0.0021734340283710574\n","CMI: 0.009945729473919418\n","CMI: 0.0011011420001186822\n","CMI: 0.0009733729917865142\n","Highest CMI score: 0.009945729473919418\n","Adding original feature: 12\n","CMI: 0.0012488268842754668\n","CMI: 0.00022814714622065857\n","CMI: 0.003449137670521518\n","CMI: 0.0022247547607269214\n","CMI: 0.0006222800121706284\n","CMI: 0.0013864452881393041\n","Highest CMI score: 0.003449137670521518\n","Adding original feature: 7\n","CMI: 0.0003619962551668632\n","CMI: 0.0010432984614722196\n","CMI: 0.0005772932820843346\n","CMI: 0.00017037561892158104\n","Highest CMI score: 0.0010432984614722196\n","Adding original feature: 13\n","CMI: 0.0007045981912619514\n","CMI: 0.00031662053290415493\n","CMI: 0.0016741258310992713\n","CMI: 5.9445782974509864e-05\n","CMI: 0.0014906538072438913\n","Highest CMI score: 0.0016741258310992713\n","Adding original feature: 45\n","CMI: 0.001786775556933684\n","Highest CMI score: 0.001786775556933684\n","Adding original feature: 49\n","Highest CMI score: -0.0010065882926422187\n","\n","[1, 15, 48, 8, 43, 12, 7, 13, 45, 49]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.22796476490753992, test score: -0.7781113218050475\n","Aggregate regression train score with FS: 0.04162016139123159, test score: -0.013064425568893645\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.22796476490753992, test score: -0.7781113218050475\n","Aggregate regression train score with FS: 0.029772062185903114, test score: -0.012354604513502565\n","###### Binary Classification ######\n","Train accuracy logistic regression CMI:  0.588\n","Test accuracy logistic regression CMI:  0.539 \n","\n","Train accuracy logistic regression CMI best 5:  0.581\n","Test accuracy logistic regression CMI best 5:  0.57 \n","\n","Train accuracy logistic regression wrapper:  0.606\n","Test accuracy logistic regression wrapper:  0.561 \n","\n","####################Piemonte_Nord####################\n","target samples:            date      mean  median  year  week  mean_std\n","0    2001-01-05  0.278983    0.00  2001     1         0\n","1    2001-01-13  0.494910    0.51  2001     2         1\n","2    2001-01-21  0.496092    0.51  2001     3         1\n","3    2001-01-29  0.427992    0.43  2001     5         0\n","4    2001-02-06  0.400512    0.41  2001     6         0\n","..          ...       ...     ...   ...   ...       ...\n","406  2009-11-27  0.363952    0.37  2009    48         0\n","407  2009-12-05  0.400487    0.40  2009    49         0\n","408  2009-12-13  0.506771    0.52  2009    50         1\n","409  2009-12-21  0.387530    0.53  2009    52         0\n","410  2009-12-29  0.279894    0.27  2009    53         0\n","\n","[411 rows x 6 columns]\n"," target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n","Feature: cyclostationary_mean_tg\n","\n","Number of features: 89\n","\n","Number of aggregated features: 9\n","\n","Feature: cyclostationary_mean_tg_1w\n","\n","Number of features: 89\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_4w\n","\n","Number of features: 89\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_tg_8w\n","\n","Number of features: 89\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_tg_12w\n","\n","Number of features: 89\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_tg_16w\n","\n","Number of features: 89\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_tg_24w\n","\n","Number of features: 89\n","\n","Number of aggregated features: 10\n","\n","Feature: cyclostationary_mean_rr\n","\n","Number of features: 89\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_1w\n","\n","Number of features: 89\n","\n","Number of aggregated features: 9\n","\n","Feature: cyclostationary_mean_rr_4w\n","\n","Number of features: 89\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_8w\n","\n","Number of features: 89\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_rr_12w\n","\n","Number of features: 89\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_16w\n","\n","Number of features: 89\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_24w\n","\n","Number of features: 89\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_HS\n","\n","Number of features: 5\n","\n","Number of aggregated features: 2\n","\n","Feature: cyclostationary_mean_HS_1w\n","\n","Number of features: 5\n","\n","Number of aggregated features: 2\n","\n","Feature: cyclostationary_mean_HS_4w\n","\n","Number of features: 5\n","\n","Number of aggregated features: 2\n","\n","Feature: cyclostationary_mean_HS_8w\n","\n","Number of features: 5\n","\n","Number of aggregated features: 2\n","\n","Feature: cyclostationary_mean_HS_12w\n","\n","Number of features: 5\n","\n","Number of aggregated features: 2\n","\n","Feature: cyclostationary_mean_HS_16w\n","\n","Number of features: 5\n","\n","Number of aggregated features: 2\n","\n","Feature: cyclostationary_mean_HS_24w\n","\n","Number of features: 5\n","\n","Number of aggregated features: 3\n","\n","\n","\n","selected columns: ['cyclostationary_mean_tg_1w_2', 'cyclostationary_mean_rr_1w_3', 'cyclostationary_mean_rr_24w_0', 'cyclostationary_mean_HS_8w_0', 'cyclostationary_mean_HS_1', 'cyclostationary_mean_rr_1w_0', 'cyclostationary_mean_rr_16w_0', 'cyclostationary_mean_HS_24w_0', 'cyclostationary_mean_tg_8w_0', 'cyclostationary_mean_tg_12w_1', 'cyclostationary_mean_tg_16w_0', 'cyclostationary_mean_tg_1w_1', 'cyclostationary_mean_tg_8w_4', 'cyclostationary_mean_tg_12w_2', 'cyclostationary_mean_HS_24w_1', 'cyclostationary_mean_rr_1w_6', 'cyclostationary_mean_tg_4w_2', 'cyclostationary_mean_HS_4w_1', 'cyclostationary_mean_rr_1w_8', 'cyclostationary_mean_tg_4w_4', 'cyclostationary_mean_rr_1w_5', 'cyclostationary_mean_rr_1w_4', 'cyclostationary_mean_rr_8w_0', 'cyclostationary_mean_rr_4w_1', 'cyclostationary_mean_rr_24w_1', 'cyclostationary_mean_tg_16w_1', 'cyclostationary_mean_tg_16w_2', 'cyclostationary_mean_tg_16w_4', 'cyclostationary_mean_tg_16w_3'], \n","\n","validation score: 0.2893752185705898, \n","\n","number of selected features: 29\n","\n","Full model and selected features with wrapper\n","\n","Full aggregate regression train score: 0.3276533436717207, test score: -0.31223501265064946\n","Aggregate regression train score with FS: 0.21982767933080694, test score: -0.1264480712172773\n","\n","Full model and best 5 selected features with wrapper\n","\n","Full aggregate regression train score: 0.3276533436717207, test score: -0.31223501265064946\n","Aggregate regression train score with FS: 0.16360452687002058, test score: 0.15691976289259701\n","----- MI Scores -----\n","[(3, 0.12947056765284407), (1, 0.11283788147272651), (19, 0.0856030770608996), (18, 0.07778501965167361), (20, 0.07319672077776422), (21, 0.07262113696636864), (62, 0.06793234317478616), (25, 0.06741274674314679), (57, 0.06597280298995706), (63, 0.0629846428854022), (15, 0.06009994985107116), (61, 0.05967618772387418), (65, 0.05898180227829219), (76, 0.057756303290887594), (17, 0.057626666410608075), (23, 0.05725671760119304), (16, 0.05461847350228548), (24, 0.0537549709167328), (58, 0.0516324218493014), (26, 0.04932062236712692), (22, 0.048867891860529124), (30, 0.04868301255783514), (83, 0.04616663408351521), (67, 0.04581078216678413), (64, 0.04365360590094661), (28, 0.04335584933447547), (80, 0.042811571469987604), (66, 0.04256784715636918), (79, 0.040812988232880494), (33, 0.0405066150024381), (84, 0.03923028420236608), (49, 0.039103317967859624), (29, 0.03868230085680102), (82, 0.03865679927018229), (69, 0.03826151367429518), (73, 0.03676070735347134), (0, 0.03606877843395367), (27, 0.03571754251976584), (5, 0.035129226618443136), (9, 0.03424908617139524), (81, 0.034134108883332626), (59, 0.033988631208898605), (7, 0.033265336772251575), (8, 0.031097402371006964), (75, 0.030542273778759673), (71, 0.029484438048305247), (11, 0.029338916533853263), (77, 0.028203347396219262), (56, 0.026952174746556343), (32, 0.026196595476859912), (74, 0.025749102689878196), (31, 0.02519741699553711), (13, 0.025033355604427012), (4, 0.02497706341783389), (42, 0.023412172650995662), (36, 0.023120288807236423), (34, 0.022624233366763703), (38, 0.022078625229650862), (68, 0.021955456491820586), (52, 0.021832984727761764), (14, 0.02165651270074619), (40, 0.021117435263182393), (78, 0.020847191965022), (2, 0.020329613254355134), (35, 0.020108224310386506), (50, 0.019452809581483144), (6, 0.018444451337167465), (54, 0.016959691435882877), (60, 0.01690311684506159), (51, 0.016468781873920105), (10, 0.016269739463553614), (44, 0.015664275496812093), (45, 0.011698234259527575), (46, 0.011654387250583759), (72, 0.011445009266239786), (70, 0.011412191251826019), (53, 0.011093931850562457), (55, 0.009507422983900919), (48, 0.008751913817516553), (39, 0.007804981016983812), (43, 0.005938892729732087), (37, 0.005038304324926465), (47, 0.0027217070388068014), (12, -0.00048074440519801714), (41, -0.004516942177767232)]\n","Best MI score: 0.12947056765284407\n","Adding first best original feature: 3\n","Highest CMI score: -0.008978038897721863\n","\n","[3]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.3276533436717207, test score: -0.31223501265064946\n","Aggregate regression train score with FS: 0.0053452259240691635, test score: -0.008613024448252737\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.3276533436717207, test score: -0.31223501265064946\n","Aggregate regression train score with FS: 0.0053452259240691635, test score: -0.008613024448252737\n","###### Binary Classification ######\n","Train accuracy logistic regression CMI:  0.573\n","Test accuracy logistic regression CMI:  0.544 \n","\n","Train accuracy logistic regression CMI best 5:  0.573\n","Test accuracy logistic regression CMI best 5:  0.544 \n","\n","Train accuracy logistic regression wrapper:  0.689\n","Test accuracy logistic regression wrapper:  0.675 \n","\n","####################Piemonte_Sud####################\n","target samples:            date      mean  median  year  week  mean_std\n","0    2001-01-05  0.278060    0.09  2001     1         0\n","1    2001-01-13  0.445159    0.48  2001     2         1\n","2    2001-01-21  0.488982    0.52  2001     3         1\n","3    2001-01-29  0.362487    0.37  2001     5         0\n","4    2001-02-06  0.430732    0.45  2001     6         0\n","..          ...       ...     ...   ...   ...       ...\n","406  2009-11-27  0.430379    0.44  2009    48         0\n","407  2009-12-05  0.419919    0.43  2009    49         0\n","408  2009-12-13  0.526648    0.55  2009    50         1\n","409  2009-12-21  0.457440    0.61  2009    52         1\n","410  2009-12-29  0.301938    0.38  2009    53         0\n","\n","[411 rows x 6 columns]\n"," target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n","Feature: cyclostationary_mean_tg\n","\n","Number of features: 176\n","\n","Number of aggregated features: 9\n","\n","Feature: cyclostationary_mean_tg_1w\n","\n","Number of features: 176\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_4w\n","\n","Number of features: 176\n","\n","Number of aggregated features: 11\n","\n","Feature: cyclostationary_mean_tg_8w\n","\n","Number of features: 176\n","\n","Number of aggregated features: 6\n","\n","Feature: cyclostationary_mean_tg_12w\n","\n","Number of features: 176\n","\n","Number of aggregated features: 7\n","\n","Feature: cyclostationary_mean_tg_16w\n","\n","Number of features: 176\n","\n","Number of aggregated features: 7\n","\n","Feature: cyclostationary_mean_tg_24w\n","\n","Number of features: 176\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_rr\n","\n","Number of features: 176\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_1w\n","\n","Number of features: 176\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_rr_4w\n","\n","Number of features: 176\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_rr_8w\n","\n","Number of features: 176\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_rr_12w\n","\n","Number of features: 176\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_16w\n","\n","Number of features: 176\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_rr_24w\n","\n","Number of features: 176\n","\n","Number of aggregated features: 10\n","\n","Feature: cyclostationary_mean_HS\n","\n","Number of features: 3\n","\n","Number of aggregated features: 2\n","\n","Feature: cyclostationary_mean_HS_1w\n","\n","Number of features: 3\n","\n","Number of aggregated features: 2\n","\n","Feature: cyclostationary_mean_HS_4w\n","\n","Number of features: 3\n","\n","Number of aggregated features: 2\n","\n","Feature: cyclostationary_mean_HS_8w\n","\n","Number of features: 3\n","\n","Number of aggregated features: 2\n","\n","Feature: cyclostationary_mean_HS_12w\n","\n","Number of features: 3\n","\n","Number of aggregated features: 2\n","\n","Feature: cyclostationary_mean_HS_16w\n","\n","Number of features: 3\n","\n","Number of aggregated features: 2\n","\n","Feature: cyclostationary_mean_HS_24w\n","\n","Number of features: 3\n","\n","Number of aggregated features: 2\n","\n","\n","\n","selected columns: ['cyclostationary_mean_rr_24w_9', 'cyclostationary_mean_tg_1w_0', 'cyclostationary_mean_tg_4w_0', 'cyclostationary_mean_HS_12w_0', 'cyclostationary_mean_rr_1w_1', 'cyclostationary_mean_HS_4w_1', 'cyclostationary_mean_HS_1', 'cyclostationary_mean_rr_8w_4', 'cyclostationary_mean_rr_8w_1', 'cyclostationary_mean_tg_4w_6', 'cyclostationary_mean_tg_1w_1', 'cyclostationary_mean_tg_4w_1', 'cyclostationary_mean_HS_8w_0', 'cyclostationary_mean_tg_8w_0', 'cyclostationary_mean_tg_12w_2', 'cyclostationary_mean_tg_4w_3', 'cyclostationary_mean_tg_4w_4', 'cyclostationary_mean_tg_8w_3'], \n","\n","validation score: 0.18623696414852964, \n","\n","number of selected features: 18\n","\n","Full model and selected features with wrapper\n","\n","Full aggregate regression train score: 0.35536544906157463, test score: -0.16534404684267257\n","Aggregate regression train score with FS: 0.15316778754785365, test score: 0.20128918507612958\n","\n","Full model and best 5 selected features with wrapper\n","\n","Full aggregate regression train score: 0.35536544906157463, test score: -0.16534404684267257\n","Aggregate regression train score with FS: 0.13580142754351288, test score: 0.18188629296473124\n","----- MI Scores -----\n","[(0, 0.1079294457400957), (2, 0.09759086867014657), (5, 0.09068970369374393), (1, 0.08925459068467705), (3, 0.08413560951790458), (87, 0.08200850856608967), (74, 0.08154690581958109), (78, 0.08023291869911069), (7, 0.07838336116576927), (81, 0.0629908421980839), (18, 0.06212115034027274), (89, 0.061744893447564855), (80, 0.060099051123127654), (14, 0.05956983162587209), (79, 0.05894765826363212), (84, 0.057934959502322275), (15, 0.057602292145096025), (21, 0.05464496889320559), (88, 0.05431411137050112), (67, 0.05367877612604142), (91, 0.05319540609544913), (73, 0.050732545342190835), (83, 0.050465614323542025), (8, 0.0501114918230622), (4, 0.04928329077696161), (90, 0.04916063735953679), (22, 0.04681517469213911), (77, 0.04617336978819419), (94, 0.04543222563947015), (92, 0.04533310176074148), (20, 0.045052269889246904), (86, 0.04477870197126896), (23, 0.044769537363075436), (93, 0.04355459180251414), (16, 0.04343289365811805), (6, 0.04246432909374095), (17, 0.0417868472724813), (24, 0.041773617585347846), (10, 0.039953495678922195), (82, 0.03887120823527717), (85, 0.037631651462370214), (64, 0.036966773820623695), (68, 0.03634273304006359), (38, 0.03502389592772381), (60, 0.0347736205648071), (58, 0.03460667316162251), (33, 0.03427092270734588), (30, 0.03348380724484556), (69, 0.03320277797598067), (29, 0.03239698796363692), (19, 0.032051172621270434), (57, 0.03180796687499343), (72, 0.030782641465693376), (76, 0.03006359949514149), (75, 0.02980769319572087), (13, 0.029306615968221175), (25, 0.02838688411780525), (49, 0.027349240770115694), (32, 0.026311389289508137), (62, 0.02610067202470866), (48, 0.025828952248301024), (66, 0.024446883185316477), (42, 0.024348715025695498), (9, 0.023570688039926454), (35, 0.02232512958228674), (71, 0.020025867145619183), (50, 0.018619517261129467), (55, 0.018377963109651525), (70, 0.017263718767361245), (59, 0.016777702848484313), (12, 0.016348946888473305), (11, 0.01571035783470338), (37, 0.015651398778694942), (28, 0.01523262046234758), (27, 0.015074381202541402), (65, 0.013401794249678295), (45, 0.011131724639962518), (31, 0.010399524382419865), (61, 0.010040067145444122), (41, 0.00980393028895221), (63, 0.008946433298220462), (47, 0.007574430769672911), (34, 0.007156607895982135), (44, 0.006391187205660978), (52, 0.005526506549551533), (40, 0.004050619326110653), (54, 0.0030768024456542297), (39, 0.003003511969135791), (36, -0.0013640603849972674), (56, -0.0016723470124216284), (26, -0.0018746298011408358), (46, -0.004719378225670808), (43, -0.005267540018887923), (53, -0.010559100607039443), (51, -0.021472999624162267)]\n","Best MI score: 0.1079294457400957\n","Adding first best original feature: 0\n","CMI: 0.04404435631936916\n","CMI: 0.0069594250057360835\n","CMI: 0.05031792587276872\n","CMI: 0.03024711017905672\n","CMI: 0.009121923959486244\n","CMI: 0.0020386815511490436\n","CMI: 0.0043693982263595665\n","CMI: 0.0008864002214116345\n","CMI: 0.005983466188065542\n","CMI: 0.006623779063380533\n","CMI: 0.009496788711774506\n","CMI: 0.008122571177258883\n","Highest CMI score: 0.05031792587276872\n","Adding original feature: 3\n","CMI: 0.02444532552508269\n","CMI: 0.0005255529040988915\n","Highest CMI score: 0.02444532552508269\n","Adding original feature: 1\n","CMI: 0.0023456228910412324\n","Highest CMI score: 0.0023456228910412324\n","Adding original feature: 2\n","Highest CMI score: -0.012619327431859478\n","\n","[0, 3, 1, 2]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.35536544906157463, test score: -0.16534404684267257\n","Aggregate regression train score with FS: 0.011630267444949549, test score: -0.006959529706205947\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.35536544906157463, test score: -0.16534404684267257\n","Aggregate regression train score with FS: 0.011630267444949549, test score: -0.006959529706205947\n","###### Binary Classification ######\n","Train accuracy logistic regression CMI:  0.607\n","Test accuracy logistic regression CMI:  0.618 \n","\n","Train accuracy logistic regression CMI best 5:  0.607\n","Test accuracy logistic regression CMI best 5:  0.618 \n","\n","Train accuracy logistic regression wrapper:  0.656\n","Test accuracy logistic regression wrapper:  0.741 \n","\n"]}],"source":["basins = ['Ticino', 'Adda', 'Oglio_Iseo', 'Dora', 'Piemonte_Nord', 'Piemonte_Sud']\n","\n","path_target = \"./csv/\"\n","path_features_snow = './features_allvalues/snow/copernicus/relevant_coords/'\n","path_features='./features_allvalues/'\n","\n","destination_folder = './GenLinCFA/temp_prec_snow_copernicus/'\n","\n","for basin in basins:\n","    print('####################' + basin + '####################')\n","\n","    target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target_binary('',max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01',\n","      path=path_target+basin+'.csv')\n","\n","    eps = 0.37\n","    actual_path = path_features+basin+'_aggreg.csv'\n","    snow_actual_path = path_features_snow+basin+'_aggreg_sd_allCoord.csv'\n","\n","    output,aggregate_trainVal,aggregate_test = aggregate_unfolded_data(actual_path,['cyclostationary_mean_tg',\n","                                                                             'cyclostationary_mean_tg_1w',\n","                                                                             'cyclostationary_mean_tg_4w',\n","                                                                             'cyclostationary_mean_tg_8w',\n","                                                                             'cyclostationary_mean_tg_12w',\n","                                                                             'cyclostationary_mean_tg_16w',\n","                                                                             'cyclostationary_mean_tg_24w',\n","                                                                             'cyclostationary_mean_rr',\n","                                                                             'cyclostationary_mean_rr_1w',\n","                                                                             'cyclostationary_mean_rr_4w',\n","                                                                             'cyclostationary_mean_rr_8w',\n","                                                                             'cyclostationary_mean_rr_12w',\n","                                                                             'cyclostationary_mean_rr_16w',\n","                                                                             'cyclostationary_mean_rr_24w'\n","                                                                            ],\n","                                                                       target_df_trainVal, eps=eps,\n","                                                                       max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01')\n","\n","    if os.path.isfile(snow_actual_path):\n","      output_snow,aggregate_trainVal_snow,aggregate_test_snow = aggregate_unfolded_data(snow_actual_path,['cyclostationary_mean_HS',\n","                                                                              'cyclostationary_mean_HS_1w',\n","                                                                              'cyclostationary_mean_HS_4w',\n","                                                                              'cyclostationary_mean_HS_8w',\n","                                                                              'cyclostationary_mean_HS_12w',\n","                                                                              'cyclostationary_mean_HS_16w',\n","                                                                              'cyclostationary_mean_HS_24w'\n","                                                                              ],\n","                                                                        target_df_trainVal, eps=eps,\n","                                                                        max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01', scale = 0.26)\n","\n","      aggregate_trainVal = pd.concat((aggregate_trainVal_snow,aggregate_trainVal),axis=1)\n","      aggregate_test = pd.concat((aggregate_test_snow,aggregate_test),axis=1)\n","\n","    selected_colnames = FS_with_linearWrapper(aggregate_trainVal, target_df_train, target_df_val, min(50,aggregate_trainVal.shape[1]-1), 228)\n","\n","    print('\\nFull model and selected features with wrapper\\n')\n","    compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n","\n","    print('\\nFull model and best 5 selected features with wrapper\\n')\n","    compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames[0:5])\n","\n","    train_string = destination_folder + basin + '_genLinCFA_wrapper_best5_train_withSnow.csv'\n","    val_string = destination_folder + basin + '_genLinCFA_wrapper_best5_val_withSnow.csv'\n","    test_string = destination_folder + basin + '_genLinCFA_wrapper_best5_test_withSnow.csv'\n","    X_train_wrapper = aggregate_trainVal.loc[:410,selected_colnames[0:5]]\n","    X_validation_wrapper = aggregate_trainVal.loc[411:,selected_colnames[0:5]]\n","    X_train_validation_wrapper = pd.concat([X_train_wrapper, X_validation_wrapper])\n","    X_test_wrapper = aggregate_test.loc[:,selected_colnames[0:5]]\n","    X_train_wrapper.to_csv(train_string, index=False)\n","    X_validation_wrapper.to_csv(val_string, index=False)\n","    X_test_wrapper.to_csv(test_string, index=False)\n","\n","    res = {\n","            \"delta\" : [],\n","            \"numSelected\" : [],\n","            \"selectedFeatures\" : []\n","        }\n","\n","    res['selectedFeatures'] = forwardFeatureSelection(10,np.array(aggregate_trainVal),\n","                                                      np.array(target_df_trainVal.mean_std),res,10,1)\n","\n","    selectedFeatures='selectedFeatures'\n","    print(f'\\n{res[selectedFeatures]}\\n')\n","\n","    selected_colnames = aggregate_trainVal.columns[res['selectedFeatures']]\n","\n","    print('\\nFull model and selected features with CMI\\n')\n","    compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n","\n","    print('\\nFull model and best 5 selected features with CMI\\n')\n","    compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames[0:5])\n","\n","    train_string = destination_folder + basin + '_genLinCFA_best5_CMI_train_withSnow.csv'\n","    val_string = destination_folder + basin + '_genLinCFA_best5_CMI_val_withSnow.csv'\n","    test_string = destination_folder + basin + '_genLinCFA_best5_CMI_test_withSnow.csv'\n","\n","    X_train_CMI5 = aggregate_trainVal.loc[:410,selected_colnames[0:5]]\n","    X_validation_CMI5 = aggregate_trainVal.loc[411:,selected_colnames[0:5]]\n","    X_train_validation_CMI5 = pd.concat([X_train_CMI5, X_validation_CMI5])\n","    X_test_CMI5 = aggregate_test.loc[:,selected_colnames[0:5]]\n","\n","    selected_colnames_CMI5 = aggregate_trainVal.loc[:,selected_colnames[0:5]].columns.values\n","\n","    X_train_CMI5.to_csv(train_string, index=False)\n","    X_validation_CMI5.to_csv(val_string, index=False)\n","    X_test_CMI5.to_csv(test_string, index=False)\n","\n","    train_string = destination_folder + basin + '_genLinCFA_CMI_train_withSnow.csv'\n","    val_string = destination_folder + basin + '_genLinCFA_CMI_val_withSnow.csv'\n","    test_string = destination_folder + basin + '_genLinCFA_CMI_test_withSnow.csv'\n","\n","    X_train_CMI = aggregate_trainVal.loc[:410,selected_colnames]\n","    X_validation_CMI = aggregate_trainVal.loc[411:,selected_colnames]\n","    X_train_validation_CMI = pd.concat([X_train_CMI, X_validation_CMI])\n","    X_test_CMI = aggregate_test.loc[:,selected_colnames]\n","\n","    X_train_CMI.to_csv(train_string, index=False)\n","    X_validation_CMI.to_csv(val_string, index=False)\n","    X_test_CMI.to_csv(test_string, index=False)\n","\n","    print('###### Binary Classification ######')\n","\n","    target_df_train = target_df_train.apply(lambda x: np.sign(x.mean_std), axis=1)\n","    target_df_val = target_df_val.apply(lambda x: np.sign(x.mean_std), axis=1)\n","    target_df_test = target_df_test.apply(lambda x: np.sign(x.mean_std), axis=1)\n","    target_df_trainVal = target_df_trainVal.apply(lambda x: np.sign(x.mean_std), axis=1)\n","\n","    log_regr = LogisticRegression(solver='lbfgs', random_state = 42)\n","\n","    # CMI\n","    log_regr.fit(X_train_validation_CMI, target_df_trainVal)\n","    print(\"Train accuracy logistic regression CMI: \", round(log_regr.score(X_train_validation_CMI, target_df_trainVal),3))\n","    print(\"Test accuracy logistic regression CMI: \", round(log_regr.score(X_test_CMI, target_df_test),3), \"\\n\")\n","\n","    # CMI best 5\n","    log_regr.fit(X_train_validation_CMI5, target_df_trainVal)\n","    print(\"Train accuracy logistic regression CMI best 5: \", round(log_regr.score(X_train_validation_CMI5, target_df_trainVal),3))\n","    print(\"Test accuracy logistic regression CMI best 5: \", round(log_regr.score(X_test_CMI5, target_df_test),3), \"\\n\")\n","\n","    # wrapper\n","    log_regr.fit(X_train_validation_wrapper, target_df_trainVal)\n","    print(\"Train accuracy logistic regression wrapper: \", round(log_regr.score(X_train_validation_wrapper, target_df_trainVal),3))\n","    print(\"Test accuracy logistic regression wrapper: \", round(log_regr.score(X_test_wrapper, target_df_test),3), \"\\n\")"],"id":"_gV8G4C6Iyaz"},{"cell_type":"markdown","metadata":{"id":"NHQGqoo7z-9g"},"source":["## Temp Prec Snow Lakes"],"id":"NHQGqoo7z-9g"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cnfAdqhIwWaA","executionInfo":{"status":"ok","timestamp":1690242094304,"user_tz":-120,"elapsed":3064367,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"}},"outputId":"246acb4b-86ed-48af-c1c6-75c9e135bcd8"},"outputs":[{"output_type":"stream","name":"stdout","text":["####################Ticino####################\n","target samples:            date      mean  median  year  week  mean_std\n","0    2001-01-05  0.264043    0.00  2001     1         0\n","1    2001-01-13  0.354618    0.39  2001     2         0\n","2    2001-01-21  0.427990    0.47  2001     3         1\n","3    2001-01-29  0.339495    0.35  2001     5         0\n","4    2001-02-06  0.324134    0.34  2001     6         0\n","..          ...       ...     ...   ...   ...       ...\n","406  2009-11-27  0.332713    0.35  2009    48         0\n","407  2009-12-05  0.370253    0.40  2009    49         0\n","408  2009-12-13  0.517201    0.57  2009    50         1\n","409  2009-12-21  0.353636    0.45  2009    52         0\n","410  2009-12-29  0.261079    0.00  2009    53         0\n","\n","[411 rows x 6 columns]\n"," target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n","Feature: cyclostationary_mean_tg\n","\n","Number of features: 92\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_tg_1w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_4w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_8w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_tg_12w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 6\n","\n","Feature: cyclostationary_mean_tg_16w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 6\n","\n","Feature: cyclostationary_mean_tg_24w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_rr\n","\n","Number of features: 92\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_1w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_rr_4w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_8w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_12w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_16w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_rr_24w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 8\n","\n","Feature: cyclostationary_mean_HS\n","\n","Number of features: 11\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_HS_1w\n","\n","Number of features: 11\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_HS_4w\n","\n","Number of features: 11\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_HS_8w\n","\n","Number of features: 11\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_HS_12w\n","\n","Number of features: 11\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_HS_16w\n","\n","Number of features: 11\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_HS_24w\n","\n","Number of features: 11\n","\n","Number of aggregated features: 3\n","\n","\n","\n","selected columns: ['cyclostationary_mean_tg_1w_1', 'cyclostationary_mean_rr_24w_2', 'cyclostationary_mean_HS_2', 'cyclostationary_mean_tg_4w_0', 'cyclostationary_mean_HS_4w_0', 'cyclostat_release_Lugano_24w', 'cyclostationary_mean_HS_24w_1', 'cyclostationary_mean_HS_16w_0', 'cyclostationary_mean_HS_4w_1', 'cyclostat_release_Maggiore_16w', 'cyclostationary_mean_tg_4w_2', 'cyclostationary_mean_tg_8w_1', 'cyclostationary_mean_tg_8w_0', 'cyclostat_level_Maggiore_24w', 'cyclostationary_mean_HS_0', 'cyclostationary_mean_HS_1w_0', 'cyclostat_inflow_Maggiore_1w', 'cyclostat_release_Maggiore_4w', 'cyclostat_release_Lugano', 'cyclostationary_mean_rr_4w_0', 'cyclostat_level_Maggiore_16w', 'cyclostationary_mean_rr_24w_0', 'cyclostat_level_Lugano_8w', 'cyclostat_inflow_Lugano_16w', 'cyclostationary_mean_tg_1w_2', 'cyclostationary_mean_tg_12w_0', 'cyclostationary_mean_tg_16w_0', 'cyclostationary_mean_tg_16w_4', 'cyclostat_release_Maggiore_1w', 'cyclostat_inflow_Lugano', 'cyclostationary_mean_HS_4w_2', 'cyclostationary_mean_tg_1w_0'], \n","\n","validation score: 0.317466824945547, \n","\n","number of selected features: 32\n","\n","Full model and selected features with wrapper\n","\n","Full aggregate regression train score: 0.3861510486280426, test score: -2.6113658074932418\n","Aggregate regression train score with FS: 0.211332320389218, test score: 0.05603985729245886\n","\n","Full model and best 5 selected features with wrapper\n","\n","Full aggregate regression train score: 0.3861510486280426, test score: -2.6113658074932418\n","Aggregate regression train score with FS: 0.13730080872886263, test score: 0.17334215588575708\n","----- MI Scores -----\n","[(23, 0.07619436851140222), (94, 0.07441931312520626), (24, 0.06906896931200217), (28, 0.06852056802960067), (26, 0.06660455307361404), (100, 0.0649726352239712), (101, 0.062483949125827526), (99, 0.061154834101528735), (25, 0.06088807942810209), (92, 0.060736978758319904), (2, 0.05929109833866007), (5, 0.05928214829064438), (27, 0.05824310484330773), (10, 0.05762123797478628), (93, 0.05545239440512146), (22, 0.05522297523167413), (69, 0.054295157155189296), (102, 0.05402631062788339), (96, 0.05325044233230598), (14, 0.05294538750989553), (85, 0.0519394248321001), (7, 0.05008060155676763), (107, 0.04880568810789905), (12, 0.048115163751890434), (3, 0.047662862897362934), (6, 0.047488824285564515), (31, 0.04657151971199622), (98, 0.046524553871722725), (4, 0.04646357249807251), (40, 0.04529046878737617), (39, 0.044000308482937525), (1, 0.04325127304478813), (29, 0.0427709935947236), (0, 0.042035023528088925), (57, 0.04202737177106451), (68, 0.04190789459252143), (58, 0.041818526764121115), (103, 0.04109799818598041), (97, 0.0402256309956469), (56, 0.038827653046544175), (95, 0.03753729733788644), (84, 0.03671730847957851), (120, 0.03663755485539108), (9, 0.03635488670481026), (17, 0.03604253869034865), (60, 0.03455350135826824), (118, 0.03431038625228101), (111, 0.03370025462479971), (72, 0.03243262035231984), (63, 0.032002396320943746), (112, 0.03160172786979048), (11, 0.031306399567740555), (32, 0.030877908471773914), (108, 0.030603657060409385), (79, 0.03015489995525939), (74, 0.029096993004445224), (8, 0.02885205461310632), (38, 0.0287590274396903), (121, 0.02872009974401041), (88, 0.028094508200157096), (13, 0.026425347803298162), (61, 0.0261434086834642), (124, 0.026055107062926502), (117, 0.025095397734455085), (73, 0.024707407342511152), (18, 0.024689691981805942), (62, 0.024333897539835253), (15, 0.023846899449943507), (75, 0.023793929211500614), (34, 0.023326683582522715), (20, 0.023058379432511877), (71, 0.022787553903856228), (59, 0.02253515338620965), (80, 0.02185642353004048), (77, 0.021201045477643902), (46, 0.019683674697863963), (50, 0.019401056144409373), (81, 0.019311135066338005), (70, 0.018781723381094045), (109, 0.01803193206066688), (19, 0.017471507039664946), (115, 0.017058757431385744), (64, 0.017045569016774356), (35, 0.016828879265827934), (36, 0.015451812824777122), (37, 0.015049707608688807), (110, 0.015013385946260248), (43, 0.014917791231975104), (53, 0.014679133520503993), (48, 0.013936453922602928), (30, 0.01384838851225433), (123, 0.013396341346383178), (104, 0.012928991013933152), (44, 0.012832363091462967), (67, 0.012682459160006404), (45, 0.012641765001735271), (55, 0.012114109290322368), (87, 0.012078822162635745), (89, 0.0116198079023633), (47, 0.010825060037588714), (91, 0.01045440605539172), (122, 0.010382096110601088), (51, 0.009671990696651625), (78, 0.008418213346720669), (76, 0.008294665702062911), (65, 0.008282081820316934), (119, 0.008001844377611396), (116, 0.007458266268690884), (90, 0.0071766066539365935), (54, 0.0071560037046853875), (33, 0.007091986352875644), (105, 0.00604328321888007), (21, 0.00583643818913481), (86, 0.005235279751429141), (41, 0.004483391034735937), (114, 0.004445007921873684), (52, 0.003241891707893248), (83, 0.0022707314974768425), (49, 0.0012844786940756298), (82, 0.0010400024002533803), (66, 0.0003457871689164371), (106, -0.000623613565416523), (113, -0.0027287068103524032), (16, -0.0060867750361585805), (42, -0.007011565293243101)]\n","Best MI score: 0.07619436851140222\n","Adding first best original feature: 23\n","CMI: 0.0424885078417675\n","CMI: 0.033656431636816586\n","CMI: 0.032995623999975174\n","CMI: 0.03665754204703467\n","CMI: 0.035430390353333244\n","CMI: 0.03878228559118106\n","CMI: 0.029578745769049203\n","CMI: 0.04339112873729373\n","CMI: 0.03114974838495596\n","CMI: 0.0331602511970205\n","CMI: 0.018507389058177087\n","CMI: 0.01590100703986909\n","CMI: 0.007376007147363597\n","CMI: 0.019837781635328178\n","CMI: 0.030006971090245027\n","CMI: 0.014536629137015283\n","CMI: 0.030459934079421686\n","CMI: 0.0167277515023172\n","CMI: 0.024202491141198365\n","CMI: 0.005177922485420358\n","CMI: 0.00784749952241108\n","CMI: 0.013624819098180724\n","CMI: 0.0024070241981222484\n","CMI: 0.01096956243228181\n","CMI: 0.00204696544792983\n","CMI: 0.003927566539001892\n","CMI: 0.001407862232270643\n","CMI: 0.0009120306323470301\n","CMI: 0.0030631925499413487\n","CMI: 0.002637055565816629\n","CMI: 0.018046360346559306\n","CMI: 0.0014556706061218394\n","CMI: 0.013220938789374567\n","CMI: 0.013776169253487042\n","CMI: 0.01304102841356708\n","CMI: 0.0027315178852214544\n","CMI: 0.017453087007609086\n","CMI: 0.007181260541283985\n","CMI: 0.023217874671034144\n","CMI: 0.010756090479374522\n","CMI: 0.020791192106256393\n","CMI: 0.000614257354135353\n","CMI: 0.011231497019055625\n","CMI: 0.035245872115852867\n","CMI: 0.02743734432527563\n","CMI: 0.031068821063846244\n","CMI: 0.005821446583474527\n","CMI: 0.003199939712128397\n","CMI: 0.012861191773261352\n","CMI: 0.004954082178859065\n","CMI: 0.012409545659913701\n","CMI: 0.02216986812888805\n","CMI: 0.001491152662443443\n","CMI: 0.012320150079380296\n","CMI: 0.014394868486600584\n","CMI: 0.015710572519931423\n","CMI: 0.008449297219921423\n","CMI: 0.005359375209194328\n","CMI: 0.0015980427824700966\n","CMI: 0.004729961990848297\n","CMI: 0.0016334117291859074\n","CMI: 0.025908770651699206\n","CMI: 0.007254437389563023\n","CMI: 0.0006989261845866263\n","CMI: 0.0017617818013760528\n","CMI: 0.03235101205349755\n","CMI: 0.04451309218245032\n","CMI: 0.06274910140135324\n","CMI: 0.04688600569028524\n","CMI: 0.07604106875566262\n","CMI: 0.07820251929407833\n","CMI: 0.03352105473726619\n","CMI: 0.06536070011399113\n","CMI: 0.07053027474182182\n","CMI: 0.06325241609656686\n","CMI: 0.07512071122754112\n","CMI: 0.06159443434064825\n","CMI: 0.00420095863000762\n","CMI: 0.011087294071173051\n","CMI: 0.004818307176485986\n","CMI: 0.013327223392531715\n","CMI: 0.007592193990890117\n","CMI: 0.0003966652364949669\n","Highest CMI score: 0.07820251929407833\n","Adding original feature: 97\n","CMI: 0.014162245573949989\n","CMI: 0.002042443648491571\n","CMI: 0.023094378273632976\n","CMI: 0.004871348373749335\n","CMI: 0.00034092158075052503\n","CMI: 0.009684719298066191\n","CMI: 0.012033931188334512\n","CMI: 0.006748927363219942\n","CMI: 0.0040350376129183185\n","CMI: 0.0004494317018657601\n","CMI: 0.014917796244612785\n","CMI: 0.014828443274983172\n","CMI: 0.00019675251132261762\n","CMI: 0.005367333687960801\n","CMI: 0.0005077016467180673\n","CMI: 0.006906046162236973\n","CMI: 0.002787162718989711\n","CMI: 0.0040462783323144125\n","CMI: 0.008055103436937217\n","CMI: 0.008752568992005938\n","CMI: 0.00023698404745559065\n","CMI: 0.009777475472491998\n","CMI: 0.003171706306189598\n","CMI: 0.0027166454287841646\n","CMI: 0.0017503132339033445\n","CMI: 0.0034353062891590014\n","CMI: 0.0010147645209668266\n","CMI: 0.0005273569465762962\n","Highest CMI score: 0.023094378273632976\n","Adding original feature: 22\n","CMI: 0.0032457784476212503\n","CMI: 0.0031728835117390553\n","CMI: 0.005413144503614853\n","CMI: 3.292299519816466e-05\n","CMI: 0.0023654461465001386\n","CMI: 0.0028914635063249094\n","CMI: 0.0018542431720025288\n","Highest CMI score: 0.005413144503614853\n","Adding original feature: 26\n","CMI: 0.0011054647387278571\n","CMI: 0.00025670996685378533\n","CMI: 0.0008777971572518639\n","CMI: 0.001147400655581443\n","Highest CMI score: 0.001147400655581443\n","Adding original feature: 111\n","CMI: 0.0013979972272976093\n","Highest CMI score: 0.0013979972272976093\n","Adding original feature: 24\n","CMI: 0.002592751137194066\n","Highest CMI score: 0.002592751137194066\n","Adding original feature: 108\n","Highest CMI score: 0.0\n","\n","[23, 97, 22, 26, 111, 24, 108]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.3861510486280426, test score: -2.6113658074932418\n","Aggregate regression train score with FS: 0.13887647527800873, test score: 0.11521803609963266\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.3861510486280426, test score: -2.6113658074932418\n","Aggregate regression train score with FS: 0.13724594973272608, test score: 0.12451069948934679\n","###### Binary Classification ######\n","Train accuracy logistic regression CMI:  0.66\n","Test accuracy logistic regression CMI:  0.667 \n","\n","Train accuracy logistic regression CMI best 5:  0.678\n","Test accuracy logistic regression CMI best 5:  0.649 \n","\n","Train accuracy logistic regression wrapper:  0.659\n","Test accuracy logistic regression wrapper:  0.706 \n","\n","####################Oglio_Iseo####################\n","target samples:            date      mean  median  year  week  mean_std\n","0    2001-01-05  0.243674    0.26  2001     1         0\n","1    2001-01-13  0.424116    0.44  2001     2         0\n","2    2001-01-21  0.393786    0.39  2001     3         0\n","3    2001-01-29  0.314939    0.31  2001     5         0\n","4    2001-02-06  0.464902    0.48  2001     6         1\n","..          ...       ...     ...   ...   ...       ...\n","406  2009-11-27  0.465734    0.48  2009    48         1\n","407  2009-12-05  0.447390    0.47  2009    49         1\n","408  2009-12-13  0.556760    0.59  2009    50         1\n","409  2009-12-21  0.307880    0.00  2009    52         0\n","410  2009-12-29  0.034211    0.00  2009    53         0\n","\n","[411 rows x 6 columns]\n"," target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n","Feature: cyclostationary_mean_tg\n","\n","Number of features: 74\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_tg_1w\n","\n","Number of features: 74\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_tg_4w\n","\n","Number of features: 74\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_tg_8w\n","\n","Number of features: 74\n","\n","Number of aggregated features: 6\n","\n","Feature: cyclostationary_mean_tg_12w\n","\n","Number of features: 74\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_tg_16w\n","\n","Number of features: 74\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_tg_24w\n","\n","Number of features: 74\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr\n","\n","Number of features: 74\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_rr_1w\n","\n","Number of features: 74\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_4w\n","\n","Number of features: 74\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_rr_8w\n","\n","Number of features: 74\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_12w\n","\n","Number of features: 74\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_rr_16w\n","\n","Number of features: 74\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_rr_24w\n","\n","Number of features: 74\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_HS\n","\n","Number of features: 2\n","\n","Number of aggregated features: 2\n","\n","Feature: cyclostationary_mean_HS_1w\n","\n","Number of features: 2\n","\n","Number of aggregated features: 2\n","\n","Feature: cyclostationary_mean_HS_4w\n","\n","Number of features: 2\n","\n","Number of aggregated features: 2\n","\n","Feature: cyclostationary_mean_HS_8w\n","\n","Number of features: 2\n","\n","Number of aggregated features: 2\n","\n","Feature: cyclostationary_mean_HS_12w\n","\n","Number of features: 2\n","\n","Number of aggregated features: 2\n","\n","Feature: cyclostationary_mean_HS_16w\n","\n","Number of features: 2\n","\n","Number of aggregated features: 2\n","\n","Feature: cyclostationary_mean_HS_24w\n","\n","Number of features: 2\n","\n","Number of aggregated features: 2\n","\n","\n","\n","selected columns: ['cyclostationary_mean_tg_3', 'cyclostationary_mean_rr_4w_2', 'cyclostationary_mean_rr_16w_0', 'cyclostationary_mean_rr_8w_2', 'cyclostationary_mean_HS_1w_0', 'cyclostationary_mean_rr_16w_3', 'cyclostat_release_Iseo_24w', 'cyclostationary_mean_rr_1w_0', 'cyclostationary_mean_tg_16w_0', 'cyclostationary_mean_tg_24w_1', 'cyclostationary_mean_HS_1', 'cyclostationary_mean_HS_0', 'cyclostationary_mean_tg_1', 'cyclostationary_mean_rr_12w_0', 'cyclostationary_mean_rr_8w_1', 'cyclostationary_mean_rr_12w_1', 'cyclostationary_mean_rr_4w_3', 'cyclostationary_mean_tg_24w_0', 'cyclostat_release_Iseo_4w', 'cyclostat_inflow_Iseo_4w', 'cyclostat_release_Iseo', 'cyclostationary_mean_HS_24w_1', 'cyclostationary_mean_HS_24w_0', 'cyclostationary_mean_HS_12w_1'], \n","\n","validation score: 0.27812966268626615, \n","\n","number of selected features: 24\n","\n","Full model and selected features with wrapper\n","\n","Full aggregate regression train score: 0.3334707120218561, test score: -0.1729314748570514\n","Aggregate regression train score with FS: 0.19895612026697385, test score: 0.15010302906175643\n","\n","Full model and best 5 selected features with wrapper\n","\n","Full aggregate regression train score: 0.3334707120218561, test score: -0.1729314748570514\n","Aggregate regression train score with FS: 0.17471707925256197, test score: 0.16138171142972368\n","----- MI Scores -----\n","[(72, 0.1905744496327849), (78, 0.18664486612794157), (75, 0.17896132992993388), (77, 0.17523729285491366), (76, 0.17508172603625458), (79, 0.1567292659441962), (80, 0.15228505454861166), (89, 0.14753170357196116), (88, 0.13265570198383692), (84, 0.1179076390924761), (82, 0.11566535428518963), (81, 0.10998199352982363), (90, 0.10933125458833352), (0, 0.10019667024592005), (5, 0.09504421377394884), (92, 0.09004668302963746), (83, 0.0898903173685656), (1, 0.08934697709940029), (4, 0.08801547051787159), (87, 0.08520717043901437), (73, 0.08297051568246404), (85, 0.08268479812984976), (86, 0.08105155385908877), (91, 0.0800034400313862), (3, 0.07997990485674795), (49, 0.07266497221224631), (74, 0.07195104222930632), (21, 0.06615760823187876), (17, 0.06568966212252096), (22, 0.06384561451534691), (15, 0.059837919207322246), (2, 0.05837089474517893), (48, 0.05516701885465093), (16, 0.054194147706084196), (20, 0.05316938841480197), (47, 0.05188683317206092), (56, 0.05102256986157405), (14, 0.05038893484353032), (52, 0.0502229974523168), (44, 0.04780120789141581), (19, 0.04622827544494628), (54, 0.04508211551080975), (7, 0.043968936004471826), (6, 0.043727267677661), (50, 0.04159780446439129), (23, 0.040986056148187996), (12, 0.040474176352505734), (55, 0.03961272489309636), (18, 0.03918759230332868), (53, 0.03729185253073095), (38, 0.03722712311744739), (45, 0.035770550084311264), (25, 0.033037162005768485), (46, 0.03268846003151463), (13, 0.03169973750573079), (36, 0.031017172889424172), (26, 0.030810121632042577), (51, 0.026720121249542005), (59, 0.026496469444884787), (60, 0.024982155243445634), (27, 0.024922595674756905), (63, 0.023335142398340007), (24, 0.022941433175940145), (31, 0.022547904723786396), (70, 0.021867964151221792), (32, 0.021239915455380284), (41, 0.021186874053272537), (67, 0.020726845524726454), (29, 0.020108930352637118), (58, 0.019998338566571308), (62, 0.018850919705713926), (57, 0.01789038139075917), (68, 0.01779064829322368), (71, 0.017061945803314417), (64, 0.015829477313208728), (35, 0.014333768190424102), (9, 0.01240549710470327), (30, 0.012204813013872957), (37, 0.011854501593770255), (33, 0.011526702628185462), (39, 0.011263322315825358), (8, 0.01096447883901458), (42, 0.00927545270063909), (28, 0.009265213312162771), (61, 0.008824703184477731), (40, 0.007772738037063627), (10, 0.005466381671924328), (11, 0.003861715984564276), (66, 0.002868876816380014), (43, 0.001949206939100508), (34, -0.0006906301575006161), (65, -0.008845519408810386), (69, -0.009153097178596354)]\n","Best MI score: 0.1905744496327849\n","Adding first best original feature: 72\n","Highest CMI score: -0.034224756009924195\n","\n","[72]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.3334707120218561, test score: -0.1729314748570514\n","Aggregate regression train score with FS: 0.006547512268677558, test score: 0.02161700402959099\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.3334707120218561, test score: -0.1729314748570514\n","Aggregate regression train score with FS: 0.006547512268677558, test score: 0.02161700402959099\n","###### Binary Classification ######\n","Train accuracy logistic regression CMI:  0.552\n","Test accuracy logistic regression CMI:  0.654 \n","\n","Train accuracy logistic regression CMI best 5:  0.552\n","Test accuracy logistic regression CMI best 5:  0.654 \n","\n","Train accuracy logistic regression wrapper:  0.693\n","Test accuracy logistic regression wrapper:  0.697 \n","\n","####################Adda####################\n","target samples:            date      mean  median  year  week  mean_std\n","0    2001-01-05  0.039373    0.00  2001     1         0\n","1    2001-01-13  0.380618    0.43  2001     2         0\n","2    2001-01-21  0.341985    0.38  2001     3         0\n","3    2001-01-29  0.322044    0.35  2001     5         0\n","4    2001-02-06  0.354954    0.40  2001     6         0\n","..          ...       ...     ...   ...   ...       ...\n","406  2009-11-27  0.382706    0.40  2009    48         0\n","407  2009-12-05  0.409921    0.46  2009    49         0\n","408  2009-12-13  0.472087    0.53  2009    50         1\n","409  2009-12-21  0.324728    0.00  2009    52         0\n","410  2009-12-29  0.086512    0.00  2009    53         0\n","\n","[411 rows x 6 columns]\n"," target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n","Feature: cyclostationary_mean_tg\n","\n","Number of features: 92\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_1w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_4w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_8w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_tg_12w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_tg_16w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_tg_24w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr\n","\n","Number of features: 92\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_rr_1w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_4w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 8\n","\n","Feature: cyclostationary_mean_rr_8w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 15\n","\n","Feature: cyclostationary_mean_rr_12w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 10\n","\n","Feature: cyclostationary_mean_rr_16w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_rr_24w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 8\n","\n","Feature: cyclostationary_mean_HS\n","\n","Number of features: 7\n","\n","Number of aggregated features: 2\n","\n","Feature: cyclostationary_mean_HS_1w\n","\n","Number of features: 7\n","\n","Number of aggregated features: 2\n","\n","Feature: cyclostationary_mean_HS_4w\n","\n","Number of features: 7\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_HS_8w\n","\n","Number of features: 7\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_HS_12w\n","\n","Number of features: 7\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_HS_16w\n","\n","Number of features: 7\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_HS_24w\n","\n","Number of features: 7\n","\n","Number of aggregated features: 2\n","\n","\n","\n","selected columns: ['cyclostationary_mean_tg_1w_2', 'cyclostationary_mean_tg_4w_1', 'cyclostationary_mean_tg_4w_2', 'cyclostationary_mean_rr_4w_0', 'cyclostationary_mean_tg_8w_0', 'cyclostationary_mean_HS_24w_1', 'cyclostationary_mean_HS_8w_0', 'cyclostationary_mean_tg_1w_1', 'cyclostationary_mean_HS_8w_1', 'cyclostationary_mean_HS_4w_0', 'cyclostat_level_Como_24w', 'cyclostat_level_Como', 'cyclostat_release_Como', 'cyclostat_release_Como_24w', 'cyclostationary_mean_tg_1w_0', 'cyclostat_inflow_Como_4w', 'cyclostat_inflow_Como_1w', 'cyclostationary_mean_rr_4w_1', 'cyclostationary_mean_rr_4w_2', 'cyclostationary_mean_HS_12w_1', 'cyclostationary_mean_rr_24w_1', 'cyclostationary_mean_rr_4w_3', 'cyclostationary_mean_HS_12w_2', 'cyclostationary_mean_rr_8w_1', 'cyclostat_release_Como_12w', 'cyclostat_level_Como_4w', 'cyclostat_level_Como_12w', 'cyclostationary_mean_HS_8w_2', 'cyclostationary_mean_tg_24w_0', 'cyclostat_level_Como_16w'], \n","\n","validation score: 0.29480716041873745, \n","\n","number of selected features: 30\n","\n","Full model and selected features with wrapper\n","\n","Full aggregate regression train score: 0.37754339431841566, test score: -0.6229393325294288\n","Aggregate regression train score with FS: 0.205456283811714, test score: -0.019934693877040388\n","\n","Full model and best 5 selected features with wrapper\n","\n","Full aggregate regression train score: 0.37754339431841566, test score: -0.6229393325294288\n","Aggregate regression train score with FS: 0.1440759008299486, test score: 0.12691405710657577\n","----- MI Scores -----\n","[(118, 0.1803491187355187), (112, 0.15950973191628584), (117, 0.15008710453577329), (110, 0.1382977073646517), (3, 0.13060303043884083), (113, 0.12959102192622393), (5, 0.12928941517574324), (1, 0.12530110884243456), (6, 0.1165339682816214), (100, 0.11324542947658948), (107, 0.11149807882112535), (109, 0.11053432071199763), (99, 0.10805586310405856), (114, 0.10688743564988559), (111, 0.10159076390149951), (108, 0.09462010331501629), (115, 0.0900928209465164), (116, 0.08230988452873646), (48, 0.07426394053968663), (49, 0.07064861805559879), (46, 0.06565546799993426), (21, 0.06341479218878367), (23, 0.06154924722054746), (0, 0.06125353666858077), (2, 0.05750978377173043), (61, 0.05510860013342701), (26, 0.05440200218511999), (22, 0.052295701741671315), (10, 0.050138004158179074), (11, 0.045934853812424695), (94, 0.045870559453819085), (34, 0.04579323938165829), (25, 0.045444831860808665), (96, 0.04535367294037398), (7, 0.040638703972186066), (104, 0.040341235244451996), (53, 0.039086985624180705), (24, 0.03650096311365742), (4, 0.03519218038788573), (72, 0.03324540115322162), (18, 0.03296326799206061), (79, 0.03275917614350123), (68, 0.032577077971148886), (77, 0.03084453721106745), (19, 0.030678973937076377), (29, 0.030586261903864025), (85, 0.029611836862427774), (14, 0.029482408688126432), (91, 0.0278595981612805), (51, 0.027764938391219938), (15, 0.027293941324075137), (83, 0.02720404690290137), (56, 0.027189588143225814), (71, 0.026191401818913468), (70, 0.026002494184630114), (32, 0.025727701206068217), (50, 0.025516049769112304), (9, 0.024475819293184167), (106, 0.023934973169744553), (63, 0.023483649557416362), (80, 0.02335650617324098), (66, 0.02332618662134555), (20, 0.023169131379861395), (78, 0.021451787817284945), (52, 0.020999521676169145), (82, 0.020663857674686176), (47, 0.02040861179732287), (33, 0.02028949015860065), (58, 0.020228344285874483), (55, 0.02021443888370932), (65, 0.019643425089019274), (62, 0.01963966321546049), (8, 0.01955726848339617), (67, 0.018534812391315932), (57, 0.018520579030288857), (17, 0.01762803092043631), (69, 0.017371321530923627), (89, 0.017209004411155988), (73, 0.016619201984015), (43, 0.015454867938594054), (39, 0.014914468037684805), (12, 0.014883411360459892), (97, 0.013818848510319547), (75, 0.013415109005516285), (86, 0.013245503955702701), (81, 0.01270934222084833), (64, 0.012184060456771631), (105, 0.011970662137764751), (36, 0.011836122999913939), (98, 0.011696370741567543), (87, 0.01163139222608697), (37, 0.011571229176405162), (16, 0.010966811032947577), (38, 0.010781106563733473), (35, 0.010647987721316315), (60, 0.010010675134999591), (92, 0.009549049764006053), (59, 0.008984038334623107), (27, 0.00887362630340825), (13, 0.008597690603685664), (31, 0.008562180462303266), (95, 0.008419358279822648), (74, 0.0080311309911059), (28, 0.007804641996140892), (76, 0.0075468002363079136), (93, 0.006327896925066662), (84, 0.006084547625136577), (88, 0.005760536401420191), (41, 0.0048664149034964325), (44, 0.0038647986716313963), (101, 0.0032482790749574766), (45, 0.001825460653871919), (102, 0.0012524337358769794), (40, 0.00024254615223875844), (54, 0.00012455591369065681), (42, -6.77000813182088e-05), (103, -0.0010593274694941758), (30, -0.0012235647650569005), (90, -0.008506724931865599)]\n","Best MI score: 0.1803491187355187\n","Adding first best original feature: 118\n","CMI: 1.0031700172552505e-05\n","CMI: 0.0001304121022430993\n","Highest CMI score: 0.0001304121022430993\n","Adding original feature: 106\n","Highest CMI score: -0.00012038040207054679\n","\n","[118, 106]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.37754339431841566, test score: -0.6229393325294288\n","Aggregate regression train score with FS: 0.01128872319523877, test score: -0.03442690441314866\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.37754339431841566, test score: -0.6229393325294288\n","Aggregate regression train score with FS: 0.01128872319523877, test score: -0.03442690441314866\n","###### Binary Classification ######\n","Train accuracy logistic regression CMI:  0.552\n","Test accuracy logistic regression CMI:  0.504 \n","\n","Train accuracy logistic regression CMI best 5:  0.552\n","Test accuracy logistic regression CMI best 5:  0.504 \n","\n","Train accuracy logistic regression wrapper:  0.664\n","Test accuracy logistic regression wrapper:  0.654 \n","\n","####################Lambro_Olona####################\n","target samples:            date      mean  median  year  week  mean_std\n","0    2001-01-05  0.369625    0.45  2001     1         0\n","1    2001-01-13  0.429563    0.43  2001     2         0\n","2    2001-01-21  0.470784    0.48  2001     3         1\n","3    2001-01-29  0.370358    0.37  2001     5         0\n","4    2001-02-06  0.372263    0.37  2001     6         0\n","..          ...       ...     ...   ...   ...       ...\n","406  2009-11-27  0.402059    0.40  2009    48         0\n","407  2009-12-05  0.389658    0.39  2009    49         0\n","408  2009-12-13  0.545184    0.56  2009    50         1\n","409  2009-12-21  0.447916    0.55  2009    52         1\n","410  2009-12-29  0.277300    0.32  2009    53         0\n","\n","[411 rows x 6 columns]\n"," target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n","Feature: cyclostationary_mean_tg\n","\n","Number of features: 55\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_1w\n","\n","Number of features: 55\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_tg_4w\n","\n","Number of features: 55\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_8w\n","\n","Number of features: 55\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_12w\n","\n","Number of features: 55\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_16w\n","\n","Number of features: 55\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_24w\n","\n","Number of features: 55\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr\n","\n","Number of features: 55\n","\n","Number of aggregated features: 10\n","\n","Feature: cyclostationary_mean_rr_1w\n","\n","Number of features: 55\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_rr_4w\n","\n","Number of features: 55\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_8w\n","\n","Number of features: 55\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_rr_12w\n","\n","Number of features: 55\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_16w\n","\n","Number of features: 55\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_24w\n","\n","Number of features: 55\n","\n","Number of aggregated features: 4\n","\n","\n","\n","selected columns: ['cyclostationary_mean_tg_1w_2', 'cyclostationary_mean_rr_1w_3', 'cyclostationary_mean_tg_4w_0', 'cyclostationary_mean_tg_4w_1', 'cyclostationary_mean_tg_1w_1', 'cyclostationary_mean_tg_12w_1', 'cyclostationary_mean_tg_1w_3', 'cyclostationary_mean_tg_8w_0', 'cyclostationary_mean_tg_16w_0', 'cyclostationary_mean_tg_24w_2', 'cyclostationary_mean_rr_24w_0', 'cyclostationary_mean_rr_1w_0', 'cyclostationary_mean_tg_12w_0', 'cyclostationary_mean_rr_4w_2', 'cyclostationary_mean_rr_8w_0', 'cyclostationary_mean_rr_5', 'cyclostationary_mean_rr_9', 'cyclostationary_mean_rr_1w_1', 'cyclostationary_mean_rr_8w_2', 'cyclostationary_mean_rr_1w_2', 'cyclostationary_mean_rr_16w_0', 'cyclostationary_mean_tg_8w_1', 'cyclostationary_mean_rr_24w_3', 'cyclostationary_mean_rr_24w_1', 'cyclostationary_mean_tg_8w_2', 'cyclostationary_mean_tg_16w_1', 'cyclostationary_mean_tg_12w_2', 'cyclostationary_mean_rr_1w_4', 'cyclostationary_mean_rr_2', 'cyclostationary_mean_rr_24w_2'], \n","\n","validation score: 0.321774158767128, \n","\n","number of selected features: 30\n","\n","Full model and selected features with wrapper\n","\n","Full aggregate regression train score: 0.2937000928866733, test score: -0.08405552446287201\n","Aggregate regression train score with FS: 0.24286307126868134, test score: 0.07123323871515497\n","\n","Full model and best 5 selected features with wrapper\n","\n","Full aggregate regression train score: 0.2937000928866733, test score: -0.08405552446287201\n","Aggregate regression train score with FS: 0.20230402434800432, test score: 0.15742143625187954\n","----- MI Scores -----\n","[(2, 0.10311237594322889), (30, 0.08694055862422356), (6, 0.07787449780492389), (5, 0.0720556273975069), (4, 0.06271940274776804), (1, 0.05969851375994328), (0, 0.058615519682940466), (26, 0.05704881315212915), (24, 0.05615915813598699), (21, 0.05393686673739326), (3, 0.05380567359210118), (38, 0.05345305452513542), (27, 0.05267297026538407), (29, 0.051144208554795664), (23, 0.05055095121462613), (53, 0.047185591023697696), (35, 0.04693658472524337), (31, 0.0465436240413615), (46, 0.04651849360064755), (28, 0.04501512298905702), (25, 0.044926568876657684), (33, 0.04277868513284016), (18, 0.042162102301100596), (32, 0.040918301260301944), (40, 0.04008731139316782), (42, 0.038113383674919864), (36, 0.03710392870689569), (52, 0.03628263881103373), (8, 0.033303195927396965), (45, 0.03258875160090288), (49, 0.03248373283764401), (47, 0.031679257584269385), (44, 0.03157562444939338), (22, 0.030455639118998203), (12, 0.029520357273300466), (51, 0.028767735547091812), (34, 0.027182443723691697), (48, 0.02512263853446698), (43, 0.02509895039439464), (37, 0.024380766265139128), (16, 0.023407327887554345), (50, 0.02306568405963686), (15, 0.021334021556279722), (41, 0.02130448756816888), (39, 0.02038992648341171), (9, 0.018202566293218255), (20, 0.014095838920602384), (17, 0.010732624300741215), (7, 0.010018841740640603), (10, 0.0022736893816504558), (11, 0.002195746901207309), (14, -0.0033559326713758692), (13, -0.00432838043126416), (19, -0.008838850181010214)]\n","Best MI score: 0.10311237594322889\n","Adding first best original feature: 2\n","CMI: 0.002013487496476049\n","CMI: 0.00011502134019777954\n","CMI: 0.012223931793437143\n","CMI: 0.014982764992296782\n","CMI: 0.017386600913983113\n","CMI: 0.008207904870655564\n","CMI: 0.006139409310800981\n","CMI: 0.010084556910882447\n","CMI: 0.02248063122534877\n","CMI: 0.006927584044450846\n","CMI: 0.023243671269399413\n","CMI: 0.03595715955716364\n","CMI: 0.013780004332222179\n","CMI: 0.034886205067099385\n","CMI: 0.00967630580886622\n","CMI: 0.0038534831493395733\n","CMI: 0.008314456313505414\n","CMI: 0.014944163277839387\n","CMI: 0.018547292630679307\n","CMI: 0.007007556987304736\n","CMI: 0.02457582978159184\n","CMI: 0.0011202128695848024\n","CMI: 0.004387842624327801\n","CMI: 0.02887898063392616\n","CMI: 0.012111723038186209\n","CMI: 0.01631957387584583\n","CMI: 0.02538525156117688\n","Highest CMI score: 0.03595715955716364\n","Adding original feature: 36\n","CMI: 0.007362389770202399\n","CMI: 0.0017608783024769536\n","CMI: 0.006080544377404906\n","CMI: 0.00422167911591137\n","CMI: 0.010647910688400403\n","CMI: 0.0009188974756970392\n","CMI: 0.004120795630297547\n","CMI: 0.0033043122566122907\n","CMI: 0.003575726137253321\n","CMI: 0.0010244928673134035\n","CMI: 0.004002298439620189\n","CMI: 0.007125215714473693\n","CMI: 0.001161424487114593\n","CMI: 0.01215855021261747\n","CMI: 0.01883223767964734\n","CMI: 0.010469420061577472\n","CMI: 0.021412086719137857\n","CMI: 0.005604803082300103\n","CMI: 0.014033641821741466\n","CMI: 0.0038732571877992394\n","CMI: 0.00363638485705986\n","CMI: 0.016951529287763195\n","CMI: 0.0029021050261523185\n","CMI: 0.0023347636976822628\n","CMI: 0.014314015756665799\n","CMI: 0.007699433010078194\n","Highest CMI score: 0.021412086719137857\n","Adding original feature: 43\n","CMI: 0.003914885939832968\n","CMI: 0.0005279697039194675\n","CMI: 0.0035989416108800076\n","CMI: 0.005609967117480769\n","CMI: 0.0016226592139165774\n","CMI: 0.005179319843684249\n","CMI: 0.007968505002537984\n","CMI: 0.012905553928318714\n","CMI: 0.018779950696649977\n","CMI: 0.0011768657265124605\n","CMI: 0.017106601450045278\n","CMI: 0.0051918079246902615\n","CMI: 0.004282507314682549\n","CMI: 0.005539225971022577\n","CMI: 0.0035097504052587214\n","CMI: 0.003581404003191624\n","CMI: 0.0012615864379158515\n","CMI: 0.008428293330236425\n","CMI: 0.004989720919502366\n","CMI: 0.00655031701171932\n","CMI: 0.015534496314542512\n","CMI: 0.021347006207390634\n","Highest CMI score: 0.021347006207390634\n","Adding original feature: 48\n","Highest CMI score: -0.005662207079336262\n","\n","[2, 36, 43, 48]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.2937000928866733, test score: -0.08405552446287201\n","Aggregate regression train score with FS: 0.18341356406592668, test score: 0.18708064011810854\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.2937000928866733, test score: -0.08405552446287201\n","Aggregate regression train score with FS: 0.18341356406592668, test score: 0.18708064011810854\n","###### Binary Classification ######\n","Train accuracy logistic regression CMI:  0.69\n","Test accuracy logistic regression CMI:  0.693 \n","\n","Train accuracy logistic regression CMI best 5:  0.69\n","Test accuracy logistic regression CMI best 5:  0.693 \n","\n","Train accuracy logistic regression wrapper:  0.684\n","Test accuracy logistic regression wrapper:  0.667 \n","\n"]}],"source":["basins = ['Ticino', 'Oglio_Iseo', 'Adda', 'Lambro_Olona']\n","\n","path_target = \"./csv/\"\n","path_features_snow = './features_allvalues/snow/copernicus/relevant_coords/'\n","path_features='./features_allvalues/'\n","path_features_lakes='./lakes/'\n","\n","destination_folder = './GenLinCFA/temp_prec_snow_lakes_copernicus/'\n","\n","for basin in basins:\n","    print('####################' + basin + '####################')\n","\n","    target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target_binary('',max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01',\n","      path=path_target+basin+'.csv')\n","\n","    eps = 0.37\n","    actual_path = path_features+basin+'_aggreg.csv'\n","    snow_actual_path = path_features_snow+basin+'_aggreg_sd_allCoord.csv'\n","    lakes_actual_path = path_features_lakes + 'lakes_' + basin + '_with_aggreg.csv'\n","\n","    output,aggregate_trainVal,aggregate_test = aggregate_unfolded_data(actual_path,['cyclostationary_mean_tg',\n","                                                                             'cyclostationary_mean_tg_1w',\n","                                                                             'cyclostationary_mean_tg_4w',\n","                                                                             'cyclostationary_mean_tg_8w',\n","                                                                             'cyclostationary_mean_tg_12w',\n","                                                                             'cyclostationary_mean_tg_16w',\n","                                                                             'cyclostationary_mean_tg_24w',\n","                                                                             'cyclostationary_mean_rr',\n","                                                                             'cyclostationary_mean_rr_1w',\n","                                                                             'cyclostationary_mean_rr_4w',\n","                                                                             'cyclostationary_mean_rr_8w',\n","                                                                             'cyclostationary_mean_rr_12w',\n","                                                                             'cyclostationary_mean_rr_16w',\n","                                                                             'cyclostationary_mean_rr_24w'\n","                                                                            ],\n","                                                                       target_df_trainVal, eps=eps,\n","                                                                       max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01')\n","\n","    if os.path.isfile(snow_actual_path):\n","      output_snow,aggregate_trainVal_snow,aggregate_test_snow = aggregate_unfolded_data(snow_actual_path,['cyclostationary_mean_HS',\n","                                                                              'cyclostationary_mean_HS_1w',\n","                                                                              'cyclostationary_mean_HS_4w',\n","                                                                              'cyclostationary_mean_HS_8w',\n","                                                                              'cyclostationary_mean_HS_12w',\n","                                                                              'cyclostationary_mean_HS_16w',\n","                                                                              'cyclostationary_mean_HS_24w'\n","                                                                              ],\n","                                                                        target_df_trainVal, eps=eps,\n","                                                                        max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01', scale = 0.26)\n","\n","      aggregate_trainVal = pd.concat((aggregate_trainVal_snow,aggregate_trainVal),axis=1)\n","      aggregate_test = pd.concat((aggregate_test_snow,aggregate_test),axis=1)\n","\n","    if os.path.isfile(lakes_actual_path):\n","      df_lakes = pd.read_csv(lakes_actual_path)\n","      df_lakes = df_lakes.drop(\"Unnamed: 0\", axis='columns')\n","\n","      df_lakes_trainVal = df_lakes.loc[(df_lakes['date'] > '2001-01-01') & (df_lakes['date'] <= '2015-01-01'),:]\n","      df_lakes_trainVal.reset_index(inplace = True, drop = True)\n","      df_lakes_trainVal = df_lakes_trainVal.iloc[:,3:]\n","      df_lakes_test = df_lakes.loc[(df_lakes['date'] > '2015-01-01') & (df_lakes['date'] <= '2020-01-01'),:]\n","      df_lakes_test.reset_index(inplace = True, drop = True)\n","      df_lakes_test = df_lakes_test.iloc[:,3:]\n","\n","      aggregate_trainVal = pd.concat((aggregate_trainVal, df_lakes_trainVal),axis=1)\n","      aggregate_test = pd.concat((aggregate_test, df_lakes_test),axis=1)\n","\n","    selected_colnames = FS_with_linearWrapper(aggregate_trainVal, target_df_train, target_df_val, min(50,aggregate_trainVal.shape[1]-1), 228)\n","\n","    print('\\nFull model and selected features with wrapper\\n')\n","    compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n","\n","    print('\\nFull model and best 5 selected features with wrapper\\n')\n","    compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames[0:5])\n","\n","    train_string = destination_folder + basin + '_genLinCFA_wrapper_best5_train_withSnowLakes.csv'\n","    val_string = destination_folder + basin + '_genLinCFA_wrapper_best5_val_withSnowLakes.csv'\n","    test_string = destination_folder + basin + '_genLinCFA_wrapper_best5_test_withSnowLakes.csv'\n","    X_train_wrapper = aggregate_trainVal.loc[:410,selected_colnames[0:5]]\n","    X_validation_wrapper = aggregate_trainVal.loc[411:,selected_colnames[0:5]]\n","    X_train_validation_wrapper = pd.concat([X_train_wrapper, X_validation_wrapper])\n","    X_test_wrapper = aggregate_test.loc[:,selected_colnames[0:5]]\n","    X_train_wrapper.to_csv(train_string, index=False)\n","    X_validation_wrapper.to_csv(val_string, index=False)\n","    X_test_wrapper.to_csv(test_string, index=False)\n","\n","    res = {\n","            \"delta\" : [],\n","            \"numSelected\" : [],\n","            \"selectedFeatures\" : []\n","        }\n","\n","    res['selectedFeatures'] = forwardFeatureSelection(10,np.array(aggregate_trainVal),\n","                                                      np.array(target_df_trainVal.mean_std),res,10,1)\n","\n","    selectedFeatures='selectedFeatures'\n","    print(f'\\n{res[selectedFeatures]}\\n')\n","\n","    selected_colnames = aggregate_trainVal.columns[res['selectedFeatures']]\n","\n","    print('\\nFull model and selected features with CMI\\n')\n","    compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n","\n","    print('\\nFull model and best 5 selected features with CMI\\n')\n","    compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames[0:5])\n","\n","    train_string = destination_folder + basin + '_genLinCFA_best5_CMI_train_withSnowLakes.csv'\n","    val_string = destination_folder + basin + '_genLinCFA_best5_CMI_val_withSnowLakes.csv'\n","    test_string = destination_folder + basin + '_genLinCFA_best5_CMI_test_withSnowLakes.csv'\n","\n","    X_train_CMI5 = aggregate_trainVal.loc[:410,selected_colnames[0:5]]\n","    X_validation_CMI5 = aggregate_trainVal.loc[411:,selected_colnames[0:5]]\n","    X_train_validation_CMI5 = pd.concat([X_train_CMI5, X_validation_CMI5])\n","    X_test_CMI5 = aggregate_test.loc[:,selected_colnames[0:5]]\n","\n","    selected_colnames_CMI5 = aggregate_trainVal.loc[:,selected_colnames[0:5]].columns.values\n","\n","    X_train_CMI5.to_csv(train_string, index=False)\n","    X_validation_CMI5.to_csv(val_string, index=False)\n","    X_test_CMI5.to_csv(test_string, index=False)\n","\n","    train_string = destination_folder + basin + '_genLinCFA_CMI_train_withSnowLakes.csv'\n","    val_string = destination_folder + basin + '_genLinCFA_CMI_val_withSnowLakes.csv'\n","    test_string = destination_folder + basin + '_genLinCFA_CMI_test_withSnowLakes.csv'\n","\n","    X_train_CMI = aggregate_trainVal.loc[:410,selected_colnames]\n","    X_validation_CMI = aggregate_trainVal.loc[411:,selected_colnames]\n","    X_train_validation_CMI = pd.concat([X_train_CMI, X_validation_CMI])\n","    X_test_CMI = aggregate_test.loc[:,selected_colnames]\n","\n","    X_train_CMI.to_csv(train_string, index=False)\n","    X_validation_CMI.to_csv(val_string, index=False)\n","    X_test_CMI.to_csv(test_string, index=False)\n","\n","    print('###### Binary Classification ######')\n","\n","    target_df_train = target_df_train.apply(lambda x: np.sign(x.mean_std), axis=1)\n","    target_df_val = target_df_val.apply(lambda x: np.sign(x.mean_std), axis=1)\n","    target_df_test = target_df_test.apply(lambda x: np.sign(x.mean_std), axis=1)\n","    target_df_trainVal = target_df_trainVal.apply(lambda x: np.sign(x.mean_std), axis=1)\n","\n","    log_regr = LogisticRegression(solver='lbfgs', random_state = 42)\n","\n","    # CMI\n","    log_regr.fit(X_train_validation_CMI, target_df_trainVal)\n","    print(\"Train accuracy logistic regression CMI: \", round(log_regr.score(X_train_validation_CMI, target_df_trainVal),3))\n","    print(\"Test accuracy logistic regression CMI: \", round(log_regr.score(X_test_CMI, target_df_test),3), \"\\n\")\n","\n","    # CMI best 5\n","    log_regr.fit(X_train_validation_CMI5, target_df_trainVal)\n","    print(\"Train accuracy logistic regression CMI best 5: \", round(log_regr.score(X_train_validation_CMI5, target_df_trainVal),3))\n","    print(\"Test accuracy logistic regression CMI best 5: \", round(log_regr.score(X_test_CMI5, target_df_test),3), \"\\n\")\n","\n","    # wrapper\n","    log_regr.fit(X_train_validation_wrapper, target_df_trainVal)\n","    print(\"Train accuracy logistic regression wrapper: \", round(log_regr.score(X_train_validation_wrapper, target_df_trainVal),3))\n","    print(\"Test accuracy logistic regression wrapper: \", round(log_regr.score(X_test_wrapper, target_df_test),3), \"\\n\")"],"id":"cnfAdqhIwWaA"},{"cell_type":"markdown","metadata":{"id":"c3WXxyk95Vyk"},"source":["## Temp Prec Lakes"],"id":"c3WXxyk95Vyk"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2958773,"status":"ok","timestamp":1690245053046,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"},"user_tz":-120},"id":"SpEton0e55Ev","outputId":"4f40c33e-388d-40de-987a-057edfddfbf0"},"outputs":[{"output_type":"stream","name":"stdout","text":["####################Adda####################\n","target samples:            date      mean  median  year  week  mean_std\n","0    2001-01-05  0.039373    0.00  2001     1         0\n","1    2001-01-13  0.380618    0.43  2001     2         0\n","2    2001-01-21  0.341985    0.38  2001     3         0\n","3    2001-01-29  0.322044    0.35  2001     5         0\n","4    2001-02-06  0.354954    0.40  2001     6         0\n","..          ...       ...     ...   ...   ...       ...\n","406  2009-11-27  0.382706    0.40  2009    48         0\n","407  2009-12-05  0.409921    0.46  2009    49         0\n","408  2009-12-13  0.472087    0.53  2009    50         1\n","409  2009-12-21  0.324728    0.00  2009    52         0\n","410  2009-12-29  0.086512    0.00  2009    53         0\n","\n","[411 rows x 6 columns]\n"," target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n","Feature: cyclostationary_mean_tg\n","\n","Number of features: 92\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_1w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_4w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_8w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_tg_12w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_tg_16w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_tg_24w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr\n","\n","Number of features: 92\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_rr_1w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_4w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 8\n","\n","Feature: cyclostationary_mean_rr_8w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 15\n","\n","Feature: cyclostationary_mean_rr_12w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 10\n","\n","Feature: cyclostationary_mean_rr_16w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_rr_24w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 8\n","\n","\n","\n","selected columns: ['cyclostationary_mean_tg_1w_2', 'cyclostationary_mean_tg_4w_1', 'cyclostationary_mean_tg_4w_2', 'cyclostationary_mean_rr_4w_0', 'cyclostationary_mean_tg_8w_0', 'cyclostat_release_Como_24w', 'cyclostat_level_Como_12w', 'cyclostat_level_Como_4w', 'cyclostat_release_Como_4w', 'cyclostat_inflow_Como', 'cyclostationary_mean_tg_8w_3', 'cyclostationary_mean_rr_24w_1', 'cyclostationary_mean_rr_4w_1', 'cyclostationary_mean_rr_4w_2'], \n","\n","validation score: 0.2913235424794933, \n","\n","number of selected features: 14\n","\n","Full model and selected features with wrapper\n","\n","Full aggregate regression train score: 0.3272490608095966, test score: -0.40318635016613835\n","Aggregate regression train score with FS: 0.17432763883194058, test score: 0.05070979808242515\n","\n","Full model and best 5 selected features with wrapper\n","\n","Full aggregate regression train score: 0.3272490608095966, test score: -0.40318635016613835\n","Aggregate regression train score with FS: 0.1440759008299486, test score: 0.12691405710657577\n","----- MI Scores -----\n","[(20, 0.1803491187355187), (14, 0.15950973191628584), (19, 0.15008710453577329), (12, 0.1382977073646517), (15, 0.12959102192622393), (2, 0.11324542947658948), (9, 0.11149807882112535), (11, 0.11053432071199763), (1, 0.10805586310405856), (16, 0.10688743564988559), (13, 0.10159076390149951), (10, 0.09462010331501629), (17, 0.0900928209465164), (18, 0.08230988452873646), (48, 0.07426394053968663), (49, 0.07064861805559879), (46, 0.06565546799993426), (21, 0.06341479218878367), (23, 0.06154924722054746), (61, 0.05510860013342701), (26, 0.05440200218511999), (22, 0.052295701741671315), (94, 0.045870559453819085), (34, 0.04579323938165829), (25, 0.045444831860808665), (96, 0.04535367294037398), (6, 0.040341235244451996), (53, 0.039086985624180705), (24, 0.03650096311365742), (72, 0.03324540115322162), (79, 0.03275917614350123), (68, 0.032577077971148886), (77, 0.03084453721106745), (29, 0.030586261903864025), (85, 0.029611836862427774), (91, 0.0278595981612805), (51, 0.027764938391219938), (83, 0.02720404690290137), (56, 0.027189588143225814), (71, 0.026191401818913468), (70, 0.026002494184630114), (32, 0.025727701206068217), (50, 0.025516049769112304), (8, 0.023934973169744553), (63, 0.023483649557416362), (80, 0.02335650617324098), (66, 0.02332618662134555), (78, 0.021451787817284945), (52, 0.020999521676169145), (82, 0.020663857674686176), (47, 0.02040861179732287), (33, 0.02028949015860065), (58, 0.020228344285874483), (55, 0.02021443888370932), (65, 0.019643425089019274), (62, 0.01963966321546049), (67, 0.018534812391315932), (57, 0.018520579030288857), (69, 0.017371321530923627), (89, 0.017209004411155988), (73, 0.016619201984015), (43, 0.015454867938594054), (39, 0.014914468037684805), (97, 0.013818848510319547), (75, 0.013415109005516285), (86, 0.013245503955702701), (81, 0.01270934222084833), (64, 0.012184060456771631), (7, 0.011970662137764751), (36, 0.011836122999913939), (0, 0.011696370741567543), (87, 0.01163139222608697), (37, 0.011571229176405162), (38, 0.010781106563733473), (35, 0.010647987721316315), (60, 0.010010675134999591), (92, 0.009549049764006053), (59, 0.008984038334623107), (27, 0.00887362630340825), (31, 0.008562180462303266), (95, 0.008419358279822648), (74, 0.0080311309911059), (28, 0.007804641996140892), (76, 0.0075468002363079136), (93, 0.006327896925066662), (84, 0.006084547625136577), (88, 0.005760536401420191), (41, 0.0048664149034964325), (44, 0.0038647986716313963), (3, 0.0032482790749574766), (45, 0.001825460653871919), (4, 0.0012524337358769794), (40, 0.00024254615223875844), (54, 0.00012455591369065681), (42, -6.77000813182088e-05), (5, -0.0010593274694941758), (30, -0.0012235647650569005), (90, -0.008506724931865599)]\n","Best MI score: 0.1803491187355187\n","Adding first best original feature: 20\n","CMI: 1.0031700172552505e-05\n","CMI: 0.0001304121022430993\n","Highest CMI score: 0.0001304121022430993\n","Adding original feature: 8\n","Highest CMI score: -0.00012038040207054679\n","\n","[20, 8]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.3272490608095966, test score: -0.40318635016613835\n","Aggregate regression train score with FS: 0.01128872319523877, test score: -0.03442690441314866\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.3272490608095966, test score: -0.40318635016613835\n","Aggregate regression train score with FS: 0.01128872319523877, test score: -0.03442690441314866\n","###### Binary Classification ######\n","Train accuracy logistic regression CMI:  0.552\n","Test accuracy logistic regression CMI:  0.504 \n","\n","Train accuracy logistic regression CMI best 5:  0.552\n","Test accuracy logistic regression CMI best 5:  0.504 \n","\n","Train accuracy logistic regression wrapper:  0.664\n","Test accuracy logistic regression wrapper:  0.654 \n","\n","####################Ticino####################\n","target samples:            date      mean  median  year  week  mean_std\n","0    2001-01-05  0.264043    0.00  2001     1         0\n","1    2001-01-13  0.354618    0.39  2001     2         0\n","2    2001-01-21  0.427990    0.47  2001     3         1\n","3    2001-01-29  0.339495    0.35  2001     5         0\n","4    2001-02-06  0.324134    0.34  2001     6         0\n","..          ...       ...     ...   ...   ...       ...\n","406  2009-11-27  0.332713    0.35  2009    48         0\n","407  2009-12-05  0.370253    0.40  2009    49         0\n","408  2009-12-13  0.517201    0.57  2009    50         1\n","409  2009-12-21  0.353636    0.45  2009    52         0\n","410  2009-12-29  0.261079    0.00  2009    53         0\n","\n","[411 rows x 6 columns]\n"," target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n","Feature: cyclostationary_mean_tg\n","\n","Number of features: 92\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_tg_1w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_4w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_8w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_tg_12w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 6\n","\n","Feature: cyclostationary_mean_tg_16w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 6\n","\n","Feature: cyclostationary_mean_tg_24w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_rr\n","\n","Number of features: 92\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_1w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_rr_4w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_8w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_12w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_16w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_rr_24w\n","\n","Number of features: 92\n","\n","Number of aggregated features: 8\n","\n","\n","\n","selected columns: ['cyclostationary_mean_tg_1w_1', 'cyclostationary_mean_rr_24w_2', 'cyclostationary_mean_tg_4w_0', 'cyclostationary_mean_tg_8w_1', 'cyclostationary_mean_tg_8w_0', 'cyclostationary_mean_tg_12w_5', 'cyclostat_release_Lugano_24w', 'cyclostat_release_Maggiore_16w', 'cyclostationary_mean_tg_16w_5', 'cyclostat_level_Lugano_4w', 'cyclostat_inflow_Maggiore_1w', 'cyclostat_release_Maggiore', 'cyclostat_level_Lugano_1w', 'cyclostat_release_Maggiore_4w', 'cyclostat_release_Maggiore_1w', 'cyclostat_inflow_Maggiore_4w', 'cyclostationary_mean_tg_16w_0', 'cyclostationary_mean_tg_8w_3', 'cyclostat_level_Maggiore_12w'], \n","\n","validation score: 0.22555925736388183, \n","\n","number of selected features: 19\n","\n","Full model and selected features with wrapper\n","\n","Full aggregate regression train score: 0.33950621229117384, test score: -2.0119472610545164\n","Aggregate regression train score with FS: 0.1578897757378077, test score: 0.09271058569675572\n","\n","Full model and best 5 selected features with wrapper\n","\n","Full aggregate regression train score: 0.33950621229117384, test score: -2.0119472610545164\n","Aggregate regression train score with FS: 0.13317966594737796, test score: 0.19193133272207696\n","----- MI Scores -----\n","[(43, 0.07619436851140222), (11, 0.07441931312520626), (44, 0.06906896931200217), (48, 0.06852056802960067), (46, 0.06660455307361404), (17, 0.0649726352239712), (18, 0.062483949125827526), (16, 0.061154834101528735), (45, 0.06088807942810209), (9, 0.060736978758319904), (47, 0.05824310484330773), (10, 0.05545239440512146), (42, 0.05522297523167413), (89, 0.054295157155189296), (19, 0.05402631062788339), (13, 0.05325044233230598), (2, 0.0519394248321001), (24, 0.04880568810789905), (51, 0.04657151971199622), (15, 0.046524553871722725), (60, 0.04529046878737617), (59, 0.044000308482937525), (49, 0.0427709935947236), (77, 0.04202737177106451), (88, 0.04190789459252143), (78, 0.041818526764121115), (20, 0.04109799818598041), (14, 0.0402256309956469), (76, 0.038827653046544175), (12, 0.03753729733788644), (1, 0.03671730847957851), (37, 0.03663755485539108), (80, 0.03455350135826824), (35, 0.03431038625228101), (28, 0.03370025462479971), (92, 0.03243262035231984), (83, 0.032002396320943746), (29, 0.03160172786979048), (52, 0.030877908471773914), (25, 0.030603657060409385), (99, 0.03015489995525939), (94, 0.029096993004445224), (58, 0.0287590274396903), (38, 0.02872009974401041), (5, 0.028094508200157096), (81, 0.0261434086834642), (41, 0.026055107062926502), (34, 0.025095397734455085), (93, 0.024707407342511152), (82, 0.024333897539835253), (95, 0.023793929211500614), (54, 0.023326683582522715), (91, 0.022787553903856228), (79, 0.02253515338620965), (100, 0.02185642353004048), (97, 0.021201045477643902), (66, 0.019683674697863963), (70, 0.019401056144409373), (101, 0.019311135066338005), (90, 0.018781723381094045), (26, 0.01803193206066688), (32, 0.017058757431385744), (84, 0.017045569016774356), (55, 0.016828879265827934), (56, 0.015451812824777122), (57, 0.015049707608688807), (27, 0.015013385946260248), (63, 0.014917791231975104), (73, 0.014679133520503993), (68, 0.013936453922602928), (50, 0.01384838851225433), (40, 0.013396341346383178), (21, 0.012928991013933152), (64, 0.012832363091462967), (87, 0.012682459160006404), (65, 0.012641765001735271), (75, 0.012114109290322368), (4, 0.012078822162635745), (6, 0.0116198079023633), (67, 0.010825060037588714), (8, 0.01045440605539172), (39, 0.010382096110601088), (71, 0.009671990696651625), (98, 0.008418213346720669), (96, 0.008294665702062911), (85, 0.008282081820316934), (36, 0.008001844377611396), (33, 0.007458266268690884), (7, 0.0071766066539365935), (74, 0.0071560037046853875), (53, 0.007091986352875644), (22, 0.00604328321888007), (3, 0.005235279751429141), (61, 0.004483391034735937), (31, 0.004445007921873684), (72, 0.003241891707893248), (0, 0.0022707314974768425), (69, 0.0012844786940756298), (102, 0.0010400024002533803), (86, 0.0003457871689164371), (23, -0.000623613565416523), (30, -0.0027287068103524032), (62, -0.007011565293243101)]\n","Best MI score: 0.07619436851140222\n","Adding first best original feature: 43\n","CMI: 0.025908770651699206\n","CMI: 0.007254437389563023\n","CMI: 0.0006989261845866263\n","CMI: 0.0017617818013760528\n","CMI: 0.03235101205349755\n","CMI: 0.04451309218245032\n","CMI: 0.06274910140135324\n","CMI: 0.04688600569028524\n","CMI: 0.07604106875566262\n","CMI: 0.07820251929407833\n","CMI: 0.03352105473726619\n","CMI: 0.06536070011399113\n","CMI: 0.07053027474182182\n","CMI: 0.06325241609656686\n","CMI: 0.07512071122754112\n","CMI: 0.06159443434064825\n","CMI: 0.00420095863000762\n","CMI: 0.011087294071173051\n","CMI: 0.004818307176485986\n","CMI: 0.013327223392531715\n","CMI: 0.007592193990890117\n","CMI: 0.0003966652364949669\n","CMI: 0.00784749952241108\n","CMI: 0.013624819098180724\n","CMI: 0.0024070241981222484\n","CMI: 0.01096956243228181\n","CMI: 0.00204696544792983\n","CMI: 0.003927566539001892\n","CMI: 0.001407862232270643\n","CMI: 0.0009120306323470301\n","CMI: 0.0030631925499413487\n","CMI: 0.002637055565816629\n","CMI: 0.018046360346559306\n","CMI: 0.0014556706061218394\n","CMI: 0.013220938789374567\n","CMI: 0.013776169253487042\n","CMI: 0.01304102841356708\n","CMI: 0.0027315178852214544\n","CMI: 0.017453087007609086\n","CMI: 0.007181260541283985\n","CMI: 0.023217874671034144\n","CMI: 0.010756090479374522\n","CMI: 0.020791192106256393\n","CMI: 0.000614257354135353\n","CMI: 0.011231497019055625\n","CMI: 0.035245872115852867\n","CMI: 0.02743734432527563\n","CMI: 0.031068821063846244\n","CMI: 0.005821446583474527\n","CMI: 0.003199939712128397\n","CMI: 0.012861191773261352\n","CMI: 0.004954082178859065\n","CMI: 0.012409545659913701\n","CMI: 0.02216986812888805\n","CMI: 0.001491152662443443\n","CMI: 0.012320150079380296\n","CMI: 0.014394868486600584\n","CMI: 0.015710572519931423\n","CMI: 0.008449297219921423\n","CMI: 0.005359375209194328\n","CMI: 0.0015980427824700966\n","CMI: 0.004729961990848297\n","CMI: 0.0016334117291859074\n","Highest CMI score: 0.07820251929407833\n","Adding original feature: 14\n","CMI: 0.00023698404745559065\n","CMI: 0.009777475472491998\n","CMI: 0.003171706306189598\n","CMI: 0.0027166454287841646\n","CMI: 0.0017503132339033445\n","CMI: 0.0034353062891590014\n","CMI: 0.0010147645209668266\n","CMI: 0.0005273569465762962\n","CMI: 0.023094378273632976\n","CMI: 0.004871348373749335\n","CMI: 0.00034092158075052503\n","CMI: 0.009684719298066191\n","CMI: 0.012033931188334512\n","CMI: 0.006748927363219942\n","CMI: 0.0040350376129183185\n","CMI: 0.0004494317018657601\n","CMI: 0.014917796244612785\n","CMI: 0.014828443274983172\n","CMI: 0.00019675251132261762\n","CMI: 0.005367333687960801\n","CMI: 0.0005077016467180673\n","CMI: 0.006906046162236973\n","CMI: 0.002787162718989711\n","CMI: 0.0040462783323144125\n","CMI: 0.008055103436937217\n","CMI: 0.008752568992005938\n","Highest CMI score: 0.023094378273632976\n","Adding original feature: 42\n","CMI: 0.0023654461465001386\n","CMI: 0.0028914635063249094\n","CMI: 0.0018542431720025288\n","CMI: 0.0032457784476212503\n","CMI: 0.0031728835117390553\n","CMI: 0.005413144503614853\n","CMI: 3.292299519816466e-05\n","Highest CMI score: 0.005413144503614853\n","Adding original feature: 46\n","CMI: 0.0008777971572518639\n","CMI: 0.001147400655581443\n","CMI: 0.0011054647387278571\n","CMI: 0.00025670996685378533\n","Highest CMI score: 0.001147400655581443\n","Adding original feature: 28\n","CMI: 0.0013979972272976093\n","Highest CMI score: 0.0013979972272976093\n","Adding original feature: 44\n","CMI: 0.002592751137194066\n","Highest CMI score: 0.002592751137194066\n","Adding original feature: 25\n","Highest CMI score: 0.0\n","\n","[43, 14, 42, 46, 28, 44, 25]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.33950621229117384, test score: -2.0119472610545164\n","Aggregate regression train score with FS: 0.13887647527800873, test score: 0.11521803609963266\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.33950621229117384, test score: -2.0119472610545164\n","Aggregate regression train score with FS: 0.13724594973272608, test score: 0.12451069948934679\n","###### Binary Classification ######\n","Train accuracy logistic regression CMI:  0.66\n","Test accuracy logistic regression CMI:  0.667 \n","\n","Train accuracy logistic regression CMI best 5:  0.678\n","Test accuracy logistic regression CMI best 5:  0.649 \n","\n","Train accuracy logistic regression wrapper:  0.64\n","Test accuracy logistic regression wrapper:  0.693 \n","\n","####################Oglio_Iseo####################\n","target samples:            date      mean  median  year  week  mean_std\n","0    2001-01-05  0.243674    0.26  2001     1         0\n","1    2001-01-13  0.424116    0.44  2001     2         0\n","2    2001-01-21  0.393786    0.39  2001     3         0\n","3    2001-01-29  0.314939    0.31  2001     5         0\n","4    2001-02-06  0.464902    0.48  2001     6         1\n","..          ...       ...     ...   ...   ...       ...\n","406  2009-11-27  0.465734    0.48  2009    48         1\n","407  2009-12-05  0.447390    0.47  2009    49         1\n","408  2009-12-13  0.556760    0.59  2009    50         1\n","409  2009-12-21  0.307880    0.00  2009    52         0\n","410  2009-12-29  0.034211    0.00  2009    53         0\n","\n","[411 rows x 6 columns]\n"," target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n","Feature: cyclostationary_mean_tg\n","\n","Number of features: 74\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_tg_1w\n","\n","Number of features: 74\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_tg_4w\n","\n","Number of features: 74\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_tg_8w\n","\n","Number of features: 74\n","\n","Number of aggregated features: 6\n","\n","Feature: cyclostationary_mean_tg_12w\n","\n","Number of features: 74\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_tg_16w\n","\n","Number of features: 74\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_tg_24w\n","\n","Number of features: 74\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr\n","\n","Number of features: 74\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_rr_1w\n","\n","Number of features: 74\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_4w\n","\n","Number of features: 74\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_rr_8w\n","\n","Number of features: 74\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_12w\n","\n","Number of features: 74\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_rr_16w\n","\n","Number of features: 74\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_rr_24w\n","\n","Number of features: 74\n","\n","Number of aggregated features: 3\n","\n","\n","\n","selected columns: ['cyclostationary_mean_tg_3', 'cyclostationary_mean_rr_4w_2', 'cyclostationary_mean_rr_16w_0', 'cyclostationary_mean_rr_8w_2', 'cyclostationary_mean_rr_1w_0', 'cyclostat_release_Iseo_24w', 'cyclostationary_mean_rr_12w_2', 'cyclostationary_mean_tg_16w_0', 'cyclostationary_mean_tg_24w_1', 'cyclostationary_mean_tg_1', 'cyclostationary_mean_tg_24w_0', 'cyclostationary_mean_rr_16w_1', 'cyclostationary_mean_rr_12w_0', 'cyclostationary_mean_rr_8w_1'], \n","\n","validation score: 0.2680604665717242, \n","\n","number of selected features: 14\n","\n","Full model and selected features with wrapper\n","\n","Full aggregate regression train score: 0.3169762655112357, test score: -0.06117692042621803\n","Aggregate regression train score with FS: 0.1847909441068305, test score: 0.15437079852668345\n","\n","Full model and best 5 selected features with wrapper\n","\n","Full aggregate regression train score: 0.3169762655112357, test score: -0.06117692042621803\n","Aggregate regression train score with FS: 0.1747698865420727, test score: 0.16318212071197047\n","----- MI Scores -----\n","[(0, 0.1905744496327849), (6, 0.18664486612794157), (3, 0.17896132992993388), (5, 0.17523729285491366), (4, 0.17508172603625458), (7, 0.1567292659441962), (8, 0.15228505454861166), (17, 0.14753170357196116), (16, 0.13265570198383692), (12, 0.1179076390924761), (10, 0.11566535428518963), (9, 0.10998199352982363), (18, 0.10933125458833352), (20, 0.09004668302963746), (11, 0.0898903173685656), (15, 0.08520717043901437), (1, 0.08297051568246404), (13, 0.08268479812984976), (14, 0.08105155385908877), (19, 0.0800034400313862), (56, 0.07266497221224631), (2, 0.07195104222930632), (28, 0.06615760823187876), (24, 0.06568966212252096), (29, 0.06384561451534691), (22, 0.059837919207322246), (55, 0.05516701885465093), (23, 0.054194147706084196), (27, 0.05316938841480197), (54, 0.05188683317206092), (63, 0.05102256986157405), (21, 0.05038893484353032), (59, 0.0502229974523168), (51, 0.04780120789141581), (26, 0.04622827544494628), (61, 0.04508211551080975), (57, 0.04159780446439129), (30, 0.040986056148187996), (62, 0.03961272489309636), (25, 0.03918759230332868), (60, 0.03729185253073095), (45, 0.03722712311744739), (52, 0.035770550084311264), (32, 0.033037162005768485), (53, 0.03268846003151463), (43, 0.031017172889424172), (33, 0.030810121632042577), (58, 0.026720121249542005), (66, 0.026496469444884787), (67, 0.024982155243445634), (34, 0.024922595674756905), (70, 0.023335142398340007), (31, 0.022941433175940145), (38, 0.022547904723786396), (77, 0.021867964151221792), (39, 0.021239915455380284), (48, 0.021186874053272537), (74, 0.020726845524726454), (36, 0.020108930352637118), (65, 0.019998338566571308), (69, 0.018850919705713926), (64, 0.01789038139075917), (75, 0.01779064829322368), (78, 0.017061945803314417), (71, 0.015829477313208728), (42, 0.014333768190424102), (37, 0.012204813013872957), (44, 0.011854501593770255), (40, 0.011526702628185462), (46, 0.011263322315825358), (49, 0.00927545270063909), (35, 0.009265213312162771), (68, 0.008824703184477731), (47, 0.007772738037063627), (73, 0.002868876816380014), (50, 0.001949206939100508), (41, -0.0006906301575006161), (72, -0.008845519408810386), (76, -0.009153097178596354)]\n","Best MI score: 0.1905744496327849\n","Adding first best original feature: 0\n","Highest CMI score: -0.04469254778687648\n","\n","[0]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.3169762655112357, test score: -0.06117692042621803\n","Aggregate regression train score with FS: 0.006547512268677558, test score: 0.02161700402959099\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.3169762655112357, test score: -0.06117692042621803\n","Aggregate regression train score with FS: 0.006547512268677558, test score: 0.02161700402959099\n","###### Binary Classification ######\n","Train accuracy logistic regression CMI:  0.552\n","Test accuracy logistic regression CMI:  0.654 \n","\n","Train accuracy logistic regression CMI best 5:  0.552\n","Test accuracy logistic regression CMI best 5:  0.654 \n","\n","Train accuracy logistic regression wrapper:  0.693\n","Test accuracy logistic regression wrapper:  0.684 \n","\n","####################Lambro_Olona####################\n","target samples:            date      mean  median  year  week  mean_std\n","0    2001-01-05  0.369625    0.45  2001     1         0\n","1    2001-01-13  0.429563    0.43  2001     2         0\n","2    2001-01-21  0.470784    0.48  2001     3         1\n","3    2001-01-29  0.370358    0.37  2001     5         0\n","4    2001-02-06  0.372263    0.37  2001     6         0\n","..          ...       ...     ...   ...   ...       ...\n","406  2009-11-27  0.402059    0.40  2009    48         0\n","407  2009-12-05  0.389658    0.39  2009    49         0\n","408  2009-12-13  0.545184    0.56  2009    50         1\n","409  2009-12-21  0.447916    0.55  2009    52         1\n","410  2009-12-29  0.277300    0.32  2009    53         0\n","\n","[411 rows x 6 columns]\n"," target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n","Feature: cyclostationary_mean_tg\n","\n","Number of features: 55\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_1w\n","\n","Number of features: 55\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_tg_4w\n","\n","Number of features: 55\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_8w\n","\n","Number of features: 55\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_12w\n","\n","Number of features: 55\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_16w\n","\n","Number of features: 55\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_tg_24w\n","\n","Number of features: 55\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr\n","\n","Number of features: 55\n","\n","Number of aggregated features: 10\n","\n","Feature: cyclostationary_mean_rr_1w\n","\n","Number of features: 55\n","\n","Number of aggregated features: 5\n","\n","Feature: cyclostationary_mean_rr_4w\n","\n","Number of features: 55\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_8w\n","\n","Number of features: 55\n","\n","Number of aggregated features: 4\n","\n","Feature: cyclostationary_mean_rr_12w\n","\n","Number of features: 55\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_16w\n","\n","Number of features: 55\n","\n","Number of aggregated features: 3\n","\n","Feature: cyclostationary_mean_rr_24w\n","\n","Number of features: 55\n","\n","Number of aggregated features: 4\n","\n","\n","\n","selected columns: ['cyclostationary_mean_tg_1w_3', 'cyclostationary_mean_rr_8w_2', 'cyclostationary_mean_tg_4w_0', 'cyclostat_inflow_Iseo_24w', 'cyclostationary_mean_rr_16w_0', 'cyclostationary_mean_rr_1w_0', 'cyclostationary_mean_rr_16w_2', 'cyclostationary_mean_tg_4w_4', 'cyclostationary_mean_tg_8w_4', 'cyclostationary_mean_tg_8w_3', 'cyclostationary_mean_tg_8w_2', 'cyclostationary_mean_tg_8w_5', 'cyclostationary_mean_tg_24w_0', 'cyclostationary_mean_rr_8w_0', 'cyclostationary_mean_tg_8w_1', 'cyclostationary_mean_tg_16w_2', 'cyclostationary_mean_tg_12w_2', 'cyclostationary_mean_tg_12w_3', 'cyclostationary_mean_rr_24w_0', 'cyclostat_release_Iseo_4w', 'cyclostationary_mean_tg_4w_1', 'cyclostat_inflow_Iseo_16w', 'cyclostationary_mean_rr_4w_1', 'cyclostationary_mean_rr_4w_2', 'cyclostationary_mean_rr_4w_3'], \n","\n","validation score: 0.3266162578896321, \n","\n","number of selected features: 25\n","\n","Full model and selected features with wrapper\n","\n","Full aggregate regression train score: 0.3096811713534863, test score: -0.023241945683435405\n","Aggregate regression train score with FS: 0.21189291073271688, test score: 0.12771950721908432\n","\n","Full model and best 5 selected features with wrapper\n","\n","Full aggregate regression train score: 0.3096811713534863, test score: -0.023241945683435405\n","Aggregate regression train score with FS: 0.160234753835092, test score: 0.18670721780059862\n","----- MI Scores -----\n","[(6, 0.19245112812108534), (0, 0.18902702087506285), (3, 0.18676888858691093), (5, 0.17193915974541277), (4, 0.1714866496766285), (8, 0.16514874481707478), (7, 0.1562410019108753), (16, 0.14271975310409724), (17, 0.13916759062823184), (10, 0.12560544472179538), (11, 0.12361092771183156), (9, 0.11836959947049068), (18, 0.11080015980944924), (12, 0.10912958385414573), (20, 0.091975755270641), (19, 0.09175415248268869), (1, 0.09158506863816884), (13, 0.09030933680490363), (14, 0.08029467905726613), (24, 0.07628910345502721), (2, 0.07574976285071564), (15, 0.07412801703850945), (27, 0.07237604907644708), (56, 0.0633423220268997), (65, 0.0631228517579975), (25, 0.06290970061901553), (29, 0.06056595361495535), (23, 0.060067312931464834), (28, 0.057726937812687756), (63, 0.05315106562773929), (57, 0.05133686210472686), (55, 0.05069580423619974), (61, 0.05044201635593219), (45, 0.04913106028312652), (21, 0.04812300272940767), (22, 0.04728561902553588), (51, 0.04590854823492392), (54, 0.04531900324748664), (66, 0.04520653292179667), (75, 0.042238564455000085), (53, 0.04174703966762112), (59, 0.041153945463665575), (26, 0.04114341483231765), (30, 0.040574419496367364), (74, 0.03944196083989261), (69, 0.0377322188897196), (37, 0.03651041399086172), (43, 0.03587168527780571), (62, 0.03536119603211719), (77, 0.035360037778866996), (58, 0.03407702322772381), (34, 0.03197320315652784), (31, 0.030043675418177707), (33, 0.029336714803511046), (72, 0.028829625009462113), (78, 0.028750120387565452), (73, 0.02615529235699964), (36, 0.025681274393615727), (71, 0.023894338649694626), (64, 0.02311811161777591), (60, 0.02163407861993433), (68, 0.020586159720118128), (35, 0.01804257293659439), (76, 0.017394965302422138), (46, 0.01732315208930794), (39, 0.017260374529849926), (52, 0.014174244764278487), (49, 0.013670110844446259), (42, 0.013076061283824032), (67, 0.011862941118455232), (38, 0.011733644196421696), (44, 0.011301569370589418), (70, 0.011076553530965243), (48, 0.0105254134454464), (50, 0.00792352276765224), (32, 0.00709638482479818), (40, 0.003201106326645513), (41, 0.0026839500466681854), (47, 0.0023550470040747807)]\n","Best MI score: 0.19245112812108534\n","Adding first best original feature: 6\n","Highest CMI score: -0.023892772180287236\n","\n","[6]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.3096811713534863, test score: -0.023241945683435405\n","Aggregate regression train score with FS: 0.020659972501833268, test score: 0.011126051055714403\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.3096811713534863, test score: -0.023241945683435405\n","Aggregate regression train score with FS: 0.020659972501833268, test score: 0.011126051055714403\n","###### Binary Classification ######\n","Train accuracy logistic regression CMI:  0.57\n","Test accuracy logistic regression CMI:  0.526 \n","\n","Train accuracy logistic regression CMI best 5:  0.57\n","Test accuracy logistic regression CMI best 5:  0.526 \n","\n","Train accuracy logistic regression wrapper:  0.673\n","Test accuracy logistic regression wrapper:  0.684 \n","\n"]}],"source":["basins = ['Adda', 'Ticino', 'Oglio_Iseo', 'Lambro_Olona']\n","path_target = \"./csv/\"\n","path_features='./features_allvalues/'\n","path_features_lakes='./lakes/'\n","destination_folder = './GenLinCFA/temp_prec_lakes/internal_ordering/'\n","\n","for basin in basins:\n","    print('####################' + basin + '####################')\n","\n","    target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target_binary('',max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01',\n","      path=path_target+basin+'.csv', window_size = 1)\n","\n","    eps = 0.37\n","    actual_path = path_features+basin+'_aggreg.csv'\n","    lakes_actual_path = path_features_lakes + 'lakes_' + basin + '_with_aggreg.csv'\n","\n","    output,aggregate_trainVal_temp_prec,aggregate_test_temp_prec = aggregate_unfolded_data(actual_path,['cyclostationary_mean_tg',\n","                                                                             'cyclostationary_mean_tg_1w',\n","                                                                             'cyclostationary_mean_tg_4w',\n","                                                                             'cyclostationary_mean_tg_8w',\n","                                                                             'cyclostationary_mean_tg_12w',\n","                                                                             'cyclostationary_mean_tg_16w',\n","                                                                             'cyclostationary_mean_tg_24w',\n","                                                                             'cyclostationary_mean_rr',\n","                                                                             'cyclostationary_mean_rr_1w',\n","                                                                             'cyclostationary_mean_rr_4w',\n","                                                                             'cyclostationary_mean_rr_8w',\n","                                                                             'cyclostationary_mean_rr_12w',\n","                                                                             'cyclostationary_mean_rr_16w',\n","                                                                             'cyclostationary_mean_rr_24w'\n","                                                                            ],\n","                                                                       target_df_trainVal, eps=eps,\n","                                                                       max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01')\n","\n","    if os.path.isfile(lakes_actual_path):\n","      df_lakes = pd.read_csv(lakes_actual_path)\n","\n","      df_lakes = df_lakes.drop(\"Unnamed: 0\", axis='columns')\n","\n","      df_lakes_trainVal = df_lakes.loc[(df_lakes['date'] > '2001-01-01') & (df_lakes['date'] <= '2015-01-01'),:]\n","      df_lakes_trainVal.reset_index(inplace = True, drop = True)\n","      df_lakes_trainVal = df_lakes_trainVal.iloc[:,3:]\n","      df_lakes_test = df_lakes.loc[(df_lakes['date'] > '2015-01-01') & (df_lakes['date'] <= '2020-01-01'),:]\n","      df_lakes_test.reset_index(inplace = True, drop = True)\n","      df_lakes_test = df_lakes_test.iloc[:,3:]\n","\n","      aggregate_trainVal = pd.concat((df_lakes_trainVal,aggregate_trainVal_temp_prec),axis=1)\n","      aggregate_test = pd.concat((df_lakes_test,aggregate_test_temp_prec),axis=1)\n","\n","    selected_colnames = FS_with_linearWrapper(aggregate_trainVal, target_df_train, target_df_val, min(50,aggregate_trainVal.shape[1]-1), 228)\n","\n","    print('\\nFull model and selected features with wrapper\\n')\n","    compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n","\n","    print('\\nFull model and best 5 selected features with wrapper\\n')\n","    compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames[0:5])\n","\n","    train_string = destination_folder + basin + '_genLinCFA_wrapper_best5_train_withLakes.csv'\n","    val_string = destination_folder + basin + '_genLinCFA_wrapper_best5_val_withLakes.csv'\n","    test_string = destination_folder + basin + '_genLinCFA_wrapper_best5_test_withLakes.csv'\n","    X_train_wrapper = aggregate_trainVal.loc[:410,selected_colnames[0:5]]\n","    X_validation_wrapper = aggregate_trainVal.loc[411:,selected_colnames[0:5]]\n","    X_train_validation_wrapper = pd.concat([X_train_wrapper, X_validation_wrapper])\n","    X_test_wrapper = aggregate_test.loc[:,selected_colnames[0:5]]\n","    X_train_wrapper.to_csv(train_string, index=False)\n","    X_validation_wrapper.to_csv(val_string, index=False)\n","    X_test_wrapper.to_csv(test_string, index=False)\n","\n","    res = {\n","            \"delta\" : [],\n","            \"numSelected\" : [],\n","            \"selectedFeatures\" : []\n","        }\n","\n","    res['selectedFeatures'] = forwardFeatureSelection(10,np.array(aggregate_trainVal),\n","                                                      np.array(target_df_trainVal.mean_std),res,10,1)\n","\n","    selectedFeatures='selectedFeatures'\n","    print(f'\\n{res[selectedFeatures]}\\n')\n","\n","    selected_colnames = aggregate_trainVal.columns[res['selectedFeatures']]\n","\n","    print('\\nFull model and selected features with CMI\\n')\n","    compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n","\n","    print('\\nFull model and best 5 selected features with CMI\\n')\n","    compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames[0:5])\n","\n","    train_string = destination_folder + basin + '_genLinCFA_best5_CMI_train_withLakes.csv'\n","    val_string = destination_folder + basin + '_genLinCFA_best5_CMI_val_withLakes.csv'\n","    test_string = destination_folder + basin + '_genLinCFA_best5_CMI_test_withLakes.csv'\n","\n","    X_train_CMI5 = aggregate_trainVal.loc[:410,selected_colnames[0:5]]\n","    X_validation_CMI5 = aggregate_trainVal.loc[411:,selected_colnames[0:5]]\n","    X_train_validation_CMI5 = pd.concat([X_train_CMI5, X_validation_CMI5])\n","    X_test_CMI5 = aggregate_test.loc[:,selected_colnames[0:5]]\n","\n","    selected_colnames_CMI5 = aggregate_trainVal.loc[:,selected_colnames[0:5]].columns.values\n","\n","    X_train_CMI5.to_csv(train_string, index=False)\n","    X_validation_CMI5.to_csv(val_string, index=False)\n","    X_test_CMI5.to_csv(test_string, index=False)\n","\n","    train_string = destination_folder + basin + '_genLinCFA_CMI_train_withLakes.csv'\n","    val_string = destination_folder + basin + '_genLinCFA_CMI_val_withLakes.csv'\n","    test_string = destination_folder + basin + '_genLinCFA_CMI_test_withLakes.csv'\n","\n","    X_train_CMI = aggregate_trainVal.loc[:410,selected_colnames]\n","    X_validation_CMI = aggregate_trainVal.loc[411:,selected_colnames]\n","    X_train_validation_CMI = pd.concat([X_train_CMI, X_validation_CMI])\n","    X_test_CMI = aggregate_test.loc[:,selected_colnames]\n","\n","    X_train_CMI.to_csv(train_string, index=False)\n","    X_validation_CMI.to_csv(val_string, index=False)\n","    X_test_CMI.to_csv(test_string, index=False)\n","\n","    print('###### Binary Classification ######')\n","\n","    target_df_train = target_df_train.apply(lambda x: np.sign(x.mean_std), axis=1)\n","    target_df_val = target_df_val.apply(lambda x: np.sign(x.mean_std), axis=1)\n","    target_df_test = target_df_test.apply(lambda x: np.sign(x.mean_std), axis=1)\n","    target_df_trainVal = target_df_trainVal.apply(lambda x: np.sign(x.mean_std), axis=1)\n","\n","    log_regr = LogisticRegression(solver='lbfgs', random_state = 42)\n","\n","    # CMI\n","    log_regr.fit(X_train_validation_CMI, target_df_trainVal)\n","    print(\"Train accuracy logistic regression CMI: \", round(log_regr.score(X_train_validation_CMI, target_df_trainVal),3))\n","    print(\"Test accuracy logistic regression CMI: \", round(log_regr.score(X_test_CMI, target_df_test),3), \"\\n\")\n","\n","    # CMI best 5\n","    log_regr.fit(X_train_validation_CMI5, target_df_trainVal)\n","    print(\"Train accuracy logistic regression CMI best 5: \", round(log_regr.score(X_train_validation_CMI5, target_df_trainVal),3))\n","    print(\"Test accuracy logistic regression CMI best 5: \", round(log_regr.score(X_test_CMI5, target_df_test),3), \"\\n\")\n","\n","    # wrapper\n","    log_regr.fit(X_train_validation_wrapper, target_df_trainVal)\n","    print(\"Train accuracy logistic regression wrapper: \", round(log_regr.score(X_train_validation_wrapper, target_df_trainVal),3))\n","    print(\"Test accuracy logistic regression wrapper: \", round(log_regr.score(X_test_wrapper, target_df_test),3), \"\\n\")"],"id":"SpEton0e55Ev"},{"cell_type":"markdown","metadata":{"id":"rYpR9P_TOe31"},"source":["## Multi task scores"],"id":"rYpR9P_TOe31"},{"cell_type":"code","execution_count":6,"metadata":{"id":"RJvLiezWRmUG","executionInfo":{"status":"ok","timestamp":1690351271447,"user_tz":-120,"elapsed":261,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"}}},"outputs":[],"source":["# for binary classification\n","\n","from sklearn.metrics import accuracy_score\n","def MTL_scores(clust_basins, df_train, df_val, df_test, targets_df_train, targets_df_val, targets_df_test):\n","\n","    colnames = [x for x in df_train.columns if x.startswith(tuple(clust_basins))]\n","\n","    clusterdf_train_withClass = pd.DataFrame()\n","    clusterdf_val_withClass = pd.DataFrame()\n","    clusterdf_test_withClass = pd.DataFrame()\n","\n","    for i in range(len(clust_basins)):\n","        clusterdf_train_withClass = pd.concat((clusterdf_train_withClass,pd.concat((df_train[colnames],pd.DataFrame(1+i*np.ones(len(df_train)),columns=['basin'])),axis=1)),axis=0)\n","        clusterdf_val_withClass = pd.concat((clusterdf_val_withClass,pd.concat((df_val[colnames],pd.DataFrame(1+i*np.ones(len(df_val)),columns=['basin'])),axis=1)),axis=0)\n","        clusterdf_test_withClass = pd.concat((clusterdf_test_withClass,pd.concat((df_test[colnames],pd.DataFrame(1+i*np.ones(len(df_test)),columns=['basin'])),axis=1)),axis=0)\n","\n","    for i in range(len(clust_basins)):\n","        clusterdf_train_withClass[clust_basins[i]] = clusterdf_train_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n","        clusterdf_val_withClass[clust_basins[i]] = clusterdf_val_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n","        clusterdf_test_withClass[clust_basins[i]] = clusterdf_test_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n","\n","    clusterdf_train_withClass = clusterdf_train_withClass.loc[:,clusterdf_train_withClass.columns != 'basin']\n","    clusterdf_val_withClass = clusterdf_val_withClass.loc[:,clusterdf_val_withClass.columns != 'basin']\n","    clusterdf_test_withClass = clusterdf_test_withClass.loc[:,clusterdf_test_withClass.columns != 'basin']\n","\n","    targets_df_train_unfolded = pd.DataFrame()\n","    targets_df_val_unfolded = pd.DataFrame()\n","    targets_df_test_unfolded = pd.DataFrame()\n","\n","    for basin in clust_basins:\n","        targets_df_train_unfolded =  pd.concat((targets_df_train_unfolded,targets_df_train[basin]),axis=0)\n","        targets_df_val_unfolded =  pd.concat((targets_df_val_unfolded,targets_df_val[basin]),axis=0)\n","        targets_df_test_unfolded =  pd.concat((targets_df_test_unfolded,targets_df_test[basin]),axis=0)\n","    targets_df_train_unfolded = targets_df_train_unfolded.reset_index(drop=True)\n","    targets_df_val_unfolded = targets_df_val_unfolded.reset_index(drop=True)\n","    targets_df_test_unfolded = targets_df_test_unfolded.reset_index(drop=True)\n","\n","    # same scores changing the solver, some differences changing penalty, some improve with l1\n","    model_ohe = LogisticRegression(max_iter = 500)\n","    model_ohe.fit(pd.concat((clusterdf_train_withClass,clusterdf_val_withClass)).values,pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)).values.ravel())\n","\n","    for basin in clust_basins:\n","        print(basin)\n","        res = model_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass[basin]==1].values)\n","        print(accuracy_score(targets_df_test[basin].values.ravel(), res))"],"id":"RJvLiezWRmUG"},{"cell_type":"code","execution_count":null,"metadata":{"id":"zvHEyv7_O-nx"},"outputs":[],"source":["### binary targets\n","basins = ['Emiliani1','Emiliani2','Garda_Mincio', 'Adda', 'Lambro_Olona', 'Ticino',\n","          'Oglio_Iseo', 'Dora', 'Piemonte_Sud', 'Piemonte_Nord']\n","\n","path_target = \"./csv/\"\n","targets_df_train = pd.DataFrame()\n","targets_df_val = pd.DataFrame()\n","targets_df_test = pd.DataFrame()\n","targets_df_trainVal = pd.DataFrame()\n","\n","for basin in basins:\n","    target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target_binary('',max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01',\n","      path=path_target+basin+'.csv', window_size = 1)\n","\n","    targets_df_train[basin] = target_df_train.mean_std\n","    targets_df_val[basin] = target_df_val.mean_std\n","    targets_df_test[basin] = target_df_test.mean_std\n","    targets_df_trainVal[basin] = target_df_trainVal.mean_std"],"id":"zvHEyv7_O-nx"},{"cell_type":"markdown","source":["## Temp Prec"],"metadata":{"id":"2EseMUwJzVbk"},"id":"2EseMUwJzVbk"},{"cell_type":"code","source":["basins = ['Adda','Dora','Emiliani1','Emiliani2','Garda_Mincio','Lambro_Olona',\n","          'Oglio_Iseo','Piemonte_Nord','Piemonte_Sud','Ticino']\n","\n","### CMI best5 features\n","path_features = './GenLinCFA/temp_prec/internal_ordering/'\n","\n","best5_CMI_fulldf_train = pd.DataFrame()\n","best5_CMI_fulldf_val = pd.DataFrame()\n","best5_CMI_fulldf_test = pd.DataFrame()\n","\n","for basin in basins:\n","    train_temp = pd.read_csv(path_features+basin+'_genLinCFA_best5_CMI_train.csv')\n","    val_temp = pd.read_csv(path_features+basin+'_genLinCFA_best5_CMI_val.csv')\n","    test_temp = pd.read_csv(path_features+basin+'_genLinCFA_best5_CMI_test.csv')\n","    best5_CMI_fulldf_train[basin+'_'+train_temp.columns.values] = train_temp\n","    best5_CMI_fulldf_val[basin+'_'+val_temp.columns.values] = val_temp\n","    best5_CMI_fulldf_test[basin+'_'+test_temp.columns.values] = test_temp"],"metadata":{"id":"f-Y3His7zq7C","executionInfo":{"status":"ok","timestamp":1690351415960,"user_tz":-120,"elapsed":9263,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"}}},"id":"f-Y3His7zq7C","execution_count":8,"outputs":[]},{"cell_type":"code","source":["basins = ['Adda','Dora','Emiliani1','Emiliani2','Garda_Mincio','Lambro_Olona',\n","          'Oglio_Iseo','Piemonte_Nord','Piemonte_Sud','Ticino']\n","\n","### CMI features\n","path_features = './GenLinCFA/temp_prec/internal_ordering/'\n","\n","CMI_fulldf_train = pd.DataFrame()\n","CMI_fulldf_val = pd.DataFrame()\n","CMI_fulldf_test = pd.DataFrame()\n","\n","for basin in basins:\n","    train_temp = pd.read_csv(path_features+basin+'_genLinCFA_CMI_train.csv')\n","    val_temp = pd.read_csv(path_features+basin+'_genLinCFA_CMI_val.csv')\n","    test_temp = pd.read_csv(path_features+basin+'_genLinCFA_CMI_test.csv')\n","    CMI_fulldf_train[basin+'_'+train_temp.columns.values] = train_temp\n","    CMI_fulldf_val[basin+'_'+val_temp.columns.values] = val_temp\n","    CMI_fulldf_test[basin+'_'+test_temp.columns.values] = test_temp"],"metadata":{"id":"k0sqLPCmz34E","executionInfo":{"status":"ok","timestamp":1690351423387,"user_tz":-120,"elapsed":7431,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"}}},"id":"k0sqLPCmz34E","execution_count":9,"outputs":[]},{"cell_type":"code","source":["basins = ['Adda','Dora','Emiliani1','Emiliani2','Garda_Mincio','Lambro_Olona',\n","          'Oglio_Iseo','Piemonte_Nord','Piemonte_Sud','Ticino']\n","\n","### wrapper best5 features\n","path_features = './GenLinCFA/temp_prec/internal_ordering/'\n","\n","best5_wrapper_fulldf_train = pd.DataFrame()\n","best5_wrapper_fulldf_val = pd.DataFrame()\n","best5_wrapper_fulldf_test = pd.DataFrame()\n","\n","for basin in basins:\n","    train_temp = pd.read_csv(path_features+basin+'_genLinCFA_wrapper_best5_train.csv')\n","    val_temp = pd.read_csv(path_features+basin+'_genLinCFA_wrapper_best5_val.csv')\n","    test_temp = pd.read_csv(path_features+basin+'_genLinCFA_wrapper_best5_test.csv')\n","    best5_wrapper_fulldf_train[basin+'_'+train_temp.columns.values] = train_temp\n","    best5_wrapper_fulldf_val[basin+'_'+val_temp.columns.values] = val_temp\n","    best5_wrapper_fulldf_test[basin+'_'+test_temp.columns.values] = test_temp"],"metadata":{"id":"JjokC8Khz4pM","executionInfo":{"status":"ok","timestamp":1690351431421,"user_tz":-120,"elapsed":8042,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"}}},"id":"JjokC8Khz4pM","execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["## Temp Prec Snow"],"metadata":{"id":"_8M5NTxhzZDy"},"id":"_8M5NTxhzZDy"},{"cell_type":"code","source":["basins = ['Adda', 'Oglio_Iseo', 'Ticino', 'Dora', 'Piemonte_Nord', 'Piemonte_Sud']\n","\n","### CMI best5 features\n","path_features = './GenLinCFA/temp_prec_snow_copernicus/'\n","\n","best5_CMI_fulldf_train = pd.DataFrame()\n","best5_CMI_fulldf_val = pd.DataFrame()\n","best5_CMI_fulldf_test = pd.DataFrame()\n","\n","for basin in basins:\n","    train_temp = pd.read_csv(path_features+basin+'_genLinCFA_best5_CMI_train_withSnow.csv')\n","    val_temp = pd.read_csv(path_features+basin+'_genLinCFA_best5_CMI_val_withSnow.csv')\n","    test_temp = pd.read_csv(path_features+basin+'_genLinCFA_best5_CMI_test_withSnow.csv')\n","    best5_CMI_fulldf_train[basin+'_'+train_temp.columns.values] = train_temp\n","    best5_CMI_fulldf_val[basin+'_'+val_temp.columns.values] = val_temp\n","    best5_CMI_fulldf_test[basin+'_'+test_temp.columns.values] = test_temp\n","\n","# exception for basin with no snow\n","basin = 'Lambro_Olona'\n","path_features = './GenLinCFA/temp_prec/internal_ordering/'\n","train_temp = pd.read_csv(path_features+basin+'_genLinCFA_best5_CMI_train.csv')\n","val_temp = pd.read_csv(path_features+basin+'_genLinCFA_best5_CMI_val.csv')\n","test_temp = pd.read_csv(path_features+basin+'_genLinCFA_best5_CMI_test.csv')\n","best5_CMI_fulldf_train[basin+'_'+train_temp.columns.values] = train_temp\n","best5_CMI_fulldf_val[basin+'_'+val_temp.columns.values] = val_temp\n","best5_CMI_fulldf_test[basin+'_'+test_temp.columns.values] = test_temp"],"metadata":{"id":"omEPxMFQ0Pfr","executionInfo":{"status":"ok","timestamp":1690353033986,"user_tz":-120,"elapsed":317,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"}}},"id":"omEPxMFQ0Pfr","execution_count":26,"outputs":[]},{"cell_type":"code","source":["basins = ['Adda', 'Oglio_Iseo', 'Ticino', 'Dora', 'Piemonte_Nord', 'Piemonte_Sud']\n","\n","### CMI features\n","path_features = './GenLinCFA/temp_prec_snow_copernicus/'\n","\n","CMI_fulldf_train = pd.DataFrame()\n","CMI_fulldf_val = pd.DataFrame()\n","CMI_fulldf_test = pd.DataFrame()\n","\n","for basin in basins:\n","    train_temp = pd.read_csv(path_features+basin+'_genLinCFA_CMI_train_withSnow.csv')\n","    val_temp = pd.read_csv(path_features+basin+'_genLinCFA_CMI_val_withSnow.csv')\n","    test_temp = pd.read_csv(path_features+basin+'_genLinCFA_CMI_test_withSnow.csv')\n","    CMI_fulldf_train[basin+'_'+train_temp.columns.values] = train_temp\n","    CMI_fulldf_val[basin+'_'+val_temp.columns.values] = val_temp\n","    CMI_fulldf_test[basin+'_'+test_temp.columns.values] = test_temp\n","\n","basin = 'Lambro_Olona'\n","path_features = './GenLinCFA/temp_prec/internal_ordering/'\n","train_temp = pd.read_csv(path_features+basin+'_genLinCFA_CMI_train.csv')\n","val_temp = pd.read_csv(path_features+basin+'_genLinCFA_CMI_val.csv')\n","test_temp = pd.read_csv(path_features+basin+'_genLinCFA_CMI_test.csv')\n","CMI_fulldf_train[basin+'_'+train_temp.columns.values] = train_temp\n","CMI_fulldf_val[basin+'_'+val_temp.columns.values] = val_temp\n","CMI_fulldf_test[basin+'_'+test_temp.columns.values] = test_temp"],"metadata":{"id":"T-tFE58C0PXO","executionInfo":{"status":"ok","timestamp":1690353036310,"user_tz":-120,"elapsed":327,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"}}},"id":"T-tFE58C0PXO","execution_count":27,"outputs":[]},{"cell_type":"code","source":["basins = ['Adda', 'Oglio_Iseo', 'Ticino', 'Dora', 'Piemonte_Nord', 'Piemonte_Sud']\n","\n","### wrapper best5 features\n","path_features = './GenLinCFA/temp_prec_snow_copernicus/'\n","\n","best5_wrapper_fulldf_train = pd.DataFrame()\n","best5_wrapper_fulldf_val = pd.DataFrame()\n","best5_wrapper_fulldf_test = pd.DataFrame()\n","\n","for basin in basins:\n","    train_temp = pd.read_csv(path_features+basin+'_genLinCFA_wrapper_best5_train_withSnow.csv')\n","    val_temp = pd.read_csv(path_features+basin+'_genLinCFA_wrapper_best5_val_withSnow.csv')\n","    test_temp = pd.read_csv(path_features+basin+'_genLinCFA_wrapper_best5_test_withSnow.csv')\n","    best5_wrapper_fulldf_train[basin+'_'+train_temp.columns.values] = train_temp\n","    best5_wrapper_fulldf_val[basin+'_'+val_temp.columns.values] = val_temp\n","    best5_wrapper_fulldf_test[basin+'_'+test_temp.columns.values] = test_temp\n","\n","basin = 'Lambro_Olona'\n","path_features = './GenLinCFA/temp_prec/internal_ordering/'\n","train_temp = pd.read_csv(path_features+basin+'_genLinCFA_wrapper_best5_train.csv')\n","val_temp = pd.read_csv(path_features+basin+'_genLinCFA_wrapper_best5_val.csv')\n","test_temp = pd.read_csv(path_features+basin+'_genLinCFA_wrapper_best5_test.csv')\n","best5_wrapper_fulldf_train[basin+'_'+train_temp.columns.values] = train_temp\n","best5_wrapper_fulldf_val[basin+'_'+val_temp.columns.values] = val_temp\n","best5_wrapper_fulldf_test[basin+'_'+test_temp.columns.values] = test_temp"],"metadata":{"id":"OYRnAWvY0PPJ","executionInfo":{"status":"ok","timestamp":1690353040537,"user_tz":-120,"elapsed":273,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"}}},"id":"OYRnAWvY0PPJ","execution_count":28,"outputs":[]},{"cell_type":"markdown","source":["## Temp Prec Snow Lakes"],"metadata":{"id":"4RUAwIEwzb91"},"id":"4RUAwIEwzb91"},{"cell_type":"code","source":["basins = ['Ticino', 'Oglio_Iseo', 'Adda', 'Lambro_Olona']\n","\n","### CMI best5 features\n","path_features = './GenLinCFA/temp_prec_snow_lakes_copernicus/'\n","\n","best5_CMI_fulldf_train = pd.DataFrame()\n","best5_CMI_fulldf_val = pd.DataFrame()\n","best5_CMI_fulldf_test = pd.DataFrame()\n","\n","for basin in basins:\n","    train_temp = pd.read_csv(path_features+basin+'_genLinCFA_best5_CMI_train_withSnowLakes.csv')\n","    val_temp = pd.read_csv(path_features+basin+'_genLinCFA_best5_CMI_val_withSnowLakes.csv')\n","    test_temp = pd.read_csv(path_features+basin+'_genLinCFA_best5_CMI_test_withSnowLakes.csv')\n","    best5_CMI_fulldf_train[basin+'_'+train_temp.columns.values] = train_temp\n","    best5_CMI_fulldf_val[basin+'_'+val_temp.columns.values] = val_temp\n","    best5_CMI_fulldf_test[basin+'_'+test_temp.columns.values] = test_temp"],"metadata":{"id":"-p8MDovs0vlT","executionInfo":{"status":"ok","timestamp":1690353263232,"user_tz":-120,"elapsed":3342,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"}}},"id":"-p8MDovs0vlT","execution_count":39,"outputs":[]},{"cell_type":"code","source":["basins = ['Ticino', 'Oglio_Iseo', 'Adda', 'Lambro_Olona']\n","\n","### CMI features\n","path_features = './GenLinCFA/temp_prec_snow_lakes_copernicus/'\n","\n","CMI_fulldf_train = pd.DataFrame()\n","CMI_fulldf_val = pd.DataFrame()\n","CMI_fulldf_test = pd.DataFrame()\n","\n","for basin in basins:\n","    train_temp = pd.read_csv(path_features+basin+'_genLinCFA_CMI_train_withSnowLakes.csv')\n","    val_temp = pd.read_csv(path_features+basin+'_genLinCFA_CMI_val_withSnowLakes.csv')\n","    test_temp = pd.read_csv(path_features+basin+'_genLinCFA_CMI_test_withSnowLakes.csv')\n","    CMI_fulldf_train[basin+'_'+train_temp.columns.values] = train_temp\n","    CMI_fulldf_val[basin+'_'+val_temp.columns.values] = val_temp\n","    CMI_fulldf_test[basin+'_'+test_temp.columns.values] = test_temp"],"metadata":{"id":"kC3m_LQ30vbZ","executionInfo":{"status":"ok","timestamp":1690353265659,"user_tz":-120,"elapsed":2433,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"}}},"id":"kC3m_LQ30vbZ","execution_count":40,"outputs":[]},{"cell_type":"code","source":["basins = ['Ticino', 'Oglio_Iseo', 'Adda', 'Lambro_Olona']\n","\n","### wrapper best5 features\n","path_features = './GenLinCFA/temp_prec_snow_lakes_copernicus/'\n","\n","best5_wrapper_fulldf_train = pd.DataFrame()\n","best5_wrapper_fulldf_val = pd.DataFrame()\n","best5_wrapper_fulldf_test = pd.DataFrame()\n","\n","for basin in basins:\n","    train_temp = pd.read_csv(path_features+basin+'_genLinCFA_wrapper_best5_train_withSnowLakes.csv')\n","    val_temp = pd.read_csv(path_features+basin+'_genLinCFA_wrapper_best5_val_withSnowLakes.csv')\n","    test_temp = pd.read_csv(path_features+basin+'_genLinCFA_wrapper_best5_test_withSnowLakes.csv')\n","    best5_wrapper_fulldf_train[basin+'_'+train_temp.columns.values] = train_temp\n","    best5_wrapper_fulldf_val[basin+'_'+val_temp.columns.values] = val_temp\n","    best5_wrapper_fulldf_test[basin+'_'+test_temp.columns.values] = test_temp"],"metadata":{"id":"slG7ZlBp0vVX","executionInfo":{"status":"ok","timestamp":1690353267989,"user_tz":-120,"elapsed":2336,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"}}},"id":"slG7ZlBp0vVX","execution_count":41,"outputs":[]},{"cell_type":"markdown","source":["## Temp Prec Lakes"],"metadata":{"id":"jo7TVpOVzk9U"},"id":"jo7TVpOVzk9U"},{"cell_type":"code","source":["basins = ['Ticino', 'Oglio_Iseo', 'Adda', 'Lambro_Olona']\n","\n","### CMI best5 features\n","path_features = './GenLinCFA/temp_prec_lakes/internal_ordering/'\n","\n","best5_CMI_fulldf_train = pd.DataFrame()\n","best5_CMI_fulldf_val = pd.DataFrame()\n","best5_CMI_fulldf_test = pd.DataFrame()\n","\n","for basin in basins:\n","    train_temp = pd.read_csv(path_features+basin+'_genLinCFA_best5_CMI_train_withLakes.csv')\n","    val_temp = pd.read_csv(path_features+basin+'_genLinCFA_best5_CMI_val_withLakes.csv')\n","    test_temp = pd.read_csv(path_features+basin+'_genLinCFA_best5_CMI_test_withLakes.csv')\n","    best5_CMI_fulldf_train[basin+'_'+train_temp.columns.values] = train_temp\n","    best5_CMI_fulldf_val[basin+'_'+val_temp.columns.values] = val_temp\n","    best5_CMI_fulldf_test[basin+'_'+test_temp.columns.values] = test_temp"],"metadata":{"id":"2_HBF54L1pqA","executionInfo":{"status":"ok","timestamp":1690353394119,"user_tz":-120,"elapsed":3894,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"}}},"id":"2_HBF54L1pqA","execution_count":51,"outputs":[]},{"cell_type":"code","source":["basins = ['Ticino', 'Oglio_Iseo', 'Adda', 'Lambro_Olona']\n","\n","### CMI features\n","path_features = './GenLinCFA/temp_prec_lakes/internal_ordering/'\n","\n","CMI_fulldf_train = pd.DataFrame()\n","CMI_fulldf_val = pd.DataFrame()\n","CMI_fulldf_test = pd.DataFrame()\n","\n","for basin in basins:\n","    train_temp = pd.read_csv(path_features+basin+'_genLinCFA_CMI_train_withLakes.csv')\n","    val_temp = pd.read_csv(path_features+basin+'_genLinCFA_CMI_val_withLakes.csv')\n","    test_temp = pd.read_csv(path_features+basin+'_genLinCFA_CMI_test_withLakes.csv')\n","    CMI_fulldf_train[basin+'_'+train_temp.columns.values] = train_temp\n","    CMI_fulldf_val[basin+'_'+val_temp.columns.values] = val_temp\n","    CMI_fulldf_test[basin+'_'+test_temp.columns.values] = test_temp"],"metadata":{"id":"M9ST6o2Y2AW5","executionInfo":{"status":"ok","timestamp":1690353396167,"user_tz":-120,"elapsed":2054,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"}}},"id":"M9ST6o2Y2AW5","execution_count":52,"outputs":[]},{"cell_type":"code","source":["basins = ['Ticino', 'Oglio_Iseo', 'Adda', 'Lambro_Olona']\n","\n","### wrapper best5 features\n","path_features = './GenLinCFA/temp_prec_lakes/internal_ordering/'\n","\n","best5_wrapper_fulldf_train = pd.DataFrame()\n","best5_wrapper_fulldf_val = pd.DataFrame()\n","best5_wrapper_fulldf_test = pd.DataFrame()\n","\n","for basin in basins:\n","    train_temp = pd.read_csv(path_features+basin+'_genLinCFA_wrapper_best5_train_withLakes.csv')\n","    val_temp = pd.read_csv(path_features+basin+'_genLinCFA_wrapper_best5_val_withLakes.csv')\n","    test_temp = pd.read_csv(path_features+basin+'_genLinCFA_wrapper_best5_test_withLakes.csv')\n","    best5_wrapper_fulldf_train[basin+'_'+train_temp.columns.values] = train_temp\n","    best5_wrapper_fulldf_val[basin+'_'+val_temp.columns.values] = val_temp\n","    best5_wrapper_fulldf_test[basin+'_'+test_temp.columns.values] = test_temp"],"metadata":{"id":"J9iAa3PU2ALY","executionInfo":{"status":"ok","timestamp":1690353398895,"user_tz":-120,"elapsed":2733,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"}}},"id":"J9iAa3PU2ALY","execution_count":53,"outputs":[]},{"cell_type":"markdown","source":["## MTL scores"],"metadata":{"id":"8uRbqslP2Sjk"},"id":"8uRbqslP2Sjk"},{"cell_type":"markdown","source":["### CMI best 5"],"metadata":{"id":"gRpxKBOG2k34"},"id":"gRpxKBOG2k34"},{"cell_type":"code","source":["MTL_scores(clust_basins=['Emiliani1','Emiliani2','Garda_Mincio'], df_train=best5_CMI_fulldf_train, df_val=best5_CMI_fulldf_val, df_test=best5_CMI_fulldf_test, targets_df_train=targets_df_train, targets_df_val=targets_df_val, targets_df_test=targets_df_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZoZJRqke2t8G","executionInfo":{"status":"ok","timestamp":1690353398896,"user_tz":-120,"elapsed":15,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"}},"outputId":"7e9d56cc-3c2a-46c9-fb13-1ce416651242"},"id":"ZoZJRqke2t8G","execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["Emiliani1\n","0.5833333333333334\n","Emiliani2\n","0.5789473684210527\n","Garda_Mincio\n","0.6491228070175439\n"]}]},{"cell_type":"code","source":["MTL_scores(clust_basins=['Dora','Piemonte_Sud', 'Piemonte_Nord'], df_train=best5_CMI_fulldf_train, df_val=best5_CMI_fulldf_val, df_test=best5_CMI_fulldf_test, targets_df_train=targets_df_train, targets_df_val=targets_df_val, targets_df_test=targets_df_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EvLPLLtF2t2q","executionInfo":{"status":"ok","timestamp":1690353399394,"user_tz":-120,"elapsed":504,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"}},"outputId":"e2fa8921-18b4-45a6-f9b0-98e75af573f4"},"id":"EvLPLLtF2t2q","execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["Dora\n","0.40350877192982454\n","Piemonte_Sud\n","0.5921052631578947\n","Piemonte_Nord\n","0.5745614035087719\n"]}]},{"cell_type":"code","source":["MTL_scores(clust_basins=['Adda', 'Lambro_Olona', 'Oglio_Iseo', 'Ticino'], df_train=best5_CMI_fulldf_train, df_val=best5_CMI_fulldf_val, df_test=best5_CMI_fulldf_test, targets_df_train=targets_df_train, targets_df_val=targets_df_val, targets_df_test=targets_df_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qGPNXi1z2twZ","executionInfo":{"status":"ok","timestamp":1690353399395,"user_tz":-120,"elapsed":6,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"}},"outputId":"71ffc27f-d3c3-4b35-af9e-324fd25dccc5"},"id":"qGPNXi1z2twZ","execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["Adda\n","0.6666666666666666\n","Lambro_Olona\n","0.6929824561403509\n","Oglio_Iseo\n","0.6710526315789473\n","Ticino\n","0.706140350877193\n"]}]},{"cell_type":"markdown","source":["### CMI"],"metadata":{"id":"iNtFMdZ62ozR"},"id":"iNtFMdZ62ozR"},{"cell_type":"code","source":["MTL_scores(clust_basins=['Emiliani1','Emiliani2','Garda_Mincio'], df_train=CMI_fulldf_train, df_val=CMI_fulldf_val, df_test=CMI_fulldf_test, targets_df_train=targets_df_train, targets_df_val=targets_df_val, targets_df_test=targets_df_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ref3W4xw2ulD","executionInfo":{"status":"ok","timestamp":1690353399896,"user_tz":-120,"elapsed":505,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"}},"outputId":"0a4707b8-57c3-4200-f400-e504f631e27d"},"id":"Ref3W4xw2ulD","execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["Emiliani1\n","0.5833333333333334\n","Emiliani2\n","0.5789473684210527\n","Garda_Mincio\n","0.6491228070175439\n"]}]},{"cell_type":"code","source":["MTL_scores(clust_basins=['Dora','Piemonte_Sud', 'Piemonte_Nord'], df_train=CMI_fulldf_train, df_val=CMI_fulldf_val, df_test=CMI_fulldf_test, targets_df_train=targets_df_train, targets_df_val=targets_df_val, targets_df_test=targets_df_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m97r-mHz2ufa","executionInfo":{"status":"ok","timestamp":1690353399896,"user_tz":-120,"elapsed":5,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"}},"outputId":"d273cc80-293f-4b51-b144-5ac974a2beb5"},"id":"m97r-mHz2ufa","execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["Dora\n","0.40350877192982454\n","Piemonte_Sud\n","0.5921052631578947\n","Piemonte_Nord\n","0.5745614035087719\n"]}]},{"cell_type":"code","source":["MTL_scores(clust_basins=['Adda', 'Lambro_Olona', 'Oglio_Iseo', 'Ticino'], df_train=CMI_fulldf_train, df_val=CMI_fulldf_val, df_test=CMI_fulldf_test, targets_df_train=targets_df_train, targets_df_val=targets_df_val, targets_df_test=targets_df_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UVJot7_q2uaX","executionInfo":{"status":"ok","timestamp":1690353400311,"user_tz":-120,"elapsed":418,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"}},"outputId":"4fb43e12-b698-4ff1-90c4-1a79b9390752"},"id":"UVJot7_q2uaX","execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["Adda\n","0.6754385964912281\n","Lambro_Olona\n","0.6973684210526315\n","Oglio_Iseo\n","0.6578947368421053\n","Ticino\n","0.7017543859649122\n"]}]},{"cell_type":"markdown","source":["### Wrapper best 5"],"metadata":{"id":"GmqbCm0-2q9z"},"id":"GmqbCm0-2q9z"},{"cell_type":"code","source":["MTL_scores(clust_basins=['Emiliani1','Emiliani2','Garda_Mincio'], df_train=best5_wrapper_fulldf_train, df_val=best5_wrapper_fulldf_val, df_test=best5_wrapper_fulldf_test, targets_df_train=targets_df_train, targets_df_val=targets_df_val, targets_df_test=targets_df_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TfLkaIIv2vVv","executionInfo":{"status":"ok","timestamp":1690353400312,"user_tz":-120,"elapsed":5,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"}},"outputId":"045c6970-afef-47e2-b12a-450f35d423a0"},"id":"TfLkaIIv2vVv","execution_count":60,"outputs":[{"output_type":"stream","name":"stdout","text":["Emiliani1\n","0.5833333333333334\n","Emiliani2\n","0.5789473684210527\n","Garda_Mincio\n","0.6491228070175439\n"]}]},{"cell_type":"code","source":["MTL_scores(clust_basins=['Dora','Piemonte_Sud', 'Piemonte_Nord'], df_train=best5_wrapper_fulldf_train, df_val=best5_wrapper_fulldf_val, df_test=best5_wrapper_fulldf_test, targets_df_train=targets_df_train, targets_df_val=targets_df_val, targets_df_test=targets_df_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-MO1H1WP2vHe","executionInfo":{"status":"ok","timestamp":1690353400676,"user_tz":-120,"elapsed":367,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"}},"outputId":"34f97698-8bd1-453e-c270-70607f0b47c3"},"id":"-MO1H1WP2vHe","execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["Dora\n","0.40350877192982454\n","Piemonte_Sud\n","0.5921052631578947\n","Piemonte_Nord\n","0.5745614035087719\n"]}]},{"cell_type":"code","source":["MTL_scores(clust_basins=['Adda', 'Lambro_Olona', 'Oglio_Iseo', 'Ticino'], df_train=best5_wrapper_fulldf_train, df_val=best5_wrapper_fulldf_val, df_test=best5_wrapper_fulldf_test, targets_df_train=targets_df_train, targets_df_val=targets_df_val, targets_df_test=targets_df_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bBMTLUrP2vB0","executionInfo":{"status":"ok","timestamp":1690353401209,"user_tz":-120,"elapsed":536,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"}},"outputId":"d9364b7c-c6b7-440f-e68a-36c3d3fde0ed"},"id":"bBMTLUrP2vB0","execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["Adda\n","0.6578947368421053\n","Lambro_Olona\n","0.6535087719298246\n","Oglio_Iseo\n","0.6754385964912281\n","Ticino\n","0.6578947368421053\n"]}]}],"metadata":{"colab":{"collapsed_sections":["NHQGqoo7z-9g","c3WXxyk95Vyk","rYpR9P_TOe31"],"provenance":[]},"kernelspec":{"display_name":"Python 3.9 (tensorflow)","language":"python","name":"tensorflow"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":5}