{"cells":[{"cell_type":"code","execution_count":null,"id":"8b6a9e5d","metadata":{"id":"8b6a9e5d"},"outputs":[],"source":["import rioxarray as xr\n","import os\n","import glob\n","import pandas as pd\n","import xarray\n","import time\n","import numpy as np\n","from datetime import datetime"]},{"cell_type":"markdown","id":"ff1051ff","metadata":{"id":"ff1051ff"},"source":["## Extract features of daily mean temperature"]},{"cell_type":"code","execution_count":null,"id":"906eed51","metadata":{"id":"906eed51","outputId":"571ab8e2-9241-4deb-8e60-a18ac3c7ed0b"},"outputs":[{"data":{"text/plain":["['./features/daily_mean_temperature/tg_ens_mean_0.1deg_reg_2011-2022_v26.0e.nc',\n"," './features/daily_mean_temperature/tg_ens_mean_0.1deg_reg_1995-2010_v26.0e.nc']"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["nc_folder_features = \"./features/daily_mean_temperature/\"\n","nc_features_paths = glob.glob(nc_folder_features+'*.nc')\n","nc_features_paths"]},{"cell_type":"code","execution_count":null,"id":"a68db0b6","metadata":{"scrolled":true,"id":"a68db0b6"},"outputs":[],"source":["for path_name in nc_features_paths:\n","    features = xarray.open_dataset(path_name)\n","    features = features['tg']\n","    features.rio.to_raster(path_name.replace(\".nc\", \".tif\"))"]},{"cell_type":"markdown","id":"db77bd79","metadata":{"id":"db77bd79"},"source":["## Extract features of daily precipitation sum"]},{"cell_type":"code","execution_count":null,"id":"101a5839","metadata":{"id":"101a5839"},"outputs":[],"source":["nc_folder_features = \"./features/daily_precipitation_sum/\"\n","nc_features_paths = glob.glob(nc_folder_features+'*.nc')\n","nc_features_paths"]},{"cell_type":"code","execution_count":null,"id":"28bc0f46","metadata":{"id":"28bc0f46"},"outputs":[],"source":["for path_name in nc_features_paths:\n","    features = xarray.open_dataset(path_name)\n","    features = features['rr']\n","    features.rio.to_raster(path_name.replace(\".nc\", \".tif\"))"]},{"cell_type":"markdown","id":"626e6963","metadata":{"id":"626e6963"},"source":["## Crop tif files in the 10 regions"]},{"cell_type":"code","execution_count":null,"id":"1f1f6c6e","metadata":{"id":"1f1f6c6e"},"outputs":[],"source":["shape_files_dir = \"./bacini_shp/\"\n","shape_files = glob.glob(shape_files_dir+'*.shp')\n","shape_files"]},{"cell_type":"code","execution_count":null,"id":"0a0271e5","metadata":{"id":"0a0271e5"},"outputs":[],"source":["tif_files_dir = \"./features/rasters/\"\n","tif_files = glob.glob(tif_files_dir+'*.tif')\n","tif_files"]},{"cell_type":"code","execution_count":null,"id":"00acab9b","metadata":{"id":"00acab9b"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","from shapely.geometry import mapping\n","import geopandas as gpd\n","\n","for tif_name in tif_files: \n","    \n","    raster = xr.open_rasterio(tif_name)\n","    \n","    for shape_name in shape_files:\n","        \n","        crop_extent = gpd.read_file(shape_name)\n","        crop_extent = crop_extent.to_crs(epsg=4326)\n","        raster = raster.rio.set_crs('epsg:4326')\n","        tiff_clipped = raster.rio.clip(crop_extent.geometry.apply(mapping), crop_extent.crs)\n","        tiff_clipped.rio.to_raster(tif_name.replace(\"_ens_mean_0.1deg_reg\", \"\").replace(\"_v26.0e.tif\", \"\") + \n","                                   shape_name.replace(\"./bacini_shp/\", \"_\").replace(\".shp\", \"\") + '.tif')"]},{"cell_type":"markdown","id":"4627af54","metadata":{"id":"4627af54"},"source":["### Create csv files from cropped tif files (mean values)"]},{"cell_type":"code","execution_count":null,"id":"fc8d3646","metadata":{"id":"fc8d3646"},"outputs":[],"source":["regions = ['Adda',\n"," 'Dora',\n"," 'Emiliani1',\n"," 'Piemonte_Sud',\n"," 'Piemonte_Nord',\n"," 'Oglio_Iseo',\n"," 'Ticino',\n"," 'Garda_Mincio',\n"," 'Lambro_Olona',\n"," 'Emiliani2']\n","\n","tif_files_dir = \"./features/rasters/\"\n","csv_files_dir = \"./features/csv/\"\n","\n","# ranges : ['1995-01-01', '2010-12-31'], ['2011-01-01', '2022-06-30']\n","dates = ['1995-01-01', '2022-06-30']\n","start = '2001-01-05'\n","\n","days = pd.date_range(start=dates[0], end=dates[1], freq = 'D')\n","\n","dates_8days = pd.date_range(start=start, end=dates[1], freq = '8D')\n","years = [date.year for date in dates_8days]\n","weeks = [date.isocalendar().week for date in dates_8days]"]},{"cell_type":"code","execution_count":null,"id":"6e11f498","metadata":{"id":"6e11f498"},"outputs":[],"source":["def feature_tifs_to_csv(feature):\n","    cropped_tif_files = [[] for i in range(len(dates))]\n","    for region in regions:\n","        cropped_tif_files = glob.glob(tif_files_dir + feature + '*' + region + '*.tif')\n","        cropped_tif_files.sort()\n","\n","        for i in range(len(cropped_tif_files)):\n","            raster = xr.open_rasterio(cropped_tif_files[i]).drop_vars([\"spatial_ref\"])\n","            dataframe = raster.to_dataset('band').to_dataframe()\n","\n","            # remove useless null values\n","            dataframe = dataframe.replace(-9999,np.NaN)\n","            dataframe = dataframe.dropna()\n","            if i == 0:\n","                complete_dataframe = dataframe\n","            else:\n","                complete_dataframe = pd.concat([complete_dataframe, dataframe], axis=1)\n","\n","        # convert dates in readable ones and remove useless range\n","\n","        complete_dataframe.columns = days.strftime('%Y-%m-%d')\n","        complete_dataframe = complete_dataframe.loc[:, complete_dataframe.columns >= start]\n","\n","        # create dataframe with mean values for each 8 days and save it as csv\n","        means = complete_dataframe.mean(axis=0)\n","        means_8days = [means[i:i+8].mean() for i in range(0, len(means), 8)]\n","        \n","        statistics = pd.DataFrame({'mean': means_8days, 'year': years, 'week': weeks},\n","                      index = dates_8days)\n","        \n","        statistics.to_csv(csv_files_dir + region + \"_\" + feature + \".csv\")"]},{"cell_type":"code","execution_count":null,"id":"28750754","metadata":{"id":"28750754"},"outputs":[],"source":["feature_tifs_to_csv('tg')\n","feature_tifs_to_csv('rr')"]},{"cell_type":"markdown","id":"9825d7ed","metadata":{"id":"9825d7ed"},"source":["### Create csv files from cropped tif files (with coordinates)  (cyclostationary mean on training set)"]},{"cell_type":"code","execution_count":null,"id":"b64168cc","metadata":{"id":"b64168cc"},"outputs":[],"source":["csv_files_dir = \"./features/csv_allvalues/\""]},{"cell_type":"code","execution_count":null,"id":"826612c7","metadata":{"id":"826612c7","outputId":"7ec6b83f-82e5-4e35-c77a-0717826e7d18"},"outputs":[{"data":{"text/plain":["['./features/rasters/tg_1995-2010_Emiliani2.tif',\n"," './features/rasters/tg_2011-2022_Emiliani2.tif']"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["cropped_tif_files = glob.glob(tif_files_dir + \"tg\" + '*' + \"Emiliani2\" + '*.tif')\n","cropped_tif_files.sort()\n","cropped_tif_files"]},{"cell_type":"code","execution_count":null,"id":"b05dccbd","metadata":{"id":"b05dccbd"},"outputs":[],"source":["#raster = xr.open_rasterio(cropped_tif_files[0]).drop_vars([\"spatial_ref\"])\n","dataframe = raster.to_dataset('band').to_dataframe()"]},{"cell_type":"code","execution_count":null,"id":"3ea78819","metadata":{"id":"3ea78819"},"outputs":[],"source":["def feature_tifs_to_csv_allcoord(feature):\n","    cropped_tif_files = [[] for i in range(len(dates))]\n","    for region in regions:\n","        cropped_tif_files = glob.glob(tif_files_dir + feature + '*' + region + '*.tif')\n","        cropped_tif_files.sort()\n","        for i in range(len(cropped_tif_files)):\n","            raster = xr.open_rasterio(cropped_tif_files[i]).drop_vars([\"spatial_ref\"])\n","            dataframe = raster.to_dataset('band').to_dataframe()\n","\n","            # remove useless null values\n","            dataframe = dataframe.replace(-9999,np.NaN)\n","            dataframe = dataframe.dropna()\n","            \n","            scale_factor = raster.attrs['scale_factor']\n","            dataframe = dataframe * scale_factor # fix the scale factor\n","            \n","            if i == 0:\n","                complete_dataframe = dataframe\n","            else:\n","                complete_dataframe = pd.concat([complete_dataframe, dataframe], axis=1)\n","\n","        complete_dataframe.columns = days.strftime('%Y-%m-%d')\n","        complete_dataframe = complete_dataframe.loc[:, complete_dataframe.columns >= start]\n","\n","        # create a multi_index with both coordinates and date\n","        multi_index_dataframe = pd.concat([complete_dataframe] * len(dates_8days), keys=dates_8days, names=['date'])\n","\n","        # save mean values for groups of 8 days\n","        for i in range(0, len(complete_dataframe.columns), 8):\n","            if i == 0:\n","                cells_means_8days = complete_dataframe.iloc[:,i:i+8].mean(axis = 1).values\n","            else:\n","                cells_means_8days = np.concatenate([cells_means_8days, complete_dataframe.iloc[:,i:i+8].mean(axis = 1).values])\n","\n","        statistics = pd.DataFrame({'mean': cells_means_8days, 'year': np.repeat(years, len(complete_dataframe)), 'week': np.repeat(weeks, len(complete_dataframe))},\n","              index = multi_index_dataframe.index)\n","\n","        n = 0.6\n","        # take only the first 60% of the dataframe and compute the cyclostationary mean for week\n","        last_training_day = round(len(dates_8days)*n)\n","\n","        train_df = statistics[statistics.index.get_level_values(0) < dates_8days[last_training_day]]\n","        # cyclostationary_means_8days\n","        weekoftheyar_mean = train_df.groupby(['week', 'y', 'x'])['mean'].mean()\n","        index = statistics.index\n","        statistics = pd.merge(statistics, weekoftheyar_mean, how='left', on=['week', 'y', 'x'], suffixes=['','_weekoftheyear']).set_index(index)\n","        statistics['cyclostationary_mean'] = statistics['mean'] - statistics['mean_weekoftheyear']\n","        statistics.drop(\"mean_weekoftheyear\", axis='columns', inplace = True)\n","\n","        statistics.to_csv(csv_files_dir + region + \"_\" + feature + \".csv\")"]},{"cell_type":"code","execution_count":null,"id":"00da0909","metadata":{"id":"00da0909"},"outputs":[],"source":["feature_tifs_to_csv_allcoord('tg')\n","feature_tifs_to_csv_allcoord('rr')"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}