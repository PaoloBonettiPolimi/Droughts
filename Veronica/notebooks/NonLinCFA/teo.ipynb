{"cells":[{"cell_type":"code","execution_count":8,"id":"87a19403","metadata":{"executionInfo":{"elapsed":2846,"status":"ok","timestamp":1690352731277,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"},"user_tz":-120},"id":"87a19403"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import sys\n","import os"]},{"cell_type":"code","execution_count":9,"id":"t4O3GfTbop-R","metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1690352731278,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"},"user_tz":-120},"id":"t4O3GfTbop-R"},"outputs":[],"source":["sys.path.append(\"../../scripts/\")\n","\n","from feature_selection import forwardFeatureSelection\n","\n","from NonLinCFA import NonLinCFA\n","from aux_GenLinCFA import prepare_target_binary\n","from aux_NonLinCFA import *"]},{"cell_type":"markdown","id":"6fd5b874","metadata":{},"source":["Funzioni per gestire l'esportazione delle aggregazioni spaziali."]},{"cell_type":"code","execution_count":10,"id":"40bbf6b4","metadata":{},"outputs":[],"source":["import pickle\n","import geopandas as gpd\n","from shapely.geometry import Point\n","\n","def parse_coordinates(coord_string):\n","    # Split the string using underscores as separators\n","    parts = coord_string.split(\"_\")\n","\n","    # Extract longitude and latitude from the parts\n","    try:\n","        longitude = float(parts[1])\n","        latitude = float(parts[2])\n","        return Point(longitude, latitude)\n","    except (IndexError, ValueError):\n","        # Handle the case where the string format is incorrect or cannot be parsed\n","        print(\"Error parsing coordinates.\")\n","        return None"]},{"cell_type":"markdown","id":"fc4f223c","metadata":{},"source":["Salva le informazioni di aggregazione spaziale:\n","\n","- `outputs` è una lista dove ogni elemento è associato a un bacino\n","- ogni elemento `output` di `outputs` è una lista di variabili\n","- `output[i]` è una lista delle componenti della variabile `i`-esima\n","- `output[i][j]` è una lista di coordinate della `j`-esima componente della variabile `i`-esima"]},{"cell_type":"code","execution_count":18,"id":"be4e23a9","metadata":{},"outputs":[],"source":["def export_spatial_components(\n","    basins_names: list[str],\n","    outputs: list[list[list[list[str]]]],\n","    variable_names: list[str],\n","    destination_file: str,\n","):\n","    basins_variable_components = {}\n","\n","    for basin, output in zip(basins_names, outputs):\n","        basin_variable_components = {}\n","\n","        for variable_name, variable_components in zip(variable_names, output):\n","            data = []\n","            for component_index, coordinates in enumerate(variable_components):\n","                for coord_string in coordinates:\n","                    data.append(\n","                        {\n","                            \"geometry\": parse_coordinates(coord_string),\n","                            \"component\": component_index,\n","                        }\n","                    )\n","\n","            basin_variable_components[variable_name] = gpd.GeoDataFrame(\n","                data, geometry=\"geometry\"\n","            )\n","\n","        basins_variable_components[basin] = basin_variable_components\n","\n","    # create parents directories of destination_file if they do not exist\n","    os.makedirs(os.path.dirname(destination_file), exist_ok=True)\n","\n","    with open(destination_file, \"wb\") as handle:\n","        pickle.dump(basins_variable_components, handle, protocol=pickle.HIGHEST_PROTOCOL)"]},{"cell_type":"code","execution_count":11,"id":"2d69df70","metadata":{},"outputs":[],"source":["variable_names = [\n","    \"cyclostationary_mean_tg\",\n","    \"cyclostationary_mean_tg_1w\",\n","    \"cyclostationary_mean_tg_4w\",\n","    \"cyclostationary_mean_tg_8w\",\n","    \"cyclostationary_mean_tg_12w\",\n","    \"cyclostationary_mean_tg_16w\",\n","    \"cyclostationary_mean_tg_24w\",\n","    \"cyclostationary_mean_rr\",\n","    \"cyclostationary_mean_rr_1w\",\n","    \"cyclostationary_mean_rr_4w\",\n","    \"cyclostationary_mean_rr_8w\",\n","    \"cyclostationary_mean_rr_12w\",\n","    \"cyclostationary_mean_rr_16w\",\n","    \"cyclostationary_mean_rr_24w\",\n","]"]},{"cell_type":"code","execution_count":15,"id":"aa3eba21","metadata":{},"outputs":[],"source":["plots_folder = \"./NonLinCFA/for_plots/internal_ordering/\"\n","path_features = \"../../final_features_allcoord/temp_prec/\"\n","path_target = \"../../VHI_target/\""]},{"cell_type":"markdown","id":"PqNz4kWf-tga","metadata":{"id":"PqNz4kWf-tga"},"source":["# Esegui la NonLinCFA nel modo classico per salvare le componenti spaziali"]},{"cell_type":"markdown","id":"f25e92a2","metadata":{},"source":["Liste per memorizzare tutti i risultati relativi a ogni bacino."]},{"cell_type":"code","execution_count":16,"id":"49265ec3","metadata":{},"outputs":[],"source":["outputs = []\n","basins = []\n","aggregate_trainvals = []\n","aggregate_tests = []"]},{"cell_type":"code","execution_count":17,"id":"Dd_c8fjYuJ9h","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2054950,"status":"ok","timestamp":1690302959330,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"},"user_tz":-120},"id":"Dd_c8fjYuJ9h","outputId":"b3b024ba-93a5-4aea-ccd2-e7b45cf3d0ce"},"outputs":[{"name":"stdout","output_type":"stream","text":["####################Adda####################\n","Number of features: 92\n","\n","eps value:  0.0010869565217391304\n","Number of aggregated features: 3\n","\n","Number of features: 92\n","\n","eps value:  0.0010869565217391304\n","Number of aggregated features: 5\n","\n","Number of features: 92\n","\n","eps value:  0.0010869565217391304\n","Number of aggregated features: 4\n","\n","Number of features: 92\n","\n","eps value:  0.0010869565217391304\n","Number of aggregated features: 1\n","\n","Number of features: 92\n","\n","eps value:  0.0010869565217391304\n","Number of aggregated features: 5\n","\n","Number of features: 92\n","\n","eps value:  0.0010869565217391304\n","Number of aggregated features: 1\n","\n","Number of features: 92\n","\n","eps value:  0.0010869565217391304\n","Number of aggregated features: 2\n","\n","Number of features: 92\n","\n","eps value:  0.0010869565217391304\n","Number of aggregated features: 1\n","\n","Number of features: 92\n","\n","eps value:  0.0010869565217391304\n","Number of aggregated features: 2\n","\n","Number of features: 92\n","\n","eps value:  0.0010869565217391304\n","Number of aggregated features: 1\n","\n","Number of features: 92\n","\n","eps value:  0.0010869565217391304\n","Number of aggregated features: 2\n","\n","Number of features: 92\n","\n","eps value:  0.0010869565217391304\n","Number of aggregated features: 1\n","\n","Number of features: 92\n","\n","eps value:  0.0010869565217391304\n","Number of aggregated features: 1\n","\n","Number of features: 92\n","\n","eps value:  0.0010869565217391304\n","Number of aggregated features: 1\n","\n","####################Dora####################\n","Number of features: 44\n","\n","eps value:  0.002272727272727273\n","Number of aggregated features: 2\n","\n","Number of features: 44\n","\n","eps value:  0.002272727272727273\n","Number of aggregated features: 2\n","\n","Number of features: 44\n","\n","eps value:  0.002272727272727273\n","Number of aggregated features: 1\n","\n","Number of features: 44\n","\n","eps value:  0.002272727272727273\n","Number of aggregated features: 1\n","\n","Number of features: 44\n","\n","eps value:  0.002272727272727273\n","Number of aggregated features: 3\n","\n","Number of features: 44\n","\n","eps value:  0.002272727272727273\n","Number of aggregated features: 2\n","\n","Number of features: 44\n","\n","eps value:  0.002272727272727273\n","Number of aggregated features: 1\n","\n","Number of features: 44\n","\n","eps value:  0.002272727272727273\n","Number of aggregated features: 1\n","\n","Number of features: 44\n","\n","eps value:  0.002272727272727273\n","Number of aggregated features: 1\n","\n","Number of features: 44\n","\n","eps value:  0.002272727272727273\n","Number of aggregated features: 1\n","\n","Number of features: 44\n","\n","eps value:  0.002272727272727273\n","Number of aggregated features: 1\n","\n","Number of features: 44\n","\n","eps value:  0.002272727272727273\n","Number of aggregated features: 1\n","\n","Number of features: 44\n","\n","eps value:  0.002272727272727273\n","Number of aggregated features: 1\n","\n","Number of features: 44\n","\n","eps value:  0.002272727272727273\n","Number of aggregated features: 1\n","\n","####################Emiliani1####################\n","Number of features: 172\n","\n","eps value:  0.0005813953488372093\n","Number of aggregated features: 7\n","\n","Number of features: 172\n","\n","eps value:  0.0005813953488372093\n","Number of aggregated features: 5\n","\n","Number of features: 172\n","\n","eps value:  0.0005813953488372093\n","Number of aggregated features: 2\n","\n","Number of features: 172\n","\n","eps value:  0.0005813953488372093\n","Number of aggregated features: 6\n","\n","Number of features: 172\n","\n","eps value:  0.0005813953488372093\n","Number of aggregated features: 9\n","\n","Number of features: 172\n","\n","eps value:  0.0005813953488372093\n","Number of aggregated features: 7\n","\n","Number of features: 172\n","\n","eps value:  0.0005813953488372093\n","Number of aggregated features: 2\n","\n","Number of features: 172\n","\n","eps value:  0.0005813953488372093\n","Number of aggregated features: 18\n","\n","Number of features: 172\n","\n","eps value:  0.0005813953488372093\n","Number of aggregated features: 17\n","\n","Number of features: 172\n","\n","eps value:  0.0005813953488372093\n","Number of aggregated features: 10\n","\n","Number of features: 172\n","\n","eps value:  0.0005813953488372093\n","Number of aggregated features: 7\n","\n","Number of features: 172\n","\n","eps value:  0.0005813953488372093\n","Number of aggregated features: 6\n","\n","Number of features: 172\n","\n","eps value:  0.0005813953488372093\n","Number of aggregated features: 4\n","\n","Number of features: 172\n","\n","eps value:  0.0005813953488372093\n","Number of aggregated features: 5\n","\n","####################Emiliani2####################\n","Number of features: 130\n","\n","eps value:  0.0007692307692307692\n","Number of aggregated features: 5\n","\n","Number of features: 130\n","\n","eps value:  0.0007692307692307692\n","Number of aggregated features: 3\n","\n","Number of features: 130\n","\n","eps value:  0.0007692307692307692\n","Number of aggregated features: 3\n","\n","Number of features: 130\n","\n","eps value:  0.0007692307692307692\n","Number of aggregated features: 3\n","\n","Number of features: 130\n","\n","eps value:  0.0007692307692307692\n","Number of aggregated features: 3\n","\n","Number of features: 130\n","\n","eps value:  0.0007692307692307692\n","Number of aggregated features: 4\n","\n","Number of features: 130\n","\n","eps value:  0.0007692307692307692\n","Number of aggregated features: 2\n","\n","Number of features: 130\n","\n","eps value:  0.0007692307692307692\n","Number of aggregated features: 4\n","\n","Number of features: 130\n","\n","eps value:  0.0007692307692307692\n","Number of aggregated features: 8\n","\n","Number of features: 130\n","\n","eps value:  0.0007692307692307692\n","Number of aggregated features: 7\n","\n","Number of features: 130\n","\n","eps value:  0.0007692307692307692\n","Number of aggregated features: 6\n","\n","Number of features: 130\n","\n","eps value:  0.0007692307692307692\n","Number of aggregated features: 1\n","\n","Number of features: 130\n","\n","eps value:  0.0007692307692307692\n","Number of aggregated features: 1\n","\n","Number of features: 130\n","\n","eps value:  0.0007692307692307692\n","Number of aggregated features: 1\n","\n","####################Garda_Mincio####################\n","Number of features: 67\n","\n","eps value:  0.0014925373134328358\n","Number of aggregated features: 1\n","\n","Number of features: 67\n","\n","eps value:  0.0014925373134328358\n","Number of aggregated features: 3\n","\n","Number of features: 67\n","\n","eps value:  0.0014925373134328358\n","Number of aggregated features: 2\n","\n","Number of features: 67\n","\n","eps value:  0.0014925373134328358\n","Number of aggregated features: 2\n","\n","Number of features: 67\n","\n","eps value:  0.0014925373134328358\n","Number of aggregated features: 1\n","\n","Number of features: 67\n","\n","eps value:  0.0014925373134328358\n","Number of aggregated features: 1\n","\n","Number of features: 67\n","\n","eps value:  0.0014925373134328358\n","Number of aggregated features: 1\n","\n","Number of features: 67\n","\n","eps value:  0.0014925373134328358\n","Number of aggregated features: 4\n","\n","Number of features: 67\n","\n","eps value:  0.0014925373134328358\n","Number of aggregated features: 4\n","\n","Number of features: 67\n","\n","eps value:  0.0014925373134328358\n","Number of aggregated features: 4\n","\n","Number of features: 67\n","\n","eps value:  0.0014925373134328358\n","Number of aggregated features: 1\n","\n","Number of features: 67\n","\n","eps value:  0.0014925373134328358\n","Number of aggregated features: 2\n","\n","Number of features: 67\n","\n","eps value:  0.0014925373134328358\n","Number of aggregated features: 2\n","\n","Number of features: 67\n","\n","eps value:  0.0014925373134328358\n","Number of aggregated features: 2\n","\n","####################Lambro_Olona####################\n","Number of features: 55\n","\n","eps value:  0.0018181818181818182\n","Number of aggregated features: 6\n","\n","Number of features: 55\n","\n","eps value:  0.0018181818181818182\n","Number of aggregated features: 6\n","\n","Number of features: 55\n","\n","eps value:  0.0018181818181818182\n","Number of aggregated features: 5\n","\n","Number of features: 55\n","\n","eps value:  0.0018181818181818182\n","Number of aggregated features: 4\n","\n","Number of features: 55\n","\n","eps value:  0.0018181818181818182\n","Number of aggregated features: 4\n","\n","Number of features: 55\n","\n","eps value:  0.0018181818181818182\n","Number of aggregated features: 3\n","\n","Number of features: 55\n","\n","eps value:  0.0018181818181818182\n","Number of aggregated features: 3\n","\n","Number of features: 55\n","\n","eps value:  0.0018181818181818182\n","Number of aggregated features: 2\n","\n","Number of features: 55\n","\n","eps value:  0.0018181818181818182\n","Number of aggregated features: 2\n","\n","Number of features: 55\n","\n","eps value:  0.0018181818181818182\n","Number of aggregated features: 1\n","\n","Number of features: 55\n","\n","eps value:  0.0018181818181818182\n","Number of aggregated features: 1\n","\n","Number of features: 55\n","\n","eps value:  0.0018181818181818182\n","Number of aggregated features: 3\n","\n","Number of features: 55\n","\n","eps value:  0.0018181818181818182\n","Number of aggregated features: 1\n","\n","Number of features: 55\n","\n","eps value:  0.0018181818181818182\n","Number of aggregated features: 1\n","\n","####################Oglio_Iseo####################\n","Number of features: 74\n","\n","eps value:  0.0013513513513513514\n","Number of aggregated features: 4\n","\n","Number of features: 74\n","\n","eps value:  0.0013513513513513514\n","Number of aggregated features: 3\n","\n","Number of features: 74\n","\n","eps value:  0.0013513513513513514\n","Number of aggregated features: 1\n","\n","Number of features: 74\n","\n","eps value:  0.0013513513513513514\n","Number of aggregated features: 1\n","\n","Number of features: 74\n","\n","eps value:  0.0013513513513513514\n","Number of aggregated features: 1\n","\n","Number of features: 74\n","\n","eps value:  0.0013513513513513514\n","Number of aggregated features: 1\n","\n","Number of features: 74\n","\n","eps value:  0.0013513513513513514\n","Number of aggregated features: 1\n","\n","Number of features: 74\n","\n","eps value:  0.0013513513513513514\n","Number of aggregated features: 1\n","\n","Number of features: 74\n","\n","eps value:  0.0013513513513513514\n","Number of aggregated features: 1\n","\n","Number of features: 74\n","\n","eps value:  0.0013513513513513514\n","Number of aggregated features: 1\n","\n","Number of features: 74\n","\n","eps value:  0.0013513513513513514\n","Number of aggregated features: 1\n","\n","Number of features: 74\n","\n","eps value:  0.0013513513513513514\n","Number of aggregated features: 1\n","\n","Number of features: 74\n","\n","eps value:  0.0013513513513513514\n","Number of aggregated features: 1\n","\n","Number of features: 74\n","\n","eps value:  0.0013513513513513514\n","Number of aggregated features: 1\n","\n","####################Piemonte_Nord####################\n","Number of features: 89\n","\n","eps value:  0.0011235955056179776\n","Number of aggregated features: 7\n","\n","Number of features: 89\n","\n","eps value:  0.0011235955056179776\n","Number of aggregated features: 5\n","\n","Number of features: 89\n","\n","eps value:  0.0011235955056179776\n","Number of aggregated features: 5\n","\n","Number of features: 89\n","\n","eps value:  0.0011235955056179776\n","Number of aggregated features: 5\n","\n","Number of features: 89\n","\n","eps value:  0.0011235955056179776\n","Number of aggregated features: 1\n","\n","Number of features: 89\n","\n","eps value:  0.0011235955056179776\n","Number of aggregated features: 1\n","\n","Number of features: 89\n","\n","eps value:  0.0011235955056179776\n","Number of aggregated features: 1\n","\n","Number of features: 89\n","\n","eps value:  0.0011235955056179776\n","Number of aggregated features: 2\n","\n","Number of features: 89\n","\n","eps value:  0.0011235955056179776\n","Number of aggregated features: 3\n","\n","Number of features: 89\n","\n","eps value:  0.0011235955056179776\n","Number of aggregated features: 4\n","\n","Number of features: 89\n","\n","eps value:  0.0011235955056179776\n","Number of aggregated features: 5\n","\n","Number of features: 89\n","\n","eps value:  0.0011235955056179776\n","Number of aggregated features: 3\n","\n","Number of features: 89\n","\n","eps value:  0.0011235955056179776\n","Number of aggregated features: 1\n","\n","Number of features: 89\n","\n","eps value:  0.0011235955056179776\n","Number of aggregated features: 1\n","\n","####################Piemonte_Sud####################\n","Number of features: 176\n","\n","eps value:  0.0005681818181818183\n","Number of aggregated features: 2\n","\n","Number of features: 176\n","\n","eps value:  0.0005681818181818183\n","Number of aggregated features: 4\n","\n","Number of features: 176\n","\n","eps value:  0.0005681818181818183\n","Number of aggregated features: 2\n","\n","Number of features: 176\n","\n","eps value:  0.0005681818181818183\n","Number of aggregated features: 3\n","\n","Number of features: 176\n","\n","eps value:  0.0005681818181818183\n","Number of aggregated features: 3\n","\n","Number of features: 176\n","\n","eps value:  0.0005681818181818183\n","Number of aggregated features: 3\n","\n","Number of features: 176\n","\n","eps value:  0.0005681818181818183\n","Number of aggregated features: 2\n","\n","Number of features: 176\n","\n","eps value:  0.0005681818181818183\n","Number of aggregated features: 3\n","\n","Number of features: 176\n","\n","eps value:  0.0005681818181818183\n","Number of aggregated features: 7\n","\n","Number of features: 176\n","\n","eps value:  0.0005681818181818183\n","Number of aggregated features: 2\n","\n","Number of features: 176\n","\n","eps value:  0.0005681818181818183\n","Number of aggregated features: 2\n","\n","Number of features: 176\n","\n","eps value:  0.0005681818181818183\n","Number of aggregated features: 2\n","\n","Number of features: 176\n","\n","eps value:  0.0005681818181818183\n","Number of aggregated features: 3\n","\n","Number of features: 176\n","\n","eps value:  0.0005681818181818183\n","Number of aggregated features: 1\n","\n","####################Ticino####################\n","Number of features: 92\n","\n","eps value:  0.0010869565217391304\n","Number of aggregated features: 3\n","\n","Number of features: 92\n","\n","eps value:  0.0010869565217391304\n","Number of aggregated features: 4\n","\n","Number of features: 92\n","\n","eps value:  0.0010869565217391304\n","Number of aggregated features: 4\n","\n","Number of features: 92\n","\n","eps value:  0.0010869565217391304\n","Number of aggregated features: 5\n","\n","Number of features: 92\n","\n","eps value:  0.0010869565217391304\n","Number of aggregated features: 2\n","\n","Number of features: 92\n","\n","eps value:  0.0010869565217391304\n","Number of aggregated features: 3\n","\n","Number of features: 92\n","\n","eps value:  0.0010869565217391304\n","Number of aggregated features: 1\n","\n","Number of features: 92\n","\n","eps value:  0.0010869565217391304\n","Number of aggregated features: 2\n","\n","Number of features: 92\n","\n","eps value:  0.0010869565217391304\n","Number of aggregated features: 2\n","\n","Number of features: 92\n","\n","eps value:  0.0010869565217391304\n","Number of aggregated features: 2\n","\n","Number of features: 92\n","\n","eps value:  0.0010869565217391304\n","Number of aggregated features: 1\n","\n","Number of features: 92\n","\n","eps value:  0.0010869565217391304\n","Number of aggregated features: 1\n","\n","Number of features: 92\n","\n","eps value:  0.0010869565217391304\n","Number of aggregated features: 1\n","\n","Number of features: 92\n","\n","eps value:  0.0010869565217391304\n","Number of aggregated features: 1\n","\n"]}],"source":["for basin in [\n","    \"Adda\",\n","    \"Dora\",\n","    \"Emiliani1\",\n","    \"Emiliani2\",\n","    \"Garda_Mincio\",\n","    \"Lambro_Olona\",\n","    \"Oglio_Iseo\",\n","    \"Piemonte_Nord\",\n","    \"Piemonte_Sud\",\n","    \"Ticino\",\n","]:\n","    print(\"####################\" + basin + \"####################\")\n","    target_df_train, target_df_val, target_df_test, target_df_trainVal = prepare_target(\n","        \"\",\n","        max_train=\"2010-01-01\",\n","        max_val=\"2015-01-01\",\n","        max_test=\"2020-01-01\",\n","        path=path_target + basin + \".csv\",\n","        window_size=1,\n","    )\n","    eps = 0.1\n","    actual_path = path_features + basin + \"_aggreg.csv\"\n","    output, aggregate_trainVal, aggregate_test = aggregate_unfolded_data(\n","        actual_path,\n","        variable_names,\n","        target_df_trainVal,\n","        eps=eps,\n","        max_train=\"2010-01-01\",\n","        max_val=\"2015-01-01\",\n","        max_test=\"2020-01-01\",\n","    )\n","    outputs.append(output)\n","    basins.append(basin)\n","    aggregate_trainvals.append(aggregate_trainVal)\n","    aggregate_tests.append(aggregate_test)"]},{"cell_type":"markdown","id":"bed4f5e9","metadata":{},"source":["Stampa i bacini elaborati prima di salvarli"]},{"cell_type":"code","execution_count":19,"id":"b89b2ae6","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['Adda', 'Dora', 'Emiliani1', 'Emiliani2', 'Garda_Mincio', 'Lambro_Olona', 'Oglio_Iseo', 'Piemonte_Nord', 'Piemonte_Sud', 'Ticino']\n"]}],"source":["print(basins)"]},{"cell_type":"code","execution_count":22,"id":"c1e86885","metadata":{},"outputs":[],"source":["export_spatial_components(basins, outputs, variable_names, \"./variable_components_basins.pickle\")"]},{"cell_type":"markdown","id":"a4764f50","metadata":{},"source":["Salva le feature aggregate (quindi prima delle CMI feature selection)"]},{"cell_type":"code","execution_count":24,"id":"11f09adc","metadata":{},"outputs":[],"source":["destination_folder = \"./NonLinCFA_noCMI/\"\n","os.makedirs(destination_folder, exist_ok=True)\n","\n","for basin, aggregate_trainval, aggregate_test in zip(\n","    basins, aggregate_trainvals, aggregate_tests\n","):\n","    # Split aggregate_trainval into train (first 411 rows) and validation\n","    aggregate_train = aggregate_trainval.iloc[:411, :]\n","    aggregate_val = aggregate_trainval.iloc[411:, :]\n","\n","    aggregate_train.to_csv(os.path.join(destination_folder, basin + \"_train.csv\"), index=False)\n","    aggregate_val.to_csv(os.path.join(destination_folder, basin + \"_val.csv\"), index=False)\n","    aggregate_test.to_csv(os.path.join(destination_folder, basin + \"_test.csv\"), index=False)"]},{"cell_type":"markdown","id":"7015777f","metadata":{},"source":["# Riesegui la NonLinCFA nel bacino Emiliani1, Emiliani2, GardaMincio"]},{"cell_type":"markdown","id":"7a119e33","metadata":{},"source":["Il codice qui sotto fa l'aggregazione con NonLinCFA dando in input `Emiliani1` + `Emiliani2` + `GardaMincio` e in output il target di:\n","\n","- `Emiliani1`\n","- `Emiliani2`\n","- `GardaMincio`\n","\n","Per un totale di 3 run."]},{"cell_type":"code","execution_count":29,"id":"4b1932a4","metadata":{},"outputs":[],"source":["destination_folder = \"./NonLinCFA_e12gm_to_single/\"\n","os.makedirs(destination_folder, exist_ok=True)"]},{"cell_type":"markdown","id":"815daff4","metadata":{},"source":["Creo l'input `Emiliani1` + `Emiliani2` + `GardaMincio` caricando i dati e concatenandoli per righe, poi lo salvo come se fosse un nuovo \"bacino\" chiamato `e12gm`."]},{"cell_type":"code","execution_count":null,"id":"43f86b88","metadata":{},"outputs":[],"source":["pd.concat([\n","    pd.read_csv(path_features+'Emiliani1'+'_aggreg.csv'),\n","    pd.read_csv(path_features+'Emiliani2'+'_aggreg.csv'),\n","    pd.read_csv(path_features+'Garda_Mincio'+'_aggreg.csv'),\n","    ],\n","    axis = 0\n",").to_csv(path_features+'e12gm_aggreg.csv', index=False)"]},{"cell_type":"markdown","id":"7ad53898","metadata":{},"source":["Liste per memorizzare tutti i risultati relativi a ogni bacino."]},{"cell_type":"code","execution_count":30,"id":"1e8190a7","metadata":{},"outputs":[],"source":["outputs = []\n","basins = []\n","aggregate_trainvals = []\n","aggregate_tests = []"]},{"cell_type":"markdown","id":"f653aea4","metadata":{},"source":["Il loop è su ogni finto bacino `e12gm_to_e1`, `e12gm_to_e2`, `e12gm_to_gm`, ognuno dei quali ha in input `e12gm` e un target diverso."]},{"cell_type":"code","execution_count":31,"id":"d68ae2bc","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["####################e12gm_to_e1####################\n","Number of features: 369\n","\n","eps value:  0.00027100271002710027\n","Number of aggregated features: 8\n","\n","Number of features: 369\n","\n","eps value:  0.00027100271002710027\n","Number of aggregated features: 11\n","\n","Number of features: 369\n","\n","eps value:  0.00027100271002710027\n","Number of aggregated features: 7\n","\n","Number of features: 369\n","\n","eps value:  0.00027100271002710027\n","Number of aggregated features: 7\n","\n","Number of features: 369\n","\n","eps value:  0.00027100271002710027\n","Number of aggregated features: 6\n","\n","Number of features: 369\n","\n","eps value:  0.00027100271002710027\n","Number of aggregated features: 3\n","\n","Number of features: 369\n","\n","eps value:  0.00027100271002710027\n","Number of aggregated features: 3\n","\n","Number of features: 369\n","\n","eps value:  0.00027100271002710027\n","Number of aggregated features: 17\n","\n","Number of features: 369\n","\n","eps value:  0.00027100271002710027\n","Number of aggregated features: 20\n","\n","Number of features: 369\n","\n","eps value:  0.00027100271002710027\n","Number of aggregated features: 9\n","\n","Number of features: 369\n","\n","eps value:  0.00027100271002710027\n","Number of aggregated features: 6\n","\n","Number of features: 369\n","\n","eps value:  0.00027100271002710027\n","Number of aggregated features: 6\n","\n","Number of features: 369\n","\n","eps value:  0.00027100271002710027\n","Number of aggregated features: 5\n","\n","Number of features: 369\n","\n","eps value:  0.00027100271002710027\n","Number of aggregated features: 6\n","\n","\n","\n","selected columns: ['cyclostationary_mean_rr_8w_0', 'cyclostationary_mean_tg_0', 'cyclostationary_mean_rr_24w_2', 'cyclostationary_mean_tg_12w_2', 'cyclostationary_mean_tg_16w_0', 'cyclostationary_mean_rr_16w_0', 'cyclostationary_mean_rr_8w_5', 'cyclostationary_mean_rr_16w_2', 'cyclostationary_mean_tg_6', 'cyclostationary_mean_rr_1w_3', 'cyclostationary_mean_rr_8w_1', 'cyclostationary_mean_rr_16w_3', 'cyclostationary_mean_tg_16w_1', 'cyclostationary_mean_tg_7', 'cyclostationary_mean_rr_4w_1', 'cyclostationary_mean_rr_4w_8', 'cyclostationary_mean_rr_1w_9', 'cyclostationary_mean_rr_1w_7', 'cyclostationary_mean_rr_12', 'cyclostationary_mean_rr_16w_4', 'cyclostationary_mean_rr_12w_5', 'cyclostationary_mean_rr_4w_7', 'cyclostationary_mean_rr_1w_13'], \n","\n","validation score: 0.5065258930269161, \n","\n","number of selected features: 23\n","\n","Full model and selected features with wrapper\n","\n","Full aggregate regression train score: 0.5568995533371772, test score: -0.2226664424907705\n","Aggregate regression train score with FS: 0.40501139188840063, test score: 0.17777091355196817\n","\n","Full model and best 5 selected features with wrapper\n","\n","Full aggregate regression train score: 0.5568995533371772, test score: -0.2226664424907705\n","Aggregate regression train score with FS: 0.34709945411513854, test score: 0.3066555794740017\n","----- MI Scores -----\n","[(84, 0.1715656337187485), (85, 0.1705659889709872), (64, 0.16057802750089792), (98, 0.14647780192223916), (91, 0.14371820938410984), (72, 0.13714507252441668), (4, 0.13313965987372708), (66, 0.12386893890867491), (15, 0.12357424757936115), (6, 0.12109184618251108), (17, 0.11978312637145276), (5, 0.11852657414283424), (74, 0.1178833059075978), (7, 0.11780543033739596), (93, 0.11774748037544872), (0, 0.11564901320306147), (79, 0.11335540936270637), (90, 0.11250156550376682), (81, 0.10847552552527642), (80, 0.10841941235654867), (75, 0.10711388855446481), (52, 0.10694362609795538), (104, 0.10692038844481008), (58, 0.1063192144447889), (77, 0.10592642517911253), (68, 0.10373775828161823), (69, 0.10314447604344332), (49, 0.10053531061638857), (110, 0.10029804670757793), (8, 0.09775882270501914), (94, 0.09739680858665234), (56, 0.09730779838035425), (112, 0.09682605442061805), (70, 0.09606615344303136), (97, 0.09521626839958978), (78, 0.09511549492120479), (14, 0.0924839844929122), (55, 0.09187529418353856), (1, 0.09178373911678772), (57, 0.09129252386046051), (73, 0.09069647988635428), (99, 0.08957371740084549), (61, 0.0867490107076037), (3, 0.08602415733777354), (88, 0.08558842129554048), (9, 0.08549512569657125), (105, 0.08369654004610444), (96, 0.0821669057438252), (106, 0.08216415145707368), (71, 0.08204931151553393), (13, 0.08145242884051562), (76, 0.08141887589357691), (101, 0.07948353042471282), (59, 0.07938626413061486), (2, 0.07889418652445655), (53, 0.07851708259943356), (50, 0.0776528208286137), (95, 0.07756374159615556), (10, 0.07645829187088074), (83, 0.07628595478406794), (12, 0.07618259714822578), (47, 0.07545095804716526), (102, 0.07407875416960118), (107, 0.07177754577104242), (63, 0.07036829948379805), (103, 0.06979935297518601), (100, 0.0683006695413712), (87, 0.0662509378719502), (30, 0.06515254344357825), (18, 0.063506481714736), (108, 0.06338562777122492), (67, 0.0631259344058466), (23, 0.062999360107454), (37, 0.062450147422903536), (48, 0.06204571315094241), (60, 0.061974850020389695), (92, 0.059819481804829364), (32, 0.056661123865107695), (51, 0.05618382383599408), (89, 0.054389288877687875), (86, 0.05293054127050454), (65, 0.05065380787754219), (39, 0.05016231527346236), (40, 0.04918687553471101), (111, 0.04853747581790974), (41, 0.0482663584331308), (21, 0.04691926930228926), (25, 0.046890937713780084), (44, 0.04310005963177069), (20, 0.043006499128736886), (82, 0.041173700126343776), (62, 0.040734011957155536), (16, 0.04036775804460502), (22, 0.03889900995002963), (109, 0.03814930418558277), (26, 0.037469287967704615), (113, 0.036066175028827155), (45, 0.03500033810663088), (28, 0.033413786588317354), (11, 0.03298367279402507), (24, 0.03262163084107232), (19, 0.031957144841208374), (35, 0.03157428073436883), (33, 0.023625674914056188), (36, 0.022506445984129826), (29, 0.022122817015110024), (27, 0.021399940888751197), (31, 0.01976606360613508), (38, 0.019504210416875823), (43, 0.018160271837931317), (54, 0.013660636574463593), (34, 0.009648700936972492), (42, 0.00870187913249558), (46, 0.004366952191336577)]\n","Best MI score: 0.1715656337187485\n","Adding first best original feature: 84\n","CMI: 0.07594926020930748\n","CMI: 0.046038494130474394\n","CMI: 0.07587641480221147\n","CMI: 0.08249212674686923\n","CMI: 0.08808202131691945\n","CMI: 0.06268223780603466\n","CMI: 0.07150691264529688\n","CMI: 0.05625135981746668\n","CMI: 0.062485025939698485\n","CMI: 0.04489292962206917\n","CMI: 0.0526812624411962\n","CMI: 0.03122302748708025\n","CMI: 0.07511421406417557\n","CMI: 0.05247856617284247\n","CMI: 0.03360665617064973\n","CMI: 0.061219637402967764\n","CMI: 0.062401806042932356\n","CMI: 0.05078750054471931\n","CMI: 0.03187811489094344\n","CMI: 0.009015346666408741\n","CMI: 0.033856922201042916\n","CMI: 0.011007718024308333\n","CMI: 0.007732032769122044\n","CMI: 0.026596958827319356\n","CMI: 0.0012126276150815074\n","CMI: 0.004424858519900321\n","CMI: 0.0068218564808200655\n","CMI: 0.023906576696984067\n","CMI: 0.01918518639647221\n","CMI: 0.015483599621867905\n","CMI: 0.005569457927909388\n","CMI: 0.015332459552881011\n","CMI: 0.0346146713254952\n","CMI: 0.0026470745894115744\n","CMI: 0.017663437626556727\n","CMI: 0.031027318341268956\n","CMI: 0.03365835636224235\n","CMI: 0.007264661953372942\n","CMI: 0.04743234322539305\n","CMI: 0.028382091079024202\n","CMI: 0.022858817112796526\n","CMI: 0.00637694673800962\n","CMI: 0.02149802176377591\n","CMI: 0.0103098538994916\n","CMI: 0.03631580170615836\n","CMI: 0.023724483430173138\n","CMI: 0.04957936557230408\n","CMI: 0.028639417695642017\n","CMI: 0.003582067037153913\n","CMI: 0.043104478330064644\n","CMI: 0.034842208565654675\n","CMI: 0.05029335897048709\n","CMI: 0.052888990079311665\n","CMI: 0.039898382659792536\n","CMI: 0.021999644940642576\n","CMI: 0.03470474225385206\n","CMI: 0.03565690297835525\n","CMI: 0.03819391566031785\n","CMI: 0.004985227494602201\n","CMI: 0.04562559592646462\n","CMI: 0.07109276559866132\n","CMI: 0.04876992497467342\n","CMI: 0.029625294453448248\n","CMI: 0.02772876918525144\n","CMI: 0.002127670644424068\n","CMI: 0.0359816055589168\n","CMI: 0.001963166071477368\n","CMI: 0.051152953552822455\n","CMI: 0.03400191365410435\n","CMI: 0.0054451340446883545\n","CMI: 0.015641678770719786\n","CMI: 0.018032197279892553\n","CMI: 0.014061609042355316\n","CMI: 0.013631644377981672\n","CMI: 0.026490780120925816\n","CMI: 0.0015752474500684843\n","CMI: 0.002148634847991826\n","CMI: 0.004706980382702258\n","CMI: 0.010696070874261249\n","CMI: 0.027995962779424594\n","CMI: 0.02216437644264649\n","CMI: 0.03928979370144198\n","CMI: 0.040926542407985794\n","CMI: 0.016578711893710102\n","CMI: 0.00754049220682626\n","CMI: 0.015975287779693564\n","CMI: 0.013486789032230467\n","CMI: 0.015544379015681231\n","CMI: 0.011220482229552908\n","CMI: 0.011197570884314029\n","CMI: 0.010103395332605625\n","CMI: 0.00609631490930318\n","CMI: 0.01277526091325587\n","CMI: 0.02775353188015614\n","CMI: 0.00023628248553875242\n","CMI: 0.01359126947932579\n","CMI: 0.0034753026471173454\n","Highest CMI score: 0.08808202131691945\n","Adding original feature: 4\n","CMI: 0.00584247256879894\n","CMI: 0.003735169871232902\n","CMI: 0.004832066248288358\n","CMI: 0.0015110419075956005\n","CMI: 0.0070368425911677135\n","CMI: 0.005381137849656992\n","CMI: 0.019043490265236218\n","CMI: 0.0006478977491242155\n","CMI: 0.011929494751859893\n","CMI: 0.01931656926570574\n","CMI: 0.013524996818539803\n","CMI: 0.015809861415727544\n","CMI: 0.009669091842963162\n","CMI: 0.01629694286126465\n","CMI: 0.006698939622309552\n","CMI: 0.0050590644884613845\n","CMI: 0.0024488745808181056\n","CMI: 0.0057892198056908595\n","CMI: 0.0017815030704226298\n","CMI: 0.0053240204739808394\n","CMI: 6.498123692399993e-05\n","CMI: 0.0016731259349713201\n","CMI: 0.001460531794438169\n","CMI: 0.0019721718987883996\n","CMI: 0.0016068235620207982\n","CMI: 0.006309121464038614\n","CMI: 0.0019537731485220755\n","CMI: 0.0026677024512612446\n","Highest CMI score: 0.01931656926570574\n","Adding original feature: 39\n","CMI: 0.001229818306085817\n","CMI: 0.0036854836147290904\n","CMI: 0.0028185613075352167\n","CMI: 0.011743282131004007\n","CMI: 0.0019414174154990804\n","CMI: 0.013109355534675682\n","Highest CMI score: 0.013109355534675682\n","Adding original feature: 93\n","CMI: 0.0028246078922316564\n","CMI: 0.004716544127405131\n","Highest CMI score: 0.004716544127405131\n","Adding original feature: 85\n","CMI: 0.005150596630587034\n","CMI: 0.004752880807493087\n","CMI: 0.0005382192856183132\n","Highest CMI score: 0.005150596630587034\n","Adding original feature: 26\n","Highest CMI score: -0.002610403643959147\n","\n","[84, 4, 39, 93, 85, 26]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.5568995533371772, test score: -0.2226664424907705\n","Aggregate regression train score with FS: 0.3288825745382554, test score: 0.2704799057726527\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.5568995533371772, test score: -0.2226664424907705\n","Aggregate regression train score with FS: 0.32858738341119487, test score: 0.26711295330437446\n","####################e12gm_to_e2####################\n","Number of features: 369\n","\n","eps value:  0.00027100271002710027\n","Number of aggregated features: 8\n","\n","Number of features: 369\n","\n","eps value:  0.00027100271002710027\n","Number of aggregated features: 7\n","\n","Number of features: 369\n","\n","eps value:  0.00027100271002710027\n","Number of aggregated features: 7\n","\n","Number of features: 369\n","\n","eps value:  0.00027100271002710027\n","Number of aggregated features: 5\n","\n","Number of features: 369\n","\n","eps value:  0.00027100271002710027\n","Number of aggregated features: 4\n","\n","Number of features: 369\n","\n","eps value:  0.00027100271002710027\n","Number of aggregated features: 3\n","\n","Number of features: 369\n","\n","eps value:  0.00027100271002710027\n","Number of aggregated features: 4\n","\n","Number of features: 369\n","\n","eps value:  0.00027100271002710027\n","Number of aggregated features: 13\n","\n","Number of features: 369\n","\n","eps value:  0.00027100271002710027\n","Number of aggregated features: 14\n","\n","Number of features: 369\n","\n","eps value:  0.00027100271002710027\n","Number of aggregated features: 12\n","\n","Number of features: 369\n","\n","eps value:  0.00027100271002710027\n","Number of aggregated features: 7\n","\n","Number of features: 369\n","\n","eps value:  0.00027100271002710027\n","Number of aggregated features: 3\n","\n","Number of features: 369\n","\n","eps value:  0.00027100271002710027\n","Number of aggregated features: 5\n","\n","Number of features: 369\n","\n","eps value:  0.00027100271002710027\n","Number of aggregated features: 2\n","\n","\n","\n","selected columns: ['cyclostationary_mean_tg_1w_3', 'cyclostationary_mean_rr_8w_0', 'cyclostationary_mean_tg_8w_4', 'cyclostationary_mean_tg_8w_0', 'cyclostationary_mean_rr_8w_5', 'cyclostationary_mean_rr_16w_2', 'cyclostationary_mean_rr_12w_1', 'cyclostationary_mean_tg_4w_3', 'cyclostationary_mean_rr_4w_9', 'cyclostationary_mean_tg_2', 'cyclostationary_mean_tg_4w_6', 'cyclostationary_mean_rr_12w_2', 'cyclostationary_mean_tg_24w_3', 'cyclostationary_mean_tg_8w_3', 'cyclostationary_mean_tg_16w_2', 'cyclostationary_mean_tg_12w_3', 'cyclostationary_mean_rr_1w_2', 'cyclostationary_mean_rr_1w_7', 'cyclostationary_mean_rr_2', 'cyclostationary_mean_rr_4w_4', 'cyclostationary_mean_rr_4w_6', 'cyclostationary_mean_rr_8w_4', 'cyclostationary_mean_tg_8w_1'], \n","\n","validation score: 0.4665892017625636, \n","\n","number of selected features: 23\n","\n","Full model and selected features with wrapper\n","\n","Full aggregate regression train score: 0.5013765488600384, test score: -0.11312395059594649\n","Aggregate regression train score with FS: 0.35127724091389856, test score: 0.04512605483243304\n","\n","Full model and best 5 selected features with wrapper\n","\n","Full aggregate regression train score: 0.5013765488600384, test score: -0.11312395059594649\n","Aggregate regression train score with FS: 0.2919925147628589, test score: 0.27537719528508364\n","----- MI Scores -----\n","[(69, 0.1294518408181301), (11, 0.12412115069797953), (86, 0.1180383773841428), (67, 0.11710341575527143), (73, 0.11548417273995464), (55, 0.11512718631160103), (77, 0.11258081014790776), (3, 0.11105606559756273), (4, 0.10718654219202059), (78, 0.10124754506232447), (54, 0.10060474159693784), (63, 0.09854005629812404), (64, 0.09848040662808978), (70, 0.0982281413324499), (10, 0.09506003801781154), (62, 0.094067297166197), (0, 0.09375579844410563), (81, 0.09334321279958982), (66, 0.09169236232012362), (21, 0.09139628132408192), (80, 0.08972348199486077), (88, 0.0865038752861074), (5, 0.08633953056624281), (89, 0.08610335699715292), (90, 0.08547390472260437), (46, 0.08458578031456047), (61, 0.08307019832931473), (12, 0.08248391792048088), (79, 0.08205295692304651), (82, 0.0801396698735916), (7, 0.080051312353485), (65, 0.07923633672693141), (60, 0.07906806150250605), (49, 0.07702085753472483), (68, 0.07586378421399209), (84, 0.07463046098076548), (8, 0.0745529956094591), (72, 0.07421300630307875), (40, 0.07402819821151656), (1, 0.07314666894158028), (75, 0.07272607982751346), (71, 0.07193896878566679), (42, 0.07141069884899842), (13, 0.07125907237334882), (45, 0.07057108943189017), (20, 0.0681128062203191), (52, 0.06797074833743491), (87, 0.06792609539430992), (41, 0.06778870429596014), (53, 0.0673015030340393), (57, 0.06717480755238658), (48, 0.0662205163504344), (9, 0.06557391467849284), (83, 0.0649874053783683), (19, 0.0646603902981421), (56, 0.06450720854906504), (47, 0.06415493841779839), (59, 0.062027459702529014), (35, 0.061312936132637684), (2, 0.06125714663466106), (43, 0.060268675132204436), (50, 0.05890571143799372), (85, 0.055694696375008686), (58, 0.0554411323124629), (23, 0.05538965642598673), (25, 0.05431854646774006), (36, 0.05335129856885183), (74, 0.04953166864293311), (76, 0.049228866225499816), (6, 0.048646420394865164), (39, 0.04684656999164143), (28, 0.044947963883539686), (26, 0.04428458759911999), (44, 0.04408167674917713), (91, 0.04398074604974582), (29, 0.04367147712253076), (22, 0.04087650547088665), (15, 0.03444803505104595), (37, 0.03279882395045534), (92, 0.032401834704363607), (51, 0.031057462208056205), (16, 0.030818226741256276), (14, 0.02643309197683547), (34, 0.025185470046959202), (30, 0.024556215496623332), (93, 0.020891847113538174), (24, 0.01955347955221047), (38, 0.017465979659333275), (17, 0.015324019306959603), (31, 0.014512857184268386), (27, 0.012001367804603176), (18, 0.009423557561512341), (33, 0.00906659767503522), (32, 0.005329259979075646)]\n","Best MI score: 0.1294518408181301\n","Adding first best original feature: 69\n","CMI: 0.07099612610275338\n","CMI: 0.048249319387826756\n","CMI: 0.024265709725314888\n","CMI: 0.05157145158511395\n","CMI: 0.04436156524946469\n","CMI: 0.051567549587093586\n","CMI: 0.025499823617346734\n","CMI: 0.03851997082976866\n","CMI: 0.01718105515170945\n","CMI: 0.054762103958135244\n","CMI: 0.05565729072107281\n","CMI: 0.0634854926904016\n","CMI: 0.02306173906683856\n","CMI: 0.0309870377833886\n","CMI: 0.00989677463317759\n","CMI: 0.004291911274066279\n","CMI: 0.009224341111301798\n","CMI: 0.015486097003036686\n","CMI: 0.02898607058761951\n","CMI: 0.025086578069439758\n","CMI: 0.012724620990870184\n","CMI: 0.030595294778429066\n","CMI: 0.014517117649518158\n","CMI: 0.01777932454295425\n","CMI: 0.005365356247559461\n","CMI: 0.00655367956493727\n","CMI: 0.004564750721220839\n","CMI: 0.013728701857312814\n","CMI: 0.020873448297810848\n","CMI: 0.01569830130839056\n","CMI: 0.016083731738417012\n","CMI: 0.0005308812070199398\n","CMI: 0.004761252586076542\n","CMI: 0.0017697577281948762\n","CMI: 0.03575162082004746\n","CMI: 0.05057187417324702\n","CMI: 0.025217039475799063\n","CMI: 0.010121568603210479\n","CMI: 0.0011176902929238841\n","CMI: 0.02606706250123117\n","CMI: 0.008022645905111647\n","CMI: 0.047097794093717504\n","CMI: 0.01854661748149633\n","CMI: 0.04064385194921358\n","CMI: 0.02747086018403669\n","CMI: 0.00804045669496442\n","CMI: 0.026562491049385434\n","CMI: 0.0008600763105130749\n","CMI: 0.01901818038295297\n","CMI: 0.0010937093412168586\n","CMI: 0.0026226839551095893\n","CMI: 0.0005371730539702191\n","CMI: 0.0013017376727881003\n","Highest CMI score: 0.07099612610275338\n","Adding original feature: 0\n","CMI: 0.0028721301974564406\n","CMI: 0.0034484005653968586\n","CMI: 0.009335184389441004\n","CMI: 0.014722916126191588\n","CMI: 0.00038497778154011897\n","CMI: 0.0012575062727083197\n","CMI: 0.006364843546433602\n","CMI: 0.010504682611028632\n","CMI: 0.0053305560838111665\n","CMI: 0.0018729662766817923\n","CMI: 0.011382316241206253\n","CMI: 0.005428374257488849\n","CMI: 2.6386295903790824e-06\n","CMI: 0.0009102772123142366\n","CMI: 4.002924330198665e-05\n","Highest CMI score: 0.014722916126191588\n","Adding original feature: 47\n","CMI: 0.002695425241795002\n","CMI: 0.0007826650052488726\n","CMI: 0.00041669783756159706\n","CMI: 0.005915402958757282\n","CMI: 0.0008384943808724121\n","CMI: 0.0022578886830989797\n","CMI: 0.007302439503385827\n","CMI: 0.008397115124830656\n","CMI: 0.010603581869706197\n","CMI: 0.004564857231744296\n","CMI: 0.012199220797770721\n","CMI: 0.02630782872646162\n","CMI: 0.0016253554434184359\n","CMI: 0.005850498011943206\n","CMI: 0.003937055807509665\n","CMI: 0.002074323534330458\n","CMI: 0.0015931644466286587\n","Highest CMI score: 0.02630782872646162\n","Adding original feature: 67\n","CMI: 0.00011334957672359813\n","CMI: 0.0012725975185859384\n","CMI: 0.0008783743004494304\n","CMI: 0.009416767954915695\n","Highest CMI score: 0.009416767954915695\n","Adding original feature: 63\n","Highest CMI score: -0.0009093935594482461\n","\n","[69, 0, 47, 67, 63]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.5013765488600384, test score: -0.11312395059594649\n","Aggregate regression train score with FS: 0.21998380548091245, test score: 0.25261301294579563\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.5013765488600384, test score: -0.11312395059594649\n","Aggregate regression train score with FS: 0.21998380548091245, test score: 0.25261301294579563\n","####################e12gm_to_gm####################\n","Number of features: 369\n","\n","eps value:  0.00027100271002710027\n","Number of aggregated features: 6\n","\n","Number of features: 369\n","\n","eps value:  0.00027100271002710027\n","Number of aggregated features: 5\n","\n","Number of features: 369\n","\n","eps value:  0.00027100271002710027\n","Number of aggregated features: 3\n","\n","Number of features: 369\n","\n","eps value:  0.00027100271002710027\n","Number of aggregated features: 8\n","\n","Number of features: 369\n","\n","eps value:  0.00027100271002710027\n","Number of aggregated features: 5\n","\n","Number of features: 369\n","\n","eps value:  0.00027100271002710027\n","Number of aggregated features: 5\n","\n","Number of features: 369\n","\n","eps value:  0.00027100271002710027\n","Number of aggregated features: 3\n","\n","Number of features: 369\n","\n","eps value:  0.00027100271002710027\n","Number of aggregated features: 12\n","\n","Number of features: 369\n","\n","eps value:  0.00027100271002710027\n","Number of aggregated features: 14\n","\n","Number of features: 369\n","\n","eps value:  0.00027100271002710027\n","Number of aggregated features: 12\n","\n","Number of features: 369\n","\n","eps value:  0.00027100271002710027\n","Number of aggregated features: 7\n","\n","Number of features: 369\n","\n","eps value:  0.00027100271002710027\n","Number of aggregated features: 3\n","\n","Number of features: 369\n","\n","eps value:  0.00027100271002710027\n","Number of aggregated features: 4\n","\n","Number of features: 369\n","\n","eps value:  0.00027100271002710027\n","Number of aggregated features: 5\n","\n","\n","\n","selected columns: ['cyclostationary_mean_rr_24w_3', 'cyclostationary_mean_tg_1w_3', 'cyclostationary_mean_tg_8w_4', 'cyclostationary_mean_rr_4w_5', 'cyclostationary_mean_rr_24w_0', 'cyclostationary_mean_tg_1w_2', 'cyclostationary_mean_tg_8w_1', 'cyclostationary_mean_tg_4w_2', 'cyclostationary_mean_rr_8w_3', 'cyclostationary_mean_tg_8w_7', 'cyclostationary_mean_rr_4w_4', 'cyclostationary_mean_tg_4w_0', 'cyclostationary_mean_tg_8w_6', 'cyclostationary_mean_rr_8w_6', 'cyclostationary_mean_rr_8w_1'], \n","\n","validation score: 0.3541389733366678, \n","\n","number of selected features: 15\n","\n","Full model and selected features with wrapper\n","\n","Full aggregate regression train score: 0.40254056877107525, test score: -0.16555931404768676\n","Aggregate regression train score with FS: 0.3031056281989247, test score: 0.14853600231565944\n","\n","Full model and best 5 selected features with wrapper\n","\n","Full aggregate regression train score: 0.40254056877107525, test score: -0.16555931404768676\n","Aggregate regression train score with FS: 0.25648652920189674, test score: 0.22028395226603492\n","----- MI Scores -----\n","[(76, 0.12476925008872786), (74, 0.11809650151811207), (64, 0.11321166856409241), (80, 0.1103724074907613), (62, 0.1100672950627717), (56, 0.10933639021139029), (90, 0.10517145105075765), (67, 0.10377338472224844), (5, 0.10353717152500307), (71, 0.10308624450153875), (82, 0.09864312695984367), (53, 0.0969712700666693), (57, 0.09517309597940551), (52, 0.09484531568363848), (4, 0.09173267220151347), (9, 0.09139530241667375), (54, 0.0907957100609136), (83, 0.08955431635394431), (58, 0.0892318784047306), (51, 0.08895948013130092), (13, 0.08885682846887785), (38, 0.08868509720021873), (60, 0.08754580253512773), (78, 0.08726492366736145), (66, 0.08711279428322304), (84, 0.08571105250141728), (77, 0.08561368806286664), (50, 0.08502135635680666), (47, 0.08395216841222164), (85, 0.08345846469272845), (43, 0.08091033244380258), (70, 0.0801576522383078), (79, 0.08004940321308185), (91, 0.07831682408748492), (63, 0.0781651929482422), (39, 0.07616489145911473), (55, 0.07559620443609047), (46, 0.07451650371106283), (8, 0.07439489835843364), (3, 0.07407045720520666), (68, 0.07209992170723488), (72, 0.07113127350663502), (42, 0.06836591184688898), (12, 0.06658384378777107), (45, 0.06498107803098911), (87, 0.064628673994825), (6, 0.06379322468579564), (0, 0.0627479737880981), (35, 0.061069397898454066), (44, 0.06066137248254247), (40, 0.05774824520176088), (29, 0.057622694269366226), (75, 0.05575007833800083), (41, 0.05457973598736777), (7, 0.05390894536891296), (1, 0.05301093009342864), (24, 0.051970674152076866), (2, 0.05088094718044374), (10, 0.046393151440040685), (49, 0.04568327892663348), (65, 0.04500002416686768), (11, 0.04155891784482619), (73, 0.0399553471455249), (26, 0.03895827429691527), (89, 0.03811522177840482), (81, 0.03768089863970666), (31, 0.037171635922329804), (16, 0.0352828941279339), (48, 0.035039786133518484), (61, 0.03412954558101008), (59, 0.033531262581387125), (27, 0.03344915351313528), (37, 0.03300312440879623), (17, 0.03299099164247334), (34, 0.03198188669761235), (32, 0.03151222991497796), (86, 0.028831595431969195), (19, 0.02799676683770335), (33, 0.027131245223443495), (14, 0.026155736907755495), (88, 0.025859454543365176), (30, 0.02426894828194926), (15, 0.02318389903240299), (36, 0.022977759908177273), (18, 0.020771167071305583), (28, 0.019852012845810004), (20, 0.01874875230482221), (23, 0.016049261112328243), (21, 0.015540179879147315), (22, 0.011062172387365506), (69, 0.010958055189494675), (25, 0.009091289910349437)]\n","Best MI score: 0.12476925008872786\n","Adding first best original feature: 76\n","CMI: 0.05234533484717266\n","CMI: 0.05637857829697704\n","CMI: 0.05142826993403371\n","CMI: 0.057925380624581746\n","CMI: 0.055133144067988804\n","CMI: 0.0759964844355461\n","CMI: 0.044874439067241784\n","CMI: 0.06459945649835583\n","CMI: 0.04487518541268523\n","CMI: 0.06556921988043182\n","CMI: 0.025268596487125927\n","CMI: 0.006127249954858416\n","CMI: 0.023243647477758478\n","CMI: 0.005801130498885643\n","CMI: 0.001278098039896508\n","CMI: 0.01175741766553745\n","CMI: 4.065118225896058e-05\n","CMI: 0.037334656120940835\n","CMI: 0.011325319620446778\n","CMI: 0.014198482542151614\n","CMI: 0.019245409788643975\n","CMI: 0.029882316193428404\n","CMI: 0.035242858730790305\n","CMI: 0.005960888964865241\n","CMI: 0.01807944353123961\n","CMI: 0.007570032764001977\n","CMI: 0.01307139541562527\n","CMI: 0.018492262316801872\n","CMI: 0.023051628632319687\n","CMI: 0.033142624395838954\n","CMI: 0.004604726911261542\n","CMI: 0.0008747442551382267\n","CMI: 0.03660322414936307\n","CMI: 0.03812026072184077\n","CMI: 0.0340049079386566\n","CMI: 0.02999808429929643\n","CMI: 0.003931500702530205\n","CMI: 0.0030875882186904846\n","CMI: 0.03404621823082751\n","CMI: 0.029041753437877432\n","CMI: 0.013373576410268484\n","CMI: 0.027536344779082483\n","CMI: 0.00406651747417805\n","CMI: 0.005682949385963226\n","CMI: 0.01150716456610787\n","CMI: 0.022976792107995497\n","CMI: 0.0063900580181574795\n","CMI: 0.013594438030849587\n","CMI: 0.00137465330489564\n","CMI: 0.0048227245632949944\n","CMI: 0.006170163421957198\n","CMI: 0.0008588178238743971\n","CMI: 0.026653077821533228\n","CMI: 0.010943857794365353\n","CMI: 0.009918248910900429\n","CMI: 0.00379258839354632\n","CMI: 0.010322851085308782\n","CMI: 0.036910313496304914\n","CMI: 0.006575688479801611\n","Highest CMI score: 0.0759964844355461\n","Adding original feature: 5\n","CMI: 0.005156884865537309\n","CMI: 0.003859719771360015\n","CMI: 0.021427221577165367\n","CMI: 0.007607694276112048\n","CMI: 0.003753768655600065\n","CMI: 0.005464938952237708\n","CMI: 0.021513998661419897\n","CMI: 0.00023504378116881441\n","CMI: 0.005660419394353272\n","CMI: 0.02516603363859793\n","CMI: 0.01178250796889374\n","CMI: 0.009758083044149629\n","CMI: 0.0032220972017188987\n","CMI: 0.006090357091908277\n","CMI: 0.0005528097358509787\n","CMI: 0.013153992194974207\n","CMI: 0.008621237857395353\n","CMI: 0.005441421712802458\n","CMI: 0.013068062164137279\n","CMI: 0.0030611237353272147\n","CMI: 0.003762454794490805\n","CMI: 0.01095882888870181\n","CMI: 0.0024644129393593672\n","CMI: 0.012077627624091591\n","CMI: 0.0008657115038779029\n","CMI: 0.007042392030374683\n","CMI: 0.008909476162243496\n","CMI: 0.005407169475925483\n","CMI: 0.0007990876505501177\n","Highest CMI score: 0.02516603363859793\n","Adding original feature: 29\n","CMI: 0.004998073080229315\n","CMI: 0.00493899883828719\n","CMI: 0.008853685568782632\n","CMI: 0.004624580258677652\n","CMI: 0.01576912988270937\n","CMI: 0.0058619339000572646\n","CMI: 0.006879519832535846\n","CMI: 0.015274879064757552\n","CMI: 0.012530676145548203\n","CMI: 0.007090149245579241\n","CMI: 0.004861090105875238\n","CMI: 0.005239628754633463\n","CMI: 0.002566603226210412\n","CMI: 0.004307685076520851\n","CMI: 0.003034046759428588\n","CMI: 0.0013064455310522194\n","Highest CMI score: 0.01576912988270937\n","Adding original feature: 28\n","CMI: 0.002687419886235526\n","CMI: 0.002718469001607965\n","CMI: 0.002454984070510313\n","CMI: 0.004715006151231271\n","Highest CMI score: 0.004715006151231271\n","Adding original feature: 62\n","CMI: 0.0008063455287909416\n","CMI: 0.010166689433452725\n","CMI: 0.0019253882849841475\n","CMI: 0.013382074954429113\n","CMI: 0.002441976963950321\n","CMI: 0.0023451876955621898\n","CMI: 0.003267101924427085\n","CMI: 0.006807203507264548\n","CMI: 0.002211718688816755\n","Highest CMI score: 0.013382074954429113\n","Adding original feature: 17\n","CMI: 4.571077559911707e-06\n","CMI: 0.0014210245021124557\n","CMI: 0.00042786629690338973\n","Highest CMI score: 0.0014210245021124557\n","Adding original feature: 20\n","CMI: 0.0005483703129269824\n","Highest CMI score: 0.0005483703129269824\n","Adding original feature: 34\n","Highest CMI score: -0.0002912125299369128\n","\n","[76, 5, 29, 28, 62, 17, 20, 34]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.40254056877107525, test score: -0.16555931404768676\n","Aggregate regression train score with FS: 0.28193556033904454, test score: 0.16959931181723664\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.40254056877107525, test score: -0.16555931404768676\n","Aggregate regression train score with FS: 0.26178725352587506, test score: 0.13545687911484117\n"]}],"source":["for basin, target_name in zip(\n","    [\"e12gm_to_e1\", \"e12gm_to_e2\", \"e12gm_to_gm\"],\n","    [\"Emiliani1\", \"Emiliani2\", \"Garda_Mincio\"],\n","):\n","    print(\"####################\" + basin + \"####################\")\n","\n","    target_df_train, target_df_val, target_df_test, target_df_trainVal = prepare_target(\n","        \"\",\n","        max_train=\"2010-01-01\",\n","        max_val=\"2015-01-01\",\n","        max_test=\"2020-01-01\",\n","        path=path_target + target_name + \".csv\",  # use the target of Garda_Mincio\n","        window_size=1,\n","    )\n","\n","    eps = 0.1\n","    actual_path = path_features + \"e12gm\" + \"_aggreg.csv\"\n","    output, aggregate_trainVal, aggregate_test = aggregate_unfolded_data(\n","        actual_path,\n","        variable_names,\n","        target_df_trainVal,\n","        eps=eps,\n","        max_train=\"2010-01-01\",\n","        max_val=\"2015-01-01\",\n","        max_test=\"2020-01-01\",\n","    )\n","\n","    outputs.append(output)\n","    basins.append(basin)\n","    aggregate_trainvals.append(aggregate_trainVal)\n","    aggregate_tests.append(aggregate_test)\n","\n","    # agg_trainVal_string = plots_folder + basin + \"_trainVal_aggreg\"\n","    # agg_test_string = plots_folder + basin + \"_test_aggreg\"\n","    # aggregate_trainVal.to_csv(agg_trainVal_string, index = False)\n","    # aggregate_test.to_csv(agg_test_string, index = False)\n","\n","    selected_colnames = FS_with_linearWrapper(\n","        aggregate_trainVal,\n","        target_df_train,\n","        target_df_val,\n","        min(50, aggregate_trainVal.shape[1] - 1),\n","        228,\n","    )\n","\n","    print(\"\\nFull model and selected features with wrapper\\n\")\n","    compare_methods(\n","        aggregate_trainVal,\n","        aggregate_test,\n","        target_df_trainVal,\n","        target_df_test,\n","        selected_colnames,\n","    )\n","\n","    print(\"\\nFull model and best 5 selected features with wrapper\\n\")\n","    compare_methods(\n","        aggregate_trainVal,\n","        aggregate_test,\n","        target_df_trainVal,\n","        target_df_test,\n","        selected_colnames[0:5],\n","    )\n","\n","    # train_string = destination_folder + basin + '_nonLinCFA_wrapper_best5_train.csv'\n","    # val_string = destination_folder + basin + '_nonLinCFA_wrapper_best5_val.csv'\n","    # test_string = destination_folder + basin + '_nonLinCFA_wrapper_best5_test.csv'\n","    # X_train_wrapper = aggregate_trainVal.loc[:410,selected_colnames[0:5]]\n","    # X_validation_wrapper = aggregate_trainVal.loc[411:,selected_colnames[0:5]]\n","    # X_train_validation_wrapper = pd.concat([X_train_wrapper, X_validation_wrapper])\n","    # X_test_wrapper = aggregate_test.loc[:,selected_colnames[0:5]]\n","    # X_train_wrapper.to_csv(train_string, index=False)\n","    # X_validation_wrapper.to_csv(val_string, index=False)\n","    # X_test_wrapper.to_csv(test_string, index=False)\n","\n","    res = {\"delta\": [], \"numSelected\": [], \"selectedFeatures\": []}\n","\n","    res[\"selectedFeatures\"] = forwardFeatureSelection(\n","        10,\n","        np.array(aggregate_trainVal),\n","        np.array(target_df_trainVal.mean_std),\n","        res,\n","        10,\n","        1,\n","    )\n","\n","    selectedFeatures = \"selectedFeatures\"\n","    print(f\"\\n{res[selectedFeatures]}\\n\")\n","\n","    selected_colnames = aggregate_trainVal.columns[res[\"selectedFeatures\"]]\n","\n","    print(\"\\nFull model and selected features with CMI\\n\")\n","    compare_methods(\n","        aggregate_trainVal,\n","        aggregate_test,\n","        target_df_trainVal,\n","        target_df_test,\n","        selected_colnames,\n","    )\n","\n","    print(\"\\nFull model and best 5 selected features with CMI\\n\")\n","    compare_methods(\n","        aggregate_trainVal,\n","        aggregate_test,\n","        target_df_trainVal,\n","        target_df_test,\n","        selected_colnames[0:5],\n","    )\n","\n","    train_string = destination_folder + basin + \"_nonLinCFA_best5_CMI_train.csv\"\n","    val_string = destination_folder + basin + \"_nonLinCFA_best5_CMI_val.csv\"\n","    test_string = destination_folder + basin + \"_nonLinCFA_best5_CMI_test.csv\"\n","\n","    X_train_CMI5 = aggregate_trainVal.loc[:410, selected_colnames[0:5]]\n","    X_validation_CMI5 = aggregate_trainVal.loc[411:, selected_colnames[0:5]]\n","    X_train_validation_CMI5 = pd.concat([X_train_CMI5, X_validation_CMI5])\n","    X_test_CMI5 = aggregate_test.loc[:, selected_colnames[0:5]]\n","\n","    selected_colnames_CMI5 = aggregate_trainVal.loc[\n","        :, selected_colnames[0:5]\n","    ].columns.values\n","\n","    X_train_CMI5.to_csv(train_string, index=False)\n","    X_validation_CMI5.to_csv(val_string, index=False)\n","    X_test_CMI5.to_csv(test_string, index=False)\n","\n","    train_string = destination_folder + basin + \"_nonLinCFA_CMI_train.csv\"\n","    val_string = destination_folder + basin + \"_nonLinCFA_CMI_val.csv\"\n","    test_string = destination_folder + basin + \"_nonLinCFA_CMI_test.csv\"\n","\n","    X_train_CMI = aggregate_trainVal.loc[:410, selected_colnames]\n","    X_validation_CMI = aggregate_trainVal.loc[411:, selected_colnames]\n","    X_train_validation_CMI = pd.concat([X_train_CMI, X_validation_CMI])\n","    X_test_CMI = aggregate_test.loc[:, selected_colnames]\n","\n","    X_train_CMI.to_csv(train_string, index=False)\n","    X_validation_CMI.to_csv(val_string, index=False)\n","    X_test_CMI.to_csv(test_string, index=False)"]},{"cell_type":"code","execution_count":35,"id":"73e54365","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['e12gm_to_e1', 'e12gm_to_e2', 'e12gm_to_gm']\n"]}],"source":["print(basins)"]},{"cell_type":"code","execution_count":33,"id":"8e255e3c","metadata":{},"outputs":[],"source":["export_spatial_components(basins, outputs, variable_names, \"./variable_components_e12gm_to_single.pickle\")"]},{"cell_type":"markdown","id":"64aeaa6c","metadata":{},"source":["Salva le feature aggregate (quindi prima delle CMI feature selection)"]},{"cell_type":"code","execution_count":34,"id":"5bba847e","metadata":{},"outputs":[],"source":["destination_folder = \"./NonLinCFA_e12gm_to_single_noCMI/\"\n","os.makedirs(destination_folder, exist_ok=True)\n","\n","for basin, aggregate_trainval, aggregate_test in zip(\n","    basins, aggregate_trainvals, aggregate_tests\n","):\n","    # Split aggregate_trainval into train (first 411 rows) and validation\n","    aggregate_train = aggregate_trainval.iloc[:411, :]\n","    aggregate_val = aggregate_trainval.iloc[411:, :]\n","\n","    aggregate_train.to_csv(os.path.join(destination_folder, basin + \"_train.csv\"), index=False)\n","    aggregate_val.to_csv(os.path.join(destination_folder, basin + \"_val.csv\"), index=False)\n","    aggregate_test.to_csv(os.path.join(destination_folder, basin + \"_test.csv\"), index=False)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"thesis","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"}},"nbformat":4,"nbformat_minor":5}
