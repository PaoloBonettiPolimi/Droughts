{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "288de91a",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44f5d87f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "sys.path.append(\"/Users/paolo/Documents/methods/CMI_FS\")\n",
    "from feature_selection import forwardFeatureSelection\n",
    "\n",
    "sys.path.append(\"/Users/paolo/Documents/methods/LinCFA\")\n",
    "from LinCFA import LinCFA\n",
    "\n",
    "sys.path.append(\"/Users/paolo/Documents/methods/NonLinCFA\")\n",
    "from NonLinCFA import NonLinCFA\n",
    "\n",
    "sys.path.append(\"/Users/paolo/Documents/Droughts/Paolo/regression_NonLinCFA\")\n",
    "from aux import standardize,unfold_dataset,compute_r2,prepare_target,prepare_features,aggregate_unfolded_data,aggregate_unfolded_data_onlyTrain,FS_with_linearWrapper,compare_methods, compute_r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c37799f6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_cells(output,selected_colnames, xmin=9, xmax=11, ymin=44, ymax=45.5):\n",
    "    x = []\n",
    "    y = []\n",
    "    colors = cm.rainbow(np.linspace(0,1,len(output)))\n",
    "    np.random.shuffle(colors)\n",
    "    fig, ax = plt.subplots(2)\n",
    "    ax[0].set_xlim(xmin,xmax)\n",
    "    ax[1].set_xlim(xmin,xmax)\n",
    "    ax[0].set_ylim(ymin,ymax)\n",
    "    ax[1].set_ylim(ymin,ymax)\n",
    "    for i in range(len(output)): \n",
    "        #print(len(output[i]))\n",
    "        x = []\n",
    "        y = []\n",
    "        \n",
    "        for datum in output[i]:\n",
    "            x.append(float(datum.split('_')[1]))\n",
    "            y.append(float(datum.split('_')[2]))\n",
    "        ax[0].scatter(x,y,color=colors[i])\n",
    "    \n",
    "    x = []\n",
    "    y = []\n",
    "    col = cm.rainbow(np.linspace(0,1,len(selected_colnames)))\n",
    "    for i in range(len(selected_colnames)): \n",
    "        idx = int(selected_colnames[i].split('_')[-1])\n",
    "        for datum in output[idx]:\n",
    "            x.append(float(datum.split('_')[1]))\n",
    "            y.append(float(datum.split('_')[2]))\n",
    "        ax[1].scatter(x,y,color=col[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c16e3a3",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version 2.10.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(f'tensorflow version {tf.__version__}')\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from numpy import * \n",
    "\n",
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e18af23d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_dendrogram(model, **kwargs):\n",
    "\n",
    "    # Children of hierarchical clustering\n",
    "    children = model.children_\n",
    "\n",
    "    # Distances between each pair of children\n",
    "    # Since we don't have this information, we can use a uniform one for plotting\n",
    "    distance = np.arange(children.shape[0])\n",
    "\n",
    "    # The number of observations contained in each cluster level\n",
    "    no_of_observations = np.arange(2, children.shape[0]+2)\n",
    "\n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "    linkage_matrix = np.column_stack([children, distance, no_of_observations]).astype(float)\n",
    "\n",
    "    # Plot the corresponding dendrogram\n",
    "    dendrogram(linkage_matrix, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee498c00",
   "metadata": {},
   "source": [
    "# Emiliani1-Emiliani2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65b4ef7",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6748c934",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.379890    0.50  2001     1 -0.382765\n",
      "1    2001-01-13  0.482679    0.58  2001     2  0.319215\n",
      "2    2001-01-21  0.516259    0.59  2001     3  0.548542\n",
      "3    2001-01-29  0.434421    0.50  2001     5 -0.010351\n",
      "4    2001-02-06  0.494805    0.54  2001     6  0.402030\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.427085    0.43  2009    48 -0.060454\n",
      "407  2009-12-05  0.547380    0.57  2009    49  0.761079\n",
      "408  2009-12-13  0.531070    0.58  2009    50  0.649694\n",
      "409  2009-12-21  0.295704    0.00  2009    52 -0.957702\n",
      "410  2009-12-29  0.027861    0.00  2009    53 -2.786888\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.214281    0.00  2001     1 -1.339879\n",
      "1    2001-01-13  0.484737    0.52  2001     2  0.402993\n",
      "2    2001-01-21  0.466071    0.47  2001     3  0.282703\n",
      "3    2001-01-29  0.417470    0.44  2001     5 -0.030490\n",
      "4    2001-02-06  0.492202    0.53  2001     6  0.451097\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.436464    0.46  2009    48  0.091910\n",
      "407  2009-12-05  0.466152    0.49  2009    49  0.283224\n",
      "408  2009-12-13  0.553659    0.59  2009    50  0.847138\n",
      "409  2009-12-21  0.507978    0.65  2009    52  0.552758\n",
      "410  2009-12-29  0.083046    0.00  2009    53 -2.185583\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n"
     ]
    }
   ],
   "source": [
    "### targets\n",
    "path_targets = '/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/csv_VHI/'\n",
    "target_df_train_E1,target_df_val_E1,target_df_test_E1,target_df_trainVal_E1 = prepare_target('',max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01', path=path_targets+'Emiliani1.csv')\n",
    "target_df_train_E2,target_df_val_E2,target_df_test_E2,target_df_trainVal_E2 = prepare_target('',max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01', path=path_targets+'Emiliani2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34c444cb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### wrapper best 5 features\n",
    "path_features = '/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/reduced_features/'\n",
    "\n",
    "best5_wrapper_train_E1 = pd.read_csv(path_features+'Emiliani1_nonLinCFA_wrapper_best5_train.csv')\n",
    "best5_wrapper_val_E1 = pd.read_csv(path_features+'Emiliani1_nonLinCFA_wrapper_best5_val.csv')\n",
    "best5_wrapper_test_E1 = pd.read_csv(path_features+'Emiliani1_nonLinCFA_wrapper_best5_test.csv')\n",
    "\n",
    "best5_wrapper_train_E2 = pd.read_csv(path_features+'Emiliani2_nonLinCFA_wrapper_best5_train.csv')\n",
    "best5_wrapper_val_E2 = pd.read_csv(path_features+'Emiliani2_nonLinCFA_wrapper_best5_val.csv')\n",
    "best5_wrapper_test_E2 = pd.read_csv(path_features+'Emiliani2_nonLinCFA_wrapper_best5_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "459fde2e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### CMI features\n",
    "path_features = '/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/reduced_features/'\n",
    "\n",
    "CMI_train_E1 = pd.read_csv(path_features+'Emiliani1_nonLinCFA_CMI_train.csv')\n",
    "CMI_val_E1 = pd.read_csv(path_features+'Emiliani1_nonLinCFA_CMI_val.csv')\n",
    "CMI_test_E1 = pd.read_csv(path_features+'Emiliani1_nonLinCFA_CMI_test.csv')\n",
    "\n",
    "CMI_train_E2 = pd.read_csv(path_features+'Emiliani2_nonLinCFA_CMI_train.csv')\n",
    "CMI_val_E2 = pd.read_csv(path_features+'Emiliani2_nonLinCFA_CMI_val.csv')\n",
    "CMI_test_E2 = pd.read_csv(path_features+'Emiliani2_nonLinCFA_CMI_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89b9c9e7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### CMI best 5 features\n",
    "path_features = '/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/reduced_features/'\n",
    "\n",
    "best5_CMI_train_E1 = pd.read_csv(path_features+'Emiliani1_nonLinCFA_best5_CMI_train.csv')\n",
    "best5_CMI_val_E1 = pd.read_csv(path_features+'Emiliani1_nonLinCFA_best5_CMI_val.csv')\n",
    "best5_CMI_test_E1 = pd.read_csv(path_features+'Emiliani1_nonLinCFA_best5_CMI_test.csv')\n",
    "\n",
    "best5_CMI_train_E2 = pd.read_csv(path_features+'Emiliani2_nonLinCFA_best5_CMI_train.csv')\n",
    "best5_CMI_val_E2 = pd.read_csv(path_features+'Emiliani2_nonLinCFA_best5_CMI_val.csv')\n",
    "best5_CMI_test_E2 = pd.read_csv(path_features+'Emiliani2_nonLinCFA_best5_CMI_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13b11c2",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## feedforward NN with wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb5d622",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Emiliani1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "95f6a5ea",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 36\n",
      "Trainable params: 36\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 10:01:40.769632: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-02-01 10:01:40.770898: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model_emiliani1_wrapperBest5 = Sequential()\n",
    "model_emiliani1_wrapperBest5.add(Dense(5, input_dim=5, activation='relu')) \n",
    "model_emiliani1_wrapperBest5.add(Dense(1)) # Output\n",
    "\n",
    "model_emiliani1_wrapperBest5.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=20, \n",
    "        verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "model_emiliani1_wrapperBest5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "52c2a87e",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6589 - val_loss: 0.6451\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6589 - val_loss: 0.6459\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6592 - val_loss: 0.6463\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6581 - val_loss: 0.6458\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6578 - val_loss: 0.6459\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6574 - val_loss: 0.6458\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6573 - val_loss: 0.6454\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6569 - val_loss: 0.6460\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6567 - val_loss: 0.6457\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6566 - val_loss: 0.6463\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6565 - val_loss: 0.6460\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6560 - val_loss: 0.6464\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6558 - val_loss: 0.6463\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6556 - val_loss: 0.6460\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6556 - val_loss: 0.6461\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6552 - val_loss: 0.6467\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6552 - val_loss: 0.6480\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6549 - val_loss: 0.6467\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6545 - val_loss: 0.6476\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6542 - val_loss: 0.6478\n",
      "Epoch 21/1000\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6240Restoring model weights from the end of the best epoch: 1.\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6542 - val_loss: 0.6473\n",
      "Epoch 21: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28be7c850>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_emiliani1_wrapperBest5.fit(best5_wrapper_train_E1,target_df_train_E1.mean_std,validation_data=(best5_wrapper_val_E1,target_df_val_E1.mean_std),\n",
    "        callbacks=[monitor],epochs=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6ce97aa7",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 10:05:16.217225: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3041542505571182"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(target_df_test_E1.mean_std, model_emiliani1_wrapperBest5.predict(best5_wrapper_test_E1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574bb196",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Emiliani2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "aff8d7f7",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 36\n",
      "Trainable params: 36\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_emiliani2_wrapperBest5 = Sequential()\n",
    "model_emiliani2_wrapperBest5.add(Dense(5, input_dim=5, activation='relu')) \n",
    "model_emiliani2_wrapperBest5.add(Dense(1)) # Output\n",
    "\n",
    "model_emiliani2_wrapperBest5.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=20, \n",
    "        verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "model_emiliani2_wrapperBest5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2d56a708",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.7843 - val_loss: 0.7550\n",
      "Epoch 2/1000\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6532"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 10:06:33.435236: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-01 10:06:33.588508: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7776 - val_loss: 0.7471\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7722 - val_loss: 0.7403\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7674 - val_loss: 0.7359\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7642 - val_loss: 0.7310\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7611 - val_loss: 0.7263\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7585 - val_loss: 0.7237\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7565 - val_loss: 0.7209\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7542 - val_loss: 0.7187\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7526 - val_loss: 0.7169\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7514 - val_loss: 0.7157\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7500 - val_loss: 0.7132\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7487 - val_loss: 0.7118\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7476 - val_loss: 0.7103\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7467 - val_loss: 0.7075\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7457 - val_loss: 0.7065\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7441 - val_loss: 0.7056\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7431 - val_loss: 0.7047\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7416 - val_loss: 0.7036\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7410 - val_loss: 0.7030\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7403 - val_loss: 0.7011\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7397 - val_loss: 0.7012\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7392 - val_loss: 0.6994\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7384 - val_loss: 0.6993\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7378 - val_loss: 0.6968\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7371 - val_loss: 0.6958\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7364 - val_loss: 0.6957\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7360 - val_loss: 0.6940\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7354 - val_loss: 0.6940\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7351 - val_loss: 0.6937\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7348 - val_loss: 0.6940\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7343 - val_loss: 0.6928\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7340 - val_loss: 0.6923\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7337 - val_loss: 0.6918\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7334 - val_loss: 0.6912\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7329 - val_loss: 0.6926\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7325 - val_loss: 0.6931\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7318 - val_loss: 0.6925\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7316 - val_loss: 0.6909\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7310 - val_loss: 0.6917\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7306 - val_loss: 0.6914\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7307 - val_loss: 0.6895\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7299 - val_loss: 0.6897\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7297 - val_loss: 0.6888\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7289 - val_loss: 0.6891\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7287 - val_loss: 0.6892\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7282 - val_loss: 0.6891\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7278 - val_loss: 0.6888\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7273 - val_loss: 0.6881\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7271 - val_loss: 0.6879\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7264 - val_loss: 0.6863\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7259 - val_loss: 0.6859\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7256 - val_loss: 0.6845\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7253 - val_loss: 0.6833\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7249 - val_loss: 0.6850\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7248 - val_loss: 0.6829\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7242 - val_loss: 0.6830\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7240 - val_loss: 0.6827\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7235 - val_loss: 0.6819\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7234 - val_loss: 0.6806\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7229 - val_loss: 0.6807\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7229 - val_loss: 0.6806\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7222 - val_loss: 0.6806\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7218 - val_loss: 0.6789\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7214 - val_loss: 0.6787\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7210 - val_loss: 0.6780\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7209 - val_loss: 0.6766\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7206 - val_loss: 0.6779\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7200 - val_loss: 0.6770\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7198 - val_loss: 0.6765\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7194 - val_loss: 0.6770\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7191 - val_loss: 0.6777\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7189 - val_loss: 0.6771\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7187 - val_loss: 0.6762\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7181 - val_loss: 0.6767\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7181 - val_loss: 0.6758\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7177 - val_loss: 0.6751\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7177 - val_loss: 0.6755\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7171 - val_loss: 0.6737\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7170 - val_loss: 0.6730\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7164 - val_loss: 0.6737\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7166 - val_loss: 0.6725\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7164 - val_loss: 0.6734\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7158 - val_loss: 0.6720\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7157 - val_loss: 0.6700\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7156 - val_loss: 0.6717\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7157 - val_loss: 0.6703\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7152 - val_loss: 0.6699\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7146 - val_loss: 0.6689\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7146 - val_loss: 0.6710\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7147 - val_loss: 0.6697\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7136 - val_loss: 0.6678\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7131 - val_loss: 0.6681\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7130 - val_loss: 0.6669\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7126 - val_loss: 0.6665\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7125 - val_loss: 0.6650\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7123 - val_loss: 0.6661\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7122 - val_loss: 0.6653\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7120 - val_loss: 0.6633\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7114 - val_loss: 0.6641\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7120 - val_loss: 0.6640\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7113 - val_loss: 0.6639\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7112 - val_loss: 0.6624\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7111 - val_loss: 0.6642\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7108 - val_loss: 0.6627\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7109 - val_loss: 0.6636\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7107 - val_loss: 0.6627\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7115 - val_loss: 0.6616\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7102 - val_loss: 0.6634\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7100 - val_loss: 0.6624\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7098 - val_loss: 0.6610\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7096 - val_loss: 0.6620\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7094 - val_loss: 0.6614\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7097 - val_loss: 0.6628\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7094 - val_loss: 0.6611\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7092 - val_loss: 0.6604\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7092 - val_loss: 0.6597\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7090 - val_loss: 0.6597\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7086 - val_loss: 0.6595\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7087 - val_loss: 0.6597\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7084 - val_loss: 0.6598\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7082 - val_loss: 0.6600\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7085 - val_loss: 0.6599\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7082 - val_loss: 0.6589\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7079 - val_loss: 0.6590\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7082 - val_loss: 0.6586\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7077 - val_loss: 0.6587\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7074 - val_loss: 0.6588\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7074 - val_loss: 0.6577\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7073 - val_loss: 0.6575\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7072 - val_loss: 0.6573\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7073 - val_loss: 0.6586\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7070 - val_loss: 0.6581\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7067 - val_loss: 0.6578\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7068 - val_loss: 0.6563\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7070 - val_loss: 0.6585\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7066 - val_loss: 0.6569\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7063 - val_loss: 0.6555\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7062 - val_loss: 0.6562\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7060 - val_loss: 0.6559\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7060 - val_loss: 0.6571\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7060 - val_loss: 0.6571\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7060 - val_loss: 0.6570\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7057 - val_loss: 0.6564\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7057 - val_loss: 0.6554\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7056 - val_loss: 0.6570\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7058 - val_loss: 0.6558\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7054 - val_loss: 0.6567\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7059 - val_loss: 0.6546\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7052 - val_loss: 0.6569\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7053 - val_loss: 0.6576\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7056 - val_loss: 0.6579\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7051 - val_loss: 0.6555\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7049 - val_loss: 0.6553\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7051 - val_loss: 0.6568\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7046 - val_loss: 0.6563\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7046 - val_loss: 0.6567\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7044 - val_loss: 0.6572\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7044 - val_loss: 0.6568\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7043 - val_loss: 0.6566\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7044 - val_loss: 0.6563\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7043 - val_loss: 0.6561\n",
      "Epoch 163/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7045 - val_loss: 0.6556\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7040 - val_loss: 0.6557\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7039 - val_loss: 0.6554\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7039 - val_loss: 0.6577\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7038 - val_loss: 0.6567\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7038 - val_loss: 0.6554\n",
      "Epoch 169/1000\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.5948Restoring model weights from the end of the best epoch: 149.\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7034 - val_loss: 0.6559\n",
      "Epoch 169: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28bd6f490>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_emiliani2_wrapperBest5.fit(best5_wrapper_train_E2,target_df_train_E2.mean_std,validation_data=(best5_wrapper_val_E2,target_df_val_E2.mean_std),\n",
    "        callbacks=[monitor],epochs=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f7efb11b",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 10:06:57.197486: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.16591095103637798"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(target_df_test_E2.mean_std, model_emiliani2_wrapperBest5.predict(best5_wrapper_test_E2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "58b9b2ae",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_46 (Dense)            (None, 4)                 52        \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57\n",
      "Trainable params: 57\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.0964"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 10:48:54.189288: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-01 10:48:54.353162: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 12ms/step - loss: 1.0964 - val_loss: 1.4965\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0148 - val_loss: 1.3574\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9536 - val_loss: 1.2370\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9072 - val_loss: 1.1516\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8768 - val_loss: 1.0846\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8534 - val_loss: 1.0262\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8331 - val_loss: 0.9803\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8170 - val_loss: 0.9393\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8056 - val_loss: 0.9088\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7959 - val_loss: 0.8898\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7888 - val_loss: 0.8802\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7819 - val_loss: 0.8707\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7760 - val_loss: 0.8607\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7702 - val_loss: 0.8565\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7662 - val_loss: 0.8495\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7610 - val_loss: 0.8436\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7577 - val_loss: 0.8392\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7545 - val_loss: 0.8296\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7511 - val_loss: 0.8248\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7489 - val_loss: 0.8268\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7455 - val_loss: 0.8291\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7429 - val_loss: 0.8341\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7397 - val_loss: 0.8298\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7370 - val_loss: 0.8268\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7343 - val_loss: 0.8208\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7319 - val_loss: 0.8171\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7293 - val_loss: 0.8117\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7267 - val_loss: 0.8065\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7244 - val_loss: 0.8060\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7223 - val_loss: 0.8022\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7200 - val_loss: 0.7965\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7177 - val_loss: 0.7998\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7153 - val_loss: 0.7969\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7128 - val_loss: 0.7919\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7106 - val_loss: 0.7876\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7084 - val_loss: 0.7847\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7063 - val_loss: 0.7820\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7041 - val_loss: 0.7861\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7023 - val_loss: 0.7850\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7008 - val_loss: 0.7862\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6992 - val_loss: 0.7745\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6971 - val_loss: 0.7759\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6958 - val_loss: 0.7719\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6941 - val_loss: 0.7675\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6922 - val_loss: 0.7616\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6913 - val_loss: 0.7521\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6891 - val_loss: 0.7554\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6872 - val_loss: 0.7479\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6857 - val_loss: 0.7457\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6843 - val_loss: 0.7433\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6828 - val_loss: 0.7374\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6809 - val_loss: 0.7322\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6803 - val_loss: 0.7299\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6780 - val_loss: 0.7285\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6770 - val_loss: 0.7254\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6756 - val_loss: 0.7236\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6746 - val_loss: 0.7240\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6731 - val_loss: 0.7271\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6728 - val_loss: 0.7300\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6714 - val_loss: 0.7214\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6703 - val_loss: 0.7180\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6693 - val_loss: 0.7178\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6688 - val_loss: 0.7216\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6680 - val_loss: 0.7192\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6672 - val_loss: 0.7165\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6664 - val_loss: 0.7152\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6655 - val_loss: 0.7168\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6643 - val_loss: 0.7152\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6639 - val_loss: 0.7143\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6635 - val_loss: 0.7143\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6623 - val_loss: 0.7131\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6615 - val_loss: 0.7153\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6607 - val_loss: 0.7141\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6602 - val_loss: 0.7161\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6596 - val_loss: 0.7144\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6590 - val_loss: 0.7170\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6589 - val_loss: 0.7204\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6582 - val_loss: 0.7134\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6575 - val_loss: 0.7160\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6565 - val_loss: 0.7160\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6556 - val_loss: 0.7150\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6550 - val_loss: 0.7166\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6545 - val_loss: 0.7208\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6545 - val_loss: 0.7193\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6534 - val_loss: 0.7158\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6531 - val_loss: 0.7200\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6526 - val_loss: 0.7194\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6519 - val_loss: 0.7187\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6511 - val_loss: 0.7131\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6506 - val_loss: 0.7153\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6498 - val_loss: 0.7184\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6494 - val_loss: 0.7173\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6496 - val_loss: 0.7226\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6486 - val_loss: 0.7153\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6479 - val_loss: 0.7162\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6478 - val_loss: 0.7215\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6471 - val_loss: 0.7221\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6465 - val_loss: 0.7220\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6463 - val_loss: 0.7206\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6457 - val_loss: 0.7167\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6454 - val_loss: 0.7184\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6448 - val_loss: 0.7182\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6442 - val_loss: 0.7175\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6442 - val_loss: 0.7146\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6443 - val_loss: 0.7134\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6428 - val_loss: 0.7222\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6434 - val_loss: 0.7270\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6425 - val_loss: 0.7169\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6422 - val_loss: 0.7194\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6418 - val_loss: 0.7178\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6420 - val_loss: 0.7203\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6413 - val_loss: 0.7213\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6407 - val_loss: 0.7210\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6402 - val_loss: 0.7210\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6398 - val_loss: 0.7187\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6395 - val_loss: 0.7213\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6396 - val_loss: 0.7194\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6393 - val_loss: 0.7265\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6393 - val_loss: 0.7258\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6390 - val_loss: 0.7261\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6382 - val_loss: 0.7275\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6385 - val_loss: 0.7190\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6379 - val_loss: 0.7227\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6372 - val_loss: 0.7229\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6369 - val_loss: 0.7231\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6366 - val_loss: 0.7227\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6363 - val_loss: 0.7281\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6362 - val_loss: 0.7218\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6359 - val_loss: 0.7272\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6353 - val_loss: 0.7248\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6352 - val_loss: 0.7265\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6350 - val_loss: 0.7208\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6348 - val_loss: 0.7256\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6343 - val_loss: 0.7258\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6343 - val_loss: 0.7257\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6340 - val_loss: 0.7215\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6335 - val_loss: 0.7266\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6333 - val_loss: 0.7257\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6336 - val_loss: 0.7239\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6329 - val_loss: 0.7187\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6331 - val_loss: 0.7288\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6326 - val_loss: 0.7218\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6325 - val_loss: 0.7233\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6318 - val_loss: 0.7238\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6316 - val_loss: 0.7234\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6315 - val_loss: 0.7188\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6309 - val_loss: 0.7180\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6305 - val_loss: 0.7199\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6302 - val_loss: 0.7205\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6300 - val_loss: 0.7189\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6296 - val_loss: 0.7177\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6293 - val_loss: 0.7151\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6287 - val_loss: 0.7180\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6284 - val_loss: 0.7194\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6282 - val_loss: 0.7164\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6278 - val_loss: 0.7199\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6276 - val_loss: 0.7170\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6274 - val_loss: 0.7193\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6276 - val_loss: 0.7115\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6265 - val_loss: 0.7205\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6267 - val_loss: 0.7182\n",
      "Epoch 162/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6270 - val_loss: 0.7131\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6255 - val_loss: 0.7201\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6260 - val_loss: 0.7189\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6252 - val_loss: 0.7164\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6248 - val_loss: 0.7130\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6251 - val_loss: 0.7108\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6243 - val_loss: 0.7178\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6241 - val_loss: 0.7140\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6240 - val_loss: 0.7149\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6236 - val_loss: 0.7146\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6235 - val_loss: 0.7143\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6233 - val_loss: 0.7140\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6230 - val_loss: 0.7102\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6223 - val_loss: 0.7121\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6224 - val_loss: 0.7120\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6219 - val_loss: 0.7146\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6223 - val_loss: 0.7126\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6215 - val_loss: 0.7134\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6218 - val_loss: 0.7096\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6210 - val_loss: 0.7136\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6207 - val_loss: 0.7157\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6209 - val_loss: 0.7126\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6200 - val_loss: 0.7105\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6198 - val_loss: 0.7102\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6197 - val_loss: 0.7043\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6194 - val_loss: 0.7092\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6185 - val_loss: 0.7098\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6197 - val_loss: 0.7123\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6179 - val_loss: 0.7023\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6176 - val_loss: 0.7046\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6174 - val_loss: 0.7136\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6170 - val_loss: 0.7056\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6165 - val_loss: 0.7064\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6161 - val_loss: 0.7052\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6160 - val_loss: 0.7094\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6164 - val_loss: 0.7017\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6156 - val_loss: 0.7072\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6149 - val_loss: 0.7045\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6145 - val_loss: 0.7100\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6151 - val_loss: 0.7054\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6140 - val_loss: 0.7044\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6142 - val_loss: 0.7094\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6141 - val_loss: 0.7044\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6141 - val_loss: 0.7029\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6136 - val_loss: 0.7076\n",
      "Epoch 207/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6129 - val_loss: 0.7031\n",
      "Epoch 208/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6130 - val_loss: 0.7006\n",
      "Epoch 209/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6128 - val_loss: 0.7053\n",
      "Epoch 210/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6126 - val_loss: 0.7023\n",
      "Epoch 211/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6121 - val_loss: 0.7023\n",
      "Epoch 212/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6119 - val_loss: 0.7022\n",
      "Epoch 213/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6118 - val_loss: 0.7035\n",
      "Epoch 214/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6113 - val_loss: 0.7045\n",
      "Epoch 215/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6112 - val_loss: 0.7031\n",
      "Epoch 216/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6113 - val_loss: 0.7013\n",
      "Epoch 217/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6111 - val_loss: 0.7041\n",
      "Epoch 218/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6104 - val_loss: 0.7017\n",
      "Epoch 219/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6110 - val_loss: 0.6995\n",
      "Epoch 220/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6100 - val_loss: 0.7075\n",
      "Epoch 221/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6104 - val_loss: 0.7056\n",
      "Epoch 222/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6100 - val_loss: 0.6965\n",
      "Epoch 223/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6108 - val_loss: 0.6978\n",
      "Epoch 224/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6095 - val_loss: 0.7009\n",
      "Epoch 225/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6090 - val_loss: 0.6979\n",
      "Epoch 226/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6089 - val_loss: 0.7033\n",
      "Epoch 227/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6088 - val_loss: 0.7003\n",
      "Epoch 228/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6084 - val_loss: 0.7003\n",
      "Epoch 229/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6085 - val_loss: 0.7002\n",
      "Epoch 230/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6082 - val_loss: 0.6985\n",
      "Epoch 231/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6087 - val_loss: 0.6934\n",
      "Epoch 232/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6077 - val_loss: 0.7022\n",
      "Epoch 233/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6076 - val_loss: 0.6997\n",
      "Epoch 234/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6072 - val_loss: 0.6975\n",
      "Epoch 235/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6069 - val_loss: 0.6993\n",
      "Epoch 236/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6068 - val_loss: 0.6957\n",
      "Epoch 237/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6069 - val_loss: 0.7008\n",
      "Epoch 238/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6062 - val_loss: 0.6988\n",
      "Epoch 239/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6060 - val_loss: 0.6953\n",
      "Epoch 240/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6062 - val_loss: 0.6956\n",
      "Epoch 241/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6062 - val_loss: 0.6943\n",
      "Epoch 242/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6056 - val_loss: 0.7024\n",
      "Epoch 243/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6056 - val_loss: 0.7027\n",
      "Epoch 244/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6054 - val_loss: 0.6938\n",
      "Epoch 245/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6055 - val_loss: 0.6958\n",
      "Epoch 246/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6047 - val_loss: 0.7023\n",
      "Epoch 247/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6047 - val_loss: 0.6956\n",
      "Epoch 248/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6046 - val_loss: 0.6977\n",
      "Epoch 249/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6042 - val_loss: 0.6964\n",
      "Epoch 250/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6049 - val_loss: 0.6998\n",
      "Epoch 251/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6038 - val_loss: 0.6926\n",
      "Epoch 252/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6034 - val_loss: 0.7018\n",
      "Epoch 253/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6039 - val_loss: 0.7001\n",
      "Epoch 254/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6040 - val_loss: 0.6954\n",
      "Epoch 255/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6030 - val_loss: 0.7000\n",
      "Epoch 256/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6029 - val_loss: 0.6967\n",
      "Epoch 257/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6028 - val_loss: 0.6943\n",
      "Epoch 258/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6029 - val_loss: 0.6995\n",
      "Epoch 259/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6025 - val_loss: 0.6971\n",
      "Epoch 260/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6022 - val_loss: 0.7011\n",
      "Epoch 261/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6031 - val_loss: 0.6940\n",
      "Epoch 262/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6017 - val_loss: 0.7017\n",
      "Epoch 263/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6015 - val_loss: 0.6978\n",
      "Epoch 264/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6014 - val_loss: 0.6999\n",
      "Epoch 265/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6016 - val_loss: 0.6973\n",
      "Epoch 266/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6018 - val_loss: 0.7049\n",
      "Epoch 267/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6011 - val_loss: 0.6994\n",
      "Epoch 268/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6017 - val_loss: 0.6915\n",
      "Epoch 269/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6011 - val_loss: 0.7036\n",
      "Epoch 270/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6007 - val_loss: 0.7035\n",
      "Epoch 271/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6001 - val_loss: 0.6959\n",
      "Epoch 272/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6003 - val_loss: 0.7027\n",
      "Epoch 273/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6007 - val_loss: 0.7030\n",
      "Epoch 274/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5993 - val_loss: 0.6970\n",
      "Epoch 275/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5998 - val_loss: 0.6961\n",
      "Epoch 276/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5998 - val_loss: 0.6993\n",
      "Epoch 277/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5991 - val_loss: 0.7002\n",
      "Epoch 278/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5998 - val_loss: 0.6945\n",
      "Epoch 279/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5996 - val_loss: 0.6969\n",
      "Epoch 280/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5989 - val_loss: 0.7054\n",
      "Epoch 281/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5997 - val_loss: 0.6969\n",
      "Epoch 282/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5988 - val_loss: 0.7026\n",
      "Epoch 283/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5988 - val_loss: 0.6968\n",
      "Epoch 284/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5980 - val_loss: 0.7001\n",
      "Epoch 285/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5984 - val_loss: 0.6994\n",
      "Epoch 286/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5978 - val_loss: 0.7003\n",
      "Epoch 287/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5978 - val_loss: 0.7000\n",
      "Epoch 288/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5974 - val_loss: 0.6991\n",
      "Epoch 289/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5977 - val_loss: 0.6955\n",
      "Epoch 290/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5970 - val_loss: 0.7018\n",
      "Epoch 291/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5976 - val_loss: 0.6988\n",
      "Epoch 292/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5968 - val_loss: 0.7022\n",
      "Epoch 293/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5971 - val_loss: 0.7057\n",
      "Epoch 294/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5964 - val_loss: 0.7007\n",
      "Epoch 295/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5970 - val_loss: 0.6971\n",
      "Epoch 296/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5967 - val_loss: 0.7030\n",
      "Epoch 297/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5964 - val_loss: 0.6919\n",
      "Epoch 298/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5966 - val_loss: 0.6986\n",
      "Epoch 299/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5958 - val_loss: 0.6991\n",
      "Epoch 300/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5953 - val_loss: 0.7029\n",
      "Epoch 301/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5957 - val_loss: 0.7025\n",
      "Epoch 302/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5957 - val_loss: 0.6991\n",
      "Epoch 303/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5958 - val_loss: 0.7063\n",
      "Epoch 304/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5953 - val_loss: 0.6982\n",
      "Epoch 305/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5952 - val_loss: 0.6997\n",
      "Epoch 306/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5945 - val_loss: 0.7065\n",
      "Epoch 307/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5946 - val_loss: 0.7033\n",
      "Epoch 308/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5943 - val_loss: 0.6989\n",
      "Epoch 309/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5942 - val_loss: 0.7017\n",
      "Epoch 310/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5949 - val_loss: 0.7029\n",
      "Epoch 311/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5935 - val_loss: 0.7065\n",
      "Epoch 312/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5933 - val_loss: 0.7016\n",
      "Epoch 313/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5933 - val_loss: 0.7040\n",
      "Epoch 314/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5932 - val_loss: 0.7001\n",
      "Epoch 315/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5929 - val_loss: 0.7015\n",
      "Epoch 316/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5928 - val_loss: 0.7035\n",
      "Epoch 317/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5927 - val_loss: 0.7088\n",
      "Epoch 318/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5931 - val_loss: 0.7025\n",
      "Epoch 319/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5930 - val_loss: 0.7047\n",
      "Epoch 320/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5921 - val_loss: 0.7033\n",
      "Epoch 321/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5921 - val_loss: 0.7069\n",
      "Epoch 322/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5921 - val_loss: 0.7078\n",
      "Epoch 323/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5933 - val_loss: 0.7022\n",
      "Epoch 324/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5916 - val_loss: 0.7069\n",
      "Epoch 325/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5919 - val_loss: 0.7039\n",
      "Epoch 326/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5926 - val_loss: 0.7099\n",
      "Epoch 327/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5918 - val_loss: 0.7014\n",
      "Epoch 328/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5920 - val_loss: 0.7121\n",
      "Epoch 329/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5914 - val_loss: 0.7053\n",
      "Epoch 330/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5911 - val_loss: 0.7065\n",
      "Epoch 331/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5914 - val_loss: 0.7065\n",
      "Epoch 332/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5911 - val_loss: 0.7053\n",
      "Epoch 333/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5929 - val_loss: 0.7191\n",
      "Epoch 334/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5905 - val_loss: 0.7034\n",
      "Epoch 335/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5907 - val_loss: 0.7063\n",
      "Epoch 336/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5904 - val_loss: 0.7066\n",
      "Epoch 337/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5900 - val_loss: 0.7056\n",
      "Epoch 338/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5898 - val_loss: 0.7049\n",
      "Epoch 339/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5900 - val_loss: 0.7088\n",
      "Epoch 340/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5907 - val_loss: 0.7066\n",
      "Epoch 341/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5905 - val_loss: 0.7141\n",
      "Epoch 342/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5894 - val_loss: 0.7045\n",
      "Epoch 343/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5893 - val_loss: 0.7067\n",
      "Epoch 344/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5892 - val_loss: 0.7096\n",
      "Epoch 345/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5894 - val_loss: 0.7123\n",
      "Epoch 346/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5888 - val_loss: 0.7079\n",
      "Epoch 347/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5888 - val_loss: 0.7106\n",
      "Epoch 348/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5885 - val_loss: 0.7133\n",
      "Epoch 349/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5892 - val_loss: 0.7080\n",
      "Epoch 350/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5885 - val_loss: 0.7106\n",
      "Epoch 351/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5886 - val_loss: 0.7080\n",
      "Epoch 352/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5881 - val_loss: 0.7095\n",
      "Epoch 353/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5892 - val_loss: 0.7108\n",
      "Epoch 354/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5883 - val_loss: 0.7129\n",
      "Epoch 355/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5883 - val_loss: 0.7107\n",
      "Epoch 356/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5879 - val_loss: 0.7090\n",
      "Epoch 357/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5879 - val_loss: 0.7065\n",
      "Epoch 358/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5878 - val_loss: 0.7126\n",
      "Epoch 359/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5880 - val_loss: 0.7138\n",
      "Epoch 360/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5878 - val_loss: 0.7034\n",
      "Epoch 361/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5872 - val_loss: 0.7135\n",
      "Epoch 362/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5874 - val_loss: 0.7090\n",
      "Epoch 363/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5876 - val_loss: 0.7155\n",
      "Epoch 364/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5875 - val_loss: 0.7046\n",
      "Epoch 365/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5868 - val_loss: 0.7060\n",
      "Epoch 366/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5865 - val_loss: 0.7105\n",
      "Epoch 367/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5874 - val_loss: 0.7045\n",
      "Epoch 368/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5862 - val_loss: 0.7107\n",
      "Epoch 369/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5880 - val_loss: 0.7151\n",
      "Epoch 370/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5868 - val_loss: 0.7133\n",
      "Epoch 371/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5861 - val_loss: 0.7102\n",
      "Epoch 372/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5862 - val_loss: 0.7114\n",
      "Epoch 373/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5858 - val_loss: 0.7066\n",
      "Epoch 374/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5857 - val_loss: 0.7109\n",
      "Epoch 375/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5854 - val_loss: 0.7110\n",
      "Epoch 376/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5855 - val_loss: 0.7094\n",
      "Epoch 377/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5853 - val_loss: 0.7112\n",
      "Epoch 378/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5862 - val_loss: 0.7090\n",
      "Epoch 379/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5850 - val_loss: 0.7071\n",
      "Epoch 380/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5855 - val_loss: 0.7160\n",
      "Epoch 381/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5848 - val_loss: 0.7119\n",
      "Epoch 382/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5848 - val_loss: 0.7103\n",
      "Epoch 383/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5848 - val_loss: 0.7105\n",
      "Epoch 384/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5846 - val_loss: 0.7121\n",
      "Epoch 385/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5846 - val_loss: 0.7089\n",
      "Epoch 386/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5844 - val_loss: 0.7121\n",
      "Epoch 387/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5845 - val_loss: 0.7081\n",
      "Epoch 388/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5847 - val_loss: 0.7156\n",
      "Epoch 389/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5839 - val_loss: 0.7065\n",
      "Epoch 390/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5841 - val_loss: 0.7115\n",
      "Epoch 391/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5836 - val_loss: 0.7162\n",
      "Epoch 392/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5837 - val_loss: 0.7110\n",
      "Epoch 393/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5837 - val_loss: 0.7065\n",
      "Epoch 394/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5838 - val_loss: 0.7113\n",
      "Epoch 395/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5833 - val_loss: 0.7167\n",
      "Epoch 396/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5843 - val_loss: 0.7201\n",
      "Epoch 397/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5837 - val_loss: 0.7149\n",
      "Epoch 398/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5840 - val_loss: 0.7144\n",
      "Epoch 399/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5832 - val_loss: 0.7155\n",
      "Epoch 400/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5829 - val_loss: 0.7146\n",
      "Epoch 401/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5832 - val_loss: 0.7173\n",
      "Epoch 402/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5833 - val_loss: 0.7165\n",
      "Epoch 403/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5830 - val_loss: 0.7075\n",
      "Epoch 404/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5832 - val_loss: 0.7188\n",
      "Epoch 405/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5827 - val_loss: 0.7134\n",
      "Epoch 406/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5826 - val_loss: 0.7171\n",
      "Epoch 407/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5823 - val_loss: 0.7115\n",
      "Epoch 408/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5825 - val_loss: 0.7157\n",
      "Epoch 409/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5825 - val_loss: 0.7135\n",
      "Epoch 410/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5837 - val_loss: 0.7194\n",
      "Epoch 411/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5819 - val_loss: 0.7129\n",
      "Epoch 412/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5822 - val_loss: 0.7088\n",
      "Epoch 413/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5819 - val_loss: 0.7186\n",
      "Epoch 414/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5820 - val_loss: 0.7163\n",
      "Epoch 415/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5815 - val_loss: 0.7136\n",
      "Epoch 416/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5821 - val_loss: 0.7191\n",
      "Epoch 417/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5815 - val_loss: 0.7190\n",
      "Epoch 418/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5820 - val_loss: 0.7182\n",
      "Epoch 419/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5822 - val_loss: 0.7189\n",
      "Epoch 420/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5817 - val_loss: 0.7192\n",
      "Epoch 421/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5815 - val_loss: 0.7174\n",
      "Epoch 422/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5815 - val_loss: 0.7221\n",
      "Epoch 423/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5813 - val_loss: 0.7159\n",
      "Epoch 424/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5808 - val_loss: 0.7189\n",
      "Epoch 425/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5806 - val_loss: 0.7211\n",
      "Epoch 426/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5809 - val_loss: 0.7176\n",
      "Epoch 427/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5815 - val_loss: 0.7277\n",
      "Epoch 428/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5807 - val_loss: 0.7164\n",
      "Epoch 429/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5802 - val_loss: 0.7173\n",
      "Epoch 430/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5803 - val_loss: 0.7202\n",
      "Epoch 431/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5806 - val_loss: 0.7176\n",
      "Epoch 432/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5803 - val_loss: 0.7241\n",
      "Epoch 433/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5810 - val_loss: 0.7178\n",
      "Epoch 434/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5819 - val_loss: 0.7151\n",
      "Epoch 435/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5804 - val_loss: 0.7230\n",
      "Epoch 436/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5802 - val_loss: 0.7241\n",
      "Epoch 437/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5804 - val_loss: 0.7166\n",
      "Epoch 438/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5798 - val_loss: 0.7272\n",
      "Epoch 439/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5796 - val_loss: 0.7275\n",
      "Epoch 440/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5801 - val_loss: 0.7221\n",
      "Epoch 441/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5799 - val_loss: 0.7272\n",
      "Epoch 442/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5802 - val_loss: 0.7186\n",
      "Epoch 443/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5796 - val_loss: 0.7206\n",
      "Epoch 444/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5791 - val_loss: 0.7273\n",
      "Epoch 445/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5795 - val_loss: 0.7262\n",
      "Epoch 446/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5793 - val_loss: 0.7240\n",
      "Epoch 447/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5790 - val_loss: 0.7287\n",
      "Epoch 448/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5789 - val_loss: 0.7310\n",
      "Epoch 449/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5790 - val_loss: 0.7268\n",
      "Epoch 450/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5791 - val_loss: 0.7254\n",
      "Epoch 451/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5791 - val_loss: 0.7312\n",
      "Epoch 452/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5780 - val_loss: 0.7241\n",
      "Epoch 453/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5788 - val_loss: 0.7202\n",
      "Epoch 454/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5781 - val_loss: 0.7280\n",
      "Epoch 455/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5787 - val_loss: 0.7244\n",
      "Epoch 456/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5785 - val_loss: 0.7234\n",
      "Epoch 457/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5777 - val_loss: 0.7319\n",
      "Epoch 458/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5780 - val_loss: 0.7299\n",
      "Epoch 459/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5784 - val_loss: 0.7295\n",
      "Epoch 460/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5779 - val_loss: 0.7317\n",
      "Epoch 461/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5771 - val_loss: 0.7270\n",
      "Epoch 462/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5781 - val_loss: 0.7286\n",
      "Epoch 463/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5777 - val_loss: 0.7213\n",
      "Epoch 464/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5771 - val_loss: 0.7267\n",
      "Epoch 465/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5778 - val_loss: 0.7297\n",
      "Epoch 466/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5770 - val_loss: 0.7273\n",
      "Epoch 467/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5764 - val_loss: 0.7309\n",
      "Epoch 468/1000\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.4749Restoring model weights from the end of the best epoch: 268.\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5769 - val_loss: 0.7333\n",
      "Epoch 468: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 10:49:24.924581: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.07439536372502698"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_emiliani2_wrapperBest5 = Sequential()\n",
    "model_emiliani2_wrapperBest5.add(Dense(4, input_dim=12, activation='relu')) \n",
    "model_emiliani2_wrapperBest5.add(Dense(1)) # Output\n",
    "\n",
    "model_emiliani2_wrapperBest5.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=200, \n",
    "        verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "model_emiliani2_wrapperBest5.summary()\n",
    "\n",
    "model_emiliani2_wrapperBest5.fit(CMI_train_E2,target_df_train_E2.mean_std,validation_data=(CMI_val_E2,target_df_val_E2.mean_std),epochs=1000,callbacks=[monitor])\n",
    "\n",
    "r2_score(target_df_test_E2.mean_std, model_emiliani2_wrapperBest5.predict(CMI_test_E2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de44ecd",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5b190de5",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 5)                 55        \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 2)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67\n",
      "Trainable params: 67\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_emiliani12_wrapperBest5 = Sequential()\n",
    "model_emiliani12_wrapperBest5.add(Dense(5, input_dim=10, activation='relu')) \n",
    "model_emiliani12_wrapperBest5.add(Dense(2)) # Output\n",
    "\n",
    "model_emiliani12_wrapperBest5.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=20, \n",
    "        verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "model_emiliani12_wrapperBest5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "655803a7",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 10:11:38.444757: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 16ms/step - loss: 0.9697 - val_loss: 0.9344\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9364 - val_loss: 0.9047\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9078 - val_loss: 0.8797\n",
      "Epoch 4/1000\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.9573"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 10:11:38.956587: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8837 - val_loss: 0.8583\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8633 - val_loss: 0.8416\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8472 - val_loss: 0.8291\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8340 - val_loss: 0.8178\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8220 - val_loss: 0.8081\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8106 - val_loss: 0.7999\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8018 - val_loss: 0.7909\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7937 - val_loss: 0.7835\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7867 - val_loss: 0.7765\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7800 - val_loss: 0.7713\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7738 - val_loss: 0.7668\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7677 - val_loss: 0.7639\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7630 - val_loss: 0.7610\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7584 - val_loss: 0.7583\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7552 - val_loss: 0.7564\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7520 - val_loss: 0.7551\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7493 - val_loss: 0.7533\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7468 - val_loss: 0.7518\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7448 - val_loss: 0.7495\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7425 - val_loss: 0.7481\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7405 - val_loss: 0.7470\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7383 - val_loss: 0.7449\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7362 - val_loss: 0.7441\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7342 - val_loss: 0.7425\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7325 - val_loss: 0.7426\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7308 - val_loss: 0.7409\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7293 - val_loss: 0.7397\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7276 - val_loss: 0.7376\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7262 - val_loss: 0.7355\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7248 - val_loss: 0.7346\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7234 - val_loss: 0.7344\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7220 - val_loss: 0.7335\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7207 - val_loss: 0.7331\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7194 - val_loss: 0.7318\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7180 - val_loss: 0.7299\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7167 - val_loss: 0.7292\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7157 - val_loss: 0.7285\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7140 - val_loss: 0.7272\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7129 - val_loss: 0.7253\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7116 - val_loss: 0.7231\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7102 - val_loss: 0.7213\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7088 - val_loss: 0.7206\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7073 - val_loss: 0.7187\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7061 - val_loss: 0.7165\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7049 - val_loss: 0.7138\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7035 - val_loss: 0.7139\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7019 - val_loss: 0.7114\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7005 - val_loss: 0.7103\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6992 - val_loss: 0.7078\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6977 - val_loss: 0.7079\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6963 - val_loss: 0.7060\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6950 - val_loss: 0.7051\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6936 - val_loss: 0.7042\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6924 - val_loss: 0.7022\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6912 - val_loss: 0.7018\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6901 - val_loss: 0.7027\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6888 - val_loss: 0.7030\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6877 - val_loss: 0.7032\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6864 - val_loss: 0.7015\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6856 - val_loss: 0.7008\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6844 - val_loss: 0.7001\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6838 - val_loss: 0.7021\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6823 - val_loss: 0.7006\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6812 - val_loss: 0.7003\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6803 - val_loss: 0.6992\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6792 - val_loss: 0.7004\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6784 - val_loss: 0.7000\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6778 - val_loss: 0.7013\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6765 - val_loss: 0.6997\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6756 - val_loss: 0.6984\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6748 - val_loss: 0.7007\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6734 - val_loss: 0.6997\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6724 - val_loss: 0.7000\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6714 - val_loss: 0.6995\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6709 - val_loss: 0.7004\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6696 - val_loss: 0.7002\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6692 - val_loss: 0.7004\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6679 - val_loss: 0.6996\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6670 - val_loss: 0.7003\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6660 - val_loss: 0.6992\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6651 - val_loss: 0.6987\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6644 - val_loss: 0.6996\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6634 - val_loss: 0.6974\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6627 - val_loss: 0.6991\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6618 - val_loss: 0.6996\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6605 - val_loss: 0.6986\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6599 - val_loss: 0.6979\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6586 - val_loss: 0.6982\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6579 - val_loss: 0.6979\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6569 - val_loss: 0.6976\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6562 - val_loss: 0.6953\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6554 - val_loss: 0.6983\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6548 - val_loss: 0.7002\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6535 - val_loss: 0.6978\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6529 - val_loss: 0.6990\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6522 - val_loss: 0.6963\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6511 - val_loss: 0.6967\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6502 - val_loss: 0.6997\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6495 - val_loss: 0.6984\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6483 - val_loss: 0.6968\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6479 - val_loss: 0.6967\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6467 - val_loss: 0.6980\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6458 - val_loss: 0.6988\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6454 - val_loss: 0.6992\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6446 - val_loss: 0.6964\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6439 - val_loss: 0.6993\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6427 - val_loss: 0.6973\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6426 - val_loss: 0.6940\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6415 - val_loss: 0.6965\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6408 - val_loss: 0.6971\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6402 - val_loss: 0.6972\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6395 - val_loss: 0.6972\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6390 - val_loss: 0.6947\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6390 - val_loss: 0.6980\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6378 - val_loss: 0.6991\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6373 - val_loss: 0.6987\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6370 - val_loss: 0.6954\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6359 - val_loss: 0.6990\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6352 - val_loss: 0.6992\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6345 - val_loss: 0.6989\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6337 - val_loss: 0.6991\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6331 - val_loss: 0.6995\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6328 - val_loss: 0.7005\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6320 - val_loss: 0.6972\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6313 - val_loss: 0.6968\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6307 - val_loss: 0.6984\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6306 - val_loss: 0.6979\n",
      "Epoch 131/1000\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6912Restoring model weights from the end of the best epoch: 111.\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6300 - val_loss: 0.6976\n",
      "Epoch 131: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28bd1c670>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best5_wrapper_train_E12 = pd.concat((best5_wrapper_train_E1,best5_wrapper_train_E2),axis=1)\n",
    "best5_wrapper_val_E12 = pd.concat((best5_wrapper_val_E1,best5_wrapper_val_E2),axis=1)\n",
    "best5_wrapper_test_E12 = pd.concat((best5_wrapper_test_E1,best5_wrapper_test_E2),axis=1)\n",
    "\n",
    "target_train_E12 = pd.concat((target_df_train_E1.mean_std,target_df_train_E2.mean_std),axis=1)\n",
    "target_val_E12 = pd.concat((target_df_val_E1.mean_std,target_df_val_E2.mean_std),axis=1)\n",
    "target_test_E12 = pd.concat((target_df_test_E1.mean_std,target_df_test_E2.mean_std),axis=1)\n",
    "\n",
    "model_emiliani12_wrapperBest5.fit(best5_wrapper_train_E12,target_train_E12,validation_data=(best5_wrapper_val_E12,target_val_E12),\n",
    "        callbacks=[monitor],epochs=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "af954713",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 3ms/step\n",
      "0.13858849170586363\n",
      "0.04033818912352716\n"
     ]
    }
   ],
   "source": [
    "res = model_emiliani12_wrapperBest5.predict(best5_wrapper_test_E12)\n",
    "\n",
    "print(r2_score(target_df_test_E1.mean_std, res[:,0]))\n",
    "print(r2_score(target_df_test_E2.mean_std, res[:,1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8361be",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## feedforward NN with CMI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7530fef0",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Emiliani1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "49e3d9cb",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41\n",
      "Trainable params: 41\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_emiliani1_CMI = Sequential()\n",
    "model_emiliani1_CMI.add(Dense(5, input_dim=6, activation='relu')) \n",
    "model_emiliani1_CMI.add(Dense(1)) # Output\n",
    "\n",
    "model_emiliani1_CMI.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=20, \n",
    "        verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "model_emiliani1_CMI.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4cf4073e",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.8032 - val_loss: 1.0234\n",
      "Epoch 2/1000\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6544"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 10:17:47.411090: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-01 10:17:47.561985: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7866 - val_loss: 0.9913\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.7745 - val_loss: 0.9581\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7629 - val_loss: 0.9315\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7540 - val_loss: 0.9070\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.8842\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7400 - val_loss: 0.8635\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7349 - val_loss: 0.8444\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7296 - val_loss: 0.8327\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7260 - val_loss: 0.8198\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7223 - val_loss: 0.8099\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.7197 - val_loss: 0.7983\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7164 - val_loss: 0.7923\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7139 - val_loss: 0.7836\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7116 - val_loss: 0.7741\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7090 - val_loss: 0.7678\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7067 - val_loss: 0.7625\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7050 - val_loss: 0.7540\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7029 - val_loss: 0.7490\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7008 - val_loss: 0.7470\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6989 - val_loss: 0.7442\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6977 - val_loss: 0.7429\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6959 - val_loss: 0.7413\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6941 - val_loss: 0.7392\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6928 - val_loss: 0.7360\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6914 - val_loss: 0.7347\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6900 - val_loss: 0.7334\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6889 - val_loss: 0.7298\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6882 - val_loss: 0.7304\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6869 - val_loss: 0.7267\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6860 - val_loss: 0.7237\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6853 - val_loss: 0.7218\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6841 - val_loss: 0.7203\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6834 - val_loss: 0.7203\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6829 - val_loss: 0.7161\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6816 - val_loss: 0.7156\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6808 - val_loss: 0.7168\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6798 - val_loss: 0.7133\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6791 - val_loss: 0.7135\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6782 - val_loss: 0.7125\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6775 - val_loss: 0.7115\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6769 - val_loss: 0.7091\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6759 - val_loss: 0.7094\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6751 - val_loss: 0.7083\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6745 - val_loss: 0.7074\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6737 - val_loss: 0.7075\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6732 - val_loss: 0.7069\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6724 - val_loss: 0.7075\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6716 - val_loss: 0.7033\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6711 - val_loss: 0.7016\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6703 - val_loss: 0.6985\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6697 - val_loss: 0.6972\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6692 - val_loss: 0.6960\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6686 - val_loss: 0.6962\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6680 - val_loss: 0.6984\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6678 - val_loss: 0.6948\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6672 - val_loss: 0.6970\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6665 - val_loss: 0.6967\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6661 - val_loss: 0.6952\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6657 - val_loss: 0.6935\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6654 - val_loss: 0.6915\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6646 - val_loss: 0.6925\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6641 - val_loss: 0.6943\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6641 - val_loss: 0.6916\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6630 - val_loss: 0.6923\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6627 - val_loss: 0.6915\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6621 - val_loss: 0.6878\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6615 - val_loss: 0.6873\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6612 - val_loss: 0.6871\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6608 - val_loss: 0.6856\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6601 - val_loss: 0.6863\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6601 - val_loss: 0.6901\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6590 - val_loss: 0.6867\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6587 - val_loss: 0.6853\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6581 - val_loss: 0.6839\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6578 - val_loss: 0.6833\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6574 - val_loss: 0.6828\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6570 - val_loss: 0.6811\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6566 - val_loss: 0.6817\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6564 - val_loss: 0.6806\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6563 - val_loss: 0.6821\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6556 - val_loss: 0.6816\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6556 - val_loss: 0.6777\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6549 - val_loss: 0.6797\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6549 - val_loss: 0.6824\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6545 - val_loss: 0.6818\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6539 - val_loss: 0.6802\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6538 - val_loss: 0.6787\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6532 - val_loss: 0.6807\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6531 - val_loss: 0.6822\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6527 - val_loss: 0.6816\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6523 - val_loss: 0.6795\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6521 - val_loss: 0.6804\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6517 - val_loss: 0.6804\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6516 - val_loss: 0.6818\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6515 - val_loss: 0.6797\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6512 - val_loss: 0.6818\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6511 - val_loss: 0.6799\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6507 - val_loss: 0.6815\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6505 - val_loss: 0.6794\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6500 - val_loss: 0.6823\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6499 - val_loss: 0.6818\n",
      "Epoch 103/1000\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6871Restoring model weights from the end of the best epoch: 83.\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6495 - val_loss: 0.6833\n",
      "Epoch 103: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x291223ca0>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_emiliani1_CMI.fit(CMI_train_E1,target_df_train_E1.mean_std,validation_data=(CMI_val_E1,target_df_val_E1.mean_std),\n",
    "        callbacks=[monitor],epochs=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6d55356f",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 10:18:11.989475: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.18709398689292256"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(target_df_test_E1.mean_std, model_emiliani1_CMI.predict(CMI_test_E1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa917e7",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Emiliani2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1488f207",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_30 (Dense)            (None, 5)                 65        \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 71\n",
      "Trainable params: 71\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_emiliani2_CMI = Sequential()\n",
    "model_emiliani2_CMI.add(Dense(5, input_dim=12, activation='relu')) \n",
    "model_emiliani2_CMI.add(Dense(1)) # Output\n",
    "\n",
    "model_emiliani2_CMI.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=20, \n",
    "        verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "model_emiliani2_CMI.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7d8e835d",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.9858 - val_loss: 0.8875\n",
      "Epoch 2/1000\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.7841"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 10:39:19.776018: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-01 10:39:19.918607: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9429 - val_loss: 0.8642\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9069 - val_loss: 0.8439\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8753 - val_loss: 0.8280\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8542 - val_loss: 0.8152\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8374 - val_loss: 0.8067\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8247 - val_loss: 0.7950\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8143 - val_loss: 0.7855\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8066 - val_loss: 0.7770\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7999 - val_loss: 0.7673\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7927 - val_loss: 0.7623\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7858 - val_loss: 0.7573\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7800 - val_loss: 0.7512\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7737 - val_loss: 0.7481\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7674 - val_loss: 0.7447\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7621 - val_loss: 0.7421\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7565 - val_loss: 0.7365\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7518 - val_loss: 0.7339\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7471 - val_loss: 0.7299\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7422 - val_loss: 0.7271\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7377 - val_loss: 0.7246\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7336 - val_loss: 0.7185\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7292 - val_loss: 0.7181\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7248 - val_loss: 0.7149\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7208 - val_loss: 0.7129\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7164 - val_loss: 0.7139\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7128 - val_loss: 0.7126\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7086 - val_loss: 0.7136\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7047 - val_loss: 0.7143\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7009 - val_loss: 0.7125\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6984 - val_loss: 0.7138\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6942 - val_loss: 0.7124\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6909 - val_loss: 0.7118\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6877 - val_loss: 0.7090\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6847 - val_loss: 0.7082\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6813 - val_loss: 0.7083\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6782 - val_loss: 0.7124\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6750 - val_loss: 0.7121\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6723 - val_loss: 0.7099\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6700 - val_loss: 0.7100\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6669 - val_loss: 0.7101\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6646 - val_loss: 0.7091\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6625 - val_loss: 0.7100\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6605 - val_loss: 0.7075\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6601 - val_loss: 0.7091\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6583 - val_loss: 0.7131\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6563 - val_loss: 0.7127\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6557 - val_loss: 0.7131\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6540 - val_loss: 0.7125\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6524 - val_loss: 0.7142\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6511 - val_loss: 0.7137\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6500 - val_loss: 0.7142\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6486 - val_loss: 0.7156\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6474 - val_loss: 0.7163\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6462 - val_loss: 0.7184\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6455 - val_loss: 0.7163\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6446 - val_loss: 0.7174\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6433 - val_loss: 0.7210\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6426 - val_loss: 0.7212\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6419 - val_loss: 0.7202\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6404 - val_loss: 0.7205\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6402 - val_loss: 0.7255\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6384 - val_loss: 0.7259\n",
      "Epoch 64/1000\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.5996Restoring model weights from the end of the best epoch: 44.\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6372 - val_loss: 0.7268\n",
      "Epoch 64: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x297349d90>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_emiliani2_CMI.fit(CMI_train_E2,target_df_train_E2.mean_std,validation_data=(CMI_val_E2,target_df_val_E2.mean_std),\n",
    "        callbacks=[monitor],epochs=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e412d8e8",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 10:39:24.127706: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2523916814140521"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(target_df_test_E2.mean_std, model_emiliani2_CMI.predict(CMI_test_E2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c4b6cc",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1e4c7f25",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_14 (Dense)            (None, 5)                 95        \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 2)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 107\n",
      "Trainable params: 107\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_emiliani12_CMI = Sequential()\n",
    "model_emiliani12_CMI.add(Dense(5, input_dim=18, activation='relu')) \n",
    "model_emiliani12_CMI.add(Dense(2)) # Output\n",
    "\n",
    "model_emiliani12_CMI.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=20, \n",
    "        verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "model_emiliani12_CMI.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "67cfd91a",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.9050"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 10:21:57.149898: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-01 10:21:57.319303: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 13ms/step - loss: 0.9050 - val_loss: 1.1153\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8695 - val_loss: 1.0542\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8426 - val_loss: 1.0049\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8225 - val_loss: 0.9554\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8055 - val_loss: 0.9124\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7917 - val_loss: 0.8862\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7804 - val_loss: 0.8606\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7698 - val_loss: 0.8344\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7594 - val_loss: 0.8116\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7522 - val_loss: 0.7901\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7429 - val_loss: 0.7736\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7363 - val_loss: 0.7622\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7307 - val_loss: 0.7494\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7244 - val_loss: 0.7445\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7194 - val_loss: 0.7378\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7153 - val_loss: 0.7326\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7108 - val_loss: 0.7293\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7066 - val_loss: 0.7278\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7028 - val_loss: 0.7253\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6991 - val_loss: 0.7221\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6958 - val_loss: 0.7266\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6925 - val_loss: 0.7217\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6889 - val_loss: 0.7213\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6863 - val_loss: 0.7206\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6832 - val_loss: 0.7218\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6801 - val_loss: 0.7217\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6771 - val_loss: 0.7132\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6745 - val_loss: 0.7130\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6723 - val_loss: 0.7185\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6698 - val_loss: 0.7138\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6669 - val_loss: 0.7179\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6645 - val_loss: 0.7166\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6622 - val_loss: 0.7196\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6596 - val_loss: 0.7169\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6571 - val_loss: 0.7180\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6551 - val_loss: 0.7095\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6520 - val_loss: 0.7125\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6496 - val_loss: 0.7172\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6471 - val_loss: 0.7124\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6446 - val_loss: 0.7127\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6420 - val_loss: 0.7127\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6403 - val_loss: 0.7097\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6375 - val_loss: 0.7173\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6351 - val_loss: 0.7150\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6337 - val_loss: 0.7165\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6314 - val_loss: 0.7246\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6288 - val_loss: 0.7158\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6265 - val_loss: 0.7157\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6251 - val_loss: 0.7131\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6226 - val_loss: 0.7229\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6211 - val_loss: 0.7244\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6190 - val_loss: 0.7268\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6177 - val_loss: 0.7325\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6152 - val_loss: 0.7307\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6142 - val_loss: 0.7273\n",
      "Epoch 56/1000\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.5984Restoring model weights from the end of the best epoch: 36.\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6123 - val_loss: 0.7316\n",
      "Epoch 56: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2984b2b50>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CMI_train_E12 = pd.concat((CMI_train_E1,CMI_train_E2),axis=1)\n",
    "CMI_val_E12 = pd.concat((CMI_val_E1,CMI_val_E2),axis=1)\n",
    "CMI_test_E12 = pd.concat((CMI_test_E1,CMI_test_E2),axis=1)\n",
    "\n",
    "target_train_E12 = pd.concat((target_df_train_E1.mean_std,target_df_train_E2.mean_std),axis=1)\n",
    "target_val_E12 = pd.concat((target_df_val_E1.mean_std,target_df_val_E2.mean_std),axis=1)\n",
    "target_test_E12 = pd.concat((target_df_test_E1.mean_std,target_df_test_E2.mean_std),axis=1)\n",
    "\n",
    "model_emiliani12_CMI.fit(CMI_train_E12,target_train_E12,validation_data=(CMI_val_E12,target_val_E12),\n",
    "        callbacks=[monitor],epochs=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5b686adc",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step\n",
      "0.06809134446862464\n",
      "0.04497803527098665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 10:22:18.815802: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "res = model_emiliani12_CMI.predict(CMI_test_E12)\n",
    "\n",
    "print(r2_score(target_df_test_E1.mean_std, res[:,0]))\n",
    "print(r2_score(target_df_test_E2.mean_std, res[:,1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4db848",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## feedforward NN with CMI best 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba9eb6b",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Emiliani1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50202dde",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 36\n",
      "Trainable params: 36\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_emiliani1_CMI_best5 = Sequential()\n",
    "model_emiliani1_CMI_best5.add(Dense(5, input_dim=5, activation='relu')) \n",
    "model_emiliani1_CMI_best5.add(Dense(1)) # Output\n",
    "\n",
    "model_emiliani1_CMI_best5.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=100, \n",
    "        verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "model_emiliani1_CMI_best5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76665b70",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.8526 - val_loss: 1.0863\n",
      "Epoch 2/1000\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.8534"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-13 14:16:22.424875: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-13 14:16:22.570913: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8273 - val_loss: 1.0323\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8047 - val_loss: 0.9817\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7867 - val_loss: 0.9379\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7725 - val_loss: 0.9026\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7628 - val_loss: 0.8717\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7549 - val_loss: 0.8470\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7483 - val_loss: 0.8248\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7411 - val_loss: 0.8094\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7367 - val_loss: 0.7892\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7325 - val_loss: 0.7734\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7284 - val_loss: 0.7622\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7252 - val_loss: 0.7556\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7229 - val_loss: 0.7476\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7208 - val_loss: 0.7412\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7188 - val_loss: 0.7368\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7170 - val_loss: 0.7353\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7154 - val_loss: 0.7317\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7141 - val_loss: 0.7278\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7123 - val_loss: 0.7259\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7110 - val_loss: 0.7244\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7097 - val_loss: 0.7232\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7086 - val_loss: 0.7201\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7071 - val_loss: 0.7195\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7060 - val_loss: 0.7209\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7046 - val_loss: 0.7186\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7034 - val_loss: 0.7165\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7024 - val_loss: 0.7196\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7011 - val_loss: 0.7153\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7000 - val_loss: 0.7126\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6989 - val_loss: 0.7126\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6976 - val_loss: 0.7101\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6967 - val_loss: 0.7038\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6956 - val_loss: 0.7032\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6946 - val_loss: 0.7026\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6930 - val_loss: 0.6967\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6918 - val_loss: 0.6928\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6907 - val_loss: 0.6911\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6892 - val_loss: 0.6877\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6881 - val_loss: 0.6875\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6869 - val_loss: 0.6837\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6858 - val_loss: 0.6838\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6843 - val_loss: 0.6781\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6830 - val_loss: 0.6773\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6819 - val_loss: 0.6739\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6807 - val_loss: 0.6747\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6795 - val_loss: 0.6746\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6782 - val_loss: 0.6723\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6768 - val_loss: 0.6721\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6753 - val_loss: 0.6729\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6739 - val_loss: 0.6679\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6721 - val_loss: 0.6693\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6704 - val_loss: 0.6680\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6688 - val_loss: 0.6697\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6672 - val_loss: 0.6680\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6652 - val_loss: 0.6668\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6632 - val_loss: 0.6678\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6616 - val_loss: 0.6678\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6595 - val_loss: 0.6676\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6581 - val_loss: 0.6639\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6562 - val_loss: 0.6653\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6551 - val_loss: 0.6639\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6533 - val_loss: 0.6616\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6512 - val_loss: 0.6576\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6500 - val_loss: 0.6569\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6489 - val_loss: 0.6575\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6479 - val_loss: 0.6628\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6472 - val_loss: 0.6630\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6468 - val_loss: 0.6640\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6462 - val_loss: 0.6636\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6457 - val_loss: 0.6632\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6454 - val_loss: 0.6635\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6448 - val_loss: 0.6646\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6447 - val_loss: 0.6609\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6442 - val_loss: 0.6614\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6436 - val_loss: 0.6629\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6434 - val_loss: 0.6636\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6431 - val_loss: 0.6619\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6425 - val_loss: 0.6632\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6423 - val_loss: 0.6621\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6420 - val_loss: 0.6645\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6415 - val_loss: 0.6631\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6411 - val_loss: 0.6624\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6407 - val_loss: 0.6625\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6403 - val_loss: 0.6630\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6402 - val_loss: 0.6640\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6408 - val_loss: 0.6653\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6393 - val_loss: 0.6634\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6392 - val_loss: 0.6603\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6394 - val_loss: 0.6644\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6385 - val_loss: 0.6629\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6385 - val_loss: 0.6637\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6381 - val_loss: 0.6626\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6382 - val_loss: 0.6607\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6377 - val_loss: 0.6637\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6378 - val_loss: 0.6657\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6377 - val_loss: 0.6658\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6372 - val_loss: 0.6631\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6373 - val_loss: 0.6620\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6369 - val_loss: 0.6609\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6367 - val_loss: 0.6625\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6366 - val_loss: 0.6615\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6364 - val_loss: 0.6642\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6363 - val_loss: 0.6648\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6363 - val_loss: 0.6622\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6362 - val_loss: 0.6609\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6358 - val_loss: 0.6620\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6358 - val_loss: 0.6634\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6357 - val_loss: 0.6648\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6357 - val_loss: 0.6636\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6353 - val_loss: 0.6604\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6356 - val_loss: 0.6583\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6352 - val_loss: 0.6617\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6353 - val_loss: 0.6634\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6352 - val_loss: 0.6608\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6349 - val_loss: 0.6618\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6346 - val_loss: 0.6625\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6347 - val_loss: 0.6629\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6345 - val_loss: 0.6607\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6347 - val_loss: 0.6623\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6344 - val_loss: 0.6605\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6342 - val_loss: 0.6597\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6344 - val_loss: 0.6626\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6342 - val_loss: 0.6612\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6344 - val_loss: 0.6598\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6344 - val_loss: 0.6579\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6337 - val_loss: 0.6604\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6337 - val_loss: 0.6610\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6339 - val_loss: 0.6620\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6339 - val_loss: 0.6564\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6333 - val_loss: 0.6601\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6335 - val_loss: 0.6613\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6335 - val_loss: 0.6583\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6333 - val_loss: 0.6594\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6337 - val_loss: 0.6591\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6332 - val_loss: 0.6598\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6330 - val_loss: 0.6602\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6328 - val_loss: 0.6604\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6328 - val_loss: 0.6584\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6326 - val_loss: 0.6581\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6327 - val_loss: 0.6593\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6325 - val_loss: 0.6586\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6324 - val_loss: 0.6605\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6324 - val_loss: 0.6586\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6321 - val_loss: 0.6610\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6321 - val_loss: 0.6589\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6320 - val_loss: 0.6569\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6320 - val_loss: 0.6599\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6318 - val_loss: 0.6594\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6316 - val_loss: 0.6579\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6317 - val_loss: 0.6580\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6315 - val_loss: 0.6608\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6317 - val_loss: 0.6594\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6312 - val_loss: 0.6569\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6316 - val_loss: 0.6604\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6314 - val_loss: 0.6562\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6310 - val_loss: 0.6570\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6312 - val_loss: 0.6581\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6311 - val_loss: 0.6589\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6309 - val_loss: 0.6559\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6310 - val_loss: 0.6553\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6308 - val_loss: 0.6585\n",
      "Epoch 163/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6310 - val_loss: 0.6598\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6307 - val_loss: 0.6552\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6313 - val_loss: 0.6580\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6303 - val_loss: 0.6557\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6305 - val_loss: 0.6546\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6306 - val_loss: 0.6569\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6302 - val_loss: 0.6596\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6303 - val_loss: 0.6571\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6304 - val_loss: 0.6592\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6301 - val_loss: 0.6571\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6300 - val_loss: 0.6574\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6298 - val_loss: 0.6566\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6300 - val_loss: 0.6560\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6300 - val_loss: 0.6567\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6297 - val_loss: 0.6576\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6297 - val_loss: 0.6572\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6297 - val_loss: 0.6560\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6296 - val_loss: 0.6550\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6295 - val_loss: 0.6545\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6296 - val_loss: 0.6575\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6296 - val_loss: 0.6587\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6298 - val_loss: 0.6575\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6295 - val_loss: 0.6560\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6298 - val_loss: 0.6547\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6298 - val_loss: 0.6574\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6292 - val_loss: 0.6552\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6293 - val_loss: 0.6557\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6291 - val_loss: 0.6579\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6292 - val_loss: 0.6572\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6289 - val_loss: 0.6550\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6289 - val_loss: 0.6539\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6290 - val_loss: 0.6557\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6288 - val_loss: 0.6559\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6285 - val_loss: 0.6576\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6291 - val_loss: 0.6574\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6284 - val_loss: 0.6591\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6286 - val_loss: 0.6553\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6290 - val_loss: 0.6551\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6283 - val_loss: 0.6573\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6280 - val_loss: 0.6564\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6283 - val_loss: 0.6571\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6280 - val_loss: 0.6576\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6279 - val_loss: 0.6575\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6279 - val_loss: 0.6567\n",
      "Epoch 207/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6279 - val_loss: 0.6581\n",
      "Epoch 208/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6284 - val_loss: 0.6552\n",
      "Epoch 209/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6276 - val_loss: 0.6583\n",
      "Epoch 210/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6276 - val_loss: 0.6586\n",
      "Epoch 211/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6274 - val_loss: 0.6562\n",
      "Epoch 212/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6274 - val_loss: 0.6584\n",
      "Epoch 213/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6276 - val_loss: 0.6565\n",
      "Epoch 214/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6270 - val_loss: 0.6554\n",
      "Epoch 215/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6274 - val_loss: 0.6541\n",
      "Epoch 216/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6271 - val_loss: 0.6577\n",
      "Epoch 217/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6270 - val_loss: 0.6596\n",
      "Epoch 218/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6267 - val_loss: 0.6578\n",
      "Epoch 219/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6264 - val_loss: 0.6572\n",
      "Epoch 220/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6263 - val_loss: 0.6575\n",
      "Epoch 221/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6262 - val_loss: 0.6558\n",
      "Epoch 222/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6260 - val_loss: 0.6586\n",
      "Epoch 223/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6259 - val_loss: 0.6589\n",
      "Epoch 224/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6258 - val_loss: 0.6585\n",
      "Epoch 225/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6257 - val_loss: 0.6578\n",
      "Epoch 226/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6255 - val_loss: 0.6572\n",
      "Epoch 227/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6253 - val_loss: 0.6583\n",
      "Epoch 228/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6254 - val_loss: 0.6565\n",
      "Epoch 229/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6252 - val_loss: 0.6555\n",
      "Epoch 230/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6250 - val_loss: 0.6563\n",
      "Epoch 231/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6248 - val_loss: 0.6575\n",
      "Epoch 232/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6245 - val_loss: 0.6589\n",
      "Epoch 233/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6246 - val_loss: 0.6576\n",
      "Epoch 234/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6243 - val_loss: 0.6559\n",
      "Epoch 235/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6245 - val_loss: 0.6565\n",
      "Epoch 236/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6250 - val_loss: 0.6577\n",
      "Epoch 237/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6242 - val_loss: 0.6581\n",
      "Epoch 238/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6243 - val_loss: 0.6582\n",
      "Epoch 239/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6241 - val_loss: 0.6551\n",
      "Epoch 240/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6237 - val_loss: 0.6576\n",
      "Epoch 241/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6236 - val_loss: 0.6560\n",
      "Epoch 242/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6236 - val_loss: 0.6580\n",
      "Epoch 243/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6237 - val_loss: 0.6561\n",
      "Epoch 244/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6231 - val_loss: 0.6574\n",
      "Epoch 245/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6234 - val_loss: 0.6576\n",
      "Epoch 246/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6232 - val_loss: 0.6582\n",
      "Epoch 247/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6229 - val_loss: 0.6564\n",
      "Epoch 248/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6228 - val_loss: 0.6578\n",
      "Epoch 249/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6228 - val_loss: 0.6562\n",
      "Epoch 250/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6226 - val_loss: 0.6570\n",
      "Epoch 251/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6227 - val_loss: 0.6565\n",
      "Epoch 252/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6224 - val_loss: 0.6577\n",
      "Epoch 253/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6224 - val_loss: 0.6584\n",
      "Epoch 254/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6228 - val_loss: 0.6546\n",
      "Epoch 255/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6221 - val_loss: 0.6567\n",
      "Epoch 256/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6222 - val_loss: 0.6594\n",
      "Epoch 257/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6221 - val_loss: 0.6541\n",
      "Epoch 258/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6217 - val_loss: 0.6552\n",
      "Epoch 259/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6220 - val_loss: 0.6563\n",
      "Epoch 260/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6217 - val_loss: 0.6540\n",
      "Epoch 261/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6217 - val_loss: 0.6552\n",
      "Epoch 262/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6213 - val_loss: 0.6555\n",
      "Epoch 263/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6217 - val_loss: 0.6567\n",
      "Epoch 264/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6209 - val_loss: 0.6541\n",
      "Epoch 265/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6211 - val_loss: 0.6525\n",
      "Epoch 266/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6208 - val_loss: 0.6544\n",
      "Epoch 267/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6208 - val_loss: 0.6538\n",
      "Epoch 268/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6210 - val_loss: 0.6540\n",
      "Epoch 269/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6205 - val_loss: 0.6537\n",
      "Epoch 270/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6205 - val_loss: 0.6524\n",
      "Epoch 271/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6202 - val_loss: 0.6537\n",
      "Epoch 272/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6202 - val_loss: 0.6530\n",
      "Epoch 273/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6203 - val_loss: 0.6530\n",
      "Epoch 274/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6199 - val_loss: 0.6531\n",
      "Epoch 275/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6204 - val_loss: 0.6537\n",
      "Epoch 276/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6197 - val_loss: 0.6519\n",
      "Epoch 277/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6199 - val_loss: 0.6512\n",
      "Epoch 278/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6199 - val_loss: 0.6536\n",
      "Epoch 279/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6204 - val_loss: 0.6504\n",
      "Epoch 280/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6192 - val_loss: 0.6514\n",
      "Epoch 281/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6192 - val_loss: 0.6532\n",
      "Epoch 282/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6194 - val_loss: 0.6525\n",
      "Epoch 283/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6189 - val_loss: 0.6519\n",
      "Epoch 284/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6190 - val_loss: 0.6493\n",
      "Epoch 285/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6190 - val_loss: 0.6484\n",
      "Epoch 286/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6187 - val_loss: 0.6506\n",
      "Epoch 287/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6186 - val_loss: 0.6506\n",
      "Epoch 288/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6188 - val_loss: 0.6487\n",
      "Epoch 289/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6186 - val_loss: 0.6490\n",
      "Epoch 290/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6182 - val_loss: 0.6481\n",
      "Epoch 291/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6188 - val_loss: 0.6512\n",
      "Epoch 292/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6182 - val_loss: 0.6506\n",
      "Epoch 293/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6180 - val_loss: 0.6492\n",
      "Epoch 294/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6181 - val_loss: 0.6482\n",
      "Epoch 295/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6182 - val_loss: 0.6463\n",
      "Epoch 296/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6178 - val_loss: 0.6483\n",
      "Epoch 297/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6175 - val_loss: 0.6477\n",
      "Epoch 298/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6176 - val_loss: 0.6475\n",
      "Epoch 299/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6174 - val_loss: 0.6476\n",
      "Epoch 300/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6176 - val_loss: 0.6488\n",
      "Epoch 301/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6173 - val_loss: 0.6464\n",
      "Epoch 302/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6172 - val_loss: 0.6467\n",
      "Epoch 303/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6171 - val_loss: 0.6463\n",
      "Epoch 304/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6171 - val_loss: 0.6458\n",
      "Epoch 305/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6172 - val_loss: 0.6471\n",
      "Epoch 306/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6171 - val_loss: 0.6454\n",
      "Epoch 307/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6169 - val_loss: 0.6433\n",
      "Epoch 308/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6169 - val_loss: 0.6449\n",
      "Epoch 309/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6164 - val_loss: 0.6443\n",
      "Epoch 310/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6169 - val_loss: 0.6465\n",
      "Epoch 311/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6162 - val_loss: 0.6441\n",
      "Epoch 312/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6173 - val_loss: 0.6404\n",
      "Epoch 313/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6167 - val_loss: 0.6454\n",
      "Epoch 314/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6162 - val_loss: 0.6445\n",
      "Epoch 315/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6164 - val_loss: 0.6415\n",
      "Epoch 316/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6164 - val_loss: 0.6439\n",
      "Epoch 317/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6163 - val_loss: 0.6464\n",
      "Epoch 318/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6159 - val_loss: 0.6451\n",
      "Epoch 319/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6157 - val_loss: 0.6429\n",
      "Epoch 320/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6162 - val_loss: 0.6436\n",
      "Epoch 321/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6162 - val_loss: 0.6408\n",
      "Epoch 322/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6159 - val_loss: 0.6424\n",
      "Epoch 323/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6157 - val_loss: 0.6426\n",
      "Epoch 324/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6157 - val_loss: 0.6428\n",
      "Epoch 325/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6153 - val_loss: 0.6430\n",
      "Epoch 326/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6156 - val_loss: 0.6427\n",
      "Epoch 327/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6152 - val_loss: 0.6419\n",
      "Epoch 328/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6154 - val_loss: 0.6426\n",
      "Epoch 329/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6153 - val_loss: 0.6444\n",
      "Epoch 330/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6152 - val_loss: 0.6444\n",
      "Epoch 331/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6155 - val_loss: 0.6413\n",
      "Epoch 332/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6149 - val_loss: 0.6451\n",
      "Epoch 333/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6152 - val_loss: 0.6460\n",
      "Epoch 334/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6150 - val_loss: 0.6436\n",
      "Epoch 335/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6148 - val_loss: 0.6416\n",
      "Epoch 336/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6149 - val_loss: 0.6432\n",
      "Epoch 337/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6147 - val_loss: 0.6436\n",
      "Epoch 338/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6147 - val_loss: 0.6429\n",
      "Epoch 339/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6152 - val_loss: 0.6427\n",
      "Epoch 340/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6147 - val_loss: 0.6441\n",
      "Epoch 341/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6146 - val_loss: 0.6439\n",
      "Epoch 342/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6144 - val_loss: 0.6423\n",
      "Epoch 343/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6144 - val_loss: 0.6446\n",
      "Epoch 344/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6145 - val_loss: 0.6451\n",
      "Epoch 345/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6142 - val_loss: 0.6436\n",
      "Epoch 346/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6141 - val_loss: 0.6419\n",
      "Epoch 347/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6144 - val_loss: 0.6450\n",
      "Epoch 348/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6141 - val_loss: 0.6416\n",
      "Epoch 349/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6146 - val_loss: 0.6420\n",
      "Epoch 350/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6139 - val_loss: 0.6454\n",
      "Epoch 351/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6139 - val_loss: 0.6433\n",
      "Epoch 352/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6137 - val_loss: 0.6454\n",
      "Epoch 353/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6141 - val_loss: 0.6430\n",
      "Epoch 354/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6138 - val_loss: 0.6455\n",
      "Epoch 355/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6140 - val_loss: 0.6430\n",
      "Epoch 356/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6134 - val_loss: 0.6438\n",
      "Epoch 357/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6134 - val_loss: 0.6427\n",
      "Epoch 358/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6136 - val_loss: 0.6438\n",
      "Epoch 359/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6139 - val_loss: 0.6443\n",
      "Epoch 360/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6139 - val_loss: 0.6421\n",
      "Epoch 361/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6131 - val_loss: 0.6426\n",
      "Epoch 362/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6142 - val_loss: 0.6426\n",
      "Epoch 363/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6130 - val_loss: 0.6427\n",
      "Epoch 364/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6136 - val_loss: 0.6441\n",
      "Epoch 365/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6129 - val_loss: 0.6448\n",
      "Epoch 366/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6129 - val_loss: 0.6444\n",
      "Epoch 367/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6130 - val_loss: 0.6440\n",
      "Epoch 368/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6132 - val_loss: 0.6444\n",
      "Epoch 369/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6129 - val_loss: 0.6411\n",
      "Epoch 370/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6129 - val_loss: 0.6439\n",
      "Epoch 371/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6126 - val_loss: 0.6432\n",
      "Epoch 372/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6128 - val_loss: 0.6426\n",
      "Epoch 373/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6126 - val_loss: 0.6424\n",
      "Epoch 374/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6125 - val_loss: 0.6428\n",
      "Epoch 375/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6133 - val_loss: 0.6448\n",
      "Epoch 376/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6128 - val_loss: 0.6415\n",
      "Epoch 377/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6125 - val_loss: 0.6436\n",
      "Epoch 378/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6124 - val_loss: 0.6433\n",
      "Epoch 379/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6124 - val_loss: 0.6442\n",
      "Epoch 380/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6122 - val_loss: 0.6419\n",
      "Epoch 381/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6124 - val_loss: 0.6422\n",
      "Epoch 382/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6122 - val_loss: 0.6430\n",
      "Epoch 383/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6125 - val_loss: 0.6440\n",
      "Epoch 384/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6125 - val_loss: 0.6404\n",
      "Epoch 385/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6119 - val_loss: 0.6420\n",
      "Epoch 386/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6121 - val_loss: 0.6434\n",
      "Epoch 387/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6120 - val_loss: 0.6422\n",
      "Epoch 388/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6122 - val_loss: 0.6408\n",
      "Epoch 389/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6119 - val_loss: 0.6435\n",
      "Epoch 390/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6117 - val_loss: 0.6409\n",
      "Epoch 391/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6117 - val_loss: 0.6419\n",
      "Epoch 392/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6120 - val_loss: 0.6449\n",
      "Epoch 393/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6117 - val_loss: 0.6437\n",
      "Epoch 394/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6119 - val_loss: 0.6436\n",
      "Epoch 395/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6115 - val_loss: 0.6416\n",
      "Epoch 396/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6116 - val_loss: 0.6425\n",
      "Epoch 397/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6115 - val_loss: 0.6441\n",
      "Epoch 398/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6115 - val_loss: 0.6445\n",
      "Epoch 399/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6116 - val_loss: 0.6415\n",
      "Epoch 400/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6114 - val_loss: 0.6423\n",
      "Epoch 401/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6125 - val_loss: 0.6407\n",
      "Epoch 402/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6115 - val_loss: 0.6441\n",
      "Epoch 403/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6117 - val_loss: 0.6408\n",
      "Epoch 404/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6117 - val_loss: 0.6402\n",
      "Epoch 405/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6112 - val_loss: 0.6423\n",
      "Epoch 406/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6116 - val_loss: 0.6442\n",
      "Epoch 407/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6116 - val_loss: 0.6394\n",
      "Epoch 408/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6112 - val_loss: 0.6395\n",
      "Epoch 409/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6108 - val_loss: 0.6431\n",
      "Epoch 410/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6111 - val_loss: 0.6460\n",
      "Epoch 411/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6111 - val_loss: 0.6432\n",
      "Epoch 412/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6106 - val_loss: 0.6420\n",
      "Epoch 413/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6109 - val_loss: 0.6409\n",
      "Epoch 414/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6110 - val_loss: 0.6418\n",
      "Epoch 415/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6104 - val_loss: 0.6440\n",
      "Epoch 416/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6111 - val_loss: 0.6481\n",
      "Epoch 417/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6110 - val_loss: 0.6429\n",
      "Epoch 418/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6109 - val_loss: 0.6425\n",
      "Epoch 419/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6104 - val_loss: 0.6454\n",
      "Epoch 420/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6105 - val_loss: 0.6429\n",
      "Epoch 421/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6109 - val_loss: 0.6429\n",
      "Epoch 422/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6105 - val_loss: 0.6435\n",
      "Epoch 423/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6102 - val_loss: 0.6433\n",
      "Epoch 424/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6104 - val_loss: 0.6431\n",
      "Epoch 425/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6108 - val_loss: 0.6457\n",
      "Epoch 426/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6099 - val_loss: 0.6428\n",
      "Epoch 427/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6102 - val_loss: 0.6442\n",
      "Epoch 428/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6099 - val_loss: 0.6427\n",
      "Epoch 429/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6104 - val_loss: 0.6420\n",
      "Epoch 430/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6102 - val_loss: 0.6446\n",
      "Epoch 431/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6102 - val_loss: 0.6433\n",
      "Epoch 432/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6099 - val_loss: 0.6438\n",
      "Epoch 433/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6102 - val_loss: 0.6457\n",
      "Epoch 434/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6101 - val_loss: 0.6420\n",
      "Epoch 435/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6104 - val_loss: 0.6425\n",
      "Epoch 436/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6102 - val_loss: 0.6448\n",
      "Epoch 437/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6097 - val_loss: 0.6439\n",
      "Epoch 438/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6095 - val_loss: 0.6440\n",
      "Epoch 439/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6098 - val_loss: 0.6434\n",
      "Epoch 440/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6098 - val_loss: 0.6464\n",
      "Epoch 441/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6095 - val_loss: 0.6438\n",
      "Epoch 442/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6098 - val_loss: 0.6464\n",
      "Epoch 443/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6093 - val_loss: 0.6454\n",
      "Epoch 444/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6098 - val_loss: 0.6428\n",
      "Epoch 445/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6092 - val_loss: 0.6467\n",
      "Epoch 446/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6091 - val_loss: 0.6456\n",
      "Epoch 447/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6091 - val_loss: 0.6453\n",
      "Epoch 448/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6093 - val_loss: 0.6465\n",
      "Epoch 449/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6088 - val_loss: 0.6442\n",
      "Epoch 450/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6093 - val_loss: 0.6446\n",
      "Epoch 451/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6088 - val_loss: 0.6455\n",
      "Epoch 452/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6091 - val_loss: 0.6467\n",
      "Epoch 453/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6092 - val_loss: 0.6474\n",
      "Epoch 454/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6091 - val_loss: 0.6441\n",
      "Epoch 455/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6093 - val_loss: 0.6452\n",
      "Epoch 456/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6088 - val_loss: 0.6448\n",
      "Epoch 457/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6087 - val_loss: 0.6469\n",
      "Epoch 458/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6087 - val_loss: 0.6475\n",
      "Epoch 459/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6087 - val_loss: 0.6440\n",
      "Epoch 460/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6084 - val_loss: 0.6458\n",
      "Epoch 461/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6086 - val_loss: 0.6495\n",
      "Epoch 462/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6090 - val_loss: 0.6464\n",
      "Epoch 463/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6084 - val_loss: 0.6462\n",
      "Epoch 464/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6087 - val_loss: 0.6488\n",
      "Epoch 465/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6088 - val_loss: 0.6472\n",
      "Epoch 466/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6086 - val_loss: 0.6484\n",
      "Epoch 467/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6080 - val_loss: 0.6458\n",
      "Epoch 468/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6084 - val_loss: 0.6446\n",
      "Epoch 469/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6084 - val_loss: 0.6484\n",
      "Epoch 470/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6088 - val_loss: 0.6435\n",
      "Epoch 471/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6087 - val_loss: 0.6461\n",
      "Epoch 472/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6085 - val_loss: 0.6469\n",
      "Epoch 473/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6081 - val_loss: 0.6486\n",
      "Epoch 474/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6084 - val_loss: 0.6498\n",
      "Epoch 475/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6080 - val_loss: 0.6468\n",
      "Epoch 476/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6081 - val_loss: 0.6443\n",
      "Epoch 477/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6080 - val_loss: 0.6462\n",
      "Epoch 478/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6083 - val_loss: 0.6469\n",
      "Epoch 479/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6078 - val_loss: 0.6462\n",
      "Epoch 480/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6083 - val_loss: 0.6477\n",
      "Epoch 481/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6082 - val_loss: 0.6433\n",
      "Epoch 482/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6078 - val_loss: 0.6448\n",
      "Epoch 483/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6081 - val_loss: 0.6510\n",
      "Epoch 484/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6078 - val_loss: 0.6514\n",
      "Epoch 485/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6076 - val_loss: 0.6493\n",
      "Epoch 486/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6076 - val_loss: 0.6451\n",
      "Epoch 487/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6082 - val_loss: 0.6460\n",
      "Epoch 488/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6079 - val_loss: 0.6448\n",
      "Epoch 489/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6076 - val_loss: 0.6476\n",
      "Epoch 490/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6078 - val_loss: 0.6506\n",
      "Epoch 491/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6077 - val_loss: 0.6475\n",
      "Epoch 492/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6074 - val_loss: 0.6470\n",
      "Epoch 493/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6073 - val_loss: 0.6486\n",
      "Epoch 494/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6074 - val_loss: 0.6490\n",
      "Epoch 495/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6074 - val_loss: 0.6478\n",
      "Epoch 496/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6071 - val_loss: 0.6496\n",
      "Epoch 497/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6073 - val_loss: 0.6489\n",
      "Epoch 498/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6071 - val_loss: 0.6473\n",
      "Epoch 499/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6071 - val_loss: 0.6493\n",
      "Epoch 500/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6073 - val_loss: 0.6502\n",
      "Epoch 501/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6071 - val_loss: 0.6479\n",
      "Epoch 502/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6076 - val_loss: 0.6443\n",
      "Epoch 503/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6071 - val_loss: 0.6465\n",
      "Epoch 504/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6072 - val_loss: 0.6494\n",
      "Epoch 505/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6068 - val_loss: 0.6477\n",
      "Epoch 506/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6070 - val_loss: 0.6498\n",
      "Epoch 507/1000\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.3982Restoring model weights from the end of the best epoch: 407.\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6069 - val_loss: 0.6471\n",
      "Epoch 507: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x177b1c760>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_emiliani1_CMI_best5.fit(best5_CMI_train_E1,target_df_train_E1.mean_std,validation_data=(best5_CMI_val_E1,target_df_val_E1.mean_std),\n",
    "        callbacks=[monitor],epochs=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1d9ddbf",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-13 14:16:56.773016: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2524697745336094"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(target_df_test_E1.mean_std, model_emiliani1_CMI_best5.predict(best5_CMI_test_E1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059020db",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Emiliani2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d7614e4",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 36\n",
      "Trainable params: 36\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_emiliani2_CMI_best5 = Sequential()\n",
    "model_emiliani2_CMI_best5.add(Dense(5, input_dim=5, activation='relu')) \n",
    "model_emiliani2_CMI_best5.add(Dense(1)) # Output\n",
    "\n",
    "model_emiliani2_CMI_best5.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=100, \n",
    "        verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "model_emiliani2_CMI_best5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae9a41d0",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 1.0360 - val_loss: 0.9248\n",
      "Epoch 2/1000\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.9788"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-13 14:17:06.486447: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-13 14:17:06.638054: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0047 - val_loss: 0.8981\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9747 - val_loss: 0.8766\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9489 - val_loss: 0.8571\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9249 - val_loss: 0.8387\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9038 - val_loss: 0.8229\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8847 - val_loss: 0.8085\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8681 - val_loss: 0.7945\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8521 - val_loss: 0.7816\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8385 - val_loss: 0.7690\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8245 - val_loss: 0.7583\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8122 - val_loss: 0.7484\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8018 - val_loss: 0.7412\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7937 - val_loss: 0.7354\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7866 - val_loss: 0.7298\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7803 - val_loss: 0.7249\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7752 - val_loss: 0.7200\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7700 - val_loss: 0.7179\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7659 - val_loss: 0.7150\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7623 - val_loss: 0.7124\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7596 - val_loss: 0.7098\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7559 - val_loss: 0.7085\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7533 - val_loss: 0.7060\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7502 - val_loss: 0.7032\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7480 - val_loss: 0.7007\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7460 - val_loss: 0.6981\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7434 - val_loss: 0.6972\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7410 - val_loss: 0.6963\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7390 - val_loss: 0.6940\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7370 - val_loss: 0.6921\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7348 - val_loss: 0.6930\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7325 - val_loss: 0.6913\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7304 - val_loss: 0.6918\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7282 - val_loss: 0.6904\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7262 - val_loss: 0.6906\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7239 - val_loss: 0.6901\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7217 - val_loss: 0.6900\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7195 - val_loss: 0.6897\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7176 - val_loss: 0.6882\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7160 - val_loss: 0.6884\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7143 - val_loss: 0.6884\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7132 - val_loss: 0.6882\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7112 - val_loss: 0.6901\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7099 - val_loss: 0.6892\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7087 - val_loss: 0.6896\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7076 - val_loss: 0.6902\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7064 - val_loss: 0.6901\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7050 - val_loss: 0.6908\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7040 - val_loss: 0.6910\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7029 - val_loss: 0.6913\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7021 - val_loss: 0.6901\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7011 - val_loss: 0.6905\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7002 - val_loss: 0.6909\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6993 - val_loss: 0.6912\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6985 - val_loss: 0.6905\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6977 - val_loss: 0.6906\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6972 - val_loss: 0.6915\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6964 - val_loss: 0.6911\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6957 - val_loss: 0.6913\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6953 - val_loss: 0.6908\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6946 - val_loss: 0.6898\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6940 - val_loss: 0.6904\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6938 - val_loss: 0.6894\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6929 - val_loss: 0.6895\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6926 - val_loss: 0.6886\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6922 - val_loss: 0.6894\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6922 - val_loss: 0.6890\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6911 - val_loss: 0.6893\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6909 - val_loss: 0.6899\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6906 - val_loss: 0.6889\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6904 - val_loss: 0.6901\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6903\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6894 - val_loss: 0.6908\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6892 - val_loss: 0.6905\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6888 - val_loss: 0.6906\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6888 - val_loss: 0.6900\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6882 - val_loss: 0.6911\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6881 - val_loss: 0.6903\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6877 - val_loss: 0.6907\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6875 - val_loss: 0.6915\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6871 - val_loss: 0.6902\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6868 - val_loss: 0.6905\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6864 - val_loss: 0.6909\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6866 - val_loss: 0.6910\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6860 - val_loss: 0.6924\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6862 - val_loss: 0.6925\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6858 - val_loss: 0.6913\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6853 - val_loss: 0.6922\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6852 - val_loss: 0.6908\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6848 - val_loss: 0.6915\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6845 - val_loss: 0.6924\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6844 - val_loss: 0.6926\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6843 - val_loss: 0.6916\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6844 - val_loss: 0.6930\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6839 - val_loss: 0.6921\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6838 - val_loss: 0.6928\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6838 - val_loss: 0.6927\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6833 - val_loss: 0.6935\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6831 - val_loss: 0.6936\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6831 - val_loss: 0.6940\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6827 - val_loss: 0.6931\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6827 - val_loss: 0.6934\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6826 - val_loss: 0.6941\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6823 - val_loss: 0.6949\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6821 - val_loss: 0.6937\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6820 - val_loss: 0.6937\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6819 - val_loss: 0.6940\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6816 - val_loss: 0.6943\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6815 - val_loss: 0.6949\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6815 - val_loss: 0.6951\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6813 - val_loss: 0.6950\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6815 - val_loss: 0.6952\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6813 - val_loss: 0.6944\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6812 - val_loss: 0.6947\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6810 - val_loss: 0.6952\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6811 - val_loss: 0.6952\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6807 - val_loss: 0.6943\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6808 - val_loss: 0.6951\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6807 - val_loss: 0.6929\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6806 - val_loss: 0.6932\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6806 - val_loss: 0.6939\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6803 - val_loss: 0.6951\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6804 - val_loss: 0.6946\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6804 - val_loss: 0.6960\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6802 - val_loss: 0.6963\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6801 - val_loss: 0.6953\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6799 - val_loss: 0.6958\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6800 - val_loss: 0.6951\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6799 - val_loss: 0.6961\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6797 - val_loss: 0.6952\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6797 - val_loss: 0.6950\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6796 - val_loss: 0.6957\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6796 - val_loss: 0.6948\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6797 - val_loss: 0.6964\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6792 - val_loss: 0.6961\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6792 - val_loss: 0.6964\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6792 - val_loss: 0.6962\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6793 - val_loss: 0.6971\n",
      "Epoch 139/1000\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.5825Restoring model weights from the end of the best epoch: 39.\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6791 - val_loss: 0.6980\n",
      "Epoch 139: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x169fb8490>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_emiliani2_CMI_best5.fit(best5_CMI_train_E2,target_df_train_E2.mean_std,validation_data=(best5_CMI_val_E2,target_df_val_E2.mean_std),\n",
    "        callbacks=[monitor],epochs=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b490632",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-13 14:17:16.161300: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2570693400412608"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(target_df_test_E2.mean_std, model_emiliani2_CMI_best5.predict(best5_CMI_test_E2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56c6504",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ed02b9c6",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_14 (Dense)            (None, 5)                 55        \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 2)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67\n",
      "Trainable params: 67\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_emiliani12_CMI_best5 = Sequential()\n",
    "model_emiliani12_CMI_best5.add(Dense(5, input_dim=10, activation='relu')) \n",
    "model_emiliani12_CMI_best5.add(Dense(2)) # Output\n",
    "\n",
    "model_emiliani12_CMI_best5.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=100, \n",
    "        verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "model_emiliani12_CMI_best5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "00120377",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "13/13 [==============================] - 1s 12ms/step - loss: 0.8394 - val_loss: 0.8951\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-13 14:17:28.995569: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-13 14:17:29.147892: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8057 - val_loss: 0.8407\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7803 - val_loss: 0.7987\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7640 - val_loss: 0.7626\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7537 - val_loss: 0.7389\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7463 - val_loss: 0.7293\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7417 - val_loss: 0.7219\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7384 - val_loss: 0.7156\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7344 - val_loss: 0.7103\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7315 - val_loss: 0.7077\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7285 - val_loss: 0.7023\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7256 - val_loss: 0.6997\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7231 - val_loss: 0.6966\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7208 - val_loss: 0.6920\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7183 - val_loss: 0.6885\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7162 - val_loss: 0.6894\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7141 - val_loss: 0.6859\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7120 - val_loss: 0.6805\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7101 - val_loss: 0.6775\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7083 - val_loss: 0.6760\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7065 - val_loss: 0.6758\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7051 - val_loss: 0.6746\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7035 - val_loss: 0.6731\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7019 - val_loss: 0.6711\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7010 - val_loss: 0.6674\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6996 - val_loss: 0.6682\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6985 - val_loss: 0.6673\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6978 - val_loss: 0.6686\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6962 - val_loss: 0.6635\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6953 - val_loss: 0.6625\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6942 - val_loss: 0.6606\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6933 - val_loss: 0.6589\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6924 - val_loss: 0.6586\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6915 - val_loss: 0.6576\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6905 - val_loss: 0.6572\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6896 - val_loss: 0.6573\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6889 - val_loss: 0.6571\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6879 - val_loss: 0.6560\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6878 - val_loss: 0.6590\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6862 - val_loss: 0.6565\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6854 - val_loss: 0.6560\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6848 - val_loss: 0.6573\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6843 - val_loss: 0.6572\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6837 - val_loss: 0.6571\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6825 - val_loss: 0.6568\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6821 - val_loss: 0.6574\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6811 - val_loss: 0.6571\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6808 - val_loss: 0.6580\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6805 - val_loss: 0.6607\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6793 - val_loss: 0.6590\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6788 - val_loss: 0.6596\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6783 - val_loss: 0.6580\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6778 - val_loss: 0.6592\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6775 - val_loss: 0.6610\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6765 - val_loss: 0.6614\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6762 - val_loss: 0.6601\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6756 - val_loss: 0.6605\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6750 - val_loss: 0.6619\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6746 - val_loss: 0.6640\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6745 - val_loss: 0.6673\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6743 - val_loss: 0.6650\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6735 - val_loss: 0.6667\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6725 - val_loss: 0.6682\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6724 - val_loss: 0.6681\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6715 - val_loss: 0.6691\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6706 - val_loss: 0.6692\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6703 - val_loss: 0.6677\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6700 - val_loss: 0.6700\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6692 - val_loss: 0.6705\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6691 - val_loss: 0.6705\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6682 - val_loss: 0.6694\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6678 - val_loss: 0.6693\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6672 - val_loss: 0.6696\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6667 - val_loss: 0.6712\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6664 - val_loss: 0.6707\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6663 - val_loss: 0.6717\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6653 - val_loss: 0.6728\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6650 - val_loss: 0.6740\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6646 - val_loss: 0.6738\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6642 - val_loss: 0.6752\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6636 - val_loss: 0.6752\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6631 - val_loss: 0.6758\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6629 - val_loss: 0.6764\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6630 - val_loss: 0.6753\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6619 - val_loss: 0.6776\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6624 - val_loss: 0.6763\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6612 - val_loss: 0.6778\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6609 - val_loss: 0.6787\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6607 - val_loss: 0.6784\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6604 - val_loss: 0.6777\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6601 - val_loss: 0.6783\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6602 - val_loss: 0.6776\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6595 - val_loss: 0.6753\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6593 - val_loss: 0.6789\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6588 - val_loss: 0.6790\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6582 - val_loss: 0.6776\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6579 - val_loss: 0.6793\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6578 - val_loss: 0.6790\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6576 - val_loss: 0.6787\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6575 - val_loss: 0.6805\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6571 - val_loss: 0.6788\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6568 - val_loss: 0.6779\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6569 - val_loss: 0.6769\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6564 - val_loss: 0.6783\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6562 - val_loss: 0.6801\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6561 - val_loss: 0.6781\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6557 - val_loss: 0.6773\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6557 - val_loss: 0.6768\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6553 - val_loss: 0.6776\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6554 - val_loss: 0.6791\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6553 - val_loss: 0.6756\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6547 - val_loss: 0.6777\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6548 - val_loss: 0.6787\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6545 - val_loss: 0.6778\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6542 - val_loss: 0.6787\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6540 - val_loss: 0.6769\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6542 - val_loss: 0.6786\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6536 - val_loss: 0.6769\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6535 - val_loss: 0.6795\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6532 - val_loss: 0.6787\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6532 - val_loss: 0.6774\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6529 - val_loss: 0.6773\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6528 - val_loss: 0.6767\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6531 - val_loss: 0.6812\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6525 - val_loss: 0.6793\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6522 - val_loss: 0.6796\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6523 - val_loss: 0.6786\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6519 - val_loss: 0.6766\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6517 - val_loss: 0.6765\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6515 - val_loss: 0.6794\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6518 - val_loss: 0.6760\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6512 - val_loss: 0.6772\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6509 - val_loss: 0.6782\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6507 - val_loss: 0.6780\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6506 - val_loss: 0.6773\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6502 - val_loss: 0.6772\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6504 - val_loss: 0.6773\n",
      "Epoch 138/1000\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6784Restoring model weights from the end of the best epoch: 38.\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6499 - val_loss: 0.6773\n",
      "Epoch 138: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x177e1a7f0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best5_CMI_train_E12 = pd.concat((best5_CMI_train_E1,best5_CMI_train_E2),axis=1)\n",
    "best5_CMI_val_E12 = pd.concat((best5_CMI_val_E1,best5_CMI_val_E2),axis=1)\n",
    "best5_CMI_test_E12 = pd.concat((best5_CMI_test_E1,best5_CMI_test_E2),axis=1)\n",
    "\n",
    "target_train_E12 = pd.concat((target_df_train_E1.mean_std,target_df_train_E2.mean_std),axis=1)\n",
    "target_val_E12 = pd.concat((target_df_val_E1.mean_std,target_df_val_E2.mean_std),axis=1)\n",
    "target_test_E12 = pd.concat((target_df_test_E1.mean_std,target_df_test_E2.mean_std),axis=1)\n",
    "\n",
    "model_emiliani12_CMI_best5.fit(best5_CMI_train_E12,target_train_E12,validation_data=(best5_CMI_val_E12,target_val_E12),\n",
    "        callbacks=[monitor],epochs=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "df768dfc",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step\n",
      "0.2646020300846088\n",
      "0.2860979483350553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-13 14:17:55.725250: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "res = model_emiliani12_CMI_best5.predict(best5_CMI_test_E12)\n",
    "\n",
    "print(r2_score(target_df_test_E1.mean_std, res[:,0]))\n",
    "print(r2_score(target_df_test_E2.mean_std, res[:,1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d526fd1",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Together, another structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "47647e9e",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_22 (Dense)            (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41\n",
      "Trainable params: 41\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_both_CMI_best5 = Sequential()\n",
    "model_both_CMI_best5.add(Dense(5, input_dim=6, activation='relu')) \n",
    "model_both_CMI_best5.add(Dense(1)) # Output\n",
    "\n",
    "model_both_CMI_best5.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=100, \n",
    "        verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "model_both_CMI_best5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fb279692",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best5_CMI_train_withClass0 = pd.concat((best5_CMI_train_E1,pd.DataFrame(np.zeros(len(best5_CMI_train_E1)),columns=['basin'])),axis=1)\n",
    "best5_CMI_train_withClass1 = pd.concat((best5_CMI_train_E2,pd.DataFrame(np.ones(len(best5_CMI_train_E1)),columns=['basin'])),axis=1)\n",
    "best5_CMI_train_withClass01 = np.concatenate((best5_CMI_train_withClass0.values,best5_CMI_train_withClass1.values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "443246ce",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best5_CMI_val_withClass0 = pd.concat((best5_CMI_val_E1,pd.DataFrame(np.zeros(len(best5_CMI_val_E1)),columns=['basin'])),axis=1)\n",
    "best5_CMI_val_withClass1 = pd.concat((best5_CMI_val_E2,pd.DataFrame(np.ones(len(best5_CMI_val_E1)),columns=['basin'])),axis=1)\n",
    "best5_CMI_val_withClass01 = np.concatenate((best5_CMI_val_withClass0.values,best5_CMI_val_withClass1.values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "077d37d7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best5_CMI_test_withClass0 = pd.concat((best5_CMI_test_E1,pd.DataFrame(np.zeros(len(best5_CMI_test_E1)),columns=['basin'])),axis=1)\n",
    "best5_CMI_test_withClass1 = pd.concat((best5_CMI_test_E2,pd.DataFrame(np.ones(len(best5_CMI_test_E1)),columns=['basin'])),axis=1)\n",
    "best5_CMI_test_withClass01 = np.concatenate((best5_CMI_test_withClass0.values,best5_CMI_test_withClass1.values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1b63c6ec",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "target_train_withClass01 = pd.concat((target_df_train_E1.mean_std,target_df_train_E2.mean_std),axis=0)\n",
    "target_val_withClass01 = pd.concat((target_df_val_E1.mean_std,target_df_val_E2.mean_std),axis=0)\n",
    "target_test_withClass01 = pd.concat((target_df_test_E1.mean_std,target_df_test_E2.mean_std),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dced8ed2",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-13 14:45:09.461116: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 12ms/step - loss: 1.0354 - val_loss: 0.9807\n",
      "Epoch 2/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.9517 - val_loss: 0.9125\n",
      "Epoch 3/1000\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.9551"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-13 14:45:10.209832: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 5ms/step - loss: 0.8976 - val_loss: 0.8774\n",
      "Epoch 4/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.8628 - val_loss: 0.8597\n",
      "Epoch 5/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.8423 - val_loss: 0.8472\n",
      "Epoch 6/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.8291 - val_loss: 0.8396\n",
      "Epoch 7/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.8193 - val_loss: 0.8338\n",
      "Epoch 8/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.8123 - val_loss: 0.8301\n",
      "Epoch 9/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.8056 - val_loss: 0.8253\n",
      "Epoch 10/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.8006 - val_loss: 0.8215\n",
      "Epoch 11/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7954 - val_loss: 0.8166\n",
      "Epoch 12/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7901 - val_loss: 0.8124\n",
      "Epoch 13/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7855 - val_loss: 0.8085\n",
      "Epoch 14/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7812 - val_loss: 0.8041\n",
      "Epoch 15/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7772 - val_loss: 0.8016\n",
      "Epoch 16/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7737 - val_loss: 0.7989\n",
      "Epoch 17/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7699 - val_loss: 0.7964\n",
      "Epoch 18/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7669 - val_loss: 0.7927\n",
      "Epoch 19/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7634 - val_loss: 0.7910\n",
      "Epoch 20/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7601 - val_loss: 0.7885\n",
      "Epoch 21/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7568 - val_loss: 0.7844\n",
      "Epoch 22/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7541 - val_loss: 0.7821\n",
      "Epoch 23/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7514 - val_loss: 0.7804\n",
      "Epoch 24/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7485 - val_loss: 0.7778\n",
      "Epoch 25/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7459 - val_loss: 0.7751\n",
      "Epoch 26/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7436 - val_loss: 0.7732\n",
      "Epoch 27/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7415 - val_loss: 0.7725\n",
      "Epoch 28/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7388 - val_loss: 0.7692\n",
      "Epoch 29/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7366 - val_loss: 0.7660\n",
      "Epoch 30/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7346 - val_loss: 0.7636\n",
      "Epoch 31/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7325 - val_loss: 0.7606\n",
      "Epoch 32/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7307 - val_loss: 0.7588\n",
      "Epoch 33/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7288 - val_loss: 0.7580\n",
      "Epoch 34/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7268 - val_loss: 0.7554\n",
      "Epoch 35/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7249 - val_loss: 0.7526\n",
      "Epoch 36/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7229 - val_loss: 0.7503\n",
      "Epoch 37/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7215 - val_loss: 0.7489\n",
      "Epoch 38/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7201 - val_loss: 0.7455\n",
      "Epoch 39/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7188 - val_loss: 0.7437\n",
      "Epoch 40/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7176 - val_loss: 0.7419\n",
      "Epoch 41/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7159 - val_loss: 0.7407\n",
      "Epoch 42/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7147 - val_loss: 0.7389\n",
      "Epoch 43/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7135 - val_loss: 0.7386\n",
      "Epoch 44/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7126 - val_loss: 0.7358\n",
      "Epoch 45/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7109 - val_loss: 0.7348\n",
      "Epoch 46/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7104 - val_loss: 0.7322\n",
      "Epoch 47/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7086 - val_loss: 0.7303\n",
      "Epoch 48/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7074 - val_loss: 0.7275\n",
      "Epoch 49/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7061 - val_loss: 0.7251\n",
      "Epoch 50/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7051 - val_loss: 0.7241\n",
      "Epoch 51/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7039 - val_loss: 0.7216\n",
      "Epoch 52/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7030 - val_loss: 0.7198\n",
      "Epoch 53/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7021 - val_loss: 0.7179\n",
      "Epoch 54/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7009 - val_loss: 0.7171\n",
      "Epoch 55/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6994 - val_loss: 0.7149\n",
      "Epoch 56/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6983 - val_loss: 0.7127\n",
      "Epoch 57/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6974 - val_loss: 0.7107\n",
      "Epoch 58/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6966 - val_loss: 0.7080\n",
      "Epoch 59/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6952 - val_loss: 0.7066\n",
      "Epoch 60/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6944 - val_loss: 0.7055\n",
      "Epoch 61/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6935 - val_loss: 0.7025\n",
      "Epoch 62/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6920 - val_loss: 0.7016\n",
      "Epoch 63/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6917 - val_loss: 0.7001\n",
      "Epoch 64/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6903 - val_loss: 0.6996\n",
      "Epoch 65/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6899 - val_loss: 0.6969\n",
      "Epoch 66/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6888 - val_loss: 0.6962\n",
      "Epoch 67/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6879 - val_loss: 0.6942\n",
      "Epoch 68/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6876 - val_loss: 0.6926\n",
      "Epoch 69/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6862 - val_loss: 0.6925\n",
      "Epoch 70/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6853 - val_loss: 0.6908\n",
      "Epoch 71/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6846 - val_loss: 0.6892\n",
      "Epoch 72/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6840 - val_loss: 0.6879\n",
      "Epoch 73/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6831 - val_loss: 0.6868\n",
      "Epoch 74/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6830 - val_loss: 0.6858\n",
      "Epoch 75/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6820 - val_loss: 0.6846\n",
      "Epoch 76/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6822 - val_loss: 0.6822\n",
      "Epoch 77/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6808 - val_loss: 0.6816\n",
      "Epoch 78/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6801 - val_loss: 0.6804\n",
      "Epoch 79/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6805 - val_loss: 0.6801\n",
      "Epoch 80/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6794 - val_loss: 0.6807\n",
      "Epoch 81/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6789 - val_loss: 0.6805\n",
      "Epoch 82/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6781 - val_loss: 0.6793\n",
      "Epoch 83/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6790 - val_loss: 0.6767\n",
      "Epoch 84/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6774 - val_loss: 0.6776\n",
      "Epoch 85/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6769 - val_loss: 0.6770\n",
      "Epoch 86/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6764 - val_loss: 0.6759\n",
      "Epoch 87/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6757 - val_loss: 0.6749\n",
      "Epoch 88/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6751 - val_loss: 0.6741\n",
      "Epoch 89/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6742 - val_loss: 0.6736\n",
      "Epoch 90/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6735 - val_loss: 0.6719\n",
      "Epoch 91/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6729 - val_loss: 0.6709\n",
      "Epoch 92/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6725 - val_loss: 0.6711\n",
      "Epoch 93/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6715 - val_loss: 0.6700\n",
      "Epoch 94/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6707 - val_loss: 0.6703\n",
      "Epoch 95/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6699 - val_loss: 0.6694\n",
      "Epoch 96/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6694 - val_loss: 0.6673\n",
      "Epoch 97/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6688 - val_loss: 0.6674\n",
      "Epoch 98/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6681 - val_loss: 0.6661\n",
      "Epoch 99/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6675 - val_loss: 0.6658\n",
      "Epoch 100/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6676 - val_loss: 0.6642\n",
      "Epoch 101/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6668 - val_loss: 0.6652\n",
      "Epoch 102/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6666 - val_loss: 0.6642\n",
      "Epoch 103/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6663 - val_loss: 0.6622\n",
      "Epoch 104/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6660 - val_loss: 0.6624\n",
      "Epoch 105/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6658 - val_loss: 0.6614\n",
      "Epoch 106/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6655 - val_loss: 0.6606\n",
      "Epoch 107/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6660 - val_loss: 0.6615\n",
      "Epoch 108/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6656 - val_loss: 0.6590\n",
      "Epoch 109/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6648 - val_loss: 0.6593\n",
      "Epoch 110/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6639 - val_loss: 0.6587\n",
      "Epoch 111/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6649 - val_loss: 0.6594\n",
      "Epoch 112/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6642 - val_loss: 0.6576\n",
      "Epoch 113/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6633 - val_loss: 0.6573\n",
      "Epoch 114/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6635 - val_loss: 0.6564\n",
      "Epoch 115/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6632 - val_loss: 0.6559\n",
      "Epoch 116/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6627 - val_loss: 0.6565\n",
      "Epoch 117/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6630 - val_loss: 0.6566\n",
      "Epoch 118/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6632 - val_loss: 0.6555\n",
      "Epoch 119/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6628 - val_loss: 0.6551\n",
      "Epoch 120/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6624 - val_loss: 0.6545\n",
      "Epoch 121/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6620 - val_loss: 0.6549\n",
      "Epoch 122/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6619 - val_loss: 0.6554\n",
      "Epoch 123/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6614 - val_loss: 0.6547\n",
      "Epoch 124/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6614 - val_loss: 0.6548\n",
      "Epoch 125/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6612 - val_loss: 0.6539\n",
      "Epoch 126/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6612 - val_loss: 0.6539\n",
      "Epoch 127/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6615 - val_loss: 0.6533\n",
      "Epoch 128/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6608 - val_loss: 0.6534\n",
      "Epoch 129/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6609 - val_loss: 0.6536\n",
      "Epoch 130/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6603 - val_loss: 0.6525\n",
      "Epoch 131/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6604 - val_loss: 0.6522\n",
      "Epoch 132/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6603 - val_loss: 0.6509\n",
      "Epoch 133/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6602 - val_loss: 0.6520\n",
      "Epoch 134/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6600 - val_loss: 0.6525\n",
      "Epoch 135/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6603 - val_loss: 0.6521\n",
      "Epoch 136/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6605 - val_loss: 0.6517\n",
      "Epoch 137/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6595 - val_loss: 0.6518\n",
      "Epoch 138/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6592 - val_loss: 0.6521\n",
      "Epoch 139/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6596 - val_loss: 0.6516\n",
      "Epoch 140/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6591 - val_loss: 0.6502\n",
      "Epoch 141/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6589 - val_loss: 0.6509\n",
      "Epoch 142/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6586 - val_loss: 0.6498\n",
      "Epoch 143/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6591 - val_loss: 0.6508\n",
      "Epoch 144/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6591 - val_loss: 0.6514\n",
      "Epoch 145/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6593 - val_loss: 0.6501\n",
      "Epoch 146/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6581 - val_loss: 0.6500\n",
      "Epoch 147/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6587 - val_loss: 0.6502\n",
      "Epoch 148/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6579 - val_loss: 0.6494\n",
      "Epoch 149/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6579 - val_loss: 0.6504\n",
      "Epoch 150/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6584 - val_loss: 0.6488\n",
      "Epoch 151/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6579 - val_loss: 0.6500\n",
      "Epoch 152/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6570 - val_loss: 0.6489\n",
      "Epoch 153/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6576 - val_loss: 0.6468\n",
      "Epoch 154/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6566 - val_loss: 0.6488\n",
      "Epoch 155/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6564 - val_loss: 0.6483\n",
      "Epoch 156/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6567 - val_loss: 0.6475\n",
      "Epoch 157/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6569 - val_loss: 0.6468\n",
      "Epoch 158/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6568 - val_loss: 0.6480\n",
      "Epoch 159/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6564 - val_loss: 0.6470\n",
      "Epoch 160/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6559 - val_loss: 0.6471\n",
      "Epoch 161/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6555 - val_loss: 0.6472\n",
      "Epoch 162/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6559 - val_loss: 0.6466\n",
      "Epoch 163/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6556 - val_loss: 0.6462\n",
      "Epoch 164/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6551 - val_loss: 0.6456\n",
      "Epoch 165/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6550 - val_loss: 0.6453\n",
      "Epoch 166/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6553 - val_loss: 0.6453\n",
      "Epoch 167/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6547 - val_loss: 0.6451\n",
      "Epoch 168/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6549 - val_loss: 0.6452\n",
      "Epoch 169/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6547 - val_loss: 0.6445\n",
      "Epoch 170/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6547 - val_loss: 0.6439\n",
      "Epoch 171/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6544 - val_loss: 0.6451\n",
      "Epoch 172/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6544 - val_loss: 0.6443\n",
      "Epoch 173/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6543 - val_loss: 0.6447\n",
      "Epoch 174/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6543 - val_loss: 0.6450\n",
      "Epoch 175/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6546 - val_loss: 0.6443\n",
      "Epoch 176/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6541 - val_loss: 0.6439\n",
      "Epoch 177/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6539 - val_loss: 0.6438\n",
      "Epoch 178/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6538 - val_loss: 0.6434\n",
      "Epoch 179/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6538 - val_loss: 0.6453\n",
      "Epoch 180/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6536 - val_loss: 0.6431\n",
      "Epoch 181/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6535 - val_loss: 0.6454\n",
      "Epoch 182/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6532 - val_loss: 0.6444\n",
      "Epoch 183/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6532 - val_loss: 0.6434\n",
      "Epoch 184/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6528 - val_loss: 0.6454\n",
      "Epoch 185/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6530 - val_loss: 0.6450\n",
      "Epoch 186/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6528 - val_loss: 0.6441\n",
      "Epoch 187/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6530 - val_loss: 0.6445\n",
      "Epoch 188/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6526 - val_loss: 0.6443\n",
      "Epoch 189/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6528 - val_loss: 0.6434\n",
      "Epoch 190/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6531 - val_loss: 0.6460\n",
      "Epoch 191/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6524 - val_loss: 0.6427\n",
      "Epoch 192/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6528 - val_loss: 0.6438\n",
      "Epoch 193/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6524 - val_loss: 0.6443\n",
      "Epoch 194/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6521 - val_loss: 0.6427\n",
      "Epoch 195/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6526 - val_loss: 0.6434\n",
      "Epoch 196/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6523 - val_loss: 0.6436\n",
      "Epoch 197/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6520 - val_loss: 0.6440\n",
      "Epoch 198/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6518 - val_loss: 0.6436\n",
      "Epoch 199/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6515 - val_loss: 0.6445\n",
      "Epoch 200/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6514 - val_loss: 0.6421\n",
      "Epoch 201/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6515 - val_loss: 0.6428\n",
      "Epoch 202/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6514 - val_loss: 0.6439\n",
      "Epoch 203/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6513 - val_loss: 0.6418\n",
      "Epoch 204/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6510 - val_loss: 0.6435\n",
      "Epoch 205/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6513 - val_loss: 0.6432\n",
      "Epoch 206/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6513 - val_loss: 0.6428\n",
      "Epoch 207/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6510 - val_loss: 0.6428\n",
      "Epoch 208/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6508 - val_loss: 0.6429\n",
      "Epoch 209/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6508 - val_loss: 0.6432\n",
      "Epoch 210/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.6508 - val_loss: 0.6425\n",
      "Epoch 211/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.6508 - val_loss: 0.6419\n",
      "Epoch 212/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.6509 - val_loss: 0.6426\n",
      "Epoch 213/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6505 - val_loss: 0.6420\n",
      "Epoch 214/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6506 - val_loss: 0.6425\n",
      "Epoch 215/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6508 - val_loss: 0.6427\n",
      "Epoch 216/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6505 - val_loss: 0.6417\n",
      "Epoch 217/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6506 - val_loss: 0.6417\n",
      "Epoch 218/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6503 - val_loss: 0.6430\n",
      "Epoch 219/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6507 - val_loss: 0.6421\n",
      "Epoch 220/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6507 - val_loss: 0.6414\n",
      "Epoch 221/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6502 - val_loss: 0.6412\n",
      "Epoch 222/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6504 - val_loss: 0.6424\n",
      "Epoch 223/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6502 - val_loss: 0.6414\n",
      "Epoch 224/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6500 - val_loss: 0.6434\n",
      "Epoch 225/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6504 - val_loss: 0.6410\n",
      "Epoch 226/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6503 - val_loss: 0.6413\n",
      "Epoch 227/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6498 - val_loss: 0.6425\n",
      "Epoch 228/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6499 - val_loss: 0.6416\n",
      "Epoch 229/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6501 - val_loss: 0.6416\n",
      "Epoch 230/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6498 - val_loss: 0.6423\n",
      "Epoch 231/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6501 - val_loss: 0.6419\n",
      "Epoch 232/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6501 - val_loss: 0.6408\n",
      "Epoch 233/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6499 - val_loss: 0.6413\n",
      "Epoch 234/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6492 - val_loss: 0.6410\n",
      "Epoch 235/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6500 - val_loss: 0.6420\n",
      "Epoch 236/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6498 - val_loss: 0.6420\n",
      "Epoch 237/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6495 - val_loss: 0.6422\n",
      "Epoch 238/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6500 - val_loss: 0.6421\n",
      "Epoch 239/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6494 - val_loss: 0.6403\n",
      "Epoch 240/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6494 - val_loss: 0.6408\n",
      "Epoch 241/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6498 - val_loss: 0.6412\n",
      "Epoch 242/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6496 - val_loss: 0.6430\n",
      "Epoch 243/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6494 - val_loss: 0.6412\n",
      "Epoch 244/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6491 - val_loss: 0.6424\n",
      "Epoch 245/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6495 - val_loss: 0.6414\n",
      "Epoch 246/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6497 - val_loss: 0.6413\n",
      "Epoch 247/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6496 - val_loss: 0.6415\n",
      "Epoch 248/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6494 - val_loss: 0.6420\n",
      "Epoch 249/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6493 - val_loss: 0.6401\n",
      "Epoch 250/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6492 - val_loss: 0.6416\n",
      "Epoch 251/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6495 - val_loss: 0.6421\n",
      "Epoch 252/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6493 - val_loss: 0.6412\n",
      "Epoch 253/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6491 - val_loss: 0.6416\n",
      "Epoch 254/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6492 - val_loss: 0.6413\n",
      "Epoch 255/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6496 - val_loss: 0.6406\n",
      "Epoch 256/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6504 - val_loss: 0.6418\n",
      "Epoch 257/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6495 - val_loss: 0.6415\n",
      "Epoch 258/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6491 - val_loss: 0.6406\n",
      "Epoch 259/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6490 - val_loss: 0.6400\n",
      "Epoch 260/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6492 - val_loss: 0.6420\n",
      "Epoch 261/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6492 - val_loss: 0.6408\n",
      "Epoch 262/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6493 - val_loss: 0.6409\n",
      "Epoch 263/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6493 - val_loss: 0.6424\n",
      "Epoch 264/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6497 - val_loss: 0.6405\n",
      "Epoch 265/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6492 - val_loss: 0.6422\n",
      "Epoch 266/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6496 - val_loss: 0.6403\n",
      "Epoch 267/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6495 - val_loss: 0.6395\n",
      "Epoch 268/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6492 - val_loss: 0.6404\n",
      "Epoch 269/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6489 - val_loss: 0.6407\n",
      "Epoch 270/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6489 - val_loss: 0.6405\n",
      "Epoch 271/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6493 - val_loss: 0.6411\n",
      "Epoch 272/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6490 - val_loss: 0.6406\n",
      "Epoch 273/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6490 - val_loss: 0.6386\n",
      "Epoch 274/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6489 - val_loss: 0.6397\n",
      "Epoch 275/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6488 - val_loss: 0.6412\n",
      "Epoch 276/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6486 - val_loss: 0.6407\n",
      "Epoch 277/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6487 - val_loss: 0.6402\n",
      "Epoch 278/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6488 - val_loss: 0.6391\n",
      "Epoch 279/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6489 - val_loss: 0.6403\n",
      "Epoch 280/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.6491 - val_loss: 0.6412\n",
      "Epoch 281/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.6489 - val_loss: 0.6393\n",
      "Epoch 282/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6491 - val_loss: 0.6398\n",
      "Epoch 283/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6489 - val_loss: 0.6401\n",
      "Epoch 284/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6488 - val_loss: 0.6417\n",
      "Epoch 285/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6490 - val_loss: 0.6405\n",
      "Epoch 286/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6485 - val_loss: 0.6414\n",
      "Epoch 287/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6491 - val_loss: 0.6415\n",
      "Epoch 288/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6487 - val_loss: 0.6400\n",
      "Epoch 289/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6488 - val_loss: 0.6406\n",
      "Epoch 290/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6488 - val_loss: 0.6396\n",
      "Epoch 291/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6493 - val_loss: 0.6398\n",
      "Epoch 292/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6491 - val_loss: 0.6394\n",
      "Epoch 293/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6489 - val_loss: 0.6390\n",
      "Epoch 294/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6495 - val_loss: 0.6402\n",
      "Epoch 295/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6499 - val_loss: 0.6397\n",
      "Epoch 296/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6490 - val_loss: 0.6410\n",
      "Epoch 297/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6488 - val_loss: 0.6416\n",
      "Epoch 298/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6492 - val_loss: 0.6423\n",
      "Epoch 299/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6494 - val_loss: 0.6409\n",
      "Epoch 300/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6487 - val_loss: 0.6402\n",
      "Epoch 301/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6487 - val_loss: 0.6403\n",
      "Epoch 302/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6485 - val_loss: 0.6399\n",
      "Epoch 303/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6489 - val_loss: 0.6405\n",
      "Epoch 304/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6488 - val_loss: 0.6387\n",
      "Epoch 305/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6491 - val_loss: 0.6403\n",
      "Epoch 306/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6487 - val_loss: 0.6411\n",
      "Epoch 307/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6487 - val_loss: 0.6400\n",
      "Epoch 308/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6491 - val_loss: 0.6403\n",
      "Epoch 309/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6485 - val_loss: 0.6422\n",
      "Epoch 310/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6490 - val_loss: 0.6408\n",
      "Epoch 311/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6489 - val_loss: 0.6408\n",
      "Epoch 312/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6486 - val_loss: 0.6400\n",
      "Epoch 313/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6484 - val_loss: 0.6402\n",
      "Epoch 314/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6488 - val_loss: 0.6407\n",
      "Epoch 315/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6485 - val_loss: 0.6412\n",
      "Epoch 316/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6487 - val_loss: 0.6411\n",
      "Epoch 317/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6484 - val_loss: 0.6395\n",
      "Epoch 318/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6492 - val_loss: 0.6410\n",
      "Epoch 319/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6488 - val_loss: 0.6397\n",
      "Epoch 320/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6484 - val_loss: 0.6402\n",
      "Epoch 321/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6486 - val_loss: 0.6414\n",
      "Epoch 322/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6487 - val_loss: 0.6392\n",
      "Epoch 323/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6489 - val_loss: 0.6406\n",
      "Epoch 324/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6487 - val_loss: 0.6420\n",
      "Epoch 325/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6483 - val_loss: 0.6409\n",
      "Epoch 326/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6485 - val_loss: 0.6405\n",
      "Epoch 327/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6481 - val_loss: 0.6410\n",
      "Epoch 328/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6486 - val_loss: 0.6405\n",
      "Epoch 329/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6481 - val_loss: 0.6404\n",
      "Epoch 330/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6484 - val_loss: 0.6405\n",
      "Epoch 331/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6482 - val_loss: 0.6396\n",
      "Epoch 332/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6485 - val_loss: 0.6419\n",
      "Epoch 333/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6483 - val_loss: 0.6400\n",
      "Epoch 334/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6482 - val_loss: 0.6402\n",
      "Epoch 335/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6485 - val_loss: 0.6396\n",
      "Epoch 336/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6488 - val_loss: 0.6396\n",
      "Epoch 337/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6487 - val_loss: 0.6408\n",
      "Epoch 338/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6486 - val_loss: 0.6409\n",
      "Epoch 339/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6484 - val_loss: 0.6397\n",
      "Epoch 340/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6483 - val_loss: 0.6414\n",
      "Epoch 341/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6483 - val_loss: 0.6415\n",
      "Epoch 342/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6481 - val_loss: 0.6421\n",
      "Epoch 343/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6490 - val_loss: 0.6413\n",
      "Epoch 344/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6486 - val_loss: 0.6401\n",
      "Epoch 345/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6480 - val_loss: 0.6404\n",
      "Epoch 346/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6485 - val_loss: 0.6403\n",
      "Epoch 347/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6483 - val_loss: 0.6413\n",
      "Epoch 348/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6484 - val_loss: 0.6397\n",
      "Epoch 349/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6484 - val_loss: 0.6388\n",
      "Epoch 350/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6480 - val_loss: 0.6398\n",
      "Epoch 351/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6487 - val_loss: 0.6402\n",
      "Epoch 352/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6478 - val_loss: 0.6390\n",
      "Epoch 353/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6485 - val_loss: 0.6387\n",
      "Epoch 354/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6479 - val_loss: 0.6399\n",
      "Epoch 355/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6483 - val_loss: 0.6391\n",
      "Epoch 356/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6481 - val_loss: 0.6390\n",
      "Epoch 357/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6485 - val_loss: 0.6411\n",
      "Epoch 358/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6482 - val_loss: 0.6404\n",
      "Epoch 359/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6483 - val_loss: 0.6409\n",
      "Epoch 360/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6480 - val_loss: 0.6403\n",
      "Epoch 361/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6479 - val_loss: 0.6405\n",
      "Epoch 362/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6479 - val_loss: 0.6415\n",
      "Epoch 363/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6489 - val_loss: 0.6401\n",
      "Epoch 364/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6483 - val_loss: 0.6412\n",
      "Epoch 365/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6486 - val_loss: 0.6418\n",
      "Epoch 366/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6478 - val_loss: 0.6402\n",
      "Epoch 367/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6479 - val_loss: 0.6403\n",
      "Epoch 368/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6483 - val_loss: 0.6412\n",
      "Epoch 369/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6478 - val_loss: 0.6391\n",
      "Epoch 370/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6477 - val_loss: 0.6391\n",
      "Epoch 371/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6478 - val_loss: 0.6393\n",
      "Epoch 372/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6479 - val_loss: 0.6392\n",
      "Epoch 373/1000\n",
      "18/26 [===================>..........] - ETA: 0s - loss: 0.6490Restoring model weights from the end of the best epoch: 273.\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6477 - val_loss: 0.6387\n",
      "Epoch 373: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2bce33850>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_both_CMI_best5.fit(best5_CMI_train_withClass01,target_train_withClass01,validation_data=(best5_CMI_val_withClass01,target_val_withClass01),\n",
    "        callbacks=[monitor],epochs=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1a817cf6",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "0.2557372464499036\n",
      "0.2790083231613376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-13 14:48:07.285909: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "res0 = model_both_CMI_best5.predict(best5_CMI_test_withClass0.values)\n",
    "res1 = model_both_CMI_best5.predict(best5_CMI_test_withClass1.values)\n",
    "\n",
    "print(r2_score(target_df_test_E1.mean_std, res0))\n",
    "print(r2_score(target_df_test_E2.mean_std, res1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14cbdd5",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### one additional feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1cced3e9",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_28 (Dense)            (None, 15)                195       \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 16        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 211\n",
      "Trainable params: 211\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_both_CMI_best5 = Sequential()\n",
    "model_both_CMI_best5.add(Dense(15, input_dim=12, activation='relu')) \n",
    "model_both_CMI_best5.add(Dense(1)) # Output\n",
    "\n",
    "model_both_CMI_best5.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=100, \n",
    "        verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "model_both_CMI_best5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "683d8ed6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best5_CMI_train_withClass0 = pd.concat((best5_CMI_train_E1,best5_CMI_train_E2,pd.DataFrame(np.zeros(len(best5_CMI_train_E1)),columns=['basin']),pd.DataFrame(np.zeros(len(best5_CMI_train_E1)),columns=['basin2'])),axis=1)\n",
    "best5_CMI_train_withClass1 = pd.concat((best5_CMI_train_E1,best5_CMI_train_E2,pd.DataFrame(np.ones(len(best5_CMI_train_E1)),columns=['basin']),pd.DataFrame(np.ones(len(best5_CMI_train_E1)),columns=['basin2'])),axis=1)\n",
    "best5_CMI_train_withClass01 = np.concatenate((best5_CMI_train_withClass0.values,best5_CMI_train_withClass1.values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9053c301",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best5_CMI_val_withClass0 = pd.concat((best5_CMI_val_E1,best5_CMI_val_E2,pd.DataFrame(np.zeros(len(best5_CMI_val_E1)),columns=['basin2']),pd.DataFrame(np.zeros(len(best5_CMI_val_E1)),columns=['basin'])),axis=1)\n",
    "best5_CMI_val_withClass1 = pd.concat((best5_CMI_val_E1,best5_CMI_val_E2,pd.DataFrame(np.ones(len(best5_CMI_val_E1)),columns=['basin2']),pd.DataFrame(np.ones(len(best5_CMI_val_E1)),columns=['basin'])),axis=1)\n",
    "best5_CMI_val_withClass01 = np.concatenate((best5_CMI_val_withClass0.values,best5_CMI_val_withClass1.values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3ef708e7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best5_CMI_test_withClass0 = pd.concat((best5_CMI_test_E1,best5_CMI_test_E2,pd.DataFrame(np.zeros(len(best5_CMI_test_E1)),columns=['basin']),pd.DataFrame(np.zeros(len(best5_CMI_test_E1)),columns=['basin2'])),axis=1)\n",
    "best5_CMI_test_withClass1 = pd.concat((best5_CMI_test_E1,best5_CMI_test_E2,pd.DataFrame(np.ones(len(best5_CMI_test_E1)),columns=['basin']),pd.DataFrame(np.ones(len(best5_CMI_test_E1)),columns=['basin2'])),axis=1)\n",
    "best5_CMI_test_withClass01 = np.concatenate((best5_CMI_test_withClass0.values,best5_CMI_test_withClass1.values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9493f027",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "target_train_withClass01 = pd.concat((target_df_train_E1.mean_std,target_df_train_E2.mean_std),axis=0)\n",
    "target_val_withClass01 = pd.concat((target_df_val_E1.mean_std,target_df_val_E2.mean_std),axis=0)\n",
    "target_test_withClass01 = pd.concat((target_df_test_E1.mean_std,target_df_test_E2.mean_std),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "39063634",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.6599 - val_loss: 0.6987\n",
      "Epoch 2/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6587 - val_loss: 0.6995\n",
      "Epoch 3/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6555 - val_loss: 0.7014\n",
      "Epoch 4/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6534 - val_loss: 0.6984\n",
      "Epoch 5/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6520 - val_loss: 0.7005\n",
      "Epoch 6/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6513 - val_loss: 0.7000\n",
      "Epoch 7/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6497 - val_loss: 0.7049\n",
      "Epoch 8/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6494 - val_loss: 0.7057\n",
      "Epoch 9/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6471 - val_loss: 0.7085\n",
      "Epoch 10/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6449 - val_loss: 0.7052\n",
      "Epoch 11/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6437 - val_loss: 0.7055\n",
      "Epoch 12/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6429 - val_loss: 0.7009\n",
      "Epoch 13/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6413 - val_loss: 0.7012\n",
      "Epoch 14/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6397 - val_loss: 0.7054\n",
      "Epoch 15/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6396 - val_loss: 0.7078\n",
      "Epoch 16/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6375 - val_loss: 0.7142\n",
      "Epoch 17/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6367 - val_loss: 0.7067\n",
      "Epoch 18/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6341 - val_loss: 0.7112\n",
      "Epoch 19/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6345 - val_loss: 0.7138\n",
      "Epoch 20/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6324 - val_loss: 0.7095\n",
      "Epoch 21/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6320 - val_loss: 0.7135\n",
      "Epoch 22/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6299 - val_loss: 0.7125\n",
      "Epoch 23/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6292 - val_loss: 0.7133\n",
      "Epoch 24/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6283 - val_loss: 0.7151\n",
      "Epoch 25/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6268 - val_loss: 0.7112\n",
      "Epoch 26/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6267 - val_loss: 0.7154\n",
      "Epoch 27/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6261 - val_loss: 0.7169\n",
      "Epoch 28/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6252 - val_loss: 0.7134\n",
      "Epoch 29/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6251 - val_loss: 0.7145\n",
      "Epoch 30/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6256 - val_loss: 0.7150\n",
      "Epoch 31/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6231 - val_loss: 0.7215\n",
      "Epoch 32/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6232 - val_loss: 0.7184\n",
      "Epoch 33/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6216 - val_loss: 0.7183\n",
      "Epoch 34/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6222 - val_loss: 0.7230\n",
      "Epoch 35/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6212 - val_loss: 0.7199\n",
      "Epoch 36/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6204 - val_loss: 0.7169\n",
      "Epoch 37/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6189 - val_loss: 0.7223\n",
      "Epoch 38/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6175 - val_loss: 0.7254\n",
      "Epoch 39/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6174 - val_loss: 0.7243\n",
      "Epoch 40/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6166 - val_loss: 0.7241\n",
      "Epoch 41/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6172 - val_loss: 0.7264\n",
      "Epoch 42/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6167 - val_loss: 0.7259\n",
      "Epoch 43/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6147 - val_loss: 0.7277\n",
      "Epoch 44/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6142 - val_loss: 0.7296\n",
      "Epoch 45/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6133 - val_loss: 0.7302\n",
      "Epoch 46/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6124 - val_loss: 0.7281\n",
      "Epoch 47/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6126 - val_loss: 0.7221\n",
      "Epoch 48/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6124 - val_loss: 0.7337\n",
      "Epoch 49/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6114 - val_loss: 0.7328\n",
      "Epoch 50/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6105 - val_loss: 0.7289\n",
      "Epoch 51/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6092 - val_loss: 0.7293\n",
      "Epoch 52/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6088 - val_loss: 0.7315\n",
      "Epoch 53/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6089 - val_loss: 0.7355\n",
      "Epoch 54/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6094 - val_loss: 0.7361\n",
      "Epoch 55/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6082 - val_loss: 0.7334\n",
      "Epoch 56/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6075 - val_loss: 0.7345\n",
      "Epoch 57/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6068 - val_loss: 0.7355\n",
      "Epoch 58/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6064 - val_loss: 0.7344\n",
      "Epoch 59/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6058 - val_loss: 0.7333\n",
      "Epoch 60/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6050 - val_loss: 0.7363\n",
      "Epoch 61/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6042 - val_loss: 0.7312\n",
      "Epoch 62/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6041 - val_loss: 0.7418\n",
      "Epoch 63/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6036 - val_loss: 0.7338\n",
      "Epoch 64/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6021 - val_loss: 0.7328\n",
      "Epoch 65/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6029 - val_loss: 0.7321\n",
      "Epoch 66/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6036 - val_loss: 0.7420\n",
      "Epoch 67/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6030 - val_loss: 0.7299\n",
      "Epoch 68/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6017 - val_loss: 0.7350\n",
      "Epoch 69/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6012 - val_loss: 0.7349\n",
      "Epoch 70/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6003 - val_loss: 0.7354\n",
      "Epoch 71/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6006 - val_loss: 0.7363\n",
      "Epoch 72/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5993 - val_loss: 0.7361\n",
      "Epoch 73/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5983 - val_loss: 0.7390\n",
      "Epoch 74/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5985 - val_loss: 0.7388\n",
      "Epoch 75/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5982 - val_loss: 0.7370\n",
      "Epoch 76/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5970 - val_loss: 0.7381\n",
      "Epoch 77/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5967 - val_loss: 0.7397\n",
      "Epoch 78/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5957 - val_loss: 0.7424\n",
      "Epoch 79/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5952 - val_loss: 0.7337\n",
      "Epoch 80/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5964 - val_loss: 0.7441\n",
      "Epoch 81/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5949 - val_loss: 0.7424\n",
      "Epoch 82/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5948 - val_loss: 0.7410\n",
      "Epoch 83/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5945 - val_loss: 0.7423\n",
      "Epoch 84/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5948 - val_loss: 0.7441\n",
      "Epoch 85/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5933 - val_loss: 0.7433\n",
      "Epoch 86/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5930 - val_loss: 0.7433\n",
      "Epoch 87/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5921 - val_loss: 0.7431\n",
      "Epoch 88/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5921 - val_loss: 0.7429\n",
      "Epoch 89/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5911 - val_loss: 0.7469\n",
      "Epoch 90/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5919 - val_loss: 0.7425\n",
      "Epoch 91/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5917 - val_loss: 0.7436\n",
      "Epoch 92/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5918 - val_loss: 0.7481\n",
      "Epoch 93/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5905 - val_loss: 0.7494\n",
      "Epoch 94/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5895 - val_loss: 0.7466\n",
      "Epoch 95/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5907 - val_loss: 0.7431\n",
      "Epoch 96/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5882 - val_loss: 0.7477\n",
      "Epoch 97/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5892 - val_loss: 0.7407\n",
      "Epoch 98/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5886 - val_loss: 0.7507\n",
      "Epoch 99/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5878 - val_loss: 0.7428\n",
      "Epoch 100/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5877 - val_loss: 0.7547\n",
      "Epoch 101/1000\n",
      "18/26 [===================>..........] - ETA: 0s - loss: 0.5936Restoring model weights from the end of the best epoch: 1.\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5872 - val_loss: 0.7429\n",
      "Epoch 101: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c23b3b50>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_both_CMI_best5.fit(best5_CMI_train_withClass01,target_train_withClass01,validation_data=(best5_CMI_val_withClass01,target_val_withClass01),\n",
    "        callbacks=[monitor],epochs=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a9948022",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "0.14092015375049294\n",
      "0.11483063130551474\n"
     ]
    }
   ],
   "source": [
    "res0 = model_both_CMI_best5.predict(best5_CMI_test_withClass0.values)\n",
    "res1 = model_both_CMI_best5.predict(best5_CMI_test_withClass1.values)\n",
    "\n",
    "print(r2_score(target_df_test_E1.mean_std, res0))\n",
    "print(r2_score(target_df_test_E2.mean_std, res1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d4877e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### additive linear regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d021d4e4",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cyclostationary_mean_rr_4w_0</th>\n",
       "      <th>cyclostationary_mean_tg_1w_4</th>\n",
       "      <th>cyclostationary_mean_rr_12w_1</th>\n",
       "      <th>cyclostationary_mean_rr_8w_1</th>\n",
       "      <th>cyclostationary_mean_tg_9</th>\n",
       "      <th>cyclostationary_mean_tg_1w_4</th>\n",
       "      <th>cyclostationary_mean_rr_4w_3</th>\n",
       "      <th>cyclostationary_mean_tg_4</th>\n",
       "      <th>cyclostationary_mean_rr_8w_0</th>\n",
       "      <th>cyclostationary_mean_rr_12w_1</th>\n",
       "      <th>basin</th>\n",
       "      <th>basin2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.112078</td>\n",
       "      <td>0.345989</td>\n",
       "      <td>1.690770</td>\n",
       "      <td>3.965287</td>\n",
       "      <td>0.268224</td>\n",
       "      <td>-0.415835</td>\n",
       "      <td>0.733822</td>\n",
       "      <td>-0.736407</td>\n",
       "      <td>2.581050</td>\n",
       "      <td>1.579481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.404523</td>\n",
       "      <td>1.128851</td>\n",
       "      <td>1.865833</td>\n",
       "      <td>1.655892</td>\n",
       "      <td>0.977612</td>\n",
       "      <td>0.237307</td>\n",
       "      <td>0.849889</td>\n",
       "      <td>0.294888</td>\n",
       "      <td>2.460299</td>\n",
       "      <td>1.146518</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.162736</td>\n",
       "      <td>0.786460</td>\n",
       "      <td>1.429151</td>\n",
       "      <td>1.672157</td>\n",
       "      <td>-0.780151</td>\n",
       "      <td>-0.259989</td>\n",
       "      <td>0.518355</td>\n",
       "      <td>-1.191392</td>\n",
       "      <td>1.657472</td>\n",
       "      <td>0.697926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.861999</td>\n",
       "      <td>0.564161</td>\n",
       "      <td>0.611897</td>\n",
       "      <td>1.593990</td>\n",
       "      <td>0.408553</td>\n",
       "      <td>-0.565851</td>\n",
       "      <td>0.239497</td>\n",
       "      <td>0.067063</td>\n",
       "      <td>1.600489</td>\n",
       "      <td>0.578318</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.461930</td>\n",
       "      <td>0.604584</td>\n",
       "      <td>4.150391</td>\n",
       "      <td>1.782496</td>\n",
       "      <td>-0.260577</td>\n",
       "      <td>-0.187005</td>\n",
       "      <td>0.696217</td>\n",
       "      <td>-0.894857</td>\n",
       "      <td>1.249495</td>\n",
       "      <td>0.843396</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>-0.211596</td>\n",
       "      <td>0.739113</td>\n",
       "      <td>-0.281990</td>\n",
       "      <td>-0.636426</td>\n",
       "      <td>1.599630</td>\n",
       "      <td>1.352614</td>\n",
       "      <td>-0.220555</td>\n",
       "      <td>0.471800</td>\n",
       "      <td>-0.187672</td>\n",
       "      <td>-0.422427</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>-0.765747</td>\n",
       "      <td>0.855313</td>\n",
       "      <td>-0.234571</td>\n",
       "      <td>-1.204469</td>\n",
       "      <td>0.920235</td>\n",
       "      <td>1.040390</td>\n",
       "      <td>0.346445</td>\n",
       "      <td>0.034058</td>\n",
       "      <td>-0.358316</td>\n",
       "      <td>-0.518833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>-0.609296</td>\n",
       "      <td>0.697286</td>\n",
       "      <td>-0.562017</td>\n",
       "      <td>-1.089158</td>\n",
       "      <td>0.341994</td>\n",
       "      <td>0.830698</td>\n",
       "      <td>0.429694</td>\n",
       "      <td>0.796373</td>\n",
       "      <td>-0.106524</td>\n",
       "      <td>-0.588942</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>-0.836849</td>\n",
       "      <td>-0.719738</td>\n",
       "      <td>-0.028118</td>\n",
       "      <td>-0.925439</td>\n",
       "      <td>-1.523290</td>\n",
       "      <td>-0.631908</td>\n",
       "      <td>-0.434877</td>\n",
       "      <td>-2.562406</td>\n",
       "      <td>-0.028237</td>\n",
       "      <td>-0.468533</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-0.283715</td>\n",
       "      <td>-1.078052</td>\n",
       "      <td>0.226971</td>\n",
       "      <td>-0.799403</td>\n",
       "      <td>-0.625862</td>\n",
       "      <td>-1.226069</td>\n",
       "      <td>0.334461</td>\n",
       "      <td>-0.263730</td>\n",
       "      <td>0.344734</td>\n",
       "      <td>-0.241170</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>822 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cyclostationary_mean_rr_4w_0  cyclostationary_mean_tg_1w_4  \\\n",
       "0                        2.112078                      0.345989   \n",
       "1                        1.404523                      1.128851   \n",
       "2                        1.162736                      0.786460   \n",
       "3                        0.861999                      0.564161   \n",
       "4                        1.461930                      0.604584   \n",
       "..                            ...                           ...   \n",
       "406                     -0.211596                      0.739113   \n",
       "407                     -0.765747                      0.855313   \n",
       "408                     -0.609296                      0.697286   \n",
       "409                     -0.836849                     -0.719738   \n",
       "410                     -0.283715                     -1.078052   \n",
       "\n",
       "     cyclostationary_mean_rr_12w_1  cyclostationary_mean_rr_8w_1  \\\n",
       "0                         1.690770                      3.965287   \n",
       "1                         1.865833                      1.655892   \n",
       "2                         1.429151                      1.672157   \n",
       "3                         0.611897                      1.593990   \n",
       "4                         4.150391                      1.782496   \n",
       "..                             ...                           ...   \n",
       "406                      -0.281990                     -0.636426   \n",
       "407                      -0.234571                     -1.204469   \n",
       "408                      -0.562017                     -1.089158   \n",
       "409                      -0.028118                     -0.925439   \n",
       "410                       0.226971                     -0.799403   \n",
       "\n",
       "     cyclostationary_mean_tg_9  cyclostationary_mean_tg_1w_4  \\\n",
       "0                     0.268224                     -0.415835   \n",
       "1                     0.977612                      0.237307   \n",
       "2                    -0.780151                     -0.259989   \n",
       "3                     0.408553                     -0.565851   \n",
       "4                    -0.260577                     -0.187005   \n",
       "..                         ...                           ...   \n",
       "406                   1.599630                      1.352614   \n",
       "407                   0.920235                      1.040390   \n",
       "408                   0.341994                      0.830698   \n",
       "409                  -1.523290                     -0.631908   \n",
       "410                  -0.625862                     -1.226069   \n",
       "\n",
       "     cyclostationary_mean_rr_4w_3  cyclostationary_mean_tg_4  \\\n",
       "0                        0.733822                  -0.736407   \n",
       "1                        0.849889                   0.294888   \n",
       "2                        0.518355                  -1.191392   \n",
       "3                        0.239497                   0.067063   \n",
       "4                        0.696217                  -0.894857   \n",
       "..                            ...                        ...   \n",
       "406                     -0.220555                   0.471800   \n",
       "407                      0.346445                   0.034058   \n",
       "408                      0.429694                   0.796373   \n",
       "409                     -0.434877                  -2.562406   \n",
       "410                      0.334461                  -0.263730   \n",
       "\n",
       "     cyclostationary_mean_rr_8w_0  cyclostationary_mean_rr_12w_1  basin  \\\n",
       "0                        2.581050                       1.579481    0.0   \n",
       "1                        2.460299                       1.146518    0.0   \n",
       "2                        1.657472                       0.697926    0.0   \n",
       "3                        1.600489                       0.578318    0.0   \n",
       "4                        1.249495                       0.843396    0.0   \n",
       "..                            ...                            ...    ...   \n",
       "406                     -0.187672                      -0.422427    1.0   \n",
       "407                     -0.358316                      -0.518833    1.0   \n",
       "408                     -0.106524                      -0.588942    1.0   \n",
       "409                     -0.028237                      -0.468533    1.0   \n",
       "410                      0.344734                      -0.241170    1.0   \n",
       "\n",
       "     basin2  \n",
       "0       1.0  \n",
       "1       1.0  \n",
       "2       1.0  \n",
       "3       1.0  \n",
       "4       1.0  \n",
       "..      ...  \n",
       "406     0.0  \n",
       "407     0.0  \n",
       "408     0.0  \n",
       "409     0.0  \n",
       "410     0.0  \n",
       "\n",
       "[822 rows x 12 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best5_CMI_train_withClass0 = pd.concat((best5_CMI_train_E1,best5_CMI_train_E2,pd.DataFrame(np.zeros(len(best5_CMI_train_E1)),columns=['basin']),pd.DataFrame(np.ones(len(best5_CMI_train_E1)),columns=['basin2'])),axis=1)\n",
    "best5_CMI_train_withClass1 = pd.concat((best5_CMI_train_E1,best5_CMI_train_E2,pd.DataFrame(np.ones(len(best5_CMI_train_E1)),columns=['basin']),pd.DataFrame(np.zeros(len(best5_CMI_train_E1)),columns=['basin2'])),axis=1)\n",
    "best5_CMI_train_withClass01 = pd.concat((best5_CMI_train_withClass0,best5_CMI_train_withClass1),axis=0)\n",
    "best5_CMI_train_withClass01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "cb560a2a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best5_CMI_val_withClass0 = pd.concat((best5_CMI_val_E1,best5_CMI_val_E2,pd.DataFrame(np.zeros(len(best5_CMI_val_E1)),columns=['basin']),pd.DataFrame(np.ones(len(best5_CMI_val_E1)),columns=['basin2'])),axis=1)\n",
    "best5_CMI_val_withClass1 = pd.concat((best5_CMI_val_E1,best5_CMI_val_E2,pd.DataFrame(np.ones(len(best5_CMI_val_E1)),columns=['basin']),pd.DataFrame(np.zeros(len(best5_CMI_val_E1)),columns=['basin2'])),axis=1)\n",
    "best5_CMI_val_withClass01 = pd.concat((best5_CMI_val_withClass0,best5_CMI_val_withClass1),axis=0)\n",
    "\n",
    "best5_CMI_test_withClass0 = pd.concat((best5_CMI_test_E1,best5_CMI_test_E2,pd.DataFrame(np.zeros(len(best5_CMI_test_E1)),columns=['basin']),pd.DataFrame(np.ones(len(best5_CMI_val_E1)),columns=['basin2'])),axis=1)\n",
    "best5_CMI_test_withClass1 = pd.concat((best5_CMI_test_E1,best5_CMI_test_E2,pd.DataFrame(np.ones(len(best5_CMI_test_E1)),columns=['basin']),pd.DataFrame(np.zeros(len(best5_CMI_val_E1)),columns=['basin2'])),axis=1)\n",
    "best5_CMI_test_withClass01 = pd.concat((best5_CMI_test_withClass0,best5_CMI_test_withClass1),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b6c67758",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "target_train_withClass01 = pd.concat((target_df_train_E1.mean_std,target_df_train_E2.mean_std),axis=0)\n",
    "target_val_withClass01 = pd.concat((target_df_val_E1.mean_std,target_df_val_E2.mean_std),axis=0)\n",
    "target_test_withClass01 = pd.concat((target_df_test_E1.mean_std,target_df_test_E2.mean_std),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "9e81e4a4",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(pd.concat((best5_CMI_train_withClass01,best5_CMI_val_withClass01)),pd.concat((target_train_withClass01,target_val_withClass01)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "7671fe2d",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34484914195705985\n",
      "0.2496609343242968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "res0 = model.predict(best5_CMI_test_withClass0.values)\n",
    "res1 = model.predict(best5_CMI_test_withClass1.values)\n",
    "\n",
    "print(r2_score(target_df_test_E1.mean_std, res0))\n",
    "print(r2_score(target_df_test_E2.mean_std, res1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c10bf4e9",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.23585931, -0.11134115,  0.17230418, -0.0261571 , -0.14259048,\n",
       "        0.06147449,  0.08651069, -0.13714384,  0.04001579, -0.03765344,\n",
       "        0.0128004 , -0.0128004 ])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "102d10db",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.00598513085606607"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "2fd9f126",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3364734050935926\n"
     ]
    }
   ],
   "source": [
    "model0 = LinearRegression()\n",
    "model0.fit(pd.concat((best5_CMI_train_E1,best5_CMI_val_E1)),pd.concat((target_df_train_E1.mean_std,target_df_val_E1.mean_std)))\n",
    "res00 = model0.predict(best5_CMI_test_E1)\n",
    "print(r2_score(target_df_test_E1.mean_std, res00))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d68552ca",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.33220598, -0.09123719,  0.18002624,  0.0414309 , -0.24917049])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model0.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "996bbdb0",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.009909447498446716"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model0.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "2f1b3d1d",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23062800854005472\n"
     ]
    }
   ],
   "source": [
    "model1 = LinearRegression()\n",
    "model1.fit(pd.concat((best5_CMI_train_E2,best5_CMI_val_E2)),pd.concat((target_df_train_E2.mean_std,target_df_val_E2.mean_std)))\n",
    "res11 = model1.predict(best5_CMI_test_E2)\n",
    "print(r2_score(target_df_test_E2.mean_std, res11))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "215bc4f4",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(pd.concat((best5_CMI_train_withClass01.iloc[:,:-2],best5_CMI_val_withClass01.iloc[:,:-2])),pd.concat((target_train_withClass01,target_val_withClass01)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "0a183e7e",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34785910131234443\n",
      "0.24779119186940968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "res0_noclass = model.predict(best5_CMI_test_withClass0.iloc[:,:-2].values)\n",
    "res1_noclasss1 = model.predict(best5_CMI_test_withClass1.iloc[:,:-2].values)\n",
    "\n",
    "print(r2_score(target_df_test_E1.mean_std, res0_noclass))\n",
    "print(r2_score(target_df_test_E2.mean_std, res1_noclasss1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "aa5c4cc6",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.005985130856066084"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "915e25a4",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model_only0 = LinearRegression()\n",
    "model_only0.fit(pd.concat((best5_CMI_train_withClass0.iloc[:,:-2],best5_CMI_val_withClass0.iloc[:,:-2])),pd.concat((target_df_train_E1.mean_std,target_df_val_E1.mean_std)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "34930f45",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3471864948497688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "res_only0 = model_only0.predict(best5_CMI_test_withClass0.iloc[:,:-2].values)\n",
    "print(r2_score(target_df_test_E1.mean_std, res_only0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b1a789",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model_only0 = LinearRegression()\n",
    "model_only0.fit(pd.concat((best5_CMI_train_withClass0.iloc[:,:-2],best5_CMI_val_withClass0.iloc[:,:-2])),pd.concat((target_df_train_E1.mean_std,target_df_val_E1.mean_std)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faaf2d6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model_only0 = LinearRegression()\n",
    "model_only0.fit(pd.concat((best5_CMI_train_withClass0.iloc[:,:-2],best5_CMI_val_withClass0.iloc[:,:-2])),pd.concat((target_df_train_E1.mean_std,target_df_val_E1.mean_std)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ea6ae05b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### metto anche tutte le interazioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "17c5032a",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cyclostationary_mean_rr_4w_0_basin</th>\n",
       "      <th>cyclostationary_mean_tg_1w_4_basin</th>\n",
       "      <th>cyclostationary_mean_rr_12w_1_basin</th>\n",
       "      <th>cyclostationary_mean_rr_8w_1_basin</th>\n",
       "      <th>cyclostationary_mean_tg_9_basin</th>\n",
       "      <th>cyclostationary_mean_tg_1w_4_basin2</th>\n",
       "      <th>cyclostationary_mean_rr_4w_3_basin2</th>\n",
       "      <th>cyclostationary_mean_tg_4_basin2</th>\n",
       "      <th>cyclostationary_mean_rr_8w_0_basin2</th>\n",
       "      <th>cyclostationary_mean_rr_12w_1_basin2</th>\n",
       "      <th>basin</th>\n",
       "      <th>basin2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.112078</td>\n",
       "      <td>0.345989</td>\n",
       "      <td>1.690770</td>\n",
       "      <td>3.965287</td>\n",
       "      <td>0.268224</td>\n",
       "      <td>-0.415835</td>\n",
       "      <td>0.733822</td>\n",
       "      <td>-0.736407</td>\n",
       "      <td>2.581050</td>\n",
       "      <td>1.579481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.404523</td>\n",
       "      <td>1.128851</td>\n",
       "      <td>1.865833</td>\n",
       "      <td>1.655892</td>\n",
       "      <td>0.977612</td>\n",
       "      <td>0.237307</td>\n",
       "      <td>0.849889</td>\n",
       "      <td>0.294888</td>\n",
       "      <td>2.460299</td>\n",
       "      <td>1.146518</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.162736</td>\n",
       "      <td>0.786460</td>\n",
       "      <td>1.429151</td>\n",
       "      <td>1.672157</td>\n",
       "      <td>-0.780151</td>\n",
       "      <td>-0.259989</td>\n",
       "      <td>0.518355</td>\n",
       "      <td>-1.191392</td>\n",
       "      <td>1.657472</td>\n",
       "      <td>0.697926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.861999</td>\n",
       "      <td>0.564161</td>\n",
       "      <td>0.611897</td>\n",
       "      <td>1.593990</td>\n",
       "      <td>0.408553</td>\n",
       "      <td>-0.565851</td>\n",
       "      <td>0.239497</td>\n",
       "      <td>0.067063</td>\n",
       "      <td>1.600489</td>\n",
       "      <td>0.578318</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.461930</td>\n",
       "      <td>0.604584</td>\n",
       "      <td>4.150391</td>\n",
       "      <td>1.782496</td>\n",
       "      <td>-0.260577</td>\n",
       "      <td>-0.187005</td>\n",
       "      <td>0.696217</td>\n",
       "      <td>-0.894857</td>\n",
       "      <td>1.249495</td>\n",
       "      <td>0.843396</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>-0.211596</td>\n",
       "      <td>0.739113</td>\n",
       "      <td>-0.281990</td>\n",
       "      <td>-0.636426</td>\n",
       "      <td>1.599630</td>\n",
       "      <td>1.352614</td>\n",
       "      <td>-0.220555</td>\n",
       "      <td>0.471800</td>\n",
       "      <td>-0.187672</td>\n",
       "      <td>-0.422427</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>-0.765747</td>\n",
       "      <td>0.855313</td>\n",
       "      <td>-0.234571</td>\n",
       "      <td>-1.204469</td>\n",
       "      <td>0.920235</td>\n",
       "      <td>1.040390</td>\n",
       "      <td>0.346445</td>\n",
       "      <td>0.034058</td>\n",
       "      <td>-0.358316</td>\n",
       "      <td>-0.518833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>-0.609296</td>\n",
       "      <td>0.697286</td>\n",
       "      <td>-0.562017</td>\n",
       "      <td>-1.089158</td>\n",
       "      <td>0.341994</td>\n",
       "      <td>0.830698</td>\n",
       "      <td>0.429694</td>\n",
       "      <td>0.796373</td>\n",
       "      <td>-0.106524</td>\n",
       "      <td>-0.588942</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>-0.836849</td>\n",
       "      <td>-0.719738</td>\n",
       "      <td>-0.028118</td>\n",
       "      <td>-0.925439</td>\n",
       "      <td>-1.523290</td>\n",
       "      <td>-0.631908</td>\n",
       "      <td>-0.434877</td>\n",
       "      <td>-2.562406</td>\n",
       "      <td>-0.028237</td>\n",
       "      <td>-0.468533</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-0.283715</td>\n",
       "      <td>-1.078052</td>\n",
       "      <td>0.226971</td>\n",
       "      <td>-0.799403</td>\n",
       "      <td>-0.625862</td>\n",
       "      <td>-1.226069</td>\n",
       "      <td>0.334461</td>\n",
       "      <td>-0.263730</td>\n",
       "      <td>0.344734</td>\n",
       "      <td>-0.241170</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>822 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cyclostationary_mean_rr_4w_0_basin  cyclostationary_mean_tg_1w_4_basin  \\\n",
       "0                              2.112078                            0.345989   \n",
       "1                              1.404523                            1.128851   \n",
       "2                              1.162736                            0.786460   \n",
       "3                              0.861999                            0.564161   \n",
       "4                              1.461930                            0.604584   \n",
       "..                                  ...                                 ...   \n",
       "406                           -0.211596                            0.739113   \n",
       "407                           -0.765747                            0.855313   \n",
       "408                           -0.609296                            0.697286   \n",
       "409                           -0.836849                           -0.719738   \n",
       "410                           -0.283715                           -1.078052   \n",
       "\n",
       "     cyclostationary_mean_rr_12w_1_basin  cyclostationary_mean_rr_8w_1_basin  \\\n",
       "0                               1.690770                            3.965287   \n",
       "1                               1.865833                            1.655892   \n",
       "2                               1.429151                            1.672157   \n",
       "3                               0.611897                            1.593990   \n",
       "4                               4.150391                            1.782496   \n",
       "..                                   ...                                 ...   \n",
       "406                            -0.281990                           -0.636426   \n",
       "407                            -0.234571                           -1.204469   \n",
       "408                            -0.562017                           -1.089158   \n",
       "409                            -0.028118                           -0.925439   \n",
       "410                             0.226971                           -0.799403   \n",
       "\n",
       "     cyclostationary_mean_tg_9_basin  cyclostationary_mean_tg_1w_4_basin2  \\\n",
       "0                           0.268224                            -0.415835   \n",
       "1                           0.977612                             0.237307   \n",
       "2                          -0.780151                            -0.259989   \n",
       "3                           0.408553                            -0.565851   \n",
       "4                          -0.260577                            -0.187005   \n",
       "..                               ...                                  ...   \n",
       "406                         1.599630                             1.352614   \n",
       "407                         0.920235                             1.040390   \n",
       "408                         0.341994                             0.830698   \n",
       "409                        -1.523290                            -0.631908   \n",
       "410                        -0.625862                            -1.226069   \n",
       "\n",
       "     cyclostationary_mean_rr_4w_3_basin2  cyclostationary_mean_tg_4_basin2  \\\n",
       "0                               0.733822                         -0.736407   \n",
       "1                               0.849889                          0.294888   \n",
       "2                               0.518355                         -1.191392   \n",
       "3                               0.239497                          0.067063   \n",
       "4                               0.696217                         -0.894857   \n",
       "..                                   ...                               ...   \n",
       "406                            -0.220555                          0.471800   \n",
       "407                             0.346445                          0.034058   \n",
       "408                             0.429694                          0.796373   \n",
       "409                            -0.434877                         -2.562406   \n",
       "410                             0.334461                         -0.263730   \n",
       "\n",
       "     cyclostationary_mean_rr_8w_0_basin2  \\\n",
       "0                               2.581050   \n",
       "1                               2.460299   \n",
       "2                               1.657472   \n",
       "3                               1.600489   \n",
       "4                               1.249495   \n",
       "..                                   ...   \n",
       "406                            -0.187672   \n",
       "407                            -0.358316   \n",
       "408                            -0.106524   \n",
       "409                            -0.028237   \n",
       "410                             0.344734   \n",
       "\n",
       "     cyclostationary_mean_rr_12w_1_basin2  basin  basin2  \n",
       "0                                1.579481    0.0     1.0  \n",
       "1                                1.146518    0.0     1.0  \n",
       "2                                0.697926    0.0     1.0  \n",
       "3                                0.578318    0.0     1.0  \n",
       "4                                0.843396    0.0     1.0  \n",
       "..                                    ...    ...     ...  \n",
       "406                             -0.422427    1.0     0.0  \n",
       "407                             -0.518833    1.0     0.0  \n",
       "408                             -0.588942    1.0     0.0  \n",
       "409                             -0.468533    1.0     0.0  \n",
       "410                             -0.241170    1.0     0.0  \n",
       "\n",
       "[822 rows x 12 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best5_CMI_train_withClass0 = pd.concat((best5_CMI_train_E1.add_suffix('_basin'),best5_CMI_train_E2.add_suffix('_basin2'),pd.DataFrame(np.zeros(len(best5_CMI_train_E1)),columns=['basin']),pd.DataFrame(np.ones(len(best5_CMI_train_E1)),columns=['basin2'])),axis=1)\n",
    "best5_CMI_train_withClass1 = pd.concat((best5_CMI_train_E1.add_suffix('_basin'),best5_CMI_train_E2.add_suffix('_basin2'),pd.DataFrame(np.ones(len(best5_CMI_train_E1)),columns=['basin']),pd.DataFrame(np.zeros(len(best5_CMI_train_E1)),columns=['basin2'])),axis=1)\n",
    "best5_CMI_train_withClass01 = pd.concat((best5_CMI_train_withClass0,best5_CMI_train_withClass1),axis=0)\n",
    "best5_CMI_train_withClass01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "87238cba",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best5_CMI_val_withClass0 = pd.concat((best5_CMI_val_E1.add_suffix('_basin'),best5_CMI_val_E2.add_suffix('_basin2'),pd.DataFrame(np.zeros(len(best5_CMI_val_E1)),columns=['basin']),pd.DataFrame(np.ones(len(best5_CMI_val_E1)),columns=['basin2'])),axis=1)\n",
    "best5_CMI_val_withClass1 = pd.concat((best5_CMI_val_E1.add_suffix('_basin'),best5_CMI_val_E2.add_suffix('_basin2'),pd.DataFrame(np.ones(len(best5_CMI_val_E1)),columns=['basin']),pd.DataFrame(np.zeros(len(best5_CMI_val_E1)),columns=['basin2'])),axis=1)\n",
    "best5_CMI_val_withClass01 = pd.concat((best5_CMI_val_withClass0,best5_CMI_val_withClass1),axis=0)\n",
    "\n",
    "best5_CMI_test_withClass0 = pd.concat((best5_CMI_test_E1.add_suffix('_basin'),best5_CMI_test_E2.add_suffix('_basin2'),pd.DataFrame(np.zeros(len(best5_CMI_test_E1)),columns=['basin']),pd.DataFrame(np.ones(len(best5_CMI_val_E1)),columns=['basin2'])),axis=1)\n",
    "best5_CMI_test_withClass1 = pd.concat((best5_CMI_test_E1.add_suffix('_basin'),best5_CMI_test_E2.add_suffix('_basin2'),pd.DataFrame(np.ones(len(best5_CMI_test_E1)),columns=['basin']),pd.DataFrame(np.zeros(len(best5_CMI_val_E1)),columns=['basin2'])),axis=1)\n",
    "best5_CMI_test_withClass01 = pd.concat((best5_CMI_test_withClass0,best5_CMI_test_withClass1),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "35864fbe",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cyclostationary_mean_rr_4w_0_basin</th>\n",
       "      <th>cyclostationary_mean_tg_1w_4_basin</th>\n",
       "      <th>cyclostationary_mean_rr_12w_1_basin</th>\n",
       "      <th>cyclostationary_mean_rr_8w_1_basin</th>\n",
       "      <th>cyclostationary_mean_tg_9_basin</th>\n",
       "      <th>cyclostationary_mean_tg_1w_4_basin2</th>\n",
       "      <th>cyclostationary_mean_rr_4w_3_basin2</th>\n",
       "      <th>cyclostationary_mean_tg_4_basin2</th>\n",
       "      <th>cyclostationary_mean_rr_8w_0_basin2</th>\n",
       "      <th>cyclostationary_mean_rr_12w_1_basin2</th>\n",
       "      <th>basin</th>\n",
       "      <th>basin2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.112078</td>\n",
       "      <td>0.345989</td>\n",
       "      <td>1.690770</td>\n",
       "      <td>3.965287</td>\n",
       "      <td>0.268224</td>\n",
       "      <td>-0.415835</td>\n",
       "      <td>0.733822</td>\n",
       "      <td>-0.736407</td>\n",
       "      <td>2.581050</td>\n",
       "      <td>1.579481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.404523</td>\n",
       "      <td>1.128851</td>\n",
       "      <td>1.865833</td>\n",
       "      <td>1.655892</td>\n",
       "      <td>0.977612</td>\n",
       "      <td>0.237307</td>\n",
       "      <td>0.849889</td>\n",
       "      <td>0.294888</td>\n",
       "      <td>2.460299</td>\n",
       "      <td>1.146518</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.162736</td>\n",
       "      <td>0.786460</td>\n",
       "      <td>1.429151</td>\n",
       "      <td>1.672157</td>\n",
       "      <td>-0.780151</td>\n",
       "      <td>-0.259989</td>\n",
       "      <td>0.518355</td>\n",
       "      <td>-1.191392</td>\n",
       "      <td>1.657472</td>\n",
       "      <td>0.697926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.861999</td>\n",
       "      <td>0.564161</td>\n",
       "      <td>0.611897</td>\n",
       "      <td>1.593990</td>\n",
       "      <td>0.408553</td>\n",
       "      <td>-0.565851</td>\n",
       "      <td>0.239497</td>\n",
       "      <td>0.067063</td>\n",
       "      <td>1.600489</td>\n",
       "      <td>0.578318</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.461930</td>\n",
       "      <td>0.604584</td>\n",
       "      <td>4.150391</td>\n",
       "      <td>1.782496</td>\n",
       "      <td>-0.260577</td>\n",
       "      <td>-0.187005</td>\n",
       "      <td>0.696217</td>\n",
       "      <td>-0.894857</td>\n",
       "      <td>1.249495</td>\n",
       "      <td>0.843396</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>-0.608772</td>\n",
       "      <td>2.159366</td>\n",
       "      <td>1.128914</td>\n",
       "      <td>0.745100</td>\n",
       "      <td>0.624547</td>\n",
       "      <td>2.050920</td>\n",
       "      <td>1.182447</td>\n",
       "      <td>0.848215</td>\n",
       "      <td>1.287369</td>\n",
       "      <td>0.181394</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>-0.325822</td>\n",
       "      <td>1.311011</td>\n",
       "      <td>0.790244</td>\n",
       "      <td>0.037201</td>\n",
       "      <td>1.691934</td>\n",
       "      <td>1.776750</td>\n",
       "      <td>1.931919</td>\n",
       "      <td>1.300383</td>\n",
       "      <td>1.500711</td>\n",
       "      <td>0.244831</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>0.588081</td>\n",
       "      <td>1.354429</td>\n",
       "      <td>1.428052</td>\n",
       "      <td>0.170754</td>\n",
       "      <td>1.924323</td>\n",
       "      <td>1.963611</td>\n",
       "      <td>2.777644</td>\n",
       "      <td>1.044000</td>\n",
       "      <td>1.878066</td>\n",
       "      <td>0.317723</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0.360721</td>\n",
       "      <td>1.653467</td>\n",
       "      <td>1.152108</td>\n",
       "      <td>0.094855</td>\n",
       "      <td>1.546077</td>\n",
       "      <td>1.734032</td>\n",
       "      <td>2.563059</td>\n",
       "      <td>1.124935</td>\n",
       "      <td>1.799993</td>\n",
       "      <td>0.278011</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>0.107863</td>\n",
       "      <td>1.265916</td>\n",
       "      <td>0.578823</td>\n",
       "      <td>-0.634415</td>\n",
       "      <td>1.023210</td>\n",
       "      <td>1.748151</td>\n",
       "      <td>0.244175</td>\n",
       "      <td>1.295160</td>\n",
       "      <td>1.036511</td>\n",
       "      <td>0.081538</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1278 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cyclostationary_mean_rr_4w_0_basin  cyclostationary_mean_tg_1w_4_basin  \\\n",
       "0                              2.112078                            0.345989   \n",
       "1                              1.404523                            1.128851   \n",
       "2                              1.162736                            0.786460   \n",
       "3                              0.861999                            0.564161   \n",
       "4                              1.461930                            0.604584   \n",
       "..                                  ...                                 ...   \n",
       "223                           -0.608772                            2.159366   \n",
       "224                           -0.325822                            1.311011   \n",
       "225                            0.588081                            1.354429   \n",
       "226                            0.360721                            1.653467   \n",
       "227                            0.107863                            1.265916   \n",
       "\n",
       "     cyclostationary_mean_rr_12w_1_basin  cyclostationary_mean_rr_8w_1_basin  \\\n",
       "0                               1.690770                            3.965287   \n",
       "1                               1.865833                            1.655892   \n",
       "2                               1.429151                            1.672157   \n",
       "3                               0.611897                            1.593990   \n",
       "4                               4.150391                            1.782496   \n",
       "..                                   ...                                 ...   \n",
       "223                             1.128914                            0.745100   \n",
       "224                             0.790244                            0.037201   \n",
       "225                             1.428052                            0.170754   \n",
       "226                             1.152108                            0.094855   \n",
       "227                             0.578823                           -0.634415   \n",
       "\n",
       "     cyclostationary_mean_tg_9_basin  cyclostationary_mean_tg_1w_4_basin2  \\\n",
       "0                           0.268224                            -0.415835   \n",
       "1                           0.977612                             0.237307   \n",
       "2                          -0.780151                            -0.259989   \n",
       "3                           0.408553                            -0.565851   \n",
       "4                          -0.260577                            -0.187005   \n",
       "..                               ...                                  ...   \n",
       "223                         0.624547                             2.050920   \n",
       "224                         1.691934                             1.776750   \n",
       "225                         1.924323                             1.963611   \n",
       "226                         1.546077                             1.734032   \n",
       "227                         1.023210                             1.748151   \n",
       "\n",
       "     cyclostationary_mean_rr_4w_3_basin2  cyclostationary_mean_tg_4_basin2  \\\n",
       "0                               0.733822                         -0.736407   \n",
       "1                               0.849889                          0.294888   \n",
       "2                               0.518355                         -1.191392   \n",
       "3                               0.239497                          0.067063   \n",
       "4                               0.696217                         -0.894857   \n",
       "..                                   ...                               ...   \n",
       "223                             1.182447                          0.848215   \n",
       "224                             1.931919                          1.300383   \n",
       "225                             2.777644                          1.044000   \n",
       "226                             2.563059                          1.124935   \n",
       "227                             0.244175                          1.295160   \n",
       "\n",
       "     cyclostationary_mean_rr_8w_0_basin2  \\\n",
       "0                               2.581050   \n",
       "1                               2.460299   \n",
       "2                               1.657472   \n",
       "3                               1.600489   \n",
       "4                               1.249495   \n",
       "..                                   ...   \n",
       "223                             1.287369   \n",
       "224                             1.500711   \n",
       "225                             1.878066   \n",
       "226                             1.799993   \n",
       "227                             1.036511   \n",
       "\n",
       "     cyclostationary_mean_rr_12w_1_basin2  basin  basin2  \n",
       "0                                1.579481    0.0     1.0  \n",
       "1                                1.146518    0.0     1.0  \n",
       "2                                0.697926    0.0     1.0  \n",
       "3                                0.578318    0.0     1.0  \n",
       "4                                0.843396    0.0     1.0  \n",
       "..                                    ...    ...     ...  \n",
       "223                              0.181394    1.0     0.0  \n",
       "224                              0.244831    1.0     0.0  \n",
       "225                              0.317723    1.0     0.0  \n",
       "226                              0.278011    1.0     0.0  \n",
       "227                              0.081538    1.0     0.0  \n",
       "\n",
       "[1278 rows x 12 columns]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trainVal = pd.concat((best5_CMI_train_withClass01,best5_CMI_val_withClass01))\n",
    "df_trainVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "79ca1b94",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in range(df_trainVal.shape[1]-2):\n",
    "    for j in ['basin','basin2']:\n",
    "        df_trainVal[df_trainVal.columns[i]+'_'+j] = df_trainVal.apply(lambda x:x[i]*x[j], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "957109ad",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cyclostationary_mean_rr_4w_0_basin',\n",
       "       'cyclostationary_mean_tg_1w_4_basin',\n",
       "       'cyclostationary_mean_rr_12w_1_basin',\n",
       "       'cyclostationary_mean_rr_8w_1_basin', 'cyclostationary_mean_tg_9_basin',\n",
       "       'cyclostationary_mean_tg_1w_4_basin2',\n",
       "       'cyclostationary_mean_rr_4w_3_basin2',\n",
       "       'cyclostationary_mean_tg_4_basin2',\n",
       "       'cyclostationary_mean_rr_8w_0_basin2',\n",
       "       'cyclostationary_mean_rr_12w_1_basin2', 'basin', 'basin2',\n",
       "       'cyclostationary_mean_rr_4w_0_basin_basin',\n",
       "       'cyclostationary_mean_rr_4w_0_basin_basin2',\n",
       "       'cyclostationary_mean_tg_1w_4_basin_basin',\n",
       "       'cyclostationary_mean_tg_1w_4_basin_basin2',\n",
       "       'cyclostationary_mean_rr_12w_1_basin_basin',\n",
       "       'cyclostationary_mean_rr_12w_1_basin_basin2',\n",
       "       'cyclostationary_mean_rr_8w_1_basin_basin',\n",
       "       'cyclostationary_mean_rr_8w_1_basin_basin2',\n",
       "       'cyclostationary_mean_tg_9_basin_basin',\n",
       "       'cyclostationary_mean_tg_9_basin_basin2',\n",
       "       'cyclostationary_mean_tg_1w_4_basin2_basin',\n",
       "       'cyclostationary_mean_tg_1w_4_basin2_basin2',\n",
       "       'cyclostationary_mean_rr_4w_3_basin2_basin',\n",
       "       'cyclostationary_mean_rr_4w_3_basin2_basin2',\n",
       "       'cyclostationary_mean_tg_4_basin2_basin',\n",
       "       'cyclostationary_mean_tg_4_basin2_basin2',\n",
       "       'cyclostationary_mean_rr_8w_0_basin2_basin',\n",
       "       'cyclostationary_mean_rr_8w_0_basin2_basin2',\n",
       "       'cyclostationary_mean_rr_12w_1_basin2_basin',\n",
       "       'cyclostationary_mean_rr_12w_1_basin2_basin2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trainVal.columns ## 32 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "0badcb14",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_withInteractions = LinearRegression()\n",
    "model_withInteractions.fit(df_trainVal,pd.concat((target_train_withClass01,target_val_withClass01)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "e2d0bc40",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cyclostationary_mean_rr_4w_0_basin</th>\n",
       "      <th>cyclostationary_mean_tg_1w_4_basin</th>\n",
       "      <th>cyclostationary_mean_rr_12w_1_basin</th>\n",
       "      <th>cyclostationary_mean_rr_8w_1_basin</th>\n",
       "      <th>cyclostationary_mean_tg_9_basin</th>\n",
       "      <th>cyclostationary_mean_tg_1w_4_basin2</th>\n",
       "      <th>cyclostationary_mean_rr_4w_3_basin2</th>\n",
       "      <th>cyclostationary_mean_tg_4_basin2</th>\n",
       "      <th>cyclostationary_mean_rr_8w_0_basin2</th>\n",
       "      <th>cyclostationary_mean_rr_12w_1_basin2</th>\n",
       "      <th>...</th>\n",
       "      <th>cyclostationary_mean_tg_1w_4_basin2_basin</th>\n",
       "      <th>cyclostationary_mean_tg_1w_4_basin2_basin2</th>\n",
       "      <th>cyclostationary_mean_rr_4w_3_basin2_basin</th>\n",
       "      <th>cyclostationary_mean_rr_4w_3_basin2_basin2</th>\n",
       "      <th>cyclostationary_mean_tg_4_basin2_basin</th>\n",
       "      <th>cyclostationary_mean_tg_4_basin2_basin2</th>\n",
       "      <th>cyclostationary_mean_rr_8w_0_basin2_basin</th>\n",
       "      <th>cyclostationary_mean_rr_8w_0_basin2_basin2</th>\n",
       "      <th>cyclostationary_mean_rr_12w_1_basin2_basin</th>\n",
       "      <th>cyclostationary_mean_rr_12w_1_basin2_basin2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.024229</td>\n",
       "      <td>-0.130768</td>\n",
       "      <td>0.384819</td>\n",
       "      <td>-0.288379</td>\n",
       "      <td>-0.758823</td>\n",
       "      <td>0.630622</td>\n",
       "      <td>0.209123</td>\n",
       "      <td>-0.468881</td>\n",
       "      <td>1.304173</td>\n",
       "      <td>-0.159103</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.630622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.209123</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.468881</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.304173</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.159103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.074161</td>\n",
       "      <td>0.394246</td>\n",
       "      <td>0.534957</td>\n",
       "      <td>0.217974</td>\n",
       "      <td>0.366976</td>\n",
       "      <td>1.194474</td>\n",
       "      <td>-0.138681</td>\n",
       "      <td>2.708734</td>\n",
       "      <td>1.737154</td>\n",
       "      <td>0.039609</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.194474</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.138681</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.708734</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.737154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.638893</td>\n",
       "      <td>2.401322</td>\n",
       "      <td>0.493120</td>\n",
       "      <td>-0.194728</td>\n",
       "      <td>1.391103</td>\n",
       "      <td>2.327133</td>\n",
       "      <td>-0.078662</td>\n",
       "      <td>0.847627</td>\n",
       "      <td>1.497008</td>\n",
       "      <td>0.156356</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.327133</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.078662</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.847627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.497008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.651903</td>\n",
       "      <td>1.977750</td>\n",
       "      <td>0.507575</td>\n",
       "      <td>-0.865029</td>\n",
       "      <td>0.986028</td>\n",
       "      <td>1.311114</td>\n",
       "      <td>-0.056919</td>\n",
       "      <td>0.457849</td>\n",
       "      <td>-0.104933</td>\n",
       "      <td>-0.191401</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.311114</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.056919</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.457849</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.104933</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.191401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.167088</td>\n",
       "      <td>0.399292</td>\n",
       "      <td>0.660056</td>\n",
       "      <td>-0.736970</td>\n",
       "      <td>-0.209023</td>\n",
       "      <td>0.207879</td>\n",
       "      <td>0.234950</td>\n",
       "      <td>-0.705268</td>\n",
       "      <td>-0.056618</td>\n",
       "      <td>0.317671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.207879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.234950</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.705268</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.056618</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>1.026728</td>\n",
       "      <td>0.066188</td>\n",
       "      <td>-0.652764</td>\n",
       "      <td>0.439127</td>\n",
       "      <td>0.883587</td>\n",
       "      <td>0.875518</td>\n",
       "      <td>2.874361</td>\n",
       "      <td>0.462921</td>\n",
       "      <td>1.142723</td>\n",
       "      <td>1.436723</td>\n",
       "      <td>...</td>\n",
       "      <td>0.875518</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.874361</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.462921</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.142723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.436723</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>1.105928</td>\n",
       "      <td>1.178374</td>\n",
       "      <td>-0.697788</td>\n",
       "      <td>0.713387</td>\n",
       "      <td>1.798072</td>\n",
       "      <td>2.013869</td>\n",
       "      <td>3.403684</td>\n",
       "      <td>1.646370</td>\n",
       "      <td>1.647574</td>\n",
       "      <td>1.695675</td>\n",
       "      <td>...</td>\n",
       "      <td>2.013869</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.403684</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.646370</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.647574</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.695675</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>1.567359</td>\n",
       "      <td>1.150618</td>\n",
       "      <td>-0.291633</td>\n",
       "      <td>0.585251</td>\n",
       "      <td>0.789272</td>\n",
       "      <td>2.283123</td>\n",
       "      <td>3.730013</td>\n",
       "      <td>0.712357</td>\n",
       "      <td>1.696177</td>\n",
       "      <td>1.558532</td>\n",
       "      <td>...</td>\n",
       "      <td>2.283123</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.730013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.712357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.696177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.558532</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>1.613891</td>\n",
       "      <td>0.412975</td>\n",
       "      <td>-0.312164</td>\n",
       "      <td>0.673733</td>\n",
       "      <td>0.695963</td>\n",
       "      <td>1.756730</td>\n",
       "      <td>3.393080</td>\n",
       "      <td>0.854092</td>\n",
       "      <td>1.702425</td>\n",
       "      <td>1.751665</td>\n",
       "      <td>...</td>\n",
       "      <td>1.756730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.393080</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.854092</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.702425</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.751665</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>1.507916</td>\n",
       "      <td>1.993004</td>\n",
       "      <td>-0.265331</td>\n",
       "      <td>1.166676</td>\n",
       "      <td>3.332968</td>\n",
       "      <td>2.984542</td>\n",
       "      <td>3.161020</td>\n",
       "      <td>2.842276</td>\n",
       "      <td>2.101849</td>\n",
       "      <td>1.875668</td>\n",
       "      <td>...</td>\n",
       "      <td>2.984542</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.161020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.842276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.101849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.875668</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>456 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cyclostationary_mean_rr_4w_0_basin  cyclostationary_mean_tg_1w_4_basin  \\\n",
       "0                             -0.024229                           -0.130768   \n",
       "1                             -0.074161                            0.394246   \n",
       "2                             -0.638893                            2.401322   \n",
       "3                             -0.651903                            1.977750   \n",
       "4                             -0.167088                            0.399292   \n",
       "..                                  ...                                 ...   \n",
       "223                            1.026728                            0.066188   \n",
       "224                            1.105928                            1.178374   \n",
       "225                            1.567359                            1.150618   \n",
       "226                            1.613891                            0.412975   \n",
       "227                            1.507916                            1.993004   \n",
       "\n",
       "     cyclostationary_mean_rr_12w_1_basin  cyclostationary_mean_rr_8w_1_basin  \\\n",
       "0                               0.384819                           -0.288379   \n",
       "1                               0.534957                            0.217974   \n",
       "2                               0.493120                           -0.194728   \n",
       "3                               0.507575                           -0.865029   \n",
       "4                               0.660056                           -0.736970   \n",
       "..                                   ...                                 ...   \n",
       "223                            -0.652764                            0.439127   \n",
       "224                            -0.697788                            0.713387   \n",
       "225                            -0.291633                            0.585251   \n",
       "226                            -0.312164                            0.673733   \n",
       "227                            -0.265331                            1.166676   \n",
       "\n",
       "     cyclostationary_mean_tg_9_basin  cyclostationary_mean_tg_1w_4_basin2  \\\n",
       "0                          -0.758823                             0.630622   \n",
       "1                           0.366976                             1.194474   \n",
       "2                           1.391103                             2.327133   \n",
       "3                           0.986028                             1.311114   \n",
       "4                          -0.209023                             0.207879   \n",
       "..                               ...                                  ...   \n",
       "223                         0.883587                             0.875518   \n",
       "224                         1.798072                             2.013869   \n",
       "225                         0.789272                             2.283123   \n",
       "226                         0.695963                             1.756730   \n",
       "227                         3.332968                             2.984542   \n",
       "\n",
       "     cyclostationary_mean_rr_4w_3_basin2  cyclostationary_mean_tg_4_basin2  \\\n",
       "0                               0.209123                         -0.468881   \n",
       "1                              -0.138681                          2.708734   \n",
       "2                              -0.078662                          0.847627   \n",
       "3                              -0.056919                          0.457849   \n",
       "4                               0.234950                         -0.705268   \n",
       "..                                   ...                               ...   \n",
       "223                             2.874361                          0.462921   \n",
       "224                             3.403684                          1.646370   \n",
       "225                             3.730013                          0.712357   \n",
       "226                             3.393080                          0.854092   \n",
       "227                             3.161020                          2.842276   \n",
       "\n",
       "     cyclostationary_mean_rr_8w_0_basin2  \\\n",
       "0                               1.304173   \n",
       "1                               1.737154   \n",
       "2                               1.497008   \n",
       "3                              -0.104933   \n",
       "4                              -0.056618   \n",
       "..                                   ...   \n",
       "223                             1.142723   \n",
       "224                             1.647574   \n",
       "225                             1.696177   \n",
       "226                             1.702425   \n",
       "227                             2.101849   \n",
       "\n",
       "     cyclostationary_mean_rr_12w_1_basin2  ...  \\\n",
       "0                               -0.159103  ...   \n",
       "1                                0.039609  ...   \n",
       "2                                0.156356  ...   \n",
       "3                               -0.191401  ...   \n",
       "4                                0.317671  ...   \n",
       "..                                    ...  ...   \n",
       "223                              1.436723  ...   \n",
       "224                              1.695675  ...   \n",
       "225                              1.558532  ...   \n",
       "226                              1.751665  ...   \n",
       "227                              1.875668  ...   \n",
       "\n",
       "     cyclostationary_mean_tg_1w_4_basin2_basin  \\\n",
       "0                                     0.000000   \n",
       "1                                     0.000000   \n",
       "2                                     0.000000   \n",
       "3                                     0.000000   \n",
       "4                                     0.000000   \n",
       "..                                         ...   \n",
       "223                                   0.875518   \n",
       "224                                   2.013869   \n",
       "225                                   2.283123   \n",
       "226                                   1.756730   \n",
       "227                                   2.984542   \n",
       "\n",
       "     cyclostationary_mean_tg_1w_4_basin2_basin2  \\\n",
       "0                                      0.630622   \n",
       "1                                      1.194474   \n",
       "2                                      2.327133   \n",
       "3                                      1.311114   \n",
       "4                                      0.207879   \n",
       "..                                          ...   \n",
       "223                                    0.000000   \n",
       "224                                    0.000000   \n",
       "225                                    0.000000   \n",
       "226                                    0.000000   \n",
       "227                                    0.000000   \n",
       "\n",
       "     cyclostationary_mean_rr_4w_3_basin2_basin  \\\n",
       "0                                     0.000000   \n",
       "1                                    -0.000000   \n",
       "2                                    -0.000000   \n",
       "3                                    -0.000000   \n",
       "4                                     0.000000   \n",
       "..                                         ...   \n",
       "223                                   2.874361   \n",
       "224                                   3.403684   \n",
       "225                                   3.730013   \n",
       "226                                   3.393080   \n",
       "227                                   3.161020   \n",
       "\n",
       "     cyclostationary_mean_rr_4w_3_basin2_basin2  \\\n",
       "0                                      0.209123   \n",
       "1                                     -0.138681   \n",
       "2                                     -0.078662   \n",
       "3                                     -0.056919   \n",
       "4                                      0.234950   \n",
       "..                                          ...   \n",
       "223                                    0.000000   \n",
       "224                                    0.000000   \n",
       "225                                    0.000000   \n",
       "226                                    0.000000   \n",
       "227                                    0.000000   \n",
       "\n",
       "     cyclostationary_mean_tg_4_basin2_basin  \\\n",
       "0                                 -0.000000   \n",
       "1                                  0.000000   \n",
       "2                                  0.000000   \n",
       "3                                  0.000000   \n",
       "4                                 -0.000000   \n",
       "..                                      ...   \n",
       "223                                0.462921   \n",
       "224                                1.646370   \n",
       "225                                0.712357   \n",
       "226                                0.854092   \n",
       "227                                2.842276   \n",
       "\n",
       "     cyclostationary_mean_tg_4_basin2_basin2  \\\n",
       "0                                  -0.468881   \n",
       "1                                   2.708734   \n",
       "2                                   0.847627   \n",
       "3                                   0.457849   \n",
       "4                                  -0.705268   \n",
       "..                                       ...   \n",
       "223                                 0.000000   \n",
       "224                                 0.000000   \n",
       "225                                 0.000000   \n",
       "226                                 0.000000   \n",
       "227                                 0.000000   \n",
       "\n",
       "     cyclostationary_mean_rr_8w_0_basin2_basin  \\\n",
       "0                                     0.000000   \n",
       "1                                     0.000000   \n",
       "2                                     0.000000   \n",
       "3                                    -0.000000   \n",
       "4                                    -0.000000   \n",
       "..                                         ...   \n",
       "223                                   1.142723   \n",
       "224                                   1.647574   \n",
       "225                                   1.696177   \n",
       "226                                   1.702425   \n",
       "227                                   2.101849   \n",
       "\n",
       "     cyclostationary_mean_rr_8w_0_basin2_basin2  \\\n",
       "0                                      1.304173   \n",
       "1                                      1.737154   \n",
       "2                                      1.497008   \n",
       "3                                     -0.104933   \n",
       "4                                     -0.056618   \n",
       "..                                          ...   \n",
       "223                                    0.000000   \n",
       "224                                    0.000000   \n",
       "225                                    0.000000   \n",
       "226                                    0.000000   \n",
       "227                                    0.000000   \n",
       "\n",
       "     cyclostationary_mean_rr_12w_1_basin2_basin  \\\n",
       "0                                     -0.000000   \n",
       "1                                      0.000000   \n",
       "2                                      0.000000   \n",
       "3                                     -0.000000   \n",
       "4                                      0.000000   \n",
       "..                                          ...   \n",
       "223                                    1.436723   \n",
       "224                                    1.695675   \n",
       "225                                    1.558532   \n",
       "226                                    1.751665   \n",
       "227                                    1.875668   \n",
       "\n",
       "     cyclostationary_mean_rr_12w_1_basin2_basin2  \n",
       "0                                      -0.159103  \n",
       "1                                       0.039609  \n",
       "2                                       0.156356  \n",
       "3                                      -0.191401  \n",
       "4                                       0.317671  \n",
       "..                                           ...  \n",
       "223                                     0.000000  \n",
       "224                                     0.000000  \n",
       "225                                     0.000000  \n",
       "226                                     0.000000  \n",
       "227                                     0.000000  \n",
       "\n",
       "[456 rows x 32 columns]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(best5_CMI_test_withClass01.shape[1]-2):\n",
    "    for j in ['basin','basin2']:\n",
    "        best5_CMI_test_withClass01[best5_CMI_test_withClass01.columns[i]+'_'+j] = best5_CMI_test_withClass01.apply(lambda x:x[i]*x[j], axis=1)\n",
    "best5_CMI_test_withClass01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "e64a19ca",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3471864948497686\n",
      "0.2506733686648961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "res0_withInteraction = model_withInteractions.predict(best5_CMI_test_withClass01[0:228].values)\n",
    "res1_withInteraction = model_withInteractions.predict(best5_CMI_test_withClass01[228:].values)\n",
    "\n",
    "print(r2_score(target_df_test_E1.mean_std, res0_withInteraction))\n",
    "print(r2_score(target_df_test_E2.mean_std, res1_withInteraction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "8da39f41",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.57239538e-01, -7.42274305e-02,  1.14869453e-01, -1.74380669e-02,\n",
       "       -9.50603216e-02,  4.09829946e-02,  5.76737955e-02, -9.14292290e-02,\n",
       "        2.66771908e-02, -2.51022919e-02,  1.74496692e-02, -1.74496692e-02,\n",
       "        1.89327870e-02,  1.38306751e-01,  9.49798810e-02, -1.69207311e-01,\n",
       "        5.36612143e-02,  6.12082385e-02, -8.29049400e-02,  6.54668730e-02,\n",
       "       -8.60571614e-03, -8.64546055e-02, -1.07736145e-01,  1.48719140e-01,\n",
       "        8.28210205e-02, -2.51472250e-02, -6.98269558e-02, -2.16022732e-02,\n",
       "        3.30761680e-02, -6.39897727e-03, -2.50412115e-02, -6.10804163e-05])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_withInteractions.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83524fe8",
   "metadata": {},
   "source": [
    "# Linear regression comparisons (additive term)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2e5e0b",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Clusters of basins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "016a36c8",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.039373    0.00  2001     1 -2.546951\n",
      "1    2001-01-13  0.380618    0.43  2001     2 -0.277191\n",
      "2    2001-01-21  0.341985    0.38  2001     3 -0.534156\n",
      "3    2001-01-29  0.322044    0.35  2001     5 -0.666789\n",
      "4    2001-02-06  0.354954    0.40  2001     6 -0.447894\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.382706    0.40  2009    48 -0.263306\n",
      "407  2009-12-05  0.409921    0.46  2009    49 -0.082282\n",
      "408  2009-12-13  0.472087    0.53  2009    50  0.331204\n",
      "409  2009-12-21  0.324728    0.00  2009    52 -0.648940\n",
      "410  2009-12-29  0.086512    0.00  2009    53 -2.233412\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.010645    0.00  2001     1 -2.129508\n",
      "1    2001-01-13  0.206769    0.00  2001     2 -0.927136\n",
      "2    2001-01-21  0.267313    0.00  2001     3 -0.555958\n",
      "3    2001-01-29  0.240836    0.20  2001     5 -0.718282\n",
      "4    2001-02-06  0.193417    0.15  2001     6 -1.008995\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.230073    0.25  2009    48 -0.784269\n",
      "407  2009-12-05  0.243632    0.24  2009    49 -0.701139\n",
      "408  2009-12-13  0.251111    0.00  2009    50 -0.655289\n",
      "409  2009-12-21  0.099246    0.00  2009    52 -1.586325\n",
      "410  2009-12-29  0.064990    0.00  2009    53 -1.796340\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.379890    0.50  2001     1 -0.382765\n",
      "1    2001-01-13  0.482679    0.58  2001     2  0.319215\n",
      "2    2001-01-21  0.516259    0.59  2001     3  0.548542\n",
      "3    2001-01-29  0.434421    0.50  2001     5 -0.010351\n",
      "4    2001-02-06  0.494805    0.54  2001     6  0.402030\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.427085    0.43  2009    48 -0.060454\n",
      "407  2009-12-05  0.547380    0.57  2009    49  0.761079\n",
      "408  2009-12-13  0.531070    0.58  2009    50  0.649694\n",
      "409  2009-12-21  0.295704    0.00  2009    52 -0.957702\n",
      "410  2009-12-29  0.027861    0.00  2009    53 -2.786888\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.214281    0.00  2001     1 -1.339879\n",
      "1    2001-01-13  0.484737    0.52  2001     2  0.402993\n",
      "2    2001-01-21  0.466071    0.47  2001     3  0.282703\n",
      "3    2001-01-29  0.417470    0.44  2001     5 -0.030490\n",
      "4    2001-02-06  0.492202    0.53  2001     6  0.451097\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.436464    0.46  2009    48  0.091910\n",
      "407  2009-12-05  0.466152    0.49  2009    49  0.283224\n",
      "408  2009-12-13  0.553659    0.59  2009    50  0.847138\n",
      "409  2009-12-21  0.507978    0.65  2009    52  0.552758\n",
      "410  2009-12-29  0.083046    0.00  2009    53 -2.185583\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.102270    0.00  2001     1 -1.996014\n",
      "1    2001-01-13  0.454431    0.53  2001     2  0.498869\n",
      "2    2001-01-21  0.323514    0.32  2001     3 -0.428613\n",
      "3    2001-01-29  0.301661    0.31  2001     5 -0.583432\n",
      "4    2001-02-06  0.394733    0.44  2001     6  0.075938\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.388573    0.44  2009    48  0.032299\n",
      "407  2009-12-05  0.402760    0.47  2009    49  0.132804\n",
      "408  2009-12-13  0.353782    0.44  2009    50 -0.214182\n",
      "409  2009-12-21  0.043947    0.00  2009    52 -2.409204\n",
      "410  2009-12-29  0.006670    0.00  2009    53 -2.673294\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.369625    0.45  2001     1 -0.439541\n",
      "1    2001-01-13  0.429563    0.43  2001     2 -0.019547\n",
      "2    2001-01-21  0.470784    0.48  2001     3  0.269293\n",
      "3    2001-01-29  0.370358    0.37  2001     5 -0.434406\n",
      "4    2001-02-06  0.372263    0.37  2001     6 -0.421060\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.402059    0.40  2009    48 -0.212272\n",
      "407  2009-12-05  0.389658    0.39  2009    49 -0.299172\n",
      "408  2009-12-13  0.545184    0.56  2009    50  0.790614\n",
      "409  2009-12-21  0.447916    0.55  2009    52  0.109054\n",
      "410  2009-12-29  0.277300    0.32  2009    53 -1.086474\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.243674    0.26  2001     1 -1.223671\n",
      "1    2001-01-13  0.424116    0.44  2001     2 -0.087252\n",
      "2    2001-01-21  0.393786    0.39  2001     3 -0.278268\n",
      "3    2001-01-29  0.314939    0.31  2001     5 -0.774846\n",
      "4    2001-02-06  0.464902    0.48  2001     6  0.169616\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.465734    0.48  2009    48  0.174854\n",
      "407  2009-12-05  0.447390    0.47  2009    49  0.059327\n",
      "408  2009-12-13  0.556760    0.59  2009    50  0.748131\n",
      "409  2009-12-21  0.307880    0.00  2009    52 -0.819305\n",
      "410  2009-12-29  0.034211    0.00  2009    53 -2.542862\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.278983    0.00  2001     1 -1.146332\n",
      "1    2001-01-13  0.494910    0.51  2001     2  0.371173\n",
      "2    2001-01-21  0.496092    0.51  2001     3  0.379474\n",
      "3    2001-01-29  0.427992    0.43  2001     5 -0.099118\n",
      "4    2001-02-06  0.400512    0.41  2001     6 -0.292244\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.363952    0.37  2009    48 -0.549184\n",
      "407  2009-12-05  0.400487    0.40  2009    49 -0.292423\n",
      "408  2009-12-13  0.506771    0.52  2009    50  0.454529\n",
      "409  2009-12-21  0.387530    0.53  2009    52 -0.383480\n",
      "410  2009-12-29  0.279894    0.27  2009    53 -1.139931\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.278060    0.09  2001     1 -0.967137\n",
      "1    2001-01-13  0.445159    0.48  2001     2  0.070382\n",
      "2    2001-01-21  0.488982    0.52  2001     3  0.342478\n",
      "3    2001-01-29  0.362487    0.37  2001     5 -0.442927\n",
      "4    2001-02-06  0.430732    0.45  2001     6 -0.019192\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.430379    0.44  2009    48 -0.021388\n",
      "407  2009-12-05  0.419919    0.43  2009    49 -0.086330\n",
      "408  2009-12-13  0.526648    0.55  2009    50  0.576347\n",
      "409  2009-12-21  0.457440    0.61  2009    52  0.146632\n",
      "410  2009-12-29  0.301938    0.38  2009    53 -0.818877\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.264043    0.00  2001     1 -1.060146\n",
      "1    2001-01-13  0.354618    0.39  2001     2 -0.405065\n",
      "2    2001-01-21  0.427990    0.47  2001     3  0.125603\n",
      "3    2001-01-29  0.339495    0.35  2001     5 -0.514438\n",
      "4    2001-02-06  0.324134    0.34  2001     6 -0.625540\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.332713    0.35  2009    48 -0.563495\n",
      "407  2009-12-05  0.370253    0.40  2009    49 -0.291984\n",
      "408  2009-12-13  0.517201    0.57  2009    50  0.770822\n",
      "409  2009-12-21  0.353636    0.45  2009    52 -0.412164\n",
      "410  2009-12-29  0.261079    0.00  2009    53 -1.081585\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n"
     ]
    }
   ],
   "source": [
    "### targets\n",
    "basins = ['Adda','Dora','Emiliani1','Emiliani2','Garda_Mincio','Lambro_Olona','Oglio_Iseo','Piemonte_Nord','Piemonte_Sud','Ticino']\n",
    "path_targets = '/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/csv_VHI/'\n",
    "targets_df_train = pd.DataFrame()\n",
    "targets_df_val = pd.DataFrame()\n",
    "targets_df_test = pd.DataFrame()\n",
    "targets_df_trainVal = pd.DataFrame()\n",
    "\n",
    "for basin in basins:\n",
    "    target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target('',max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01', path=path_targets+basin+'.csv')\n",
    "    targets_df_train[basin] = target_df_train.mean_std\n",
    "    targets_df_val[basin] = target_df_val.mean_std\n",
    "    targets_df_test[basin] = target_df_test.mean_std\n",
    "    targets_df_trainVal[basin] = target_df_trainVal.mean_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "0b3ff08f",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sb\n",
    "from sklearn.cluster import KMeans\n",
    "dataplot = sb.heatmap(targets_df_trainVal.corr(), annot=True,vmin=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "479a468a",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 1, 1, 1, 2, 2, 0, 0, 2], dtype=int32)"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clust = KMeans(n_clusters=3)\n",
    "classes = clust.fit_predict(np.transpose(targets_df_trainVal))\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "7452d751",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dora' 'Piemonte_Nord' 'Piemonte_Sud']\n",
      "['Emiliani1' 'Emiliani2' 'Garda_Mincio']\n",
      "['Adda' 'Lambro_Olona' 'Oglio_Iseo' 'Ticino']\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(targets_df_trainVal.loc[:,classes==i].columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "084537a5",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 1, 1, 0, 2, 0, 2, 2, 2], dtype=int32)"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clust = KMeans(n_clusters=4)\n",
    "classes = clust.fit_predict(np.transpose(targets_df_trainVal))\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "7437ffa1",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Adda' 'Garda_Mincio' 'Oglio_Iseo']\n",
      "['Emiliani1' 'Emiliani2']\n",
      "['Lambro_Olona' 'Piemonte_Nord' 'Piemonte_Sud' 'Ticino']\n",
      "['Dora']\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(targets_df_trainVal.loc[:,classes==i].columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20aeb9a2",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## features loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "9ea7f48f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### wrapper best 5 features\n",
    "path_features = '/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/reduced_features/'\n",
    "\n",
    "best5_wrapper_fulldf_train = pd.DataFrame()\n",
    "best5_wrapper_fulldf_val = pd.DataFrame()\n",
    "best5_wrapper_fulldf_test = pd.DataFrame()\n",
    "\n",
    "for basin in basins:\n",
    "    best5_wrapper_train_temp = pd.read_csv(path_features+basin+'_nonLinCFA_wrapper_best5_train.csv')\n",
    "    best5_wrapper_val_temp = pd.read_csv(path_features+basin+'_nonLinCFA_wrapper_best5_val.csv')\n",
    "    best5_wrapper_test_temp = pd.read_csv(path_features+basin+'_nonLinCFA_wrapper_best5_test.csv')\n",
    "    best5_wrapper_fulldf_train[basin+'_'+best5_wrapper_train_temp.columns.values] = best5_wrapper_train_temp\n",
    "    best5_wrapper_fulldf_val[basin+'_'+best5_wrapper_val_temp.columns.values] = best5_wrapper_val_temp\n",
    "    best5_wrapper_fulldf_test[basin+'_'+best5_wrapper_test_temp.columns.values] = best5_wrapper_test_temp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "5a786a60",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### CMI features\n",
    "path_features = '/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/reduced_features/'\n",
    "\n",
    "CMI_fulldf_train = pd.DataFrame()\n",
    "CMI_fulldf_val = pd.DataFrame()\n",
    "CMI_fulldf_test = pd.DataFrame()\n",
    "\n",
    "for basin in basins:\n",
    "    train_temp = pd.read_csv(path_features+basin+'_nonLinCFA_CMI_train.csv')\n",
    "    val_temp = pd.read_csv(path_features+basin+'_nonLinCFA_CMI_val.csv')\n",
    "    test_temp = pd.read_csv(path_features+basin+'_nonLinCFA_CMI_test.csv')\n",
    "    CMI_fulldf_train[basin+'_'+train_temp.columns.values] = train_temp\n",
    "    CMI_fulldf_val[basin+'_'+val_temp.columns.values] = val_temp\n",
    "    CMI_fulldf_test[basin+'_'+test_temp.columns.values] = test_temp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "e5900737",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### CMI best5 features\n",
    "path_features = '/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/reduced_features/'\n",
    "\n",
    "best5_CMI_fulldf_train = pd.DataFrame()\n",
    "best5_CMI_fulldf_val = pd.DataFrame()\n",
    "best5_CMI_fulldf_test = pd.DataFrame()\n",
    "\n",
    "for basin in basins:\n",
    "    train_temp = pd.read_csv(path_features+basin+'_nonLinCFA_best5_CMI_train.csv')\n",
    "    val_temp = pd.read_csv(path_features+basin+'_nonLinCFA_best5_CMI_val.csv')\n",
    "    test_temp = pd.read_csv(path_features+basin+'_nonLinCFA_best5_CMI_test.csv')\n",
    "    best5_CMI_fulldf_train[basin+'_'+train_temp.columns.values] = train_temp\n",
    "    best5_CMI_fulldf_val[basin+'_'+val_temp.columns.values] = val_temp\n",
    "    best5_CMI_fulldf_test[basin+'_'+test_temp.columns.values] = test_temp\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c317fc60",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Full model - Wrapper best 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "796a6f58",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best5_wrapper_fulldf_train_withClass = pd.DataFrame()\n",
    "best5_wrapper_fulldf_val_withClass = pd.DataFrame()\n",
    "best5_wrapper_fulldf_test_withClass = pd.DataFrame()\n",
    "\n",
    "for i in range(10):\n",
    "    best5_wrapper_fulldf_train_withClass = pd.concat((best5_wrapper_fulldf_train_withClass,pd.concat((best5_wrapper_fulldf_train,pd.DataFrame(1+i*np.ones(len(best5_wrapper_fulldf_train)),columns=['basin'])),axis=1)),axis=0)\n",
    "    best5_wrapper_fulldf_val_withClass = pd.concat((best5_wrapper_fulldf_val_withClass,pd.concat((best5_wrapper_fulldf_val,pd.DataFrame(1+i*np.ones(len(best5_wrapper_fulldf_val)),columns=['basin'])),axis=1)),axis=0)\n",
    "    best5_wrapper_fulldf_test_withClass = pd.concat((best5_wrapper_fulldf_test_withClass,pd.concat((best5_wrapper_fulldf_test,pd.DataFrame(1+i*np.ones(len(best5_wrapper_fulldf_test)),columns=['basin'])),axis=1)),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "d9c7fef5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "targets_df_train_unfolded = pd.DataFrame()\n",
    "targets_df_val_unfolded = pd.DataFrame()\n",
    "targets_df_test_unfolded = pd.DataFrame()\n",
    "\n",
    "for basin in basins:\n",
    "    targets_df_train_unfolded =  pd.concat((targets_df_train_unfolded,targets_df_train[basin]),axis=0)\n",
    "    targets_df_val_unfolded =  pd.concat((targets_df_val_unfolded,targets_df_val[basin]),axis=0)\n",
    "    targets_df_test_unfolded =  pd.concat((targets_df_test_unfolded,targets_df_test[basin]),axis=0)\n",
    "targets_df_train_unfolded = targets_df_train_unfolded.reset_index(drop=True)\n",
    "targets_df_val_unfolded = targets_df_val_unfolded.reset_index(drop=True)\n",
    "targets_df_test_unfolded = targets_df_test_unfolded.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "ac175a72",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### senza one-hot encoding\n",
    "model_full = LinearRegression()\n",
    "model_full.fit(pd.concat((best5_wrapper_fulldf_train_withClass,best5_wrapper_fulldf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "883b97db",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5491554759619361\n",
      "-1.0423450950191295\n",
      "-0.6594175746250646\n",
      "-0.7279030457484599\n",
      "-0.3240293352193375\n",
      "-0.7789305558620834\n",
      "-0.586276530759325\n",
      "-0.625783137074384\n",
      "-0.825757489868459\n",
      "-0.6676428068629505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    res = model_full.predict(best5_wrapper_fulldf_test_withClass.loc[best5_wrapper_fulldf_test_withClass.basin==i+1].values)\n",
    "    print(r2_score(targets_df_test[basins[i]].values, res))\n",
    "\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "69d7ab54",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### con OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "0bf66abe",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    best5_wrapper_fulldf_train_withClass[basins[i]] = best5_wrapper_fulldf_train_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    best5_wrapper_fulldf_val_withClass[basins[i]] = best5_wrapper_fulldf_val_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    best5_wrapper_fulldf_test_withClass[basins[i]] = best5_wrapper_fulldf_test_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "bb15b566",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adda_cyclostationary_mean_tg_1w_3</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_1w_6</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_1w_5</th>\n",
       "      <th>Adda_cyclostationary_mean_rr_1w_0</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_16w_2</th>\n",
       "      <th>Dora_cyclostationary_mean_tg_1w_0</th>\n",
       "      <th>Dora_cyclostationary_mean_rr_4w_1</th>\n",
       "      <th>Dora_cyclostationary_mean_tg_1w_2</th>\n",
       "      <th>Dora_cyclostationary_mean_tg_4w_1</th>\n",
       "      <th>Dora_cyclostationary_mean_tg_4w_0</th>\n",
       "      <th>...</th>\n",
       "      <th>Adda</th>\n",
       "      <th>Dora</th>\n",
       "      <th>Emiliani1</th>\n",
       "      <th>Emiliani2</th>\n",
       "      <th>Garda_Mincio</th>\n",
       "      <th>Lambro_Olona</th>\n",
       "      <th>Oglio_Iseo</th>\n",
       "      <th>Piemonte_Nord</th>\n",
       "      <th>Piemonte_Sud</th>\n",
       "      <th>Ticino</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.862899</td>\n",
       "      <td>-1.709060</td>\n",
       "      <td>-1.866687</td>\n",
       "      <td>1.001341</td>\n",
       "      <td>-3.062159</td>\n",
       "      <td>-0.858428</td>\n",
       "      <td>0.569944</td>\n",
       "      <td>-0.645734</td>\n",
       "      <td>-0.958059</td>\n",
       "      <td>-1.179177</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.093639</td>\n",
       "      <td>-0.490888</td>\n",
       "      <td>-1.024977</td>\n",
       "      <td>1.976018</td>\n",
       "      <td>-1.604230</td>\n",
       "      <td>-0.144075</td>\n",
       "      <td>2.777501</td>\n",
       "      <td>-0.040254</td>\n",
       "      <td>0.064877</td>\n",
       "      <td>-0.154668</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.524505</td>\n",
       "      <td>-0.923993</td>\n",
       "      <td>-0.954945</td>\n",
       "      <td>1.350939</td>\n",
       "      <td>-2.492491</td>\n",
       "      <td>-0.543433</td>\n",
       "      <td>1.425829</td>\n",
       "      <td>-0.727940</td>\n",
       "      <td>-1.002116</td>\n",
       "      <td>-0.919496</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.666293</td>\n",
       "      <td>-1.171925</td>\n",
       "      <td>-1.039569</td>\n",
       "      <td>0.464342</td>\n",
       "      <td>-1.901370</td>\n",
       "      <td>-0.723360</td>\n",
       "      <td>1.785519</td>\n",
       "      <td>-0.924722</td>\n",
       "      <td>-0.601101</td>\n",
       "      <td>-0.594848</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.416695</td>\n",
       "      <td>-0.855241</td>\n",
       "      <td>-1.185594</td>\n",
       "      <td>0.406680</td>\n",
       "      <td>-2.302021</td>\n",
       "      <td>-0.540293</td>\n",
       "      <td>1.524603</td>\n",
       "      <td>-0.569035</td>\n",
       "      <td>-0.789653</td>\n",
       "      <td>-0.843317</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>1.568770</td>\n",
       "      <td>1.778381</td>\n",
       "      <td>1.494928</td>\n",
       "      <td>-1.208471</td>\n",
       "      <td>1.138232</td>\n",
       "      <td>1.462830</td>\n",
       "      <td>-0.520256</td>\n",
       "      <td>1.585661</td>\n",
       "      <td>0.807565</td>\n",
       "      <td>0.577376</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>0.812306</td>\n",
       "      <td>1.051617</td>\n",
       "      <td>0.843470</td>\n",
       "      <td>0.824414</td>\n",
       "      <td>1.152253</td>\n",
       "      <td>0.599620</td>\n",
       "      <td>-0.530550</td>\n",
       "      <td>0.724000</td>\n",
       "      <td>1.020805</td>\n",
       "      <td>0.776516</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.876968</td>\n",
       "      <td>0.470849</td>\n",
       "      <td>0.404951</td>\n",
       "      <td>1.236207</td>\n",
       "      <td>1.253158</td>\n",
       "      <td>0.344849</td>\n",
       "      <td>0.031726</td>\n",
       "      <td>0.422436</td>\n",
       "      <td>0.910086</td>\n",
       "      <td>0.715672</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>-0.723696</td>\n",
       "      <td>-1.195756</td>\n",
       "      <td>-1.026883</td>\n",
       "      <td>-0.159932</td>\n",
       "      <td>0.874675</td>\n",
       "      <td>-1.130239</td>\n",
       "      <td>-0.154282</td>\n",
       "      <td>-1.116372</td>\n",
       "      <td>0.237759</td>\n",
       "      <td>0.083901</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-1.413870</td>\n",
       "      <td>-1.470946</td>\n",
       "      <td>-1.326713</td>\n",
       "      <td>0.209276</td>\n",
       "      <td>0.821070</td>\n",
       "      <td>-1.598190</td>\n",
       "      <td>0.583732</td>\n",
       "      <td>-1.711036</td>\n",
       "      <td>-0.182408</td>\n",
       "      <td>-0.229108</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4110 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Adda_cyclostationary_mean_tg_1w_3  Adda_cyclostationary_mean_tg_1w_6  \\\n",
       "0                            -0.862899                          -1.709060   \n",
       "1                            -0.093639                          -0.490888   \n",
       "2                            -0.524505                          -0.923993   \n",
       "3                            -0.666293                          -1.171925   \n",
       "4                            -0.416695                          -0.855241   \n",
       "..                                 ...                                ...   \n",
       "406                           1.568770                           1.778381   \n",
       "407                           0.812306                           1.051617   \n",
       "408                           0.876968                           0.470849   \n",
       "409                          -0.723696                          -1.195756   \n",
       "410                          -1.413870                          -1.470946   \n",
       "\n",
       "     Adda_cyclostationary_mean_tg_1w_5  Adda_cyclostationary_mean_rr_1w_0  \\\n",
       "0                            -1.866687                           1.001341   \n",
       "1                            -1.024977                           1.976018   \n",
       "2                            -0.954945                           1.350939   \n",
       "3                            -1.039569                           0.464342   \n",
       "4                            -1.185594                           0.406680   \n",
       "..                                 ...                                ...   \n",
       "406                           1.494928                          -1.208471   \n",
       "407                           0.843470                           0.824414   \n",
       "408                           0.404951                           1.236207   \n",
       "409                          -1.026883                          -0.159932   \n",
       "410                          -1.326713                           0.209276   \n",
       "\n",
       "     Adda_cyclostationary_mean_tg_16w_2  Dora_cyclostationary_mean_tg_1w_0  \\\n",
       "0                             -3.062159                          -0.858428   \n",
       "1                             -1.604230                          -0.144075   \n",
       "2                             -2.492491                          -0.543433   \n",
       "3                             -1.901370                          -0.723360   \n",
       "4                             -2.302021                          -0.540293   \n",
       "..                                  ...                                ...   \n",
       "406                            1.138232                           1.462830   \n",
       "407                            1.152253                           0.599620   \n",
       "408                            1.253158                           0.344849   \n",
       "409                            0.874675                          -1.130239   \n",
       "410                            0.821070                          -1.598190   \n",
       "\n",
       "     Dora_cyclostationary_mean_rr_4w_1  Dora_cyclostationary_mean_tg_1w_2  \\\n",
       "0                             0.569944                          -0.645734   \n",
       "1                             2.777501                          -0.040254   \n",
       "2                             1.425829                          -0.727940   \n",
       "3                             1.785519                          -0.924722   \n",
       "4                             1.524603                          -0.569035   \n",
       "..                                 ...                                ...   \n",
       "406                          -0.520256                           1.585661   \n",
       "407                          -0.530550                           0.724000   \n",
       "408                           0.031726                           0.422436   \n",
       "409                          -0.154282                          -1.116372   \n",
       "410                           0.583732                          -1.711036   \n",
       "\n",
       "     Dora_cyclostationary_mean_tg_4w_1  Dora_cyclostationary_mean_tg_4w_0  \\\n",
       "0                            -0.958059                          -1.179177   \n",
       "1                             0.064877                          -0.154668   \n",
       "2                            -1.002116                          -0.919496   \n",
       "3                            -0.601101                          -0.594848   \n",
       "4                            -0.789653                          -0.843317   \n",
       "..                                 ...                                ...   \n",
       "406                           0.807565                           0.577376   \n",
       "407                           1.020805                           0.776516   \n",
       "408                           0.910086                           0.715672   \n",
       "409                           0.237759                           0.083901   \n",
       "410                          -0.182408                          -0.229108   \n",
       "\n",
       "     ...  Adda  Dora  Emiliani1  Emiliani2  Garda_Mincio  Lambro_Olona  \\\n",
       "0    ...     1     0          0          0             0             0   \n",
       "1    ...     1     0          0          0             0             0   \n",
       "2    ...     1     0          0          0             0             0   \n",
       "3    ...     1     0          0          0             0             0   \n",
       "4    ...     1     0          0          0             0             0   \n",
       "..   ...   ...   ...        ...        ...           ...           ...   \n",
       "406  ...     0     0          0          0             0             0   \n",
       "407  ...     0     0          0          0             0             0   \n",
       "408  ...     0     0          0          0             0             0   \n",
       "409  ...     0     0          0          0             0             0   \n",
       "410  ...     0     0          0          0             0             0   \n",
       "\n",
       "     Oglio_Iseo  Piemonte_Nord  Piemonte_Sud  Ticino  \n",
       "0             0              0             0       0  \n",
       "1             0              0             0       0  \n",
       "2             0              0             0       0  \n",
       "3             0              0             0       0  \n",
       "4             0              0             0       0  \n",
       "..          ...            ...           ...     ...  \n",
       "406           0              0             0       1  \n",
       "407           0              0             0       1  \n",
       "408           0              0             0       1  \n",
       "409           0              0             0       1  \n",
       "410           0              0             0       1  \n",
       "\n",
       "[4110 rows x 61 columns]"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best5_wrapper_fulldf_train_withClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "11259b11",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_full_ohe = LinearRegression()\n",
    "model_full_ohe.fit(pd.concat((best5_wrapper_fulldf_train_withClass,best5_wrapper_fulldf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "2b1fbc59",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5415005337955616\n",
      "-1.0338308669146623\n",
      "-0.6131189863744742\n",
      "-0.7083968352300551\n",
      "-0.39181095113804565\n",
      "-0.7874150404941778\n",
      "-0.5603225748543441\n",
      "-0.6433379917406741\n",
      "-0.8360326699741558\n",
      "-0.6155985316411592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    res = model_full_ohe.predict(best5_wrapper_fulldf_test_withClass.loc[best5_wrapper_fulldf_test_withClass.basin==i+1].values)\n",
    "    print(r2_score(targets_df_test[basins[i]].values, res))\n",
    "\n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ef7cf5",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Full model - CMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "3c8e73b8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fulldf_train_withClass = pd.DataFrame()\n",
    "fulldf_val_withClass = pd.DataFrame()\n",
    "fulldf_test_withClass = pd.DataFrame()\n",
    "\n",
    "for i in range(10):\n",
    "    fulldf_train_withClass = pd.concat((fulldf_train_withClass,pd.concat((CMI_fulldf_train,pd.DataFrame(1+i*np.ones(len(CMI_fulldf_train)),columns=['basin'])),axis=1)),axis=0)\n",
    "    fulldf_val_withClass = pd.concat((fulldf_val_withClass,pd.concat((CMI_fulldf_val,pd.DataFrame(1+i*np.ones(len(CMI_fulldf_val)),columns=['basin'])),axis=1)),axis=0)\n",
    "    fulldf_test_withClass = pd.concat((fulldf_test_withClass,pd.concat((CMI_fulldf_test,pd.DataFrame(1+i*np.ones(len(CMI_fulldf_test)),columns=['basin'])),axis=1)),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "1bfd3a8a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "targets_df_train_unfolded = pd.DataFrame()\n",
    "targets_df_val_unfolded = pd.DataFrame()\n",
    "targets_df_test_unfolded = pd.DataFrame()\n",
    "\n",
    "for basin in basins:\n",
    "    targets_df_train_unfolded =  pd.concat((targets_df_train_unfolded,targets_df_train[basin]),axis=0)\n",
    "    targets_df_val_unfolded =  pd.concat((targets_df_val_unfolded,targets_df_val[basin]),axis=0)\n",
    "    targets_df_test_unfolded =  pd.concat((targets_df_test_unfolded,targets_df_test[basin]),axis=0)\n",
    "targets_df_train_unfolded = targets_df_train_unfolded.reset_index(drop=True)\n",
    "targets_df_val_unfolded = targets_df_val_unfolded.reset_index(drop=True)\n",
    "targets_df_test_unfolded = targets_df_test_unfolded.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "d6f7b3f4",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### senza one-hot encoding\n",
    "model_full = LinearRegression()\n",
    "model_full.fit(pd.concat((fulldf_train_withClass,fulldf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "4fcdaab0",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.32432543674993175\n",
      "-0.8338333508633748\n",
      "-0.5346654436935785\n",
      "-0.6156751999424308\n",
      "-0.29797616991576814\n",
      "-0.6914126013197579\n",
      "-0.43343408191227617\n",
      "-0.6440930744307678\n",
      "-0.8875935087066893\n",
      "-0.5576540694126282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    res = model_full.predict(fulldf_test_withClass.loc[fulldf_test_withClass.basin==i+1].values)\n",
    "    print(r2_score(targets_df_test[basins[i]].values, res))\n",
    "\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "f9675873",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### con OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "2154e4f5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    fulldf_train_withClass[basins[i]] = fulldf_train_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    fulldf_val_withClass[basins[i]] = fulldf_val_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    fulldf_test_withClass[basins[i]] = fulldf_test_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "27528dd1",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;background-color: white;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_full_ohe = LinearRegression()\n",
    "model_full_ohe.fit(pd.concat((fulldf_train_withClass,fulldf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "44ebbb8e",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.3343247368017468\n",
      "-0.8408703888186033\n",
      "-0.522049414451657\n",
      "-0.6268155983314645\n",
      "-0.3506464522126824\n",
      "-0.6975832864306979\n",
      "-0.4271381098033764\n",
      "-0.683697356646664\n",
      "-0.922163317963026\n",
      "-0.5326480209316058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    res = model_full_ohe.predict(fulldf_test_withClass.loc[fulldf_test_withClass.basin==i+1].values)\n",
    "    print(r2_score(targets_df_test[basins[i]].values, res))\n",
    "\n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec7ac38",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Full model - CMI best5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "8ac427aa",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fulldf_train_withClass = pd.DataFrame()\n",
    "fulldf_val_withClass = pd.DataFrame()\n",
    "fulldf_test_withClass = pd.DataFrame()\n",
    "\n",
    "for i in range(10):\n",
    "    fulldf_train_withClass = pd.concat((fulldf_train_withClass,pd.concat((best5_CMI_fulldf_train,pd.DataFrame(1+i*np.ones(len(best5_CMI_fulldf_train)),columns=['basin'])),axis=1)),axis=0)\n",
    "    fulldf_val_withClass = pd.concat((fulldf_val_withClass,pd.concat((best5_CMI_fulldf_val,pd.DataFrame(1+i*np.ones(len(best5_CMI_fulldf_val)),columns=['basin'])),axis=1)),axis=0)\n",
    "    fulldf_test_withClass = pd.concat((fulldf_test_withClass,pd.concat((best5_CMI_fulldf_test,pd.DataFrame(1+i*np.ones(len(best5_CMI_fulldf_test)),columns=['basin'])),axis=1)),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "7ed966df",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "targets_df_train_unfolded = pd.DataFrame()\n",
    "targets_df_val_unfolded = pd.DataFrame()\n",
    "targets_df_test_unfolded = pd.DataFrame()\n",
    "\n",
    "for basin in basins:\n",
    "    targets_df_train_unfolded =  pd.concat((targets_df_train_unfolded,targets_df_train[basin]),axis=0)\n",
    "    targets_df_val_unfolded =  pd.concat((targets_df_val_unfolded,targets_df_val[basin]),axis=0)\n",
    "    targets_df_test_unfolded =  pd.concat((targets_df_test_unfolded,targets_df_test[basin]),axis=0)\n",
    "targets_df_train_unfolded = targets_df_train_unfolded.reset_index(drop=True)\n",
    "targets_df_val_unfolded = targets_df_val_unfolded.reset_index(drop=True)\n",
    "targets_df_test_unfolded = targets_df_test_unfolded.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "35ee6441",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {color: black;background-color: white;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### senza one-hot encoding\n",
    "model_full = LinearRegression()\n",
    "model_full.fit(pd.concat((fulldf_train_withClass,fulldf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "e4b5bedf",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07074209099490547\n",
      "-0.3400251166748527\n",
      "0.021472147689631682\n",
      "-0.018948230897721796\n",
      "0.1079367225647263\n",
      "-0.10209848606072591\n",
      "0.040766556111391794\n",
      "-0.09174830928989253\n",
      "-0.25051627456874725\n",
      "-0.05702704585485252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    res = model_full.predict(fulldf_test_withClass.loc[fulldf_test_withClass.basin==i+1].values)\n",
    "    print(r2_score(targets_df_test[basins[i]].values, res))\n",
    "\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "619f1dff",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### con OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "da6d08fc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    fulldf_train_withClass[basins[i]] = fulldf_train_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    fulldf_val_withClass[basins[i]] = fulldf_val_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    fulldf_test_withClass[basins[i]] = fulldf_test_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "2cbfbaca",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {color: black;background-color: white;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" checked><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_full_ohe = LinearRegression()\n",
    "model_full_ohe.fit(pd.concat((fulldf_train_withClass,fulldf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "a810b111",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07483055333995814\n",
      "-0.33438354490326283\n",
      "0.04241445328655613\n",
      "-0.01150395664153292\n",
      "0.10141628406867964\n",
      "-0.10104147267469954\n",
      "0.05616066638937134\n",
      "-0.10050670963023434\n",
      "-0.2571160595620916\n",
      "-0.02778105022402344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    res = model_full_ohe.predict(fulldf_test_withClass.loc[fulldf_test_withClass.basin==i+1].values)\n",
    "    print(r2_score(targets_df_test[basins[i]].values, res))\n",
    "\n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843bde20",
   "metadata": {},
   "source": [
    "## Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b028bfc",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Emiliani1 - Emiliani2 - Garda_Mincio: wrapper best 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "d9b4bbde",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### prova con Emiliani1 e 2 e Garda_Mincio\n",
    "clust_basins = ['Emiliani1','Emiliani2','Garda_Mincio']\n",
    "colnames = [x for x in best5_wrapper_fulldf_train.columns if x.startswith('Emiliani1') or x.startswith('Emiliani2') or x.startswith('Garda_Mincio')]\n",
    "\n",
    "best5_wrapper_clusterdf_train_withClass = pd.DataFrame()\n",
    "best5_wrapper_clusterdf_val_withClass = pd.DataFrame()\n",
    "best5_wrapper_clusterdf_test_withClass = pd.DataFrame()\n",
    "\n",
    "for i in range(3):\n",
    "    best5_wrapper_clusterdf_train_withClass = pd.concat((best5_wrapper_clusterdf_train_withClass,pd.concat((best5_wrapper_fulldf_train[colnames],pd.DataFrame(1+i*np.ones(len(best5_wrapper_fulldf_train)),columns=['basin'])),axis=1)),axis=0)\n",
    "    best5_wrapper_clusterdf_val_withClass = pd.concat((best5_wrapper_clusterdf_val_withClass,pd.concat((best5_wrapper_fulldf_val[colnames],pd.DataFrame(1+i*np.ones(len(best5_wrapper_fulldf_val)),columns=['basin'])),axis=1)),axis=0)\n",
    "    best5_wrapper_clusterdf_test_withClass = pd.concat((best5_wrapper_clusterdf_test_withClass,pd.concat((best5_wrapper_fulldf_test[colnames],pd.DataFrame(1+i*np.ones(len(best5_wrapper_fulldf_test)),columns=['basin'])),axis=1)),axis=0)\n",
    "\n",
    "for i in range(3):\n",
    "    best5_wrapper_clusterdf_train_withClass[clust_basins[i]] = best5_wrapper_clusterdf_train_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    best5_wrapper_clusterdf_val_withClass[clust_basins[i]] = best5_wrapper_clusterdf_val_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    best5_wrapper_clusterdf_test_withClass[clust_basins[i]] = best5_wrapper_clusterdf_test_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "\n",
    "best5_wrapper_clusterdf_train_withClass = best5_wrapper_clusterdf_train_withClass.loc[:,best5_wrapper_clusterdf_train_withClass.columns != 'basin']\n",
    "best5_wrapper_clusterdf_val_withClass = best5_wrapper_clusterdf_val_withClass.loc[:,best5_wrapper_clusterdf_val_withClass.columns != 'basin']\n",
    "best5_wrapper_clusterdf_test_withClass = best5_wrapper_clusterdf_test_withClass.loc[:,best5_wrapper_clusterdf_test_withClass.columns != 'basin']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "15f27ff6",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emiliani1_cyclostationary_mean_rr_8w_0</th>\n",
       "      <th>Emiliani1_cyclostationary_mean_tg_0</th>\n",
       "      <th>Emiliani1_cyclostationary_mean_rr_16w_1</th>\n",
       "      <th>Emiliani1_cyclostationary_mean_rr_12w_2</th>\n",
       "      <th>Emiliani1_cyclostationary_mean_rr_1w_4</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_tg_1w_5</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_rr_8w_3</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_tg_8w_1</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_rr_16w_2</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_tg_1w_6</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_4w_1</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_tg_0</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_24w_1</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_24w_4</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_24w_6</th>\n",
       "      <th>Emiliani1</th>\n",
       "      <th>Emiliani2</th>\n",
       "      <th>Garda_Mincio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.563762</td>\n",
       "      <td>0.702658</td>\n",
       "      <td>2.356915</td>\n",
       "      <td>4.551719</td>\n",
       "      <td>0.733057</td>\n",
       "      <td>-0.890461</td>\n",
       "      <td>1.715033</td>\n",
       "      <td>0.451434</td>\n",
       "      <td>5.057234</td>\n",
       "      <td>0.839851</td>\n",
       "      <td>1.758769</td>\n",
       "      <td>0.309939</td>\n",
       "      <td>1.937637</td>\n",
       "      <td>2.719823</td>\n",
       "      <td>2.154612</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.725573</td>\n",
       "      <td>1.770284</td>\n",
       "      <td>2.298396</td>\n",
       "      <td>1.893610</td>\n",
       "      <td>0.688605</td>\n",
       "      <td>-0.266454</td>\n",
       "      <td>0.884643</td>\n",
       "      <td>1.266314</td>\n",
       "      <td>3.825332</td>\n",
       "      <td>1.871824</td>\n",
       "      <td>1.121893</td>\n",
       "      <td>1.158323</td>\n",
       "      <td>1.850264</td>\n",
       "      <td>4.725401</td>\n",
       "      <td>4.547085</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.426653</td>\n",
       "      <td>-0.294432</td>\n",
       "      <td>1.655602</td>\n",
       "      <td>1.912331</td>\n",
       "      <td>0.400704</td>\n",
       "      <td>-0.541753</td>\n",
       "      <td>0.397911</td>\n",
       "      <td>0.262699</td>\n",
       "      <td>2.978955</td>\n",
       "      <td>2.175787</td>\n",
       "      <td>0.598275</td>\n",
       "      <td>-0.747849</td>\n",
       "      <td>1.614353</td>\n",
       "      <td>2.989650</td>\n",
       "      <td>3.013864</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.048203</td>\n",
       "      <td>1.312823</td>\n",
       "      <td>0.788894</td>\n",
       "      <td>1.822362</td>\n",
       "      <td>0.740061</td>\n",
       "      <td>-0.679603</td>\n",
       "      <td>0.054424</td>\n",
       "      <td>0.396038</td>\n",
       "      <td>2.665933</td>\n",
       "      <td>2.151856</td>\n",
       "      <td>0.310672</td>\n",
       "      <td>0.618235</td>\n",
       "      <td>1.102825</td>\n",
       "      <td>2.877711</td>\n",
       "      <td>2.874078</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.795649</td>\n",
       "      <td>0.083310</td>\n",
       "      <td>4.072560</td>\n",
       "      <td>2.039331</td>\n",
       "      <td>1.203853</td>\n",
       "      <td>-0.500179</td>\n",
       "      <td>0.103811</td>\n",
       "      <td>0.302639</td>\n",
       "      <td>2.141665</td>\n",
       "      <td>2.644978</td>\n",
       "      <td>0.314132</td>\n",
       "      <td>-0.197356</td>\n",
       "      <td>1.639373</td>\n",
       "      <td>1.887482</td>\n",
       "      <td>2.011651</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>-0.549183</td>\n",
       "      <td>1.068315</td>\n",
       "      <td>-0.544373</td>\n",
       "      <td>-0.687935</td>\n",
       "      <td>-1.495602</td>\n",
       "      <td>0.805732</td>\n",
       "      <td>-0.293248</td>\n",
       "      <td>0.661497</td>\n",
       "      <td>-0.655689</td>\n",
       "      <td>1.600522</td>\n",
       "      <td>0.030398</td>\n",
       "      <td>1.386827</td>\n",
       "      <td>-1.000215</td>\n",
       "      <td>-0.832783</td>\n",
       "      <td>-0.872908</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>-0.481985</td>\n",
       "      <td>0.560944</td>\n",
       "      <td>-0.518064</td>\n",
       "      <td>-0.626884</td>\n",
       "      <td>-0.968744</td>\n",
       "      <td>0.306776</td>\n",
       "      <td>-0.156714</td>\n",
       "      <td>0.689496</td>\n",
       "      <td>-0.459704</td>\n",
       "      <td>1.017618</td>\n",
       "      <td>0.377049</td>\n",
       "      <td>0.600403</td>\n",
       "      <td>-0.657988</td>\n",
       "      <td>-0.534876</td>\n",
       "      <td>-0.467096</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>-0.402054</td>\n",
       "      <td>0.350446</td>\n",
       "      <td>-0.616373</td>\n",
       "      <td>-0.606093</td>\n",
       "      <td>-0.646526</td>\n",
       "      <td>0.503166</td>\n",
       "      <td>0.174464</td>\n",
       "      <td>0.605186</td>\n",
       "      <td>-0.408143</td>\n",
       "      <td>0.542851</td>\n",
       "      <td>0.643723</td>\n",
       "      <td>0.382350</td>\n",
       "      <td>-0.459207</td>\n",
       "      <td>-0.351997</td>\n",
       "      <td>-0.249248</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>-0.146823</td>\n",
       "      <td>-1.792820</td>\n",
       "      <td>-0.325116</td>\n",
       "      <td>-0.462663</td>\n",
       "      <td>-0.400672</td>\n",
       "      <td>-1.067879</td>\n",
       "      <td>0.229314</td>\n",
       "      <td>0.030515</td>\n",
       "      <td>-0.452395</td>\n",
       "      <td>-0.750222</td>\n",
       "      <td>-0.102080</td>\n",
       "      <td>-1.910985</td>\n",
       "      <td>-0.487928</td>\n",
       "      <td>-0.312771</td>\n",
       "      <td>-0.184850</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-0.051540</td>\n",
       "      <td>-0.120537</td>\n",
       "      <td>-0.236889</td>\n",
       "      <td>-0.568468</td>\n",
       "      <td>1.556927</td>\n",
       "      <td>-1.709317</td>\n",
       "      <td>0.223387</td>\n",
       "      <td>0.115353</td>\n",
       "      <td>-0.222063</td>\n",
       "      <td>-0.857548</td>\n",
       "      <td>0.187242</td>\n",
       "      <td>-0.460368</td>\n",
       "      <td>-0.433529</td>\n",
       "      <td>-0.297669</td>\n",
       "      <td>0.028905</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1233 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Emiliani1_cyclostationary_mean_rr_8w_0  \\\n",
       "0                                  2.563762   \n",
       "1                                  1.725573   \n",
       "2                                  1.426653   \n",
       "3                                  1.048203   \n",
       "4                                  1.795649   \n",
       "..                                      ...   \n",
       "406                               -0.549183   \n",
       "407                               -0.481985   \n",
       "408                               -0.402054   \n",
       "409                               -0.146823   \n",
       "410                               -0.051540   \n",
       "\n",
       "     Emiliani1_cyclostationary_mean_tg_0  \\\n",
       "0                               0.702658   \n",
       "1                               1.770284   \n",
       "2                              -0.294432   \n",
       "3                               1.312823   \n",
       "4                               0.083310   \n",
       "..                                   ...   \n",
       "406                             1.068315   \n",
       "407                             0.560944   \n",
       "408                             0.350446   \n",
       "409                            -1.792820   \n",
       "410                            -0.120537   \n",
       "\n",
       "     Emiliani1_cyclostationary_mean_rr_16w_1  \\\n",
       "0                                   2.356915   \n",
       "1                                   2.298396   \n",
       "2                                   1.655602   \n",
       "3                                   0.788894   \n",
       "4                                   4.072560   \n",
       "..                                       ...   \n",
       "406                                -0.544373   \n",
       "407                                -0.518064   \n",
       "408                                -0.616373   \n",
       "409                                -0.325116   \n",
       "410                                -0.236889   \n",
       "\n",
       "     Emiliani1_cyclostationary_mean_rr_12w_2  \\\n",
       "0                                   4.551719   \n",
       "1                                   1.893610   \n",
       "2                                   1.912331   \n",
       "3                                   1.822362   \n",
       "4                                   2.039331   \n",
       "..                                       ...   \n",
       "406                                -0.687935   \n",
       "407                                -0.626884   \n",
       "408                                -0.606093   \n",
       "409                                -0.462663   \n",
       "410                                -0.568468   \n",
       "\n",
       "     Emiliani1_cyclostationary_mean_rr_1w_4  \\\n",
       "0                                  0.733057   \n",
       "1                                  0.688605   \n",
       "2                                  0.400704   \n",
       "3                                  0.740061   \n",
       "4                                  1.203853   \n",
       "..                                      ...   \n",
       "406                               -1.495602   \n",
       "407                               -0.968744   \n",
       "408                               -0.646526   \n",
       "409                               -0.400672   \n",
       "410                                1.556927   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_tg_1w_5  \\\n",
       "0                                 -0.890461   \n",
       "1                                 -0.266454   \n",
       "2                                 -0.541753   \n",
       "3                                 -0.679603   \n",
       "4                                 -0.500179   \n",
       "..                                      ...   \n",
       "406                                0.805732   \n",
       "407                                0.306776   \n",
       "408                                0.503166   \n",
       "409                               -1.067879   \n",
       "410                               -1.709317   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_rr_8w_3  \\\n",
       "0                                  1.715033   \n",
       "1                                  0.884643   \n",
       "2                                  0.397911   \n",
       "3                                  0.054424   \n",
       "4                                  0.103811   \n",
       "..                                      ...   \n",
       "406                               -0.293248   \n",
       "407                               -0.156714   \n",
       "408                                0.174464   \n",
       "409                                0.229314   \n",
       "410                                0.223387   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_tg_8w_1  \\\n",
       "0                                  0.451434   \n",
       "1                                  1.266314   \n",
       "2                                  0.262699   \n",
       "3                                  0.396038   \n",
       "4                                  0.302639   \n",
       "..                                      ...   \n",
       "406                                0.661497   \n",
       "407                                0.689496   \n",
       "408                                0.605186   \n",
       "409                                0.030515   \n",
       "410                                0.115353   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_rr_16w_2  \\\n",
       "0                                   5.057234   \n",
       "1                                   3.825332   \n",
       "2                                   2.978955   \n",
       "3                                   2.665933   \n",
       "4                                   2.141665   \n",
       "..                                       ...   \n",
       "406                                -0.655689   \n",
       "407                                -0.459704   \n",
       "408                                -0.408143   \n",
       "409                                -0.452395   \n",
       "410                                -0.222063   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_tg_1w_6  \\\n",
       "0                                  0.839851   \n",
       "1                                  1.871824   \n",
       "2                                  2.175787   \n",
       "3                                  2.151856   \n",
       "4                                  2.644978   \n",
       "..                                      ...   \n",
       "406                                1.600522   \n",
       "407                                1.017618   \n",
       "408                                0.542851   \n",
       "409                               -0.750222   \n",
       "410                               -0.857548   \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_4w_1  \\\n",
       "0                                     1.758769   \n",
       "1                                     1.121893   \n",
       "2                                     0.598275   \n",
       "3                                     0.310672   \n",
       "4                                     0.314132   \n",
       "..                                         ...   \n",
       "406                                   0.030398   \n",
       "407                                   0.377049   \n",
       "408                                   0.643723   \n",
       "409                                  -0.102080   \n",
       "410                                   0.187242   \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_tg_0  \\\n",
       "0                                  0.309939   \n",
       "1                                  1.158323   \n",
       "2                                 -0.747849   \n",
       "3                                  0.618235   \n",
       "4                                 -0.197356   \n",
       "..                                      ...   \n",
       "406                                1.386827   \n",
       "407                                0.600403   \n",
       "408                                0.382350   \n",
       "409                               -1.910985   \n",
       "410                               -0.460368   \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_24w_1  \\\n",
       "0                                      1.937637   \n",
       "1                                      1.850264   \n",
       "2                                      1.614353   \n",
       "3                                      1.102825   \n",
       "4                                      1.639373   \n",
       "..                                          ...   \n",
       "406                                   -1.000215   \n",
       "407                                   -0.657988   \n",
       "408                                   -0.459207   \n",
       "409                                   -0.487928   \n",
       "410                                   -0.433529   \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_24w_4  \\\n",
       "0                                      2.719823   \n",
       "1                                      4.725401   \n",
       "2                                      2.989650   \n",
       "3                                      2.877711   \n",
       "4                                      1.887482   \n",
       "..                                          ...   \n",
       "406                                   -0.832783   \n",
       "407                                   -0.534876   \n",
       "408                                   -0.351997   \n",
       "409                                   -0.312771   \n",
       "410                                   -0.297669   \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_24w_6  Emiliani1  Emiliani2  \\\n",
       "0                                      2.154612          1          0   \n",
       "1                                      4.547085          1          0   \n",
       "2                                      3.013864          1          0   \n",
       "3                                      2.874078          1          0   \n",
       "4                                      2.011651          1          0   \n",
       "..                                          ...        ...        ...   \n",
       "406                                   -0.872908          0          0   \n",
       "407                                   -0.467096          0          0   \n",
       "408                                   -0.249248          0          0   \n",
       "409                                   -0.184850          0          0   \n",
       "410                                    0.028905          0          0   \n",
       "\n",
       "     Garda_Mincio  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "..            ...  \n",
       "406             1  \n",
       "407             1  \n",
       "408             1  \n",
       "409             1  \n",
       "410             1  \n",
       "\n",
       "[1233 rows x 18 columns]"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best5_wrapper_clusterdf_train_withClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "e1e62dcc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "targets_df_train_unfolded = pd.DataFrame()\n",
    "targets_df_val_unfolded = pd.DataFrame()\n",
    "targets_df_test_unfolded = pd.DataFrame()\n",
    "\n",
    "for basin in ['Emiliani1','Emiliani2','Garda_Mincio']:\n",
    "    targets_df_train_unfolded =  pd.concat((targets_df_train_unfolded,targets_df_train[basin]),axis=0)\n",
    "    targets_df_val_unfolded =  pd.concat((targets_df_val_unfolded,targets_df_val[basin]),axis=0)\n",
    "    targets_df_test_unfolded =  pd.concat((targets_df_test_unfolded,targets_df_test[basin]),axis=0)\n",
    "targets_df_train_unfolded = targets_df_train_unfolded.reset_index(drop=True)\n",
    "targets_df_val_unfolded = targets_df_val_unfolded.reset_index(drop=True)\n",
    "targets_df_test_unfolded = targets_df_test_unfolded.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "22593ca2",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.382765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.319215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.548542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.010351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.402030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>0.032299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>0.132804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>-0.214182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>-2.409204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>-2.673294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1233 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0    -0.382765\n",
       "1     0.319215\n",
       "2     0.548542\n",
       "3    -0.010351\n",
       "4     0.402030\n",
       "...        ...\n",
       "1228  0.032299\n",
       "1229  0.132804\n",
       "1230 -0.214182\n",
       "1231 -2.409204\n",
       "1232 -2.673294\n",
       "\n",
       "[1233 rows x 1 columns]"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_df_train_unfolded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "2e2eb590",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31486223593225293\n",
      "0.2084530199165946\n",
      "0.24633777765773346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_E1E2GM_ohe = LinearRegression()\n",
    "model_E1E2GM_ohe.fit(pd.concat((best5_wrapper_clusterdf_train_withClass,best5_wrapper_clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_E1E2GM_ohe.predict(best5_wrapper_clusterdf_test_withClass.loc[best5_wrapper_clusterdf_test_withClass.Emiliani1==1].values)\n",
    "print(r2_score(targets_df_test['Emiliani1'].values, res))\n",
    "res = model_E1E2GM_ohe.predict(best5_wrapper_clusterdf_test_withClass.loc[best5_wrapper_clusterdf_test_withClass.Emiliani2==1].values)\n",
    "print(r2_score(targets_df_test['Emiliani2'].values, res))\n",
    "res = model_E1E2GM_ohe.predict(best5_wrapper_clusterdf_test_withClass.loc[best5_wrapper_clusterdf_test_withClass.Garda_Mincio==1].values)\n",
    "print(r2_score(targets_df_test['Garda_Mincio'].values, res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "51451691",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emiliani1_cyclostationary_mean_rr_8w_0</th>\n",
       "      <th>Emiliani1_cyclostationary_mean_tg_0</th>\n",
       "      <th>Emiliani1_cyclostationary_mean_rr_16w_1</th>\n",
       "      <th>Emiliani1_cyclostationary_mean_rr_12w_2</th>\n",
       "      <th>Emiliani1_cyclostationary_mean_rr_1w_4</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_tg_1w_5</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_rr_8w_3</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_tg_8w_1</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_rr_16w_2</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_tg_1w_6</th>\n",
       "      <th>...</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_tg_0_Garda_Mincio</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_24w_1_Emiliani1</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_24w_1_Emiliani2</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_24w_1_Garda_Mincio</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_24w_4_Emiliani1</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_24w_4_Emiliani2</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_24w_4_Garda_Mincio</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_24w_6_Emiliani1</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_24w_6_Emiliani2</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_24w_6_Garda_Mincio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.563762</td>\n",
       "      <td>0.702658</td>\n",
       "      <td>2.356915</td>\n",
       "      <td>4.551719</td>\n",
       "      <td>0.733057</td>\n",
       "      <td>-0.890461</td>\n",
       "      <td>1.715033</td>\n",
       "      <td>0.451434</td>\n",
       "      <td>5.057234</td>\n",
       "      <td>0.839851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.937637</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.719823</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.154612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.725573</td>\n",
       "      <td>1.770284</td>\n",
       "      <td>2.298396</td>\n",
       "      <td>1.893610</td>\n",
       "      <td>0.688605</td>\n",
       "      <td>-0.266454</td>\n",
       "      <td>0.884643</td>\n",
       "      <td>1.266314</td>\n",
       "      <td>3.825332</td>\n",
       "      <td>1.871824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.850264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.725401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.547085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.426653</td>\n",
       "      <td>-0.294432</td>\n",
       "      <td>1.655602</td>\n",
       "      <td>1.912331</td>\n",
       "      <td>0.400704</td>\n",
       "      <td>-0.541753</td>\n",
       "      <td>0.397911</td>\n",
       "      <td>0.262699</td>\n",
       "      <td>2.978955</td>\n",
       "      <td>2.175787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.614353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.989650</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.013864</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.048203</td>\n",
       "      <td>1.312823</td>\n",
       "      <td>0.788894</td>\n",
       "      <td>1.822362</td>\n",
       "      <td>0.740061</td>\n",
       "      <td>-0.679603</td>\n",
       "      <td>0.054424</td>\n",
       "      <td>0.396038</td>\n",
       "      <td>2.665933</td>\n",
       "      <td>2.151856</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.102825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.877711</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.874078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.795649</td>\n",
       "      <td>0.083310</td>\n",
       "      <td>4.072560</td>\n",
       "      <td>2.039331</td>\n",
       "      <td>1.203853</td>\n",
       "      <td>-0.500179</td>\n",
       "      <td>0.103811</td>\n",
       "      <td>0.302639</td>\n",
       "      <td>2.141665</td>\n",
       "      <td>2.644978</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.639373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.887482</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.011651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>-0.549183</td>\n",
       "      <td>1.068315</td>\n",
       "      <td>-0.544373</td>\n",
       "      <td>-0.687935</td>\n",
       "      <td>-1.495602</td>\n",
       "      <td>0.805732</td>\n",
       "      <td>-0.293248</td>\n",
       "      <td>0.661497</td>\n",
       "      <td>-0.655689</td>\n",
       "      <td>1.600522</td>\n",
       "      <td>...</td>\n",
       "      <td>1.386827</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-1.000215</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.832783</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.872908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>-0.481985</td>\n",
       "      <td>0.560944</td>\n",
       "      <td>-0.518064</td>\n",
       "      <td>-0.626884</td>\n",
       "      <td>-0.968744</td>\n",
       "      <td>0.306776</td>\n",
       "      <td>-0.156714</td>\n",
       "      <td>0.689496</td>\n",
       "      <td>-0.459704</td>\n",
       "      <td>1.017618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600403</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.657988</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.534876</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.467096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>-0.402054</td>\n",
       "      <td>0.350446</td>\n",
       "      <td>-0.616373</td>\n",
       "      <td>-0.606093</td>\n",
       "      <td>-0.646526</td>\n",
       "      <td>0.503166</td>\n",
       "      <td>0.174464</td>\n",
       "      <td>0.605186</td>\n",
       "      <td>-0.408143</td>\n",
       "      <td>0.542851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382350</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.459207</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.351997</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.249248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>-0.146823</td>\n",
       "      <td>-1.792820</td>\n",
       "      <td>-0.325116</td>\n",
       "      <td>-0.462663</td>\n",
       "      <td>-0.400672</td>\n",
       "      <td>-1.067879</td>\n",
       "      <td>0.229314</td>\n",
       "      <td>0.030515</td>\n",
       "      <td>-0.452395</td>\n",
       "      <td>-0.750222</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.910985</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.487928</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.312771</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.184850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-0.051540</td>\n",
       "      <td>-0.120537</td>\n",
       "      <td>-0.236889</td>\n",
       "      <td>-0.568468</td>\n",
       "      <td>1.556927</td>\n",
       "      <td>-1.709317</td>\n",
       "      <td>0.223387</td>\n",
       "      <td>0.115353</td>\n",
       "      <td>-0.222063</td>\n",
       "      <td>-0.857548</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.460368</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.433529</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.297669</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1233 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Emiliani1_cyclostationary_mean_rr_8w_0  \\\n",
       "0                                  2.563762   \n",
       "1                                  1.725573   \n",
       "2                                  1.426653   \n",
       "3                                  1.048203   \n",
       "4                                  1.795649   \n",
       "..                                      ...   \n",
       "406                               -0.549183   \n",
       "407                               -0.481985   \n",
       "408                               -0.402054   \n",
       "409                               -0.146823   \n",
       "410                               -0.051540   \n",
       "\n",
       "     Emiliani1_cyclostationary_mean_tg_0  \\\n",
       "0                               0.702658   \n",
       "1                               1.770284   \n",
       "2                              -0.294432   \n",
       "3                               1.312823   \n",
       "4                               0.083310   \n",
       "..                                   ...   \n",
       "406                             1.068315   \n",
       "407                             0.560944   \n",
       "408                             0.350446   \n",
       "409                            -1.792820   \n",
       "410                            -0.120537   \n",
       "\n",
       "     Emiliani1_cyclostationary_mean_rr_16w_1  \\\n",
       "0                                   2.356915   \n",
       "1                                   2.298396   \n",
       "2                                   1.655602   \n",
       "3                                   0.788894   \n",
       "4                                   4.072560   \n",
       "..                                       ...   \n",
       "406                                -0.544373   \n",
       "407                                -0.518064   \n",
       "408                                -0.616373   \n",
       "409                                -0.325116   \n",
       "410                                -0.236889   \n",
       "\n",
       "     Emiliani1_cyclostationary_mean_rr_12w_2  \\\n",
       "0                                   4.551719   \n",
       "1                                   1.893610   \n",
       "2                                   1.912331   \n",
       "3                                   1.822362   \n",
       "4                                   2.039331   \n",
       "..                                       ...   \n",
       "406                                -0.687935   \n",
       "407                                -0.626884   \n",
       "408                                -0.606093   \n",
       "409                                -0.462663   \n",
       "410                                -0.568468   \n",
       "\n",
       "     Emiliani1_cyclostationary_mean_rr_1w_4  \\\n",
       "0                                  0.733057   \n",
       "1                                  0.688605   \n",
       "2                                  0.400704   \n",
       "3                                  0.740061   \n",
       "4                                  1.203853   \n",
       "..                                      ...   \n",
       "406                               -1.495602   \n",
       "407                               -0.968744   \n",
       "408                               -0.646526   \n",
       "409                               -0.400672   \n",
       "410                                1.556927   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_tg_1w_5  \\\n",
       "0                                 -0.890461   \n",
       "1                                 -0.266454   \n",
       "2                                 -0.541753   \n",
       "3                                 -0.679603   \n",
       "4                                 -0.500179   \n",
       "..                                      ...   \n",
       "406                                0.805732   \n",
       "407                                0.306776   \n",
       "408                                0.503166   \n",
       "409                               -1.067879   \n",
       "410                               -1.709317   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_rr_8w_3  \\\n",
       "0                                  1.715033   \n",
       "1                                  0.884643   \n",
       "2                                  0.397911   \n",
       "3                                  0.054424   \n",
       "4                                  0.103811   \n",
       "..                                      ...   \n",
       "406                               -0.293248   \n",
       "407                               -0.156714   \n",
       "408                                0.174464   \n",
       "409                                0.229314   \n",
       "410                                0.223387   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_tg_8w_1  \\\n",
       "0                                  0.451434   \n",
       "1                                  1.266314   \n",
       "2                                  0.262699   \n",
       "3                                  0.396038   \n",
       "4                                  0.302639   \n",
       "..                                      ...   \n",
       "406                                0.661497   \n",
       "407                                0.689496   \n",
       "408                                0.605186   \n",
       "409                                0.030515   \n",
       "410                                0.115353   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_rr_16w_2  \\\n",
       "0                                   5.057234   \n",
       "1                                   3.825332   \n",
       "2                                   2.978955   \n",
       "3                                   2.665933   \n",
       "4                                   2.141665   \n",
       "..                                       ...   \n",
       "406                                -0.655689   \n",
       "407                                -0.459704   \n",
       "408                                -0.408143   \n",
       "409                                -0.452395   \n",
       "410                                -0.222063   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_tg_1w_6  ...  \\\n",
       "0                                  0.839851  ...   \n",
       "1                                  1.871824  ...   \n",
       "2                                  2.175787  ...   \n",
       "3                                  2.151856  ...   \n",
       "4                                  2.644978  ...   \n",
       "..                                      ...  ...   \n",
       "406                                1.600522  ...   \n",
       "407                                1.017618  ...   \n",
       "408                                0.542851  ...   \n",
       "409                               -0.750222  ...   \n",
       "410                               -0.857548  ...   \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_tg_0_Garda_Mincio  \\\n",
       "0                                             0.000000     \n",
       "1                                             0.000000     \n",
       "2                                            -0.000000     \n",
       "3                                             0.000000     \n",
       "4                                            -0.000000     \n",
       "..                                                 ...     \n",
       "406                                           1.386827     \n",
       "407                                           0.600403     \n",
       "408                                           0.382350     \n",
       "409                                          -1.910985     \n",
       "410                                          -0.460368     \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_24w_1_Emiliani1  \\\n",
       "0                                             1.937637      \n",
       "1                                             1.850264      \n",
       "2                                             1.614353      \n",
       "3                                             1.102825      \n",
       "4                                             1.639373      \n",
       "..                                                 ...      \n",
       "406                                          -0.000000      \n",
       "407                                          -0.000000      \n",
       "408                                          -0.000000      \n",
       "409                                          -0.000000      \n",
       "410                                          -0.000000      \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_24w_1_Emiliani2  \\\n",
       "0                                                  0.0      \n",
       "1                                                  0.0      \n",
       "2                                                  0.0      \n",
       "3                                                  0.0      \n",
       "4                                                  0.0      \n",
       "..                                                 ...      \n",
       "406                                               -0.0      \n",
       "407                                               -0.0      \n",
       "408                                               -0.0      \n",
       "409                                               -0.0      \n",
       "410                                               -0.0      \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_24w_1_Garda_Mincio  \\\n",
       "0                                             0.000000         \n",
       "1                                             0.000000         \n",
       "2                                             0.000000         \n",
       "3                                             0.000000         \n",
       "4                                             0.000000         \n",
       "..                                                 ...         \n",
       "406                                          -1.000215         \n",
       "407                                          -0.657988         \n",
       "408                                          -0.459207         \n",
       "409                                          -0.487928         \n",
       "410                                          -0.433529         \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_24w_4_Emiliani1  \\\n",
       "0                                             2.719823      \n",
       "1                                             4.725401      \n",
       "2                                             2.989650      \n",
       "3                                             2.877711      \n",
       "4                                             1.887482      \n",
       "..                                                 ...      \n",
       "406                                          -0.000000      \n",
       "407                                          -0.000000      \n",
       "408                                          -0.000000      \n",
       "409                                          -0.000000      \n",
       "410                                          -0.000000      \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_24w_4_Emiliani2  \\\n",
       "0                                                  0.0      \n",
       "1                                                  0.0      \n",
       "2                                                  0.0      \n",
       "3                                                  0.0      \n",
       "4                                                  0.0      \n",
       "..                                                 ...      \n",
       "406                                               -0.0      \n",
       "407                                               -0.0      \n",
       "408                                               -0.0      \n",
       "409                                               -0.0      \n",
       "410                                               -0.0      \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_24w_4_Garda_Mincio  \\\n",
       "0                                             0.000000         \n",
       "1                                             0.000000         \n",
       "2                                             0.000000         \n",
       "3                                             0.000000         \n",
       "4                                             0.000000         \n",
       "..                                                 ...         \n",
       "406                                          -0.832783         \n",
       "407                                          -0.534876         \n",
       "408                                          -0.351997         \n",
       "409                                          -0.312771         \n",
       "410                                          -0.297669         \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_24w_6_Emiliani1  \\\n",
       "0                                             2.154612      \n",
       "1                                             4.547085      \n",
       "2                                             3.013864      \n",
       "3                                             2.874078      \n",
       "4                                             2.011651      \n",
       "..                                                 ...      \n",
       "406                                          -0.000000      \n",
       "407                                          -0.000000      \n",
       "408                                          -0.000000      \n",
       "409                                          -0.000000      \n",
       "410                                           0.000000      \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_24w_6_Emiliani2  \\\n",
       "0                                                  0.0      \n",
       "1                                                  0.0      \n",
       "2                                                  0.0      \n",
       "3                                                  0.0      \n",
       "4                                                  0.0      \n",
       "..                                                 ...      \n",
       "406                                               -0.0      \n",
       "407                                               -0.0      \n",
       "408                                               -0.0      \n",
       "409                                               -0.0      \n",
       "410                                                0.0      \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_24w_6_Garda_Mincio  \n",
       "0                                             0.000000        \n",
       "1                                             0.000000        \n",
       "2                                             0.000000        \n",
       "3                                             0.000000        \n",
       "4                                             0.000000        \n",
       "..                                                 ...        \n",
       "406                                          -0.872908        \n",
       "407                                          -0.467096        \n",
       "408                                          -0.249248        \n",
       "409                                          -0.184850        \n",
       "410                                           0.028905        \n",
       "\n",
       "[1233 rows x 63 columns]"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(best5_wrapper_clusterdf_train_withClass.shape[1]-len(clust_basins)):\n",
    "    for j in clust_basins:\n",
    "        best5_wrapper_clusterdf_train_withClass[best5_wrapper_clusterdf_train_withClass.columns[i]+'_'+j] = best5_wrapper_clusterdf_train_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "        best5_wrapper_clusterdf_val_withClass[best5_wrapper_clusterdf_val_withClass.columns[i]+'_'+j] = best5_wrapper_clusterdf_val_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "        best5_wrapper_clusterdf_test_withClass[best5_wrapper_clusterdf_test_withClass.columns[i]+'_'+j] = best5_wrapper_clusterdf_test_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "\n",
    "best5_wrapper_clusterdf_train_withClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "e1247120",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2983574252239063\n",
      "0.2060983834314577\n",
      "0.23368544966756366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_E1E2GM_ohe = LinearRegression()\n",
    "model_E1E2GM_ohe.fit(pd.concat((best5_wrapper_clusterdf_train_withClass,best5_wrapper_clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_E1E2GM_ohe.predict(best5_wrapper_clusterdf_test_withClass.loc[best5_wrapper_clusterdf_test_withClass.Emiliani1==1].values)\n",
    "print(r2_score(targets_df_test['Emiliani1'].values, res))\n",
    "res = model_E1E2GM_ohe.predict(best5_wrapper_clusterdf_test_withClass.loc[best5_wrapper_clusterdf_test_withClass.Emiliani2==1].values)\n",
    "print(r2_score(targets_df_test['Emiliani2'].values, res))\n",
    "res = model_E1E2GM_ohe.predict(best5_wrapper_clusterdf_test_withClass.loc[best5_wrapper_clusterdf_test_withClass.Garda_Mincio==1].values)\n",
    "print(r2_score(targets_df_test['Garda_Mincio'].values, res))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a932b5de",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Emiliani1 - Emiliani2 - Garda_Mincio: CMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "b2245869",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### prova con Emiliani1 e 2 e Garda_Mincio\n",
    "clust_basins = ['Emiliani1','Emiliani2','Garda_Mincio']\n",
    "colnames = [x for x in CMI_fulldf_train.columns if x.startswith('Emiliani1') or x.startswith('Emiliani2') or x.startswith('Garda_Mincio')]\n",
    "\n",
    "clusterdf_train_withClass = pd.DataFrame()\n",
    "clusterdf_val_withClass = pd.DataFrame()\n",
    "clusterdf_test_withClass = pd.DataFrame()\n",
    "\n",
    "for i in range(3):\n",
    "    clusterdf_train_withClass = pd.concat((clusterdf_train_withClass,pd.concat((CMI_fulldf_train[colnames],pd.DataFrame(1+i*np.ones(len(CMI_fulldf_train)),columns=['basin'])),axis=1)),axis=0)\n",
    "    clusterdf_val_withClass = pd.concat((clusterdf_val_withClass,pd.concat((CMI_fulldf_val[colnames],pd.DataFrame(1+i*np.ones(len(CMI_fulldf_val)),columns=['basin'])),axis=1)),axis=0)\n",
    "    clusterdf_test_withClass = pd.concat((clusterdf_test_withClass,pd.concat((CMI_fulldf_test[colnames],pd.DataFrame(1+i*np.ones(len(CMI_fulldf_test)),columns=['basin'])),axis=1)),axis=0)\n",
    "\n",
    "for i in range(3):\n",
    "    clusterdf_train_withClass[clust_basins[i]] = clusterdf_train_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    clusterdf_val_withClass[clust_basins[i]] = clusterdf_val_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    clusterdf_test_withClass[clust_basins[i]] = clusterdf_test_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "\n",
    "clusterdf_train_withClass = clusterdf_train_withClass.loc[:,clusterdf_train_withClass.columns != 'basin']\n",
    "clusterdf_val_withClass = clusterdf_val_withClass.loc[:,clusterdf_val_withClass.columns != 'basin']\n",
    "clusterdf_test_withClass = clusterdf_test_withClass.loc[:,clusterdf_test_withClass.columns != 'basin']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "5ae0ff20",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emiliani1_cyclostationary_mean_rr_4w_0</th>\n",
       "      <th>Emiliani1_cyclostationary_mean_tg_1w_4</th>\n",
       "      <th>Emiliani1_cyclostationary_mean_rr_12w_1</th>\n",
       "      <th>Emiliani1_cyclostationary_mean_rr_8w_1</th>\n",
       "      <th>Emiliani1_cyclostationary_mean_tg_9</th>\n",
       "      <th>Emiliani1_cyclostationary_mean_rr_8w_0</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_tg_1w_4</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_rr_4w_3</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_tg_4</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_rr_8w_0</th>\n",
       "      <th>...</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_rr_12w_0</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_4w_0</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_tg_0</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_8w_0</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_12w_2</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_tg_8w_0</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_4w_1</th>\n",
       "      <th>Emiliani1</th>\n",
       "      <th>Emiliani2</th>\n",
       "      <th>Garda_Mincio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.112078</td>\n",
       "      <td>0.345989</td>\n",
       "      <td>1.690770</td>\n",
       "      <td>3.965287</td>\n",
       "      <td>0.268224</td>\n",
       "      <td>2.563762</td>\n",
       "      <td>-0.415835</td>\n",
       "      <td>0.733822</td>\n",
       "      <td>-0.736407</td>\n",
       "      <td>2.581050</td>\n",
       "      <td>...</td>\n",
       "      <td>2.601327</td>\n",
       "      <td>1.154090</td>\n",
       "      <td>0.309939</td>\n",
       "      <td>1.365733</td>\n",
       "      <td>1.718220</td>\n",
       "      <td>0.523659</td>\n",
       "      <td>1.758769</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.404523</td>\n",
       "      <td>1.128851</td>\n",
       "      <td>1.865833</td>\n",
       "      <td>1.655892</td>\n",
       "      <td>0.977612</td>\n",
       "      <td>1.725573</td>\n",
       "      <td>0.237307</td>\n",
       "      <td>0.849889</td>\n",
       "      <td>0.294888</td>\n",
       "      <td>2.460299</td>\n",
       "      <td>...</td>\n",
       "      <td>2.248295</td>\n",
       "      <td>1.494420</td>\n",
       "      <td>1.158323</td>\n",
       "      <td>1.161450</td>\n",
       "      <td>3.292752</td>\n",
       "      <td>1.350980</td>\n",
       "      <td>1.121893</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.162736</td>\n",
       "      <td>0.786460</td>\n",
       "      <td>1.429151</td>\n",
       "      <td>1.672157</td>\n",
       "      <td>-0.780151</td>\n",
       "      <td>1.426653</td>\n",
       "      <td>-0.259989</td>\n",
       "      <td>0.518355</td>\n",
       "      <td>-1.191392</td>\n",
       "      <td>1.657472</td>\n",
       "      <td>...</td>\n",
       "      <td>1.476876</td>\n",
       "      <td>0.992024</td>\n",
       "      <td>-0.747849</td>\n",
       "      <td>0.765542</td>\n",
       "      <td>2.143920</td>\n",
       "      <td>0.395851</td>\n",
       "      <td>0.598275</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.861999</td>\n",
       "      <td>0.564161</td>\n",
       "      <td>0.611897</td>\n",
       "      <td>1.593990</td>\n",
       "      <td>0.408553</td>\n",
       "      <td>1.048203</td>\n",
       "      <td>-0.565851</td>\n",
       "      <td>0.239497</td>\n",
       "      <td>0.067063</td>\n",
       "      <td>1.600489</td>\n",
       "      <td>...</td>\n",
       "      <td>1.354389</td>\n",
       "      <td>0.831685</td>\n",
       "      <td>0.618235</td>\n",
       "      <td>0.486500</td>\n",
       "      <td>2.057757</td>\n",
       "      <td>0.584992</td>\n",
       "      <td>0.310672</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.461930</td>\n",
       "      <td>0.604584</td>\n",
       "      <td>4.150391</td>\n",
       "      <td>1.782496</td>\n",
       "      <td>-0.260577</td>\n",
       "      <td>1.795649</td>\n",
       "      <td>-0.187005</td>\n",
       "      <td>0.696217</td>\n",
       "      <td>-0.894857</td>\n",
       "      <td>1.249495</td>\n",
       "      <td>...</td>\n",
       "      <td>1.149851</td>\n",
       "      <td>0.648410</td>\n",
       "      <td>-0.197356</td>\n",
       "      <td>0.471393</td>\n",
       "      <td>1.411145</td>\n",
       "      <td>0.375705</td>\n",
       "      <td>0.314132</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>-0.211596</td>\n",
       "      <td>0.739113</td>\n",
       "      <td>-0.281990</td>\n",
       "      <td>-0.636426</td>\n",
       "      <td>1.599630</td>\n",
       "      <td>-0.549183</td>\n",
       "      <td>1.352614</td>\n",
       "      <td>-0.220555</td>\n",
       "      <td>0.471800</td>\n",
       "      <td>-0.187672</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.500492</td>\n",
       "      <td>-0.325559</td>\n",
       "      <td>1.386827</td>\n",
       "      <td>-0.243007</td>\n",
       "      <td>-0.779607</td>\n",
       "      <td>0.784844</td>\n",
       "      <td>0.030398</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>-0.765747</td>\n",
       "      <td>0.855313</td>\n",
       "      <td>-0.234571</td>\n",
       "      <td>-1.204469</td>\n",
       "      <td>0.920235</td>\n",
       "      <td>-0.481985</td>\n",
       "      <td>1.040390</td>\n",
       "      <td>0.346445</td>\n",
       "      <td>0.034058</td>\n",
       "      <td>-0.358316</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.168721</td>\n",
       "      <td>-0.048154</td>\n",
       "      <td>0.600403</td>\n",
       "      <td>-0.089677</td>\n",
       "      <td>-0.282528</td>\n",
       "      <td>0.689576</td>\n",
       "      <td>0.377049</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>-0.609296</td>\n",
       "      <td>0.697286</td>\n",
       "      <td>-0.562017</td>\n",
       "      <td>-1.089158</td>\n",
       "      <td>0.341994</td>\n",
       "      <td>-0.402054</td>\n",
       "      <td>0.830698</td>\n",
       "      <td>0.429694</td>\n",
       "      <td>0.796373</td>\n",
       "      <td>-0.106524</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094182</td>\n",
       "      <td>0.392946</td>\n",
       "      <td>0.382350</td>\n",
       "      <td>0.196236</td>\n",
       "      <td>-0.211020</td>\n",
       "      <td>0.473678</td>\n",
       "      <td>0.643723</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>-0.836849</td>\n",
       "      <td>-0.719738</td>\n",
       "      <td>-0.028118</td>\n",
       "      <td>-0.925439</td>\n",
       "      <td>-1.523290</td>\n",
       "      <td>-0.146823</td>\n",
       "      <td>-0.631908</td>\n",
       "      <td>-0.434877</td>\n",
       "      <td>-2.562406</td>\n",
       "      <td>-0.028237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027915</td>\n",
       "      <td>-0.140998</td>\n",
       "      <td>-1.910985</td>\n",
       "      <td>0.283754</td>\n",
       "      <td>-0.190893</td>\n",
       "      <td>-0.254712</td>\n",
       "      <td>-0.102080</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-0.283715</td>\n",
       "      <td>-1.078052</td>\n",
       "      <td>0.226971</td>\n",
       "      <td>-0.799403</td>\n",
       "      <td>-0.625862</td>\n",
       "      <td>-0.051540</td>\n",
       "      <td>-1.226069</td>\n",
       "      <td>0.334461</td>\n",
       "      <td>-0.263730</td>\n",
       "      <td>0.344734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228144</td>\n",
       "      <td>0.297361</td>\n",
       "      <td>-0.460368</td>\n",
       "      <td>0.250722</td>\n",
       "      <td>0.025355</td>\n",
       "      <td>-0.180499</td>\n",
       "      <td>0.187242</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1233 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Emiliani1_cyclostationary_mean_rr_4w_0  \\\n",
       "0                                  2.112078   \n",
       "1                                  1.404523   \n",
       "2                                  1.162736   \n",
       "3                                  0.861999   \n",
       "4                                  1.461930   \n",
       "..                                      ...   \n",
       "406                               -0.211596   \n",
       "407                               -0.765747   \n",
       "408                               -0.609296   \n",
       "409                               -0.836849   \n",
       "410                               -0.283715   \n",
       "\n",
       "     Emiliani1_cyclostationary_mean_tg_1w_4  \\\n",
       "0                                  0.345989   \n",
       "1                                  1.128851   \n",
       "2                                  0.786460   \n",
       "3                                  0.564161   \n",
       "4                                  0.604584   \n",
       "..                                      ...   \n",
       "406                                0.739113   \n",
       "407                                0.855313   \n",
       "408                                0.697286   \n",
       "409                               -0.719738   \n",
       "410                               -1.078052   \n",
       "\n",
       "     Emiliani1_cyclostationary_mean_rr_12w_1  \\\n",
       "0                                   1.690770   \n",
       "1                                   1.865833   \n",
       "2                                   1.429151   \n",
       "3                                   0.611897   \n",
       "4                                   4.150391   \n",
       "..                                       ...   \n",
       "406                                -0.281990   \n",
       "407                                -0.234571   \n",
       "408                                -0.562017   \n",
       "409                                -0.028118   \n",
       "410                                 0.226971   \n",
       "\n",
       "     Emiliani1_cyclostationary_mean_rr_8w_1  \\\n",
       "0                                  3.965287   \n",
       "1                                  1.655892   \n",
       "2                                  1.672157   \n",
       "3                                  1.593990   \n",
       "4                                  1.782496   \n",
       "..                                      ...   \n",
       "406                               -0.636426   \n",
       "407                               -1.204469   \n",
       "408                               -1.089158   \n",
       "409                               -0.925439   \n",
       "410                               -0.799403   \n",
       "\n",
       "     Emiliani1_cyclostationary_mean_tg_9  \\\n",
       "0                               0.268224   \n",
       "1                               0.977612   \n",
       "2                              -0.780151   \n",
       "3                               0.408553   \n",
       "4                              -0.260577   \n",
       "..                                   ...   \n",
       "406                             1.599630   \n",
       "407                             0.920235   \n",
       "408                             0.341994   \n",
       "409                            -1.523290   \n",
       "410                            -0.625862   \n",
       "\n",
       "     Emiliani1_cyclostationary_mean_rr_8w_0  \\\n",
       "0                                  2.563762   \n",
       "1                                  1.725573   \n",
       "2                                  1.426653   \n",
       "3                                  1.048203   \n",
       "4                                  1.795649   \n",
       "..                                      ...   \n",
       "406                               -0.549183   \n",
       "407                               -0.481985   \n",
       "408                               -0.402054   \n",
       "409                               -0.146823   \n",
       "410                               -0.051540   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_tg_1w_4  \\\n",
       "0                                 -0.415835   \n",
       "1                                  0.237307   \n",
       "2                                 -0.259989   \n",
       "3                                 -0.565851   \n",
       "4                                 -0.187005   \n",
       "..                                      ...   \n",
       "406                                1.352614   \n",
       "407                                1.040390   \n",
       "408                                0.830698   \n",
       "409                               -0.631908   \n",
       "410                               -1.226069   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_rr_4w_3  \\\n",
       "0                                  0.733822   \n",
       "1                                  0.849889   \n",
       "2                                  0.518355   \n",
       "3                                  0.239497   \n",
       "4                                  0.696217   \n",
       "..                                      ...   \n",
       "406                               -0.220555   \n",
       "407                                0.346445   \n",
       "408                                0.429694   \n",
       "409                               -0.434877   \n",
       "410                                0.334461   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_tg_4  \\\n",
       "0                              -0.736407   \n",
       "1                               0.294888   \n",
       "2                              -1.191392   \n",
       "3                               0.067063   \n",
       "4                              -0.894857   \n",
       "..                                   ...   \n",
       "406                             0.471800   \n",
       "407                             0.034058   \n",
       "408                             0.796373   \n",
       "409                            -2.562406   \n",
       "410                            -0.263730   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_rr_8w_0  ...  \\\n",
       "0                                  2.581050  ...   \n",
       "1                                  2.460299  ...   \n",
       "2                                  1.657472  ...   \n",
       "3                                  1.600489  ...   \n",
       "4                                  1.249495  ...   \n",
       "..                                      ...  ...   \n",
       "406                               -0.187672  ...   \n",
       "407                               -0.358316  ...   \n",
       "408                               -0.106524  ...   \n",
       "409                               -0.028237  ...   \n",
       "410                                0.344734  ...   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_rr_12w_0  \\\n",
       "0                                   2.601327   \n",
       "1                                   2.248295   \n",
       "2                                   1.476876   \n",
       "3                                   1.354389   \n",
       "4                                   1.149851   \n",
       "..                                       ...   \n",
       "406                                -0.500492   \n",
       "407                                -0.168721   \n",
       "408                                -0.094182   \n",
       "409                                 0.027915   \n",
       "410                                 0.228144   \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_4w_0  \\\n",
       "0                                     1.154090   \n",
       "1                                     1.494420   \n",
       "2                                     0.992024   \n",
       "3                                     0.831685   \n",
       "4                                     0.648410   \n",
       "..                                         ...   \n",
       "406                                  -0.325559   \n",
       "407                                  -0.048154   \n",
       "408                                   0.392946   \n",
       "409                                  -0.140998   \n",
       "410                                   0.297361   \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_tg_0  \\\n",
       "0                                  0.309939   \n",
       "1                                  1.158323   \n",
       "2                                 -0.747849   \n",
       "3                                  0.618235   \n",
       "4                                 -0.197356   \n",
       "..                                      ...   \n",
       "406                                1.386827   \n",
       "407                                0.600403   \n",
       "408                                0.382350   \n",
       "409                               -1.910985   \n",
       "410                               -0.460368   \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_8w_0  \\\n",
       "0                                     1.365733   \n",
       "1                                     1.161450   \n",
       "2                                     0.765542   \n",
       "3                                     0.486500   \n",
       "4                                     0.471393   \n",
       "..                                         ...   \n",
       "406                                  -0.243007   \n",
       "407                                  -0.089677   \n",
       "408                                   0.196236   \n",
       "409                                   0.283754   \n",
       "410                                   0.250722   \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_12w_2  \\\n",
       "0                                      1.718220   \n",
       "1                                      3.292752   \n",
       "2                                      2.143920   \n",
       "3                                      2.057757   \n",
       "4                                      1.411145   \n",
       "..                                          ...   \n",
       "406                                   -0.779607   \n",
       "407                                   -0.282528   \n",
       "408                                   -0.211020   \n",
       "409                                   -0.190893   \n",
       "410                                    0.025355   \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_tg_8w_0  \\\n",
       "0                                     0.523659   \n",
       "1                                     1.350980   \n",
       "2                                     0.395851   \n",
       "3                                     0.584992   \n",
       "4                                     0.375705   \n",
       "..                                         ...   \n",
       "406                                   0.784844   \n",
       "407                                   0.689576   \n",
       "408                                   0.473678   \n",
       "409                                  -0.254712   \n",
       "410                                  -0.180499   \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_4w_1  Emiliani1  Emiliani2  \\\n",
       "0                                     1.758769          1          0   \n",
       "1                                     1.121893          1          0   \n",
       "2                                     0.598275          1          0   \n",
       "3                                     0.310672          1          0   \n",
       "4                                     0.314132          1          0   \n",
       "..                                         ...        ...        ...   \n",
       "406                                   0.030398          0          0   \n",
       "407                                   0.377049          0          0   \n",
       "408                                   0.643723          0          0   \n",
       "409                                  -0.102080          0          0   \n",
       "410                                   0.187242          0          0   \n",
       "\n",
       "     Garda_Mincio  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "..            ...  \n",
       "406             1  \n",
       "407             1  \n",
       "408             1  \n",
       "409             1  \n",
       "410             1  \n",
       "\n",
       "[1233 rows x 27 columns]"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterdf_train_withClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "1168cfe6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "targets_df_train_unfolded = pd.DataFrame()\n",
    "targets_df_val_unfolded = pd.DataFrame()\n",
    "targets_df_test_unfolded = pd.DataFrame()\n",
    "\n",
    "for basin in ['Emiliani1','Emiliani2','Garda_Mincio']:\n",
    "    targets_df_train_unfolded =  pd.concat((targets_df_train_unfolded,targets_df_train[basin]),axis=0)\n",
    "    targets_df_val_unfolded =  pd.concat((targets_df_val_unfolded,targets_df_val[basin]),axis=0)\n",
    "    targets_df_test_unfolded =  pd.concat((targets_df_test_unfolded,targets_df_test[basin]),axis=0)\n",
    "targets_df_train_unfolded = targets_df_train_unfolded.reset_index(drop=True)\n",
    "targets_df_val_unfolded = targets_df_val_unfolded.reset_index(drop=True)\n",
    "targets_df_test_unfolded = targets_df_test_unfolded.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "076285b1",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.382765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.319215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.548542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.010351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.402030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>0.032299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>0.132804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>-0.214182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>-2.409204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>-2.673294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1233 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0    -0.382765\n",
       "1     0.319215\n",
       "2     0.548542\n",
       "3    -0.010351\n",
       "4     0.402030\n",
       "...        ...\n",
       "1228  0.032299\n",
       "1229  0.132804\n",
       "1230 -0.214182\n",
       "1231 -2.409204\n",
       "1232 -2.673294\n",
       "\n",
       "[1233 rows x 1 columns]"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_df_train_unfolded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "ca3e4ad6",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24672638409672598\n",
      "0.13606766610694088\n",
      "0.22388038233882868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_E1E2GM_ohe = LinearRegression()\n",
    "model_E1E2GM_ohe.fit(pd.concat((clusterdf_train_withClass,clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_E1E2GM_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Emiliani1==1].values)\n",
    "print(r2_score(targets_df_test['Emiliani1'].values, res))\n",
    "res = model_E1E2GM_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Emiliani2==1].values)\n",
    "print(r2_score(targets_df_test['Emiliani2'].values, res))\n",
    "res = model_E1E2GM_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Garda_Mincio==1].values)\n",
    "print(r2_score(targets_df_test['Garda_Mincio'].values, res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "01635641",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emiliani1_cyclostationary_mean_rr_4w_0</th>\n",
       "      <th>Emiliani1_cyclostationary_mean_tg_1w_4</th>\n",
       "      <th>Emiliani1_cyclostationary_mean_rr_12w_1</th>\n",
       "      <th>Emiliani1_cyclostationary_mean_rr_8w_1</th>\n",
       "      <th>Emiliani1_cyclostationary_mean_tg_9</th>\n",
       "      <th>Emiliani1_cyclostationary_mean_rr_8w_0</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_tg_1w_4</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_rr_4w_3</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_tg_4</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_rr_8w_0</th>\n",
       "      <th>...</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_8w_0_Garda_Mincio</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_12w_2_Emiliani1</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_12w_2_Emiliani2</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_12w_2_Garda_Mincio</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_tg_8w_0_Emiliani1</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_tg_8w_0_Emiliani2</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_tg_8w_0_Garda_Mincio</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_4w_1_Emiliani1</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_4w_1_Emiliani2</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_4w_1_Garda_Mincio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.112078</td>\n",
       "      <td>0.345989</td>\n",
       "      <td>1.690770</td>\n",
       "      <td>3.965287</td>\n",
       "      <td>0.268224</td>\n",
       "      <td>2.563762</td>\n",
       "      <td>-0.415835</td>\n",
       "      <td>0.733822</td>\n",
       "      <td>-0.736407</td>\n",
       "      <td>2.581050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.718220</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.523659</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.758769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.404523</td>\n",
       "      <td>1.128851</td>\n",
       "      <td>1.865833</td>\n",
       "      <td>1.655892</td>\n",
       "      <td>0.977612</td>\n",
       "      <td>1.725573</td>\n",
       "      <td>0.237307</td>\n",
       "      <td>0.849889</td>\n",
       "      <td>0.294888</td>\n",
       "      <td>2.460299</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.292752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.350980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.121893</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.162736</td>\n",
       "      <td>0.786460</td>\n",
       "      <td>1.429151</td>\n",
       "      <td>1.672157</td>\n",
       "      <td>-0.780151</td>\n",
       "      <td>1.426653</td>\n",
       "      <td>-0.259989</td>\n",
       "      <td>0.518355</td>\n",
       "      <td>-1.191392</td>\n",
       "      <td>1.657472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.143920</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.395851</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.598275</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.861999</td>\n",
       "      <td>0.564161</td>\n",
       "      <td>0.611897</td>\n",
       "      <td>1.593990</td>\n",
       "      <td>0.408553</td>\n",
       "      <td>1.048203</td>\n",
       "      <td>-0.565851</td>\n",
       "      <td>0.239497</td>\n",
       "      <td>0.067063</td>\n",
       "      <td>1.600489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.057757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.584992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.310672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.461930</td>\n",
       "      <td>0.604584</td>\n",
       "      <td>4.150391</td>\n",
       "      <td>1.782496</td>\n",
       "      <td>-0.260577</td>\n",
       "      <td>1.795649</td>\n",
       "      <td>-0.187005</td>\n",
       "      <td>0.696217</td>\n",
       "      <td>-0.894857</td>\n",
       "      <td>1.249495</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.411145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375705</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.314132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>-0.211596</td>\n",
       "      <td>0.739113</td>\n",
       "      <td>-0.281990</td>\n",
       "      <td>-0.636426</td>\n",
       "      <td>1.599630</td>\n",
       "      <td>-0.549183</td>\n",
       "      <td>1.352614</td>\n",
       "      <td>-0.220555</td>\n",
       "      <td>0.471800</td>\n",
       "      <td>-0.187672</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.243007</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.779607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.784844</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>-0.765747</td>\n",
       "      <td>0.855313</td>\n",
       "      <td>-0.234571</td>\n",
       "      <td>-1.204469</td>\n",
       "      <td>0.920235</td>\n",
       "      <td>-0.481985</td>\n",
       "      <td>1.040390</td>\n",
       "      <td>0.346445</td>\n",
       "      <td>0.034058</td>\n",
       "      <td>-0.358316</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.089677</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.282528</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.689576</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.377049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>-0.609296</td>\n",
       "      <td>0.697286</td>\n",
       "      <td>-0.562017</td>\n",
       "      <td>-1.089158</td>\n",
       "      <td>0.341994</td>\n",
       "      <td>-0.402054</td>\n",
       "      <td>0.830698</td>\n",
       "      <td>0.429694</td>\n",
       "      <td>0.796373</td>\n",
       "      <td>-0.106524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.196236</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.211020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.473678</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.643723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>-0.836849</td>\n",
       "      <td>-0.719738</td>\n",
       "      <td>-0.028118</td>\n",
       "      <td>-0.925439</td>\n",
       "      <td>-1.523290</td>\n",
       "      <td>-0.146823</td>\n",
       "      <td>-0.631908</td>\n",
       "      <td>-0.434877</td>\n",
       "      <td>-2.562406</td>\n",
       "      <td>-0.028237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.283754</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.190893</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.254712</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.102080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-0.283715</td>\n",
       "      <td>-1.078052</td>\n",
       "      <td>0.226971</td>\n",
       "      <td>-0.799403</td>\n",
       "      <td>-0.625862</td>\n",
       "      <td>-0.051540</td>\n",
       "      <td>-1.226069</td>\n",
       "      <td>0.334461</td>\n",
       "      <td>-0.263730</td>\n",
       "      <td>0.344734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250722</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025355</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.180499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.187242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1233 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Emiliani1_cyclostationary_mean_rr_4w_0  \\\n",
       "0                                  2.112078   \n",
       "1                                  1.404523   \n",
       "2                                  1.162736   \n",
       "3                                  0.861999   \n",
       "4                                  1.461930   \n",
       "..                                      ...   \n",
       "406                               -0.211596   \n",
       "407                               -0.765747   \n",
       "408                               -0.609296   \n",
       "409                               -0.836849   \n",
       "410                               -0.283715   \n",
       "\n",
       "     Emiliani1_cyclostationary_mean_tg_1w_4  \\\n",
       "0                                  0.345989   \n",
       "1                                  1.128851   \n",
       "2                                  0.786460   \n",
       "3                                  0.564161   \n",
       "4                                  0.604584   \n",
       "..                                      ...   \n",
       "406                                0.739113   \n",
       "407                                0.855313   \n",
       "408                                0.697286   \n",
       "409                               -0.719738   \n",
       "410                               -1.078052   \n",
       "\n",
       "     Emiliani1_cyclostationary_mean_rr_12w_1  \\\n",
       "0                                   1.690770   \n",
       "1                                   1.865833   \n",
       "2                                   1.429151   \n",
       "3                                   0.611897   \n",
       "4                                   4.150391   \n",
       "..                                       ...   \n",
       "406                                -0.281990   \n",
       "407                                -0.234571   \n",
       "408                                -0.562017   \n",
       "409                                -0.028118   \n",
       "410                                 0.226971   \n",
       "\n",
       "     Emiliani1_cyclostationary_mean_rr_8w_1  \\\n",
       "0                                  3.965287   \n",
       "1                                  1.655892   \n",
       "2                                  1.672157   \n",
       "3                                  1.593990   \n",
       "4                                  1.782496   \n",
       "..                                      ...   \n",
       "406                               -0.636426   \n",
       "407                               -1.204469   \n",
       "408                               -1.089158   \n",
       "409                               -0.925439   \n",
       "410                               -0.799403   \n",
       "\n",
       "     Emiliani1_cyclostationary_mean_tg_9  \\\n",
       "0                               0.268224   \n",
       "1                               0.977612   \n",
       "2                              -0.780151   \n",
       "3                               0.408553   \n",
       "4                              -0.260577   \n",
       "..                                   ...   \n",
       "406                             1.599630   \n",
       "407                             0.920235   \n",
       "408                             0.341994   \n",
       "409                            -1.523290   \n",
       "410                            -0.625862   \n",
       "\n",
       "     Emiliani1_cyclostationary_mean_rr_8w_0  \\\n",
       "0                                  2.563762   \n",
       "1                                  1.725573   \n",
       "2                                  1.426653   \n",
       "3                                  1.048203   \n",
       "4                                  1.795649   \n",
       "..                                      ...   \n",
       "406                               -0.549183   \n",
       "407                               -0.481985   \n",
       "408                               -0.402054   \n",
       "409                               -0.146823   \n",
       "410                               -0.051540   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_tg_1w_4  \\\n",
       "0                                 -0.415835   \n",
       "1                                  0.237307   \n",
       "2                                 -0.259989   \n",
       "3                                 -0.565851   \n",
       "4                                 -0.187005   \n",
       "..                                      ...   \n",
       "406                                1.352614   \n",
       "407                                1.040390   \n",
       "408                                0.830698   \n",
       "409                               -0.631908   \n",
       "410                               -1.226069   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_rr_4w_3  \\\n",
       "0                                  0.733822   \n",
       "1                                  0.849889   \n",
       "2                                  0.518355   \n",
       "3                                  0.239497   \n",
       "4                                  0.696217   \n",
       "..                                      ...   \n",
       "406                               -0.220555   \n",
       "407                                0.346445   \n",
       "408                                0.429694   \n",
       "409                               -0.434877   \n",
       "410                                0.334461   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_tg_4  \\\n",
       "0                              -0.736407   \n",
       "1                               0.294888   \n",
       "2                              -1.191392   \n",
       "3                               0.067063   \n",
       "4                              -0.894857   \n",
       "..                                   ...   \n",
       "406                             0.471800   \n",
       "407                             0.034058   \n",
       "408                             0.796373   \n",
       "409                            -2.562406   \n",
       "410                            -0.263730   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_rr_8w_0  ...  \\\n",
       "0                                  2.581050  ...   \n",
       "1                                  2.460299  ...   \n",
       "2                                  1.657472  ...   \n",
       "3                                  1.600489  ...   \n",
       "4                                  1.249495  ...   \n",
       "..                                      ...  ...   \n",
       "406                               -0.187672  ...   \n",
       "407                               -0.358316  ...   \n",
       "408                               -0.106524  ...   \n",
       "409                               -0.028237  ...   \n",
       "410                                0.344734  ...   \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_8w_0_Garda_Mincio  \\\n",
       "0                                             0.000000        \n",
       "1                                             0.000000        \n",
       "2                                             0.000000        \n",
       "3                                             0.000000        \n",
       "4                                             0.000000        \n",
       "..                                                 ...        \n",
       "406                                          -0.243007        \n",
       "407                                          -0.089677        \n",
       "408                                           0.196236        \n",
       "409                                           0.283754        \n",
       "410                                           0.250722        \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_12w_2_Emiliani1  \\\n",
       "0                                             1.718220      \n",
       "1                                             3.292752      \n",
       "2                                             2.143920      \n",
       "3                                             2.057757      \n",
       "4                                             1.411145      \n",
       "..                                                 ...      \n",
       "406                                          -0.000000      \n",
       "407                                          -0.000000      \n",
       "408                                          -0.000000      \n",
       "409                                          -0.000000      \n",
       "410                                           0.000000      \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_12w_2_Emiliani2  \\\n",
       "0                                                  0.0      \n",
       "1                                                  0.0      \n",
       "2                                                  0.0      \n",
       "3                                                  0.0      \n",
       "4                                                  0.0      \n",
       "..                                                 ...      \n",
       "406                                               -0.0      \n",
       "407                                               -0.0      \n",
       "408                                               -0.0      \n",
       "409                                               -0.0      \n",
       "410                                                0.0      \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_12w_2_Garda_Mincio  \\\n",
       "0                                             0.000000         \n",
       "1                                             0.000000         \n",
       "2                                             0.000000         \n",
       "3                                             0.000000         \n",
       "4                                             0.000000         \n",
       "..                                                 ...         \n",
       "406                                          -0.779607         \n",
       "407                                          -0.282528         \n",
       "408                                          -0.211020         \n",
       "409                                          -0.190893         \n",
       "410                                           0.025355         \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_tg_8w_0_Emiliani1  \\\n",
       "0                                             0.523659     \n",
       "1                                             1.350980     \n",
       "2                                             0.395851     \n",
       "3                                             0.584992     \n",
       "4                                             0.375705     \n",
       "..                                                 ...     \n",
       "406                                           0.000000     \n",
       "407                                           0.000000     \n",
       "408                                           0.000000     \n",
       "409                                          -0.000000     \n",
       "410                                          -0.000000     \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_tg_8w_0_Emiliani2  \\\n",
       "0                                                  0.0     \n",
       "1                                                  0.0     \n",
       "2                                                  0.0     \n",
       "3                                                  0.0     \n",
       "4                                                  0.0     \n",
       "..                                                 ...     \n",
       "406                                                0.0     \n",
       "407                                                0.0     \n",
       "408                                                0.0     \n",
       "409                                               -0.0     \n",
       "410                                               -0.0     \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_tg_8w_0_Garda_Mincio  \\\n",
       "0                                             0.000000        \n",
       "1                                             0.000000        \n",
       "2                                             0.000000        \n",
       "3                                             0.000000        \n",
       "4                                             0.000000        \n",
       "..                                                 ...        \n",
       "406                                           0.784844        \n",
       "407                                           0.689576        \n",
       "408                                           0.473678        \n",
       "409                                          -0.254712        \n",
       "410                                          -0.180499        \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_4w_1_Emiliani1  \\\n",
       "0                                             1.758769     \n",
       "1                                             1.121893     \n",
       "2                                             0.598275     \n",
       "3                                             0.310672     \n",
       "4                                             0.314132     \n",
       "..                                                 ...     \n",
       "406                                           0.000000     \n",
       "407                                           0.000000     \n",
       "408                                           0.000000     \n",
       "409                                          -0.000000     \n",
       "410                                           0.000000     \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_4w_1_Emiliani2  \\\n",
       "0                                                  0.0     \n",
       "1                                                  0.0     \n",
       "2                                                  0.0     \n",
       "3                                                  0.0     \n",
       "4                                                  0.0     \n",
       "..                                                 ...     \n",
       "406                                                0.0     \n",
       "407                                                0.0     \n",
       "408                                                0.0     \n",
       "409                                               -0.0     \n",
       "410                                                0.0     \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_4w_1_Garda_Mincio  \n",
       "0                                             0.000000       \n",
       "1                                             0.000000       \n",
       "2                                             0.000000       \n",
       "3                                             0.000000       \n",
       "4                                             0.000000       \n",
       "..                                                 ...       \n",
       "406                                           0.030398       \n",
       "407                                           0.377049       \n",
       "408                                           0.643723       \n",
       "409                                          -0.102080       \n",
       "410                                           0.187242       \n",
       "\n",
       "[1233 rows x 99 columns]"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(clusterdf_train_withClass.shape[1]-len(clust_basins)):\n",
    "    for j in clust_basins:\n",
    "        clusterdf_train_withClass[clusterdf_train_withClass.columns[i]+'_'+j] = clusterdf_train_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "        clusterdf_val_withClass[clusterdf_val_withClass.columns[i]+'_'+j] = clusterdf_val_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "        clusterdf_test_withClass[clusterdf_test_withClass.columns[i]+'_'+j] = clusterdf_test_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "\n",
    "clusterdf_train_withClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "d07bdd76",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27369143203190605\n",
      "0.1317049349915349\n",
      "0.2036432280102406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_E1E2GM_ohe = LinearRegression()\n",
    "model_E1E2GM_ohe.fit(pd.concat((clusterdf_train_withClass,clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_E1E2GM_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Emiliani1==1].values)\n",
    "print(r2_score(targets_df_test['Emiliani1'].values, res))\n",
    "res = model_E1E2GM_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Emiliani2==1].values)\n",
    "print(r2_score(targets_df_test['Emiliani2'].values, res))\n",
    "res = model_E1E2GM_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Garda_Mincio==1].values)\n",
    "print(r2_score(targets_df_test['Garda_Mincio'].values, res))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b92661",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Emiliani1 - Emiliani2 - Garda_Mincio: CMI best 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "55da185e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### prova con Emiliani1 e 2 e Garda_Mincio\n",
    "clust_basins = ['Emiliani1','Emiliani2','Garda_Mincio']\n",
    "colnames = [x for x in best5_CMI_fulldf_train.columns if x.startswith('Emiliani1') or x.startswith('Emiliani2') or x.startswith('Garda_Mincio')]\n",
    "\n",
    "clusterdf_train_withClass = pd.DataFrame()\n",
    "clusterdf_val_withClass = pd.DataFrame()\n",
    "clusterdf_test_withClass = pd.DataFrame()\n",
    "\n",
    "for i in range(3):\n",
    "    clusterdf_train_withClass = pd.concat((clusterdf_train_withClass,pd.concat((best5_CMI_fulldf_train[colnames],pd.DataFrame(1+i*np.ones(len(best5_CMI_fulldf_train)),columns=['basin'])),axis=1)),axis=0)\n",
    "    clusterdf_val_withClass = pd.concat((clusterdf_val_withClass,pd.concat((best5_CMI_fulldf_val[colnames],pd.DataFrame(1+i*np.ones(len(best5_CMI_fulldf_val)),columns=['basin'])),axis=1)),axis=0)\n",
    "    clusterdf_test_withClass = pd.concat((clusterdf_test_withClass,pd.concat((best5_CMI_fulldf_test[colnames],pd.DataFrame(1+i*np.ones(len(best5_CMI_fulldf_test)),columns=['basin'])),axis=1)),axis=0)\n",
    "\n",
    "for i in range(3):\n",
    "    clusterdf_train_withClass[clust_basins[i]] = clusterdf_train_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    clusterdf_val_withClass[clust_basins[i]] = clusterdf_val_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    clusterdf_test_withClass[clust_basins[i]] = clusterdf_test_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "\n",
    "clusterdf_train_withClass = clusterdf_train_withClass.loc[:,clusterdf_train_withClass.columns != 'basin']\n",
    "clusterdf_val_withClass = clusterdf_val_withClass.loc[:,clusterdf_val_withClass.columns != 'basin']\n",
    "clusterdf_test_withClass = clusterdf_test_withClass.loc[:,clusterdf_test_withClass.columns != 'basin']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "597c5252",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emiliani1_cyclostationary_mean_rr_4w_0</th>\n",
       "      <th>Emiliani1_cyclostationary_mean_tg_1w_4</th>\n",
       "      <th>Emiliani1_cyclostationary_mean_rr_12w_1</th>\n",
       "      <th>Emiliani1_cyclostationary_mean_rr_8w_1</th>\n",
       "      <th>Emiliani1_cyclostationary_mean_tg_9</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_tg_1w_4</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_rr_4w_3</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_tg_4</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_rr_8w_0</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_rr_12w_1</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_4w_0</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_tg_0</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_8w_0</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_12w_2</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_tg_8w_0</th>\n",
       "      <th>Emiliani1</th>\n",
       "      <th>Emiliani2</th>\n",
       "      <th>Garda_Mincio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.112078</td>\n",
       "      <td>0.345989</td>\n",
       "      <td>1.690770</td>\n",
       "      <td>3.965287</td>\n",
       "      <td>0.268224</td>\n",
       "      <td>-0.415835</td>\n",
       "      <td>0.733822</td>\n",
       "      <td>-0.736407</td>\n",
       "      <td>2.581050</td>\n",
       "      <td>1.579481</td>\n",
       "      <td>1.154090</td>\n",
       "      <td>0.309939</td>\n",
       "      <td>1.365733</td>\n",
       "      <td>1.718220</td>\n",
       "      <td>0.523659</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.404523</td>\n",
       "      <td>1.128851</td>\n",
       "      <td>1.865833</td>\n",
       "      <td>1.655892</td>\n",
       "      <td>0.977612</td>\n",
       "      <td>0.237307</td>\n",
       "      <td>0.849889</td>\n",
       "      <td>0.294888</td>\n",
       "      <td>2.460299</td>\n",
       "      <td>1.146518</td>\n",
       "      <td>1.494420</td>\n",
       "      <td>1.158323</td>\n",
       "      <td>1.161450</td>\n",
       "      <td>3.292752</td>\n",
       "      <td>1.350980</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.162736</td>\n",
       "      <td>0.786460</td>\n",
       "      <td>1.429151</td>\n",
       "      <td>1.672157</td>\n",
       "      <td>-0.780151</td>\n",
       "      <td>-0.259989</td>\n",
       "      <td>0.518355</td>\n",
       "      <td>-1.191392</td>\n",
       "      <td>1.657472</td>\n",
       "      <td>0.697926</td>\n",
       "      <td>0.992024</td>\n",
       "      <td>-0.747849</td>\n",
       "      <td>0.765542</td>\n",
       "      <td>2.143920</td>\n",
       "      <td>0.395851</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.861999</td>\n",
       "      <td>0.564161</td>\n",
       "      <td>0.611897</td>\n",
       "      <td>1.593990</td>\n",
       "      <td>0.408553</td>\n",
       "      <td>-0.565851</td>\n",
       "      <td>0.239497</td>\n",
       "      <td>0.067063</td>\n",
       "      <td>1.600489</td>\n",
       "      <td>0.578318</td>\n",
       "      <td>0.831685</td>\n",
       "      <td>0.618235</td>\n",
       "      <td>0.486500</td>\n",
       "      <td>2.057757</td>\n",
       "      <td>0.584992</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.461930</td>\n",
       "      <td>0.604584</td>\n",
       "      <td>4.150391</td>\n",
       "      <td>1.782496</td>\n",
       "      <td>-0.260577</td>\n",
       "      <td>-0.187005</td>\n",
       "      <td>0.696217</td>\n",
       "      <td>-0.894857</td>\n",
       "      <td>1.249495</td>\n",
       "      <td>0.843396</td>\n",
       "      <td>0.648410</td>\n",
       "      <td>-0.197356</td>\n",
       "      <td>0.471393</td>\n",
       "      <td>1.411145</td>\n",
       "      <td>0.375705</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>-0.211596</td>\n",
       "      <td>0.739113</td>\n",
       "      <td>-0.281990</td>\n",
       "      <td>-0.636426</td>\n",
       "      <td>1.599630</td>\n",
       "      <td>1.352614</td>\n",
       "      <td>-0.220555</td>\n",
       "      <td>0.471800</td>\n",
       "      <td>-0.187672</td>\n",
       "      <td>-0.422427</td>\n",
       "      <td>-0.325559</td>\n",
       "      <td>1.386827</td>\n",
       "      <td>-0.243007</td>\n",
       "      <td>-0.779607</td>\n",
       "      <td>0.784844</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>-0.765747</td>\n",
       "      <td>0.855313</td>\n",
       "      <td>-0.234571</td>\n",
       "      <td>-1.204469</td>\n",
       "      <td>0.920235</td>\n",
       "      <td>1.040390</td>\n",
       "      <td>0.346445</td>\n",
       "      <td>0.034058</td>\n",
       "      <td>-0.358316</td>\n",
       "      <td>-0.518833</td>\n",
       "      <td>-0.048154</td>\n",
       "      <td>0.600403</td>\n",
       "      <td>-0.089677</td>\n",
       "      <td>-0.282528</td>\n",
       "      <td>0.689576</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>-0.609296</td>\n",
       "      <td>0.697286</td>\n",
       "      <td>-0.562017</td>\n",
       "      <td>-1.089158</td>\n",
       "      <td>0.341994</td>\n",
       "      <td>0.830698</td>\n",
       "      <td>0.429694</td>\n",
       "      <td>0.796373</td>\n",
       "      <td>-0.106524</td>\n",
       "      <td>-0.588942</td>\n",
       "      <td>0.392946</td>\n",
       "      <td>0.382350</td>\n",
       "      <td>0.196236</td>\n",
       "      <td>-0.211020</td>\n",
       "      <td>0.473678</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>-0.836849</td>\n",
       "      <td>-0.719738</td>\n",
       "      <td>-0.028118</td>\n",
       "      <td>-0.925439</td>\n",
       "      <td>-1.523290</td>\n",
       "      <td>-0.631908</td>\n",
       "      <td>-0.434877</td>\n",
       "      <td>-2.562406</td>\n",
       "      <td>-0.028237</td>\n",
       "      <td>-0.468533</td>\n",
       "      <td>-0.140998</td>\n",
       "      <td>-1.910985</td>\n",
       "      <td>0.283754</td>\n",
       "      <td>-0.190893</td>\n",
       "      <td>-0.254712</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-0.283715</td>\n",
       "      <td>-1.078052</td>\n",
       "      <td>0.226971</td>\n",
       "      <td>-0.799403</td>\n",
       "      <td>-0.625862</td>\n",
       "      <td>-1.226069</td>\n",
       "      <td>0.334461</td>\n",
       "      <td>-0.263730</td>\n",
       "      <td>0.344734</td>\n",
       "      <td>-0.241170</td>\n",
       "      <td>0.297361</td>\n",
       "      <td>-0.460368</td>\n",
       "      <td>0.250722</td>\n",
       "      <td>0.025355</td>\n",
       "      <td>-0.180499</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1233 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Emiliani1_cyclostationary_mean_rr_4w_0  \\\n",
       "0                                  2.112078   \n",
       "1                                  1.404523   \n",
       "2                                  1.162736   \n",
       "3                                  0.861999   \n",
       "4                                  1.461930   \n",
       "..                                      ...   \n",
       "406                               -0.211596   \n",
       "407                               -0.765747   \n",
       "408                               -0.609296   \n",
       "409                               -0.836849   \n",
       "410                               -0.283715   \n",
       "\n",
       "     Emiliani1_cyclostationary_mean_tg_1w_4  \\\n",
       "0                                  0.345989   \n",
       "1                                  1.128851   \n",
       "2                                  0.786460   \n",
       "3                                  0.564161   \n",
       "4                                  0.604584   \n",
       "..                                      ...   \n",
       "406                                0.739113   \n",
       "407                                0.855313   \n",
       "408                                0.697286   \n",
       "409                               -0.719738   \n",
       "410                               -1.078052   \n",
       "\n",
       "     Emiliani1_cyclostationary_mean_rr_12w_1  \\\n",
       "0                                   1.690770   \n",
       "1                                   1.865833   \n",
       "2                                   1.429151   \n",
       "3                                   0.611897   \n",
       "4                                   4.150391   \n",
       "..                                       ...   \n",
       "406                                -0.281990   \n",
       "407                                -0.234571   \n",
       "408                                -0.562017   \n",
       "409                                -0.028118   \n",
       "410                                 0.226971   \n",
       "\n",
       "     Emiliani1_cyclostationary_mean_rr_8w_1  \\\n",
       "0                                  3.965287   \n",
       "1                                  1.655892   \n",
       "2                                  1.672157   \n",
       "3                                  1.593990   \n",
       "4                                  1.782496   \n",
       "..                                      ...   \n",
       "406                               -0.636426   \n",
       "407                               -1.204469   \n",
       "408                               -1.089158   \n",
       "409                               -0.925439   \n",
       "410                               -0.799403   \n",
       "\n",
       "     Emiliani1_cyclostationary_mean_tg_9  \\\n",
       "0                               0.268224   \n",
       "1                               0.977612   \n",
       "2                              -0.780151   \n",
       "3                               0.408553   \n",
       "4                              -0.260577   \n",
       "..                                   ...   \n",
       "406                             1.599630   \n",
       "407                             0.920235   \n",
       "408                             0.341994   \n",
       "409                            -1.523290   \n",
       "410                            -0.625862   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_tg_1w_4  \\\n",
       "0                                 -0.415835   \n",
       "1                                  0.237307   \n",
       "2                                 -0.259989   \n",
       "3                                 -0.565851   \n",
       "4                                 -0.187005   \n",
       "..                                      ...   \n",
       "406                                1.352614   \n",
       "407                                1.040390   \n",
       "408                                0.830698   \n",
       "409                               -0.631908   \n",
       "410                               -1.226069   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_rr_4w_3  \\\n",
       "0                                  0.733822   \n",
       "1                                  0.849889   \n",
       "2                                  0.518355   \n",
       "3                                  0.239497   \n",
       "4                                  0.696217   \n",
       "..                                      ...   \n",
       "406                               -0.220555   \n",
       "407                                0.346445   \n",
       "408                                0.429694   \n",
       "409                               -0.434877   \n",
       "410                                0.334461   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_tg_4  \\\n",
       "0                              -0.736407   \n",
       "1                               0.294888   \n",
       "2                              -1.191392   \n",
       "3                               0.067063   \n",
       "4                              -0.894857   \n",
       "..                                   ...   \n",
       "406                             0.471800   \n",
       "407                             0.034058   \n",
       "408                             0.796373   \n",
       "409                            -2.562406   \n",
       "410                            -0.263730   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_rr_8w_0  \\\n",
       "0                                  2.581050   \n",
       "1                                  2.460299   \n",
       "2                                  1.657472   \n",
       "3                                  1.600489   \n",
       "4                                  1.249495   \n",
       "..                                      ...   \n",
       "406                               -0.187672   \n",
       "407                               -0.358316   \n",
       "408                               -0.106524   \n",
       "409                               -0.028237   \n",
       "410                                0.344734   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_rr_12w_1  \\\n",
       "0                                   1.579481   \n",
       "1                                   1.146518   \n",
       "2                                   0.697926   \n",
       "3                                   0.578318   \n",
       "4                                   0.843396   \n",
       "..                                       ...   \n",
       "406                                -0.422427   \n",
       "407                                -0.518833   \n",
       "408                                -0.588942   \n",
       "409                                -0.468533   \n",
       "410                                -0.241170   \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_4w_0  \\\n",
       "0                                     1.154090   \n",
       "1                                     1.494420   \n",
       "2                                     0.992024   \n",
       "3                                     0.831685   \n",
       "4                                     0.648410   \n",
       "..                                         ...   \n",
       "406                                  -0.325559   \n",
       "407                                  -0.048154   \n",
       "408                                   0.392946   \n",
       "409                                  -0.140998   \n",
       "410                                   0.297361   \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_tg_0  \\\n",
       "0                                  0.309939   \n",
       "1                                  1.158323   \n",
       "2                                 -0.747849   \n",
       "3                                  0.618235   \n",
       "4                                 -0.197356   \n",
       "..                                      ...   \n",
       "406                                1.386827   \n",
       "407                                0.600403   \n",
       "408                                0.382350   \n",
       "409                               -1.910985   \n",
       "410                               -0.460368   \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_8w_0  \\\n",
       "0                                     1.365733   \n",
       "1                                     1.161450   \n",
       "2                                     0.765542   \n",
       "3                                     0.486500   \n",
       "4                                     0.471393   \n",
       "..                                         ...   \n",
       "406                                  -0.243007   \n",
       "407                                  -0.089677   \n",
       "408                                   0.196236   \n",
       "409                                   0.283754   \n",
       "410                                   0.250722   \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_12w_2  \\\n",
       "0                                      1.718220   \n",
       "1                                      3.292752   \n",
       "2                                      2.143920   \n",
       "3                                      2.057757   \n",
       "4                                      1.411145   \n",
       "..                                          ...   \n",
       "406                                   -0.779607   \n",
       "407                                   -0.282528   \n",
       "408                                   -0.211020   \n",
       "409                                   -0.190893   \n",
       "410                                    0.025355   \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_tg_8w_0  Emiliani1  Emiliani2  \\\n",
       "0                                     0.523659          1          0   \n",
       "1                                     1.350980          1          0   \n",
       "2                                     0.395851          1          0   \n",
       "3                                     0.584992          1          0   \n",
       "4                                     0.375705          1          0   \n",
       "..                                         ...        ...        ...   \n",
       "406                                   0.784844          0          0   \n",
       "407                                   0.689576          0          0   \n",
       "408                                   0.473678          0          0   \n",
       "409                                  -0.254712          0          0   \n",
       "410                                  -0.180499          0          0   \n",
       "\n",
       "     Garda_Mincio  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "..            ...  \n",
       "406             1  \n",
       "407             1  \n",
       "408             1  \n",
       "409             1  \n",
       "410             1  \n",
       "\n",
       "[1233 rows x 18 columns]"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterdf_train_withClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "b48b19df",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "targets_df_train_unfolded = pd.DataFrame()\n",
    "targets_df_val_unfolded = pd.DataFrame()\n",
    "targets_df_test_unfolded = pd.DataFrame()\n",
    "\n",
    "for basin in ['Emiliani1','Emiliani2','Garda_Mincio']:\n",
    "    targets_df_train_unfolded =  pd.concat((targets_df_train_unfolded,targets_df_train[basin]),axis=0)\n",
    "    targets_df_val_unfolded =  pd.concat((targets_df_val_unfolded,targets_df_val[basin]),axis=0)\n",
    "    targets_df_test_unfolded =  pd.concat((targets_df_test_unfolded,targets_df_test[basin]),axis=0)\n",
    "targets_df_train_unfolded = targets_df_train_unfolded.reset_index(drop=True)\n",
    "targets_df_val_unfolded = targets_df_val_unfolded.reset_index(drop=True)\n",
    "targets_df_test_unfolded = targets_df_test_unfolded.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "61c3ffd8",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.382765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.319215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.548542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.010351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.402030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>0.032299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>0.132804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>-0.214182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>-2.409204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>-2.673294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1233 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0    -0.382765\n",
       "1     0.319215\n",
       "2     0.548542\n",
       "3    -0.010351\n",
       "4     0.402030\n",
       "...        ...\n",
       "1228  0.032299\n",
       "1229  0.132804\n",
       "1230 -0.214182\n",
       "1231 -2.409204\n",
       "1232 -2.673294\n",
       "\n",
       "[1233 rows x 1 columns]"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_df_train_unfolded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "714f56e5",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4031090822249198\n",
      "0.3100764945337038\n",
      "0.28477623168379684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_E1E2GM_ohe = LinearRegression()\n",
    "model_E1E2GM_ohe.fit(pd.concat((clusterdf_train_withClass,clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_E1E2GM_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Emiliani1==1].values)\n",
    "print(r2_score(targets_df_test['Emiliani1'].values, res))\n",
    "res = model_E1E2GM_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Emiliani2==1].values)\n",
    "print(r2_score(targets_df_test['Emiliani2'].values, res))\n",
    "res = model_E1E2GM_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Garda_Mincio==1].values)\n",
    "print(r2_score(targets_df_test['Garda_Mincio'].values, res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "f5d2a8ea",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.15359654 -0.08367787  0.18876555 -0.08755932 -0.12342461 -0.00735284\n",
      "   0.12504554 -0.11491597 -0.04351746 -0.02367721 -0.03127354 -0.03282753\n",
      "   0.24373819 -0.07772121  0.11412778 -0.05248622 -0.02688542  0.07937163]] [0.0245803]\n"
     ]
    }
   ],
   "source": [
    "print(model_E1E2GM_ohe.coef_,model_E1E2GM_ohe.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "aa9c82bf",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emiliani1_cyclostationary_mean_rr_4w_0</th>\n",
       "      <th>Emiliani1_cyclostationary_mean_tg_1w_4</th>\n",
       "      <th>Emiliani1_cyclostationary_mean_rr_12w_1</th>\n",
       "      <th>Emiliani1_cyclostationary_mean_rr_8w_1</th>\n",
       "      <th>Emiliani1_cyclostationary_mean_tg_9</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_tg_1w_4</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_rr_4w_3</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_tg_4</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_rr_8w_0</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_rr_12w_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_tg_0_Garda_Mincio</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_8w_0_Emiliani1</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_8w_0_Emiliani2</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_8w_0_Garda_Mincio</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_12w_2_Emiliani1</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_12w_2_Emiliani2</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_12w_2_Garda_Mincio</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_tg_8w_0_Emiliani1</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_tg_8w_0_Emiliani2</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_tg_8w_0_Garda_Mincio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.112078</td>\n",
       "      <td>0.345989</td>\n",
       "      <td>1.690770</td>\n",
       "      <td>3.965287</td>\n",
       "      <td>0.268224</td>\n",
       "      <td>-0.415835</td>\n",
       "      <td>0.733822</td>\n",
       "      <td>-0.736407</td>\n",
       "      <td>2.581050</td>\n",
       "      <td>1.579481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.365733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.718220</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.523659</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.404523</td>\n",
       "      <td>1.128851</td>\n",
       "      <td>1.865833</td>\n",
       "      <td>1.655892</td>\n",
       "      <td>0.977612</td>\n",
       "      <td>0.237307</td>\n",
       "      <td>0.849889</td>\n",
       "      <td>0.294888</td>\n",
       "      <td>2.460299</td>\n",
       "      <td>1.146518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.161450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.292752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.350980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.162736</td>\n",
       "      <td>0.786460</td>\n",
       "      <td>1.429151</td>\n",
       "      <td>1.672157</td>\n",
       "      <td>-0.780151</td>\n",
       "      <td>-0.259989</td>\n",
       "      <td>0.518355</td>\n",
       "      <td>-1.191392</td>\n",
       "      <td>1.657472</td>\n",
       "      <td>0.697926</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.765542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.143920</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.395851</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.861999</td>\n",
       "      <td>0.564161</td>\n",
       "      <td>0.611897</td>\n",
       "      <td>1.593990</td>\n",
       "      <td>0.408553</td>\n",
       "      <td>-0.565851</td>\n",
       "      <td>0.239497</td>\n",
       "      <td>0.067063</td>\n",
       "      <td>1.600489</td>\n",
       "      <td>0.578318</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.486500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.057757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.584992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.461930</td>\n",
       "      <td>0.604584</td>\n",
       "      <td>4.150391</td>\n",
       "      <td>1.782496</td>\n",
       "      <td>-0.260577</td>\n",
       "      <td>-0.187005</td>\n",
       "      <td>0.696217</td>\n",
       "      <td>-0.894857</td>\n",
       "      <td>1.249495</td>\n",
       "      <td>0.843396</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.471393</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.411145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375705</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>-0.211596</td>\n",
       "      <td>0.739113</td>\n",
       "      <td>-0.281990</td>\n",
       "      <td>-0.636426</td>\n",
       "      <td>1.599630</td>\n",
       "      <td>1.352614</td>\n",
       "      <td>-0.220555</td>\n",
       "      <td>0.471800</td>\n",
       "      <td>-0.187672</td>\n",
       "      <td>-0.422427</td>\n",
       "      <td>...</td>\n",
       "      <td>1.386827</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.243007</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.779607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.784844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>-0.765747</td>\n",
       "      <td>0.855313</td>\n",
       "      <td>-0.234571</td>\n",
       "      <td>-1.204469</td>\n",
       "      <td>0.920235</td>\n",
       "      <td>1.040390</td>\n",
       "      <td>0.346445</td>\n",
       "      <td>0.034058</td>\n",
       "      <td>-0.358316</td>\n",
       "      <td>-0.518833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600403</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.089677</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.282528</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.689576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>-0.609296</td>\n",
       "      <td>0.697286</td>\n",
       "      <td>-0.562017</td>\n",
       "      <td>-1.089158</td>\n",
       "      <td>0.341994</td>\n",
       "      <td>0.830698</td>\n",
       "      <td>0.429694</td>\n",
       "      <td>0.796373</td>\n",
       "      <td>-0.106524</td>\n",
       "      <td>-0.588942</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.196236</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.211020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.473678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>-0.836849</td>\n",
       "      <td>-0.719738</td>\n",
       "      <td>-0.028118</td>\n",
       "      <td>-0.925439</td>\n",
       "      <td>-1.523290</td>\n",
       "      <td>-0.631908</td>\n",
       "      <td>-0.434877</td>\n",
       "      <td>-2.562406</td>\n",
       "      <td>-0.028237</td>\n",
       "      <td>-0.468533</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.910985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.283754</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.190893</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.254712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-0.283715</td>\n",
       "      <td>-1.078052</td>\n",
       "      <td>0.226971</td>\n",
       "      <td>-0.799403</td>\n",
       "      <td>-0.625862</td>\n",
       "      <td>-1.226069</td>\n",
       "      <td>0.334461</td>\n",
       "      <td>-0.263730</td>\n",
       "      <td>0.344734</td>\n",
       "      <td>-0.241170</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.460368</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250722</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025355</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.180499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1233 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Emiliani1_cyclostationary_mean_rr_4w_0  \\\n",
       "0                                  2.112078   \n",
       "1                                  1.404523   \n",
       "2                                  1.162736   \n",
       "3                                  0.861999   \n",
       "4                                  1.461930   \n",
       "..                                      ...   \n",
       "406                               -0.211596   \n",
       "407                               -0.765747   \n",
       "408                               -0.609296   \n",
       "409                               -0.836849   \n",
       "410                               -0.283715   \n",
       "\n",
       "     Emiliani1_cyclostationary_mean_tg_1w_4  \\\n",
       "0                                  0.345989   \n",
       "1                                  1.128851   \n",
       "2                                  0.786460   \n",
       "3                                  0.564161   \n",
       "4                                  0.604584   \n",
       "..                                      ...   \n",
       "406                                0.739113   \n",
       "407                                0.855313   \n",
       "408                                0.697286   \n",
       "409                               -0.719738   \n",
       "410                               -1.078052   \n",
       "\n",
       "     Emiliani1_cyclostationary_mean_rr_12w_1  \\\n",
       "0                                   1.690770   \n",
       "1                                   1.865833   \n",
       "2                                   1.429151   \n",
       "3                                   0.611897   \n",
       "4                                   4.150391   \n",
       "..                                       ...   \n",
       "406                                -0.281990   \n",
       "407                                -0.234571   \n",
       "408                                -0.562017   \n",
       "409                                -0.028118   \n",
       "410                                 0.226971   \n",
       "\n",
       "     Emiliani1_cyclostationary_mean_rr_8w_1  \\\n",
       "0                                  3.965287   \n",
       "1                                  1.655892   \n",
       "2                                  1.672157   \n",
       "3                                  1.593990   \n",
       "4                                  1.782496   \n",
       "..                                      ...   \n",
       "406                               -0.636426   \n",
       "407                               -1.204469   \n",
       "408                               -1.089158   \n",
       "409                               -0.925439   \n",
       "410                               -0.799403   \n",
       "\n",
       "     Emiliani1_cyclostationary_mean_tg_9  \\\n",
       "0                               0.268224   \n",
       "1                               0.977612   \n",
       "2                              -0.780151   \n",
       "3                               0.408553   \n",
       "4                              -0.260577   \n",
       "..                                   ...   \n",
       "406                             1.599630   \n",
       "407                             0.920235   \n",
       "408                             0.341994   \n",
       "409                            -1.523290   \n",
       "410                            -0.625862   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_tg_1w_4  \\\n",
       "0                                 -0.415835   \n",
       "1                                  0.237307   \n",
       "2                                 -0.259989   \n",
       "3                                 -0.565851   \n",
       "4                                 -0.187005   \n",
       "..                                      ...   \n",
       "406                                1.352614   \n",
       "407                                1.040390   \n",
       "408                                0.830698   \n",
       "409                               -0.631908   \n",
       "410                               -1.226069   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_rr_4w_3  \\\n",
       "0                                  0.733822   \n",
       "1                                  0.849889   \n",
       "2                                  0.518355   \n",
       "3                                  0.239497   \n",
       "4                                  0.696217   \n",
       "..                                      ...   \n",
       "406                               -0.220555   \n",
       "407                                0.346445   \n",
       "408                                0.429694   \n",
       "409                               -0.434877   \n",
       "410                                0.334461   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_tg_4  \\\n",
       "0                              -0.736407   \n",
       "1                               0.294888   \n",
       "2                              -1.191392   \n",
       "3                               0.067063   \n",
       "4                              -0.894857   \n",
       "..                                   ...   \n",
       "406                             0.471800   \n",
       "407                             0.034058   \n",
       "408                             0.796373   \n",
       "409                            -2.562406   \n",
       "410                            -0.263730   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_rr_8w_0  \\\n",
       "0                                  2.581050   \n",
       "1                                  2.460299   \n",
       "2                                  1.657472   \n",
       "3                                  1.600489   \n",
       "4                                  1.249495   \n",
       "..                                      ...   \n",
       "406                               -0.187672   \n",
       "407                               -0.358316   \n",
       "408                               -0.106524   \n",
       "409                               -0.028237   \n",
       "410                                0.344734   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_rr_12w_1  ...  \\\n",
       "0                                   1.579481  ...   \n",
       "1                                   1.146518  ...   \n",
       "2                                   0.697926  ...   \n",
       "3                                   0.578318  ...   \n",
       "4                                   0.843396  ...   \n",
       "..                                       ...  ...   \n",
       "406                                -0.422427  ...   \n",
       "407                                -0.518833  ...   \n",
       "408                                -0.588942  ...   \n",
       "409                                -0.468533  ...   \n",
       "410                                -0.241170  ...   \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_tg_0_Garda_Mincio  \\\n",
       "0                                             0.000000     \n",
       "1                                             0.000000     \n",
       "2                                            -0.000000     \n",
       "3                                             0.000000     \n",
       "4                                            -0.000000     \n",
       "..                                                 ...     \n",
       "406                                           1.386827     \n",
       "407                                           0.600403     \n",
       "408                                           0.382350     \n",
       "409                                          -1.910985     \n",
       "410                                          -0.460368     \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_8w_0_Emiliani1  \\\n",
       "0                                             1.365733     \n",
       "1                                             1.161450     \n",
       "2                                             0.765542     \n",
       "3                                             0.486500     \n",
       "4                                             0.471393     \n",
       "..                                                 ...     \n",
       "406                                          -0.000000     \n",
       "407                                          -0.000000     \n",
       "408                                           0.000000     \n",
       "409                                           0.000000     \n",
       "410                                           0.000000     \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_8w_0_Emiliani2  \\\n",
       "0                                                  0.0     \n",
       "1                                                  0.0     \n",
       "2                                                  0.0     \n",
       "3                                                  0.0     \n",
       "4                                                  0.0     \n",
       "..                                                 ...     \n",
       "406                                               -0.0     \n",
       "407                                               -0.0     \n",
       "408                                                0.0     \n",
       "409                                                0.0     \n",
       "410                                                0.0     \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_8w_0_Garda_Mincio  \\\n",
       "0                                             0.000000        \n",
       "1                                             0.000000        \n",
       "2                                             0.000000        \n",
       "3                                             0.000000        \n",
       "4                                             0.000000        \n",
       "..                                                 ...        \n",
       "406                                          -0.243007        \n",
       "407                                          -0.089677        \n",
       "408                                           0.196236        \n",
       "409                                           0.283754        \n",
       "410                                           0.250722        \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_12w_2_Emiliani1  \\\n",
       "0                                             1.718220      \n",
       "1                                             3.292752      \n",
       "2                                             2.143920      \n",
       "3                                             2.057757      \n",
       "4                                             1.411145      \n",
       "..                                                 ...      \n",
       "406                                          -0.000000      \n",
       "407                                          -0.000000      \n",
       "408                                          -0.000000      \n",
       "409                                          -0.000000      \n",
       "410                                           0.000000      \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_12w_2_Emiliani2  \\\n",
       "0                                                  0.0      \n",
       "1                                                  0.0      \n",
       "2                                                  0.0      \n",
       "3                                                  0.0      \n",
       "4                                                  0.0      \n",
       "..                                                 ...      \n",
       "406                                               -0.0      \n",
       "407                                               -0.0      \n",
       "408                                               -0.0      \n",
       "409                                               -0.0      \n",
       "410                                                0.0      \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_12w_2_Garda_Mincio  \\\n",
       "0                                             0.000000         \n",
       "1                                             0.000000         \n",
       "2                                             0.000000         \n",
       "3                                             0.000000         \n",
       "4                                             0.000000         \n",
       "..                                                 ...         \n",
       "406                                          -0.779607         \n",
       "407                                          -0.282528         \n",
       "408                                          -0.211020         \n",
       "409                                          -0.190893         \n",
       "410                                           0.025355         \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_tg_8w_0_Emiliani1  \\\n",
       "0                                             0.523659     \n",
       "1                                             1.350980     \n",
       "2                                             0.395851     \n",
       "3                                             0.584992     \n",
       "4                                             0.375705     \n",
       "..                                                 ...     \n",
       "406                                           0.000000     \n",
       "407                                           0.000000     \n",
       "408                                           0.000000     \n",
       "409                                          -0.000000     \n",
       "410                                          -0.000000     \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_tg_8w_0_Emiliani2  \\\n",
       "0                                                  0.0     \n",
       "1                                                  0.0     \n",
       "2                                                  0.0     \n",
       "3                                                  0.0     \n",
       "4                                                  0.0     \n",
       "..                                                 ...     \n",
       "406                                                0.0     \n",
       "407                                                0.0     \n",
       "408                                                0.0     \n",
       "409                                               -0.0     \n",
       "410                                               -0.0     \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_tg_8w_0_Garda_Mincio  \n",
       "0                                             0.000000       \n",
       "1                                             0.000000       \n",
       "2                                             0.000000       \n",
       "3                                             0.000000       \n",
       "4                                             0.000000       \n",
       "..                                                 ...       \n",
       "406                                           0.784844       \n",
       "407                                           0.689576       \n",
       "408                                           0.473678       \n",
       "409                                          -0.254712       \n",
       "410                                          -0.180499       \n",
       "\n",
       "[1233 rows x 63 columns]"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(clusterdf_train_withClass.shape[1]-len(clust_basins)):\n",
    "    for j in clust_basins:\n",
    "        clusterdf_train_withClass[clusterdf_train_withClass.columns[i]+'_'+j] = clusterdf_train_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "        clusterdf_val_withClass[clusterdf_val_withClass.columns[i]+'_'+j] = clusterdf_val_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "        clusterdf_test_withClass[clusterdf_test_withClass.columns[i]+'_'+j] = clusterdf_test_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "\n",
    "clusterdf_train_withClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "d1baa779",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4159901109016101\n",
      "0.31316188469641604\n",
      "0.24666673132732686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_E1E2GM_ohe = LinearRegression()\n",
    "model_E1E2GM_ohe.fit(pd.concat((clusterdf_train_withClass,clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_E1E2GM_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Emiliani1==1].values)\n",
    "print(r2_score(targets_df_test['Emiliani1'].values, res))\n",
    "res = model_E1E2GM_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Emiliani2==1].values)\n",
    "print(r2_score(targets_df_test['Emiliani2'].values, res))\n",
    "res = model_E1E2GM_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Garda_Mincio==1].values)\n",
    "print(r2_score(targets_df_test['Garda_Mincio'].values, res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b157c7c1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cea06c6a",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Adda - Lambro_Olona - Oglio_Iseo - Ticino: wrapper best 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "88e7f00e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "clust_basins = ['Adda', 'Lambro_Olona', 'Oglio_Iseo', 'Ticino']\n",
    "colnames = [x for x in best5_wrapper_fulldf_train.columns if x.startswith('Adda') or x.startswith('Lambro_Olona') or x.startswith('Oglio_Iseo') or x.startswith('Ticino')]\n",
    "\n",
    "best5_wrapper_clusterdf_train_withClass = pd.DataFrame()\n",
    "best5_wrapper_clusterdf_val_withClass = pd.DataFrame()\n",
    "best5_wrapper_clusterdf_test_withClass = pd.DataFrame()\n",
    "\n",
    "for i in range(len(clust_basins)):\n",
    "    best5_wrapper_clusterdf_train_withClass = pd.concat((best5_wrapper_clusterdf_train_withClass,pd.concat((best5_wrapper_fulldf_train[colnames],pd.DataFrame(1+i*np.ones(len(best5_wrapper_fulldf_train)),columns=['basin'])),axis=1)),axis=0)\n",
    "    best5_wrapper_clusterdf_val_withClass = pd.concat((best5_wrapper_clusterdf_val_withClass,pd.concat((best5_wrapper_fulldf_val[colnames],pd.DataFrame(1+i*np.ones(len(best5_wrapper_fulldf_val)),columns=['basin'])),axis=1)),axis=0)\n",
    "    best5_wrapper_clusterdf_test_withClass = pd.concat((best5_wrapper_clusterdf_test_withClass,pd.concat((best5_wrapper_fulldf_test[colnames],pd.DataFrame(1+i*np.ones(len(best5_wrapper_fulldf_test)),columns=['basin'])),axis=1)),axis=0)\n",
    "\n",
    "for i in range(len(clust_basins)):\n",
    "    best5_wrapper_clusterdf_train_withClass[clust_basins[i]] = best5_wrapper_clusterdf_train_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    best5_wrapper_clusterdf_val_withClass[clust_basins[i]] = best5_wrapper_clusterdf_val_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    best5_wrapper_clusterdf_test_withClass[clust_basins[i]] = best5_wrapper_clusterdf_test_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "\n",
    "best5_wrapper_clusterdf_train_withClass = best5_wrapper_clusterdf_train_withClass.loc[:,best5_wrapper_clusterdf_train_withClass.columns != 'basin']\n",
    "best5_wrapper_clusterdf_val_withClass = best5_wrapper_clusterdf_val_withClass.loc[:,best5_wrapper_clusterdf_val_withClass.columns != 'basin']\n",
    "best5_wrapper_clusterdf_test_withClass = best5_wrapper_clusterdf_test_withClass.loc[:,best5_wrapper_clusterdf_test_withClass.columns != 'basin']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "abc5431f",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adda_cyclostationary_mean_tg_1w_3</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_1w_6</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_1w_5</th>\n",
       "      <th>Adda_cyclostationary_mean_rr_1w_0</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_16w_2</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_tg_1w_2</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_rr_1w_1</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_tg_1w_5</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_tg_1w_4</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_tg_24w_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Oglio_Iseo_cyclostationary_mean_tg_1w_2</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_1w_3</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_1w_1</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_16w_3</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_24w_0</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_24w_1</th>\n",
       "      <th>Adda</th>\n",
       "      <th>Lambro_Olona</th>\n",
       "      <th>Oglio_Iseo</th>\n",
       "      <th>Ticino</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.862899</td>\n",
       "      <td>-1.709060</td>\n",
       "      <td>-1.866687</td>\n",
       "      <td>1.001341</td>\n",
       "      <td>-3.062159</td>\n",
       "      <td>-0.016453</td>\n",
       "      <td>1.139294</td>\n",
       "      <td>0.598277</td>\n",
       "      <td>-0.325450</td>\n",
       "      <td>0.326942</td>\n",
       "      <td>...</td>\n",
       "      <td>0.633924</td>\n",
       "      <td>-0.093720</td>\n",
       "      <td>0.367163</td>\n",
       "      <td>-2.519366</td>\n",
       "      <td>1.086902</td>\n",
       "      <td>0.923555</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.093639</td>\n",
       "      <td>-0.490888</td>\n",
       "      <td>-1.024977</td>\n",
       "      <td>1.976018</td>\n",
       "      <td>-1.604230</td>\n",
       "      <td>0.588844</td>\n",
       "      <td>1.558519</td>\n",
       "      <td>1.327611</td>\n",
       "      <td>0.401314</td>\n",
       "      <td>1.779921</td>\n",
       "      <td>...</td>\n",
       "      <td>1.150367</td>\n",
       "      <td>0.660804</td>\n",
       "      <td>1.109746</td>\n",
       "      <td>-1.279902</td>\n",
       "      <td>2.955987</td>\n",
       "      <td>3.878325</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.524505</td>\n",
       "      <td>-0.923993</td>\n",
       "      <td>-0.954945</td>\n",
       "      <td>1.350939</td>\n",
       "      <td>-2.492491</td>\n",
       "      <td>0.354168</td>\n",
       "      <td>0.824111</td>\n",
       "      <td>1.123972</td>\n",
       "      <td>0.373232</td>\n",
       "      <td>0.816023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.652153</td>\n",
       "      <td>0.398414</td>\n",
       "      <td>0.745952</td>\n",
       "      <td>-1.931105</td>\n",
       "      <td>1.397907</td>\n",
       "      <td>2.009521</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.666293</td>\n",
       "      <td>-1.171925</td>\n",
       "      <td>-1.039569</td>\n",
       "      <td>0.464342</td>\n",
       "      <td>-1.901370</td>\n",
       "      <td>0.207584</td>\n",
       "      <td>0.400613</td>\n",
       "      <td>0.838592</td>\n",
       "      <td>0.208962</td>\n",
       "      <td>1.160471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280106</td>\n",
       "      <td>0.123697</td>\n",
       "      <td>0.265868</td>\n",
       "      <td>-1.487132</td>\n",
       "      <td>1.452206</td>\n",
       "      <td>2.031725</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.416695</td>\n",
       "      <td>-0.855241</td>\n",
       "      <td>-1.185594</td>\n",
       "      <td>0.406680</td>\n",
       "      <td>-2.302021</td>\n",
       "      <td>0.395861</td>\n",
       "      <td>0.313123</td>\n",
       "      <td>0.990957</td>\n",
       "      <td>0.484058</td>\n",
       "      <td>0.876454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.659749</td>\n",
       "      <td>0.385859</td>\n",
       "      <td>0.489741</td>\n",
       "      <td>-1.755441</td>\n",
       "      <td>1.059559</td>\n",
       "      <td>1.666844</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>1.568770</td>\n",
       "      <td>1.778381</td>\n",
       "      <td>1.494928</td>\n",
       "      <td>-1.208471</td>\n",
       "      <td>1.138232</td>\n",
       "      <td>1.284746</td>\n",
       "      <td>-1.204774</td>\n",
       "      <td>1.292422</td>\n",
       "      <td>1.757969</td>\n",
       "      <td>0.987092</td>\n",
       "      <td>...</td>\n",
       "      <td>1.451391</td>\n",
       "      <td>1.365035</td>\n",
       "      <td>-0.995021</td>\n",
       "      <td>1.029462</td>\n",
       "      <td>-0.889708</td>\n",
       "      <td>-1.175881</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>0.812306</td>\n",
       "      <td>1.051617</td>\n",
       "      <td>0.843470</td>\n",
       "      <td>0.824414</td>\n",
       "      <td>1.152253</td>\n",
       "      <td>1.022290</td>\n",
       "      <td>0.454118</td>\n",
       "      <td>1.054859</td>\n",
       "      <td>1.437956</td>\n",
       "      <td>0.978438</td>\n",
       "      <td>...</td>\n",
       "      <td>1.312351</td>\n",
       "      <td>0.754469</td>\n",
       "      <td>0.937092</td>\n",
       "      <td>1.054968</td>\n",
       "      <td>-0.475943</td>\n",
       "      <td>-0.744283</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.876968</td>\n",
       "      <td>0.470849</td>\n",
       "      <td>0.404951</td>\n",
       "      <td>1.236207</td>\n",
       "      <td>1.253158</td>\n",
       "      <td>0.881454</td>\n",
       "      <td>0.935050</td>\n",
       "      <td>0.963252</td>\n",
       "      <td>0.693918</td>\n",
       "      <td>0.832314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.945694</td>\n",
       "      <td>0.700923</td>\n",
       "      <td>1.093168</td>\n",
       "      <td>1.164702</td>\n",
       "      <td>-0.394052</td>\n",
       "      <td>-0.658232</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>-0.723696</td>\n",
       "      <td>-1.195756</td>\n",
       "      <td>-1.026883</td>\n",
       "      <td>-0.159932</td>\n",
       "      <td>0.874675</td>\n",
       "      <td>-0.485089</td>\n",
       "      <td>-0.092682</td>\n",
       "      <td>-0.604243</td>\n",
       "      <td>-0.416388</td>\n",
       "      <td>0.627521</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.424773</td>\n",
       "      <td>-0.742700</td>\n",
       "      <td>-0.315473</td>\n",
       "      <td>0.830063</td>\n",
       "      <td>-0.260074</td>\n",
       "      <td>-0.519229</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-1.413870</td>\n",
       "      <td>-1.470946</td>\n",
       "      <td>-1.326713</td>\n",
       "      <td>0.209276</td>\n",
       "      <td>0.821070</td>\n",
       "      <td>-1.329610</td>\n",
       "      <td>0.113361</td>\n",
       "      <td>-1.328723</td>\n",
       "      <td>-0.822069</td>\n",
       "      <td>0.628527</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.361463</td>\n",
       "      <td>-1.265944</td>\n",
       "      <td>0.131009</td>\n",
       "      <td>0.771344</td>\n",
       "      <td>-0.397287</td>\n",
       "      <td>-0.805547</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1644 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Adda_cyclostationary_mean_tg_1w_3  Adda_cyclostationary_mean_tg_1w_6  \\\n",
       "0                            -0.862899                          -1.709060   \n",
       "1                            -0.093639                          -0.490888   \n",
       "2                            -0.524505                          -0.923993   \n",
       "3                            -0.666293                          -1.171925   \n",
       "4                            -0.416695                          -0.855241   \n",
       "..                                 ...                                ...   \n",
       "406                           1.568770                           1.778381   \n",
       "407                           0.812306                           1.051617   \n",
       "408                           0.876968                           0.470849   \n",
       "409                          -0.723696                          -1.195756   \n",
       "410                          -1.413870                          -1.470946   \n",
       "\n",
       "     Adda_cyclostationary_mean_tg_1w_5  Adda_cyclostationary_mean_rr_1w_0  \\\n",
       "0                            -1.866687                           1.001341   \n",
       "1                            -1.024977                           1.976018   \n",
       "2                            -0.954945                           1.350939   \n",
       "3                            -1.039569                           0.464342   \n",
       "4                            -1.185594                           0.406680   \n",
       "..                                 ...                                ...   \n",
       "406                           1.494928                          -1.208471   \n",
       "407                           0.843470                           0.824414   \n",
       "408                           0.404951                           1.236207   \n",
       "409                          -1.026883                          -0.159932   \n",
       "410                          -1.326713                           0.209276   \n",
       "\n",
       "     Adda_cyclostationary_mean_tg_16w_2  \\\n",
       "0                             -3.062159   \n",
       "1                             -1.604230   \n",
       "2                             -2.492491   \n",
       "3                             -1.901370   \n",
       "4                             -2.302021   \n",
       "..                                  ...   \n",
       "406                            1.138232   \n",
       "407                            1.152253   \n",
       "408                            1.253158   \n",
       "409                            0.874675   \n",
       "410                            0.821070   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_tg_1w_2  \\\n",
       "0                                    -0.016453   \n",
       "1                                     0.588844   \n",
       "2                                     0.354168   \n",
       "3                                     0.207584   \n",
       "4                                     0.395861   \n",
       "..                                         ...   \n",
       "406                                   1.284746   \n",
       "407                                   1.022290   \n",
       "408                                   0.881454   \n",
       "409                                  -0.485089   \n",
       "410                                  -1.329610   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_rr_1w_1  \\\n",
       "0                                     1.139294   \n",
       "1                                     1.558519   \n",
       "2                                     0.824111   \n",
       "3                                     0.400613   \n",
       "4                                     0.313123   \n",
       "..                                         ...   \n",
       "406                                  -1.204774   \n",
       "407                                   0.454118   \n",
       "408                                   0.935050   \n",
       "409                                  -0.092682   \n",
       "410                                   0.113361   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_tg_1w_5  \\\n",
       "0                                     0.598277   \n",
       "1                                     1.327611   \n",
       "2                                     1.123972   \n",
       "3                                     0.838592   \n",
       "4                                     0.990957   \n",
       "..                                         ...   \n",
       "406                                   1.292422   \n",
       "407                                   1.054859   \n",
       "408                                   0.963252   \n",
       "409                                  -0.604243   \n",
       "410                                  -1.328723   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_tg_1w_4  \\\n",
       "0                                    -0.325450   \n",
       "1                                     0.401314   \n",
       "2                                     0.373232   \n",
       "3                                     0.208962   \n",
       "4                                     0.484058   \n",
       "..                                         ...   \n",
       "406                                   1.757969   \n",
       "407                                   1.437956   \n",
       "408                                   0.693918   \n",
       "409                                  -0.416388   \n",
       "410                                  -0.822069   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_tg_24w_1  ...  \\\n",
       "0                                      0.326942  ...   \n",
       "1                                      1.779921  ...   \n",
       "2                                      0.816023  ...   \n",
       "3                                      1.160471  ...   \n",
       "4                                      0.876454  ...   \n",
       "..                                          ...  ...   \n",
       "406                                    0.987092  ...   \n",
       "407                                    0.978438  ...   \n",
       "408                                    0.832314  ...   \n",
       "409                                    0.627521  ...   \n",
       "410                                    0.628527  ...   \n",
       "\n",
       "     Oglio_Iseo_cyclostationary_mean_tg_1w_2  \\\n",
       "0                                   0.633924   \n",
       "1                                   1.150367   \n",
       "2                                   0.652153   \n",
       "3                                   0.280106   \n",
       "4                                   0.659749   \n",
       "..                                       ...   \n",
       "406                                 1.451391   \n",
       "407                                 1.312351   \n",
       "408                                 0.945694   \n",
       "409                                -0.424773   \n",
       "410                                -1.361463   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_1w_3  Ticino_cyclostationary_mean_rr_1w_1  \\\n",
       "0                              -0.093720                             0.367163   \n",
       "1                               0.660804                             1.109746   \n",
       "2                               0.398414                             0.745952   \n",
       "3                               0.123697                             0.265868   \n",
       "4                               0.385859                             0.489741   \n",
       "..                                   ...                                  ...   \n",
       "406                             1.365035                            -0.995021   \n",
       "407                             0.754469                             0.937092   \n",
       "408                             0.700923                             1.093168   \n",
       "409                            -0.742700                            -0.315473   \n",
       "410                            -1.265944                             0.131009   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_16w_3  \\\n",
       "0                               -2.519366   \n",
       "1                               -1.279902   \n",
       "2                               -1.931105   \n",
       "3                               -1.487132   \n",
       "4                               -1.755441   \n",
       "..                                    ...   \n",
       "406                              1.029462   \n",
       "407                              1.054968   \n",
       "408                              1.164702   \n",
       "409                              0.830063   \n",
       "410                              0.771344   \n",
       "\n",
       "     Ticino_cyclostationary_mean_rr_24w_0  \\\n",
       "0                                1.086902   \n",
       "1                                2.955987   \n",
       "2                                1.397907   \n",
       "3                                1.452206   \n",
       "4                                1.059559   \n",
       "..                                    ...   \n",
       "406                             -0.889708   \n",
       "407                             -0.475943   \n",
       "408                             -0.394052   \n",
       "409                             -0.260074   \n",
       "410                             -0.397287   \n",
       "\n",
       "     Ticino_cyclostationary_mean_rr_24w_1  Adda  Lambro_Olona  Oglio_Iseo  \\\n",
       "0                                0.923555     1             0           0   \n",
       "1                                3.878325     1             0           0   \n",
       "2                                2.009521     1             0           0   \n",
       "3                                2.031725     1             0           0   \n",
       "4                                1.666844     1             0           0   \n",
       "..                                    ...   ...           ...         ...   \n",
       "406                             -1.175881     0             0           0   \n",
       "407                             -0.744283     0             0           0   \n",
       "408                             -0.658232     0             0           0   \n",
       "409                             -0.519229     0             0           0   \n",
       "410                             -0.805547     0             0           0   \n",
       "\n",
       "     Ticino  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "..      ...  \n",
       "406       1  \n",
       "407       1  \n",
       "408       1  \n",
       "409       1  \n",
       "410       1  \n",
       "\n",
       "[1644 rows x 24 columns]"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best5_wrapper_clusterdf_train_withClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "18021e90",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "targets_df_train_unfolded = pd.DataFrame()\n",
    "targets_df_val_unfolded = pd.DataFrame()\n",
    "targets_df_test_unfolded = pd.DataFrame()\n",
    "\n",
    "for basin in clust_basins:\n",
    "    targets_df_train_unfolded =  pd.concat((targets_df_train_unfolded,targets_df_train[basin]),axis=0)\n",
    "    targets_df_val_unfolded =  pd.concat((targets_df_val_unfolded,targets_df_val[basin]),axis=0)\n",
    "    targets_df_test_unfolded =  pd.concat((targets_df_test_unfolded,targets_df_test[basin]),axis=0)\n",
    "targets_df_train_unfolded = targets_df_train_unfolded.reset_index(drop=True)\n",
    "targets_df_val_unfolded = targets_df_val_unfolded.reset_index(drop=True)\n",
    "targets_df_test_unfolded = targets_df_test_unfolded.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "be3993e9",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.546951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.277191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.534156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.666789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.447894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1639</th>\n",
       "      <td>-0.563495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1640</th>\n",
       "      <td>-0.291984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1641</th>\n",
       "      <td>0.770822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1642</th>\n",
       "      <td>-0.412164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643</th>\n",
       "      <td>-1.081585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1644 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0    -2.546951\n",
       "1    -0.277191\n",
       "2    -0.534156\n",
       "3    -0.666789\n",
       "4    -0.447894\n",
       "...        ...\n",
       "1639 -0.563495\n",
       "1640 -0.291984\n",
       "1641  0.770822\n",
       "1642 -0.412164\n",
       "1643 -1.081585\n",
       "\n",
       "[1644 rows x 1 columns]"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_df_train_unfolded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "24012160",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.035985702392081764\n",
      "-0.022537911682852352\n",
      "-0.01660417154567484\n",
      "-0.003059224965991536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_ALOT_ohe = LinearRegression()\n",
    "model_ALOT_ohe.fit(pd.concat((best5_wrapper_clusterdf_train_withClass,best5_wrapper_clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_ALOT_ohe.predict(best5_wrapper_clusterdf_test_withClass.loc[best5_wrapper_clusterdf_test_withClass.Adda==1].values)\n",
    "print(r2_score(targets_df_test['Adda'].values, res))\n",
    "res = model_ALOT_ohe.predict(best5_wrapper_clusterdf_test_withClass.loc[best5_wrapper_clusterdf_test_withClass.Lambro_Olona==1].values)\n",
    "print(r2_score(targets_df_test['Lambro_Olona'].values, res))\n",
    "res = model_ALOT_ohe.predict(best5_wrapper_clusterdf_test_withClass.loc[best5_wrapper_clusterdf_test_withClass.Oglio_Iseo==1].values)\n",
    "print(r2_score(targets_df_test['Oglio_Iseo'].values, res))\n",
    "res = model_ALOT_ohe.predict(best5_wrapper_clusterdf_test_withClass.loc[best5_wrapper_clusterdf_test_withClass.Ticino==1].values)\n",
    "print(r2_score(targets_df_test['Ticino'].values, res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "d5ef023f",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adda_cyclostationary_mean_tg_1w_3</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_1w_6</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_1w_5</th>\n",
       "      <th>Adda_cyclostationary_mean_rr_1w_0</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_16w_2</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_tg_1w_2</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_rr_1w_1</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_tg_1w_5</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_tg_1w_4</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_tg_24w_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_16w_3_Oglio_Iseo</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_16w_3_Ticino</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_24w_0_Adda</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_24w_0_Lambro_Olona</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_24w_0_Oglio_Iseo</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_24w_0_Ticino</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_24w_1_Adda</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_24w_1_Lambro_Olona</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_24w_1_Oglio_Iseo</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_24w_1_Ticino</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.862899</td>\n",
       "      <td>-1.709060</td>\n",
       "      <td>-1.866687</td>\n",
       "      <td>1.001341</td>\n",
       "      <td>-3.062159</td>\n",
       "      <td>-0.016453</td>\n",
       "      <td>1.139294</td>\n",
       "      <td>0.598277</td>\n",
       "      <td>-0.325450</td>\n",
       "      <td>0.326942</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.086902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.923555</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.093639</td>\n",
       "      <td>-0.490888</td>\n",
       "      <td>-1.024977</td>\n",
       "      <td>1.976018</td>\n",
       "      <td>-1.604230</td>\n",
       "      <td>0.588844</td>\n",
       "      <td>1.558519</td>\n",
       "      <td>1.327611</td>\n",
       "      <td>0.401314</td>\n",
       "      <td>1.779921</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>2.955987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.878325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.524505</td>\n",
       "      <td>-0.923993</td>\n",
       "      <td>-0.954945</td>\n",
       "      <td>1.350939</td>\n",
       "      <td>-2.492491</td>\n",
       "      <td>0.354168</td>\n",
       "      <td>0.824111</td>\n",
       "      <td>1.123972</td>\n",
       "      <td>0.373232</td>\n",
       "      <td>0.816023</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.397907</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.009521</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.666293</td>\n",
       "      <td>-1.171925</td>\n",
       "      <td>-1.039569</td>\n",
       "      <td>0.464342</td>\n",
       "      <td>-1.901370</td>\n",
       "      <td>0.207584</td>\n",
       "      <td>0.400613</td>\n",
       "      <td>0.838592</td>\n",
       "      <td>0.208962</td>\n",
       "      <td>1.160471</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.452206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.031725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.416695</td>\n",
       "      <td>-0.855241</td>\n",
       "      <td>-1.185594</td>\n",
       "      <td>0.406680</td>\n",
       "      <td>-2.302021</td>\n",
       "      <td>0.395861</td>\n",
       "      <td>0.313123</td>\n",
       "      <td>0.990957</td>\n",
       "      <td>0.484058</td>\n",
       "      <td>0.876454</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.059559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.666844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>1.568770</td>\n",
       "      <td>1.778381</td>\n",
       "      <td>1.494928</td>\n",
       "      <td>-1.208471</td>\n",
       "      <td>1.138232</td>\n",
       "      <td>1.284746</td>\n",
       "      <td>-1.204774</td>\n",
       "      <td>1.292422</td>\n",
       "      <td>1.757969</td>\n",
       "      <td>0.987092</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.029462</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.889708</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-1.175881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>0.812306</td>\n",
       "      <td>1.051617</td>\n",
       "      <td>0.843470</td>\n",
       "      <td>0.824414</td>\n",
       "      <td>1.152253</td>\n",
       "      <td>1.022290</td>\n",
       "      <td>0.454118</td>\n",
       "      <td>1.054859</td>\n",
       "      <td>1.437956</td>\n",
       "      <td>0.978438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.054968</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.475943</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.744283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.876968</td>\n",
       "      <td>0.470849</td>\n",
       "      <td>0.404951</td>\n",
       "      <td>1.236207</td>\n",
       "      <td>1.253158</td>\n",
       "      <td>0.881454</td>\n",
       "      <td>0.935050</td>\n",
       "      <td>0.963252</td>\n",
       "      <td>0.693918</td>\n",
       "      <td>0.832314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.164702</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.394052</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.658232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>-0.723696</td>\n",
       "      <td>-1.195756</td>\n",
       "      <td>-1.026883</td>\n",
       "      <td>-0.159932</td>\n",
       "      <td>0.874675</td>\n",
       "      <td>-0.485089</td>\n",
       "      <td>-0.092682</td>\n",
       "      <td>-0.604243</td>\n",
       "      <td>-0.416388</td>\n",
       "      <td>0.627521</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.830063</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.260074</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.519229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-1.413870</td>\n",
       "      <td>-1.470946</td>\n",
       "      <td>-1.326713</td>\n",
       "      <td>0.209276</td>\n",
       "      <td>0.821070</td>\n",
       "      <td>-1.329610</td>\n",
       "      <td>0.113361</td>\n",
       "      <td>-1.328723</td>\n",
       "      <td>-0.822069</td>\n",
       "      <td>0.628527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.771344</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.397287</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.805547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1644 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Adda_cyclostationary_mean_tg_1w_3  Adda_cyclostationary_mean_tg_1w_6  \\\n",
       "0                            -0.862899                          -1.709060   \n",
       "1                            -0.093639                          -0.490888   \n",
       "2                            -0.524505                          -0.923993   \n",
       "3                            -0.666293                          -1.171925   \n",
       "4                            -0.416695                          -0.855241   \n",
       "..                                 ...                                ...   \n",
       "406                           1.568770                           1.778381   \n",
       "407                           0.812306                           1.051617   \n",
       "408                           0.876968                           0.470849   \n",
       "409                          -0.723696                          -1.195756   \n",
       "410                          -1.413870                          -1.470946   \n",
       "\n",
       "     Adda_cyclostationary_mean_tg_1w_5  Adda_cyclostationary_mean_rr_1w_0  \\\n",
       "0                            -1.866687                           1.001341   \n",
       "1                            -1.024977                           1.976018   \n",
       "2                            -0.954945                           1.350939   \n",
       "3                            -1.039569                           0.464342   \n",
       "4                            -1.185594                           0.406680   \n",
       "..                                 ...                                ...   \n",
       "406                           1.494928                          -1.208471   \n",
       "407                           0.843470                           0.824414   \n",
       "408                           0.404951                           1.236207   \n",
       "409                          -1.026883                          -0.159932   \n",
       "410                          -1.326713                           0.209276   \n",
       "\n",
       "     Adda_cyclostationary_mean_tg_16w_2  \\\n",
       "0                             -3.062159   \n",
       "1                             -1.604230   \n",
       "2                             -2.492491   \n",
       "3                             -1.901370   \n",
       "4                             -2.302021   \n",
       "..                                  ...   \n",
       "406                            1.138232   \n",
       "407                            1.152253   \n",
       "408                            1.253158   \n",
       "409                            0.874675   \n",
       "410                            0.821070   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_tg_1w_2  \\\n",
       "0                                    -0.016453   \n",
       "1                                     0.588844   \n",
       "2                                     0.354168   \n",
       "3                                     0.207584   \n",
       "4                                     0.395861   \n",
       "..                                         ...   \n",
       "406                                   1.284746   \n",
       "407                                   1.022290   \n",
       "408                                   0.881454   \n",
       "409                                  -0.485089   \n",
       "410                                  -1.329610   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_rr_1w_1  \\\n",
       "0                                     1.139294   \n",
       "1                                     1.558519   \n",
       "2                                     0.824111   \n",
       "3                                     0.400613   \n",
       "4                                     0.313123   \n",
       "..                                         ...   \n",
       "406                                  -1.204774   \n",
       "407                                   0.454118   \n",
       "408                                   0.935050   \n",
       "409                                  -0.092682   \n",
       "410                                   0.113361   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_tg_1w_5  \\\n",
       "0                                     0.598277   \n",
       "1                                     1.327611   \n",
       "2                                     1.123972   \n",
       "3                                     0.838592   \n",
       "4                                     0.990957   \n",
       "..                                         ...   \n",
       "406                                   1.292422   \n",
       "407                                   1.054859   \n",
       "408                                   0.963252   \n",
       "409                                  -0.604243   \n",
       "410                                  -1.328723   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_tg_1w_4  \\\n",
       "0                                    -0.325450   \n",
       "1                                     0.401314   \n",
       "2                                     0.373232   \n",
       "3                                     0.208962   \n",
       "4                                     0.484058   \n",
       "..                                         ...   \n",
       "406                                   1.757969   \n",
       "407                                   1.437956   \n",
       "408                                   0.693918   \n",
       "409                                  -0.416388   \n",
       "410                                  -0.822069   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_tg_24w_1  ...  \\\n",
       "0                                      0.326942  ...   \n",
       "1                                      1.779921  ...   \n",
       "2                                      0.816023  ...   \n",
       "3                                      1.160471  ...   \n",
       "4                                      0.876454  ...   \n",
       "..                                          ...  ...   \n",
       "406                                    0.987092  ...   \n",
       "407                                    0.978438  ...   \n",
       "408                                    0.832314  ...   \n",
       "409                                    0.627521  ...   \n",
       "410                                    0.628527  ...   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_16w_3_Oglio_Iseo  \\\n",
       "0                                               -0.0   \n",
       "1                                               -0.0   \n",
       "2                                               -0.0   \n",
       "3                                               -0.0   \n",
       "4                                               -0.0   \n",
       "..                                               ...   \n",
       "406                                              0.0   \n",
       "407                                              0.0   \n",
       "408                                              0.0   \n",
       "409                                              0.0   \n",
       "410                                              0.0   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_16w_3_Ticino  \\\n",
       "0                                      -0.000000   \n",
       "1                                      -0.000000   \n",
       "2                                      -0.000000   \n",
       "3                                      -0.000000   \n",
       "4                                      -0.000000   \n",
       "..                                           ...   \n",
       "406                                     1.029462   \n",
       "407                                     1.054968   \n",
       "408                                     1.164702   \n",
       "409                                     0.830063   \n",
       "410                                     0.771344   \n",
       "\n",
       "     Ticino_cyclostationary_mean_rr_24w_0_Adda  \\\n",
       "0                                     1.086902   \n",
       "1                                     2.955987   \n",
       "2                                     1.397907   \n",
       "3                                     1.452206   \n",
       "4                                     1.059559   \n",
       "..                                         ...   \n",
       "406                                  -0.000000   \n",
       "407                                  -0.000000   \n",
       "408                                  -0.000000   \n",
       "409                                  -0.000000   \n",
       "410                                  -0.000000   \n",
       "\n",
       "     Ticino_cyclostationary_mean_rr_24w_0_Lambro_Olona  \\\n",
       "0                                                  0.0   \n",
       "1                                                  0.0   \n",
       "2                                                  0.0   \n",
       "3                                                  0.0   \n",
       "4                                                  0.0   \n",
       "..                                                 ...   \n",
       "406                                               -0.0   \n",
       "407                                               -0.0   \n",
       "408                                               -0.0   \n",
       "409                                               -0.0   \n",
       "410                                               -0.0   \n",
       "\n",
       "     Ticino_cyclostationary_mean_rr_24w_0_Oglio_Iseo  \\\n",
       "0                                                0.0   \n",
       "1                                                0.0   \n",
       "2                                                0.0   \n",
       "3                                                0.0   \n",
       "4                                                0.0   \n",
       "..                                               ...   \n",
       "406                                             -0.0   \n",
       "407                                             -0.0   \n",
       "408                                             -0.0   \n",
       "409                                             -0.0   \n",
       "410                                             -0.0   \n",
       "\n",
       "     Ticino_cyclostationary_mean_rr_24w_0_Ticino  \\\n",
       "0                                       0.000000   \n",
       "1                                       0.000000   \n",
       "2                                       0.000000   \n",
       "3                                       0.000000   \n",
       "4                                       0.000000   \n",
       "..                                           ...   \n",
       "406                                    -0.889708   \n",
       "407                                    -0.475943   \n",
       "408                                    -0.394052   \n",
       "409                                    -0.260074   \n",
       "410                                    -0.397287   \n",
       "\n",
       "     Ticino_cyclostationary_mean_rr_24w_1_Adda  \\\n",
       "0                                     0.923555   \n",
       "1                                     3.878325   \n",
       "2                                     2.009521   \n",
       "3                                     2.031725   \n",
       "4                                     1.666844   \n",
       "..                                         ...   \n",
       "406                                  -0.000000   \n",
       "407                                  -0.000000   \n",
       "408                                  -0.000000   \n",
       "409                                  -0.000000   \n",
       "410                                  -0.000000   \n",
       "\n",
       "     Ticino_cyclostationary_mean_rr_24w_1_Lambro_Olona  \\\n",
       "0                                                  0.0   \n",
       "1                                                  0.0   \n",
       "2                                                  0.0   \n",
       "3                                                  0.0   \n",
       "4                                                  0.0   \n",
       "..                                                 ...   \n",
       "406                                               -0.0   \n",
       "407                                               -0.0   \n",
       "408                                               -0.0   \n",
       "409                                               -0.0   \n",
       "410                                               -0.0   \n",
       "\n",
       "     Ticino_cyclostationary_mean_rr_24w_1_Oglio_Iseo  \\\n",
       "0                                                0.0   \n",
       "1                                                0.0   \n",
       "2                                                0.0   \n",
       "3                                                0.0   \n",
       "4                                                0.0   \n",
       "..                                               ...   \n",
       "406                                             -0.0   \n",
       "407                                             -0.0   \n",
       "408                                             -0.0   \n",
       "409                                             -0.0   \n",
       "410                                             -0.0   \n",
       "\n",
       "     Ticino_cyclostationary_mean_rr_24w_1_Ticino  \n",
       "0                                       0.000000  \n",
       "1                                       0.000000  \n",
       "2                                       0.000000  \n",
       "3                                       0.000000  \n",
       "4                                       0.000000  \n",
       "..                                           ...  \n",
       "406                                    -1.175881  \n",
       "407                                    -0.744283  \n",
       "408                                    -0.658232  \n",
       "409                                    -0.519229  \n",
       "410                                    -0.805547  \n",
       "\n",
       "[1644 rows x 104 columns]"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(best5_wrapper_clusterdf_train_withClass.shape[1]-len(clust_basins)):\n",
    "    for j in clust_basins:\n",
    "        best5_wrapper_clusterdf_train_withClass[best5_wrapper_clusterdf_train_withClass.columns[i]+'_'+j] = best5_wrapper_clusterdf_train_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "        best5_wrapper_clusterdf_val_withClass[best5_wrapper_clusterdf_val_withClass.columns[i]+'_'+j] = best5_wrapper_clusterdf_val_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "        best5_wrapper_clusterdf_test_withClass[best5_wrapper_clusterdf_test_withClass.columns[i]+'_'+j] = best5_wrapper_clusterdf_test_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "\n",
    "best5_wrapper_clusterdf_train_withClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "bb7d3b55",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.025485091324654707\n",
      "-0.040504606273706\n",
      "-0.19022139049651954\n",
      "0.10691584689345834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_ALOT_ohe = LinearRegression()\n",
    "model_ALOT_ohe.fit(pd.concat((best5_wrapper_clusterdf_train_withClass,best5_wrapper_clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_ALOT_ohe.predict(best5_wrapper_clusterdf_test_withClass.loc[best5_wrapper_clusterdf_test_withClass.Adda==1].values)\n",
    "print(r2_score(targets_df_test['Adda'].values, res))\n",
    "res = model_ALOT_ohe.predict(best5_wrapper_clusterdf_test_withClass.loc[best5_wrapper_clusterdf_test_withClass.Lambro_Olona==1].values)\n",
    "print(r2_score(targets_df_test['Lambro_Olona'].values, res))\n",
    "res = model_ALOT_ohe.predict(best5_wrapper_clusterdf_test_withClass.loc[best5_wrapper_clusterdf_test_withClass.Oglio_Iseo==1].values)\n",
    "print(r2_score(targets_df_test['Oglio_Iseo'].values, res))\n",
    "res = model_ALOT_ohe.predict(best5_wrapper_clusterdf_test_withClass.loc[best5_wrapper_clusterdf_test_withClass.Ticino==1].values)\n",
    "print(r2_score(targets_df_test['Ticino'].values, res))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035694ac",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Adda - Lambro_Olona - Oglio_Iseo - Ticino: CMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "5b6fb31d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "clust_basins = ['Adda', 'Lambro_Olona', 'Oglio_Iseo', 'Ticino']\n",
    "colnames = [x for x in CMI_fulldf_train.columns if x.startswith('Adda') or x.startswith('Lambro_Olona') or x.startswith('Oglio_Iseo') or x.startswith('Ticino')]\n",
    "\n",
    "clusterdf_train_withClass = pd.DataFrame()\n",
    "clusterdf_val_withClass = pd.DataFrame()\n",
    "clusterdf_test_withClass = pd.DataFrame()\n",
    "\n",
    "for i in range(len(clust_basins)):\n",
    "    clusterdf_train_withClass = pd.concat((clusterdf_train_withClass,pd.concat((CMI_fulldf_train[colnames],pd.DataFrame(1+i*np.ones(len(CMI_fulldf_train)),columns=['basin'])),axis=1)),axis=0)\n",
    "    clusterdf_val_withClass = pd.concat((clusterdf_val_withClass,pd.concat((CMI_fulldf_val[colnames],pd.DataFrame(1+i*np.ones(len(CMI_fulldf_val)),columns=['basin'])),axis=1)),axis=0)\n",
    "    clusterdf_test_withClass = pd.concat((clusterdf_test_withClass,pd.concat((CMI_fulldf_test[colnames],pd.DataFrame(1+i*np.ones(len(CMI_fulldf_test)),columns=['basin'])),axis=1)),axis=0)\n",
    "\n",
    "for i in range(len(clust_basins)):\n",
    "    clusterdf_train_withClass[clust_basins[i]] = clusterdf_train_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    clusterdf_val_withClass[clust_basins[i]] = clusterdf_val_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    clusterdf_test_withClass[clust_basins[i]] = clusterdf_test_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "\n",
    "clusterdf_train_withClass = clusterdf_train_withClass.loc[:,clusterdf_train_withClass.columns != 'basin']\n",
    "clusterdf_val_withClass = clusterdf_val_withClass.loc[:,clusterdf_val_withClass.columns != 'basin']\n",
    "clusterdf_test_withClass = clusterdf_test_withClass.loc[:,clusterdf_test_withClass.columns != 'basin']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "ccc316ce",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adda_cyclostationary_mean_tg_1w_3</th>\n",
       "      <th>Adda_cyclostationary_mean_rr_12w_1</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_16w_0</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_24w_2</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_24w_0</th>\n",
       "      <th>Adda_cyclostationary_mean_rr_24w_2</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_16w_2</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_8w_3</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_12w_2</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_16w_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Oglio_Iseo_cyclostationary_mean_tg_1w_1</th>\n",
       "      <th>Oglio_Iseo_cyclostationary_mean_tg_24w_0</th>\n",
       "      <th>Oglio_Iseo_cyclostationary_mean_tg_8w_2</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_0</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_4w_0</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_1</th>\n",
       "      <th>Adda</th>\n",
       "      <th>Lambro_Olona</th>\n",
       "      <th>Oglio_Iseo</th>\n",
       "      <th>Ticino</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.862899</td>\n",
       "      <td>1.560382</td>\n",
       "      <td>1.711682</td>\n",
       "      <td>-2.770704</td>\n",
       "      <td>1.914831</td>\n",
       "      <td>1.558385</td>\n",
       "      <td>-3.062159</td>\n",
       "      <td>-2.717835</td>\n",
       "      <td>-2.894908</td>\n",
       "      <td>-1.573558</td>\n",
       "      <td>...</td>\n",
       "      <td>0.354242</td>\n",
       "      <td>-0.437988</td>\n",
       "      <td>-1.562524</td>\n",
       "      <td>-0.432799</td>\n",
       "      <td>0.611605</td>\n",
       "      <td>-0.442197</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.093639</td>\n",
       "      <td>5.036114</td>\n",
       "      <td>2.547788</td>\n",
       "      <td>-0.879312</td>\n",
       "      <td>2.856614</td>\n",
       "      <td>5.651050</td>\n",
       "      <td>-1.604230</td>\n",
       "      <td>-0.773323</td>\n",
       "      <td>-1.521259</td>\n",
       "      <td>-0.081890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.814679</td>\n",
       "      <td>0.943677</td>\n",
       "      <td>-0.432666</td>\n",
       "      <td>0.776085</td>\n",
       "      <td>1.691336</td>\n",
       "      <td>0.807518</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.524505</td>\n",
       "      <td>3.177144</td>\n",
       "      <td>1.634451</td>\n",
       "      <td>-2.052028</td>\n",
       "      <td>1.827839</td>\n",
       "      <td>3.585398</td>\n",
       "      <td>-2.492491</td>\n",
       "      <td>-1.882391</td>\n",
       "      <td>-2.358171</td>\n",
       "      <td>-1.022712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.209296</td>\n",
       "      <td>-0.174601</td>\n",
       "      <td>-1.152962</td>\n",
       "      <td>-0.906320</td>\n",
       "      <td>0.832271</td>\n",
       "      <td>-1.081813</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.666293</td>\n",
       "      <td>3.205993</td>\n",
       "      <td>1.836713</td>\n",
       "      <td>-1.425685</td>\n",
       "      <td>2.055666</td>\n",
       "      <td>3.473244</td>\n",
       "      <td>-1.901370</td>\n",
       "      <td>-1.316877</td>\n",
       "      <td>-1.801222</td>\n",
       "      <td>-0.568594</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.056410</td>\n",
       "      <td>0.195684</td>\n",
       "      <td>-0.862380</td>\n",
       "      <td>0.529173</td>\n",
       "      <td>0.859041</td>\n",
       "      <td>0.324392</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.416695</td>\n",
       "      <td>2.498195</td>\n",
       "      <td>1.795310</td>\n",
       "      <td>-1.994518</td>\n",
       "      <td>2.009029</td>\n",
       "      <td>2.635690</td>\n",
       "      <td>-2.302021</td>\n",
       "      <td>-1.671404</td>\n",
       "      <td>-2.178712</td>\n",
       "      <td>-0.939871</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188935</td>\n",
       "      <td>-0.108776</td>\n",
       "      <td>-1.137538</td>\n",
       "      <td>-0.687667</td>\n",
       "      <td>0.647203</td>\n",
       "      <td>-0.553079</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>1.568770</td>\n",
       "      <td>-1.467261</td>\n",
       "      <td>0.783570</td>\n",
       "      <td>1.524212</td>\n",
       "      <td>0.639345</td>\n",
       "      <td>-1.396357</td>\n",
       "      <td>1.138232</td>\n",
       "      <td>0.857006</td>\n",
       "      <td>1.270194</td>\n",
       "      <td>0.993754</td>\n",
       "      <td>...</td>\n",
       "      <td>1.178621</td>\n",
       "      <td>1.072707</td>\n",
       "      <td>0.708063</td>\n",
       "      <td>1.481505</td>\n",
       "      <td>-1.023397</td>\n",
       "      <td>1.527659</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>0.812306</td>\n",
       "      <td>-0.715887</td>\n",
       "      <td>0.868596</td>\n",
       "      <td>1.477729</td>\n",
       "      <td>0.671680</td>\n",
       "      <td>-0.906659</td>\n",
       "      <td>1.152253</td>\n",
       "      <td>0.691913</td>\n",
       "      <td>1.009645</td>\n",
       "      <td>1.038541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.874900</td>\n",
       "      <td>1.054781</td>\n",
       "      <td>0.578971</td>\n",
       "      <td>0.121450</td>\n",
       "      <td>-0.154876</td>\n",
       "      <td>0.019115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.876968</td>\n",
       "      <td>-0.558495</td>\n",
       "      <td>0.899390</td>\n",
       "      <td>1.352693</td>\n",
       "      <td>0.504706</td>\n",
       "      <td>-0.775360</td>\n",
       "      <td>1.253158</td>\n",
       "      <td>0.563242</td>\n",
       "      <td>1.039944</td>\n",
       "      <td>1.110398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.552941</td>\n",
       "      <td>0.896998</td>\n",
       "      <td>0.450693</td>\n",
       "      <td>0.865426</td>\n",
       "      <td>0.083449</td>\n",
       "      <td>1.039841</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>-0.723696</td>\n",
       "      <td>-0.626439</td>\n",
       "      <td>0.725991</td>\n",
       "      <td>1.102009</td>\n",
       "      <td>0.391753</td>\n",
       "      <td>-0.669538</td>\n",
       "      <td>0.874675</td>\n",
       "      <td>-0.309515</td>\n",
       "      <td>0.500579</td>\n",
       "      <td>0.800302</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.656226</td>\n",
       "      <td>0.726259</td>\n",
       "      <td>-0.210982</td>\n",
       "      <td>-2.359776</td>\n",
       "      <td>0.001375</td>\n",
       "      <td>-2.580108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-1.413870</td>\n",
       "      <td>-0.338666</td>\n",
       "      <td>0.604737</td>\n",
       "      <td>1.186923</td>\n",
       "      <td>0.312637</td>\n",
       "      <td>-0.681557</td>\n",
       "      <td>0.821070</td>\n",
       "      <td>0.105468</td>\n",
       "      <td>0.413493</td>\n",
       "      <td>0.731104</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.042254</td>\n",
       "      <td>0.724881</td>\n",
       "      <td>0.083086</td>\n",
       "      <td>0.061748</td>\n",
       "      <td>0.518063</td>\n",
       "      <td>-0.183864</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1644 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Adda_cyclostationary_mean_tg_1w_3  Adda_cyclostationary_mean_rr_12w_1  \\\n",
       "0                            -0.862899                            1.560382   \n",
       "1                            -0.093639                            5.036114   \n",
       "2                            -0.524505                            3.177144   \n",
       "3                            -0.666293                            3.205993   \n",
       "4                            -0.416695                            2.498195   \n",
       "..                                 ...                                 ...   \n",
       "406                           1.568770                           -1.467261   \n",
       "407                           0.812306                           -0.715887   \n",
       "408                           0.876968                           -0.558495   \n",
       "409                          -0.723696                           -0.626439   \n",
       "410                          -1.413870                           -0.338666   \n",
       "\n",
       "     Adda_cyclostationary_mean_tg_16w_0  Adda_cyclostationary_mean_tg_24w_2  \\\n",
       "0                              1.711682                           -2.770704   \n",
       "1                              2.547788                           -0.879312   \n",
       "2                              1.634451                           -2.052028   \n",
       "3                              1.836713                           -1.425685   \n",
       "4                              1.795310                           -1.994518   \n",
       "..                                  ...                                 ...   \n",
       "406                            0.783570                            1.524212   \n",
       "407                            0.868596                            1.477729   \n",
       "408                            0.899390                            1.352693   \n",
       "409                            0.725991                            1.102009   \n",
       "410                            0.604737                            1.186923   \n",
       "\n",
       "     Adda_cyclostationary_mean_tg_24w_0  Adda_cyclostationary_mean_rr_24w_2  \\\n",
       "0                              1.914831                            1.558385   \n",
       "1                              2.856614                            5.651050   \n",
       "2                              1.827839                            3.585398   \n",
       "3                              2.055666                            3.473244   \n",
       "4                              2.009029                            2.635690   \n",
       "..                                  ...                                 ...   \n",
       "406                            0.639345                           -1.396357   \n",
       "407                            0.671680                           -0.906659   \n",
       "408                            0.504706                           -0.775360   \n",
       "409                            0.391753                           -0.669538   \n",
       "410                            0.312637                           -0.681557   \n",
       "\n",
       "     Adda_cyclostationary_mean_tg_16w_2  Adda_cyclostationary_mean_tg_8w_3  \\\n",
       "0                             -3.062159                          -2.717835   \n",
       "1                             -1.604230                          -0.773323   \n",
       "2                             -2.492491                          -1.882391   \n",
       "3                             -1.901370                          -1.316877   \n",
       "4                             -2.302021                          -1.671404   \n",
       "..                                  ...                                ...   \n",
       "406                            1.138232                           0.857006   \n",
       "407                            1.152253                           0.691913   \n",
       "408                            1.253158                           0.563242   \n",
       "409                            0.874675                          -0.309515   \n",
       "410                            0.821070                           0.105468   \n",
       "\n",
       "     Adda_cyclostationary_mean_tg_12w_2  Adda_cyclostationary_mean_tg_16w_1  \\\n",
       "0                             -2.894908                           -1.573558   \n",
       "1                             -1.521259                           -0.081890   \n",
       "2                             -2.358171                           -1.022712   \n",
       "3                             -1.801222                           -0.568594   \n",
       "4                             -2.178712                           -0.939871   \n",
       "..                                  ...                                 ...   \n",
       "406                            1.270194                            0.993754   \n",
       "407                            1.009645                            1.038541   \n",
       "408                            1.039944                            1.110398   \n",
       "409                            0.500579                            0.800302   \n",
       "410                            0.413493                            0.731104   \n",
       "\n",
       "     ...  Oglio_Iseo_cyclostationary_mean_tg_1w_1  \\\n",
       "0    ...                                 0.354242   \n",
       "1    ...                                 0.814679   \n",
       "2    ...                                 0.209296   \n",
       "3    ...                                -0.056410   \n",
       "4    ...                                 0.188935   \n",
       "..   ...                                      ...   \n",
       "406  ...                                 1.178621   \n",
       "407  ...                                 0.874900   \n",
       "408  ...                                 0.552941   \n",
       "409  ...                                -0.656226   \n",
       "410  ...                                -1.042254   \n",
       "\n",
       "     Oglio_Iseo_cyclostationary_mean_tg_24w_0  \\\n",
       "0                                   -0.437988   \n",
       "1                                    0.943677   \n",
       "2                                   -0.174601   \n",
       "3                                    0.195684   \n",
       "4                                   -0.108776   \n",
       "..                                        ...   \n",
       "406                                  1.072707   \n",
       "407                                  1.054781   \n",
       "408                                  0.896998   \n",
       "409                                  0.726259   \n",
       "410                                  0.724881   \n",
       "\n",
       "     Oglio_Iseo_cyclostationary_mean_tg_8w_2  \\\n",
       "0                                  -1.562524   \n",
       "1                                  -0.432666   \n",
       "2                                  -1.152962   \n",
       "3                                  -0.862380   \n",
       "4                                  -1.137538   \n",
       "..                                       ...   \n",
       "406                                 0.708063   \n",
       "407                                 0.578971   \n",
       "408                                 0.450693   \n",
       "409                                -0.210982   \n",
       "410                                 0.083086   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_0  Ticino_cyclostationary_mean_rr_4w_0  \\\n",
       "0                           -0.432799                             0.611605   \n",
       "1                            0.776085                             1.691336   \n",
       "2                           -0.906320                             0.832271   \n",
       "3                            0.529173                             0.859041   \n",
       "4                           -0.687667                             0.647203   \n",
       "..                                ...                                  ...   \n",
       "406                          1.481505                            -1.023397   \n",
       "407                          0.121450                            -0.154876   \n",
       "408                          0.865426                             0.083449   \n",
       "409                         -2.359776                             0.001375   \n",
       "410                          0.061748                             0.518063   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_1  Adda  Lambro_Olona  Oglio_Iseo  Ticino  \n",
       "0                           -0.442197     1             0           0       0  \n",
       "1                            0.807518     1             0           0       0  \n",
       "2                           -1.081813     1             0           0       0  \n",
       "3                            0.324392     1             0           0       0  \n",
       "4                           -0.553079     1             0           0       0  \n",
       "..                                ...   ...           ...         ...     ...  \n",
       "406                          1.527659     0             0           0       1  \n",
       "407                          0.019115     0             0           0       1  \n",
       "408                          1.039841     0             0           0       1  \n",
       "409                         -2.580108     0             0           0       1  \n",
       "410                         -0.183864     0             0           0       1  \n",
       "\n",
       "[1644 rows x 29 columns]"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterdf_train_withClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "898be3ca",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "targets_df_train_unfolded = pd.DataFrame()\n",
    "targets_df_val_unfolded = pd.DataFrame()\n",
    "targets_df_test_unfolded = pd.DataFrame()\n",
    "\n",
    "for basin in clust_basins:\n",
    "    targets_df_train_unfolded =  pd.concat((targets_df_train_unfolded,targets_df_train[basin]),axis=0)\n",
    "    targets_df_val_unfolded =  pd.concat((targets_df_val_unfolded,targets_df_val[basin]),axis=0)\n",
    "    targets_df_test_unfolded =  pd.concat((targets_df_test_unfolded,targets_df_test[basin]),axis=0)\n",
    "targets_df_train_unfolded = targets_df_train_unfolded.reset_index(drop=True)\n",
    "targets_df_val_unfolded = targets_df_val_unfolded.reset_index(drop=True)\n",
    "targets_df_test_unfolded = targets_df_test_unfolded.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "a2a2619c",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.546951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.277191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.534156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.666789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.447894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1639</th>\n",
       "      <td>-0.563495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1640</th>\n",
       "      <td>-0.291984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1641</th>\n",
       "      <td>0.770822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1642</th>\n",
       "      <td>-0.412164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643</th>\n",
       "      <td>-1.081585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1644 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0    -2.546951\n",
       "1    -0.277191\n",
       "2    -0.534156\n",
       "3    -0.666789\n",
       "4    -0.447894\n",
       "...        ...\n",
       "1639 -0.563495\n",
       "1640 -0.291984\n",
       "1641  0.770822\n",
       "1642 -0.412164\n",
       "1643 -1.081585\n",
       "\n",
       "[1644 rows x 1 columns]"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_df_train_unfolded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "66016179",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.27602252513373093\n",
      "-0.33286368279662315\n",
      "-0.2930646584680894\n",
      "-0.22789296896759081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_ALOT_ohe = LinearRegression()\n",
    "model_ALOT_ohe.fit(pd.concat((clusterdf_train_withClass,clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Adda==1].values)\n",
    "print(r2_score(targets_df_test['Adda'].values, res))\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Lambro_Olona==1].values)\n",
    "print(r2_score(targets_df_test['Lambro_Olona'].values, res))\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Oglio_Iseo==1].values)\n",
    "print(r2_score(targets_df_test['Oglio_Iseo'].values, res))\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Ticino==1].values)\n",
    "print(r2_score(targets_df_test['Ticino'].values, res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "c011a5e5",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adda_cyclostationary_mean_tg_1w_3</th>\n",
       "      <th>Adda_cyclostationary_mean_rr_12w_1</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_16w_0</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_24w_2</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_24w_0</th>\n",
       "      <th>Adda_cyclostationary_mean_rr_24w_2</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_16w_2</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_8w_3</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_12w_2</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_16w_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_0_Oglio_Iseo</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_0_Ticino</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_4w_0_Adda</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_4w_0_Lambro_Olona</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_4w_0_Oglio_Iseo</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_4w_0_Ticino</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_1_Adda</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_1_Lambro_Olona</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_1_Oglio_Iseo</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_1_Ticino</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.862899</td>\n",
       "      <td>1.560382</td>\n",
       "      <td>1.711682</td>\n",
       "      <td>-2.770704</td>\n",
       "      <td>1.914831</td>\n",
       "      <td>1.558385</td>\n",
       "      <td>-3.062159</td>\n",
       "      <td>-2.717835</td>\n",
       "      <td>-2.894908</td>\n",
       "      <td>-1.573558</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.611605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.442197</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.093639</td>\n",
       "      <td>5.036114</td>\n",
       "      <td>2.547788</td>\n",
       "      <td>-0.879312</td>\n",
       "      <td>2.856614</td>\n",
       "      <td>5.651050</td>\n",
       "      <td>-1.604230</td>\n",
       "      <td>-0.773323</td>\n",
       "      <td>-1.521259</td>\n",
       "      <td>-0.081890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.691336</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.807518</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.524505</td>\n",
       "      <td>3.177144</td>\n",
       "      <td>1.634451</td>\n",
       "      <td>-2.052028</td>\n",
       "      <td>1.827839</td>\n",
       "      <td>3.585398</td>\n",
       "      <td>-2.492491</td>\n",
       "      <td>-1.882391</td>\n",
       "      <td>-2.358171</td>\n",
       "      <td>-1.022712</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.832271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.081813</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.666293</td>\n",
       "      <td>3.205993</td>\n",
       "      <td>1.836713</td>\n",
       "      <td>-1.425685</td>\n",
       "      <td>2.055666</td>\n",
       "      <td>3.473244</td>\n",
       "      <td>-1.901370</td>\n",
       "      <td>-1.316877</td>\n",
       "      <td>-1.801222</td>\n",
       "      <td>-0.568594</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.859041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.324392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.416695</td>\n",
       "      <td>2.498195</td>\n",
       "      <td>1.795310</td>\n",
       "      <td>-1.994518</td>\n",
       "      <td>2.009029</td>\n",
       "      <td>2.635690</td>\n",
       "      <td>-2.302021</td>\n",
       "      <td>-1.671404</td>\n",
       "      <td>-2.178712</td>\n",
       "      <td>-0.939871</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.647203</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.553079</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>1.568770</td>\n",
       "      <td>-1.467261</td>\n",
       "      <td>0.783570</td>\n",
       "      <td>1.524212</td>\n",
       "      <td>0.639345</td>\n",
       "      <td>-1.396357</td>\n",
       "      <td>1.138232</td>\n",
       "      <td>0.857006</td>\n",
       "      <td>1.270194</td>\n",
       "      <td>0.993754</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.481505</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-1.023397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.527659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>0.812306</td>\n",
       "      <td>-0.715887</td>\n",
       "      <td>0.868596</td>\n",
       "      <td>1.477729</td>\n",
       "      <td>0.671680</td>\n",
       "      <td>-0.906659</td>\n",
       "      <td>1.152253</td>\n",
       "      <td>0.691913</td>\n",
       "      <td>1.009645</td>\n",
       "      <td>1.038541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.121450</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.154876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.876968</td>\n",
       "      <td>-0.558495</td>\n",
       "      <td>0.899390</td>\n",
       "      <td>1.352693</td>\n",
       "      <td>0.504706</td>\n",
       "      <td>-0.775360</td>\n",
       "      <td>1.253158</td>\n",
       "      <td>0.563242</td>\n",
       "      <td>1.039944</td>\n",
       "      <td>1.110398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.865426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083449</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.039841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>-0.723696</td>\n",
       "      <td>-0.626439</td>\n",
       "      <td>0.725991</td>\n",
       "      <td>1.102009</td>\n",
       "      <td>0.391753</td>\n",
       "      <td>-0.669538</td>\n",
       "      <td>0.874675</td>\n",
       "      <td>-0.309515</td>\n",
       "      <td>0.500579</td>\n",
       "      <td>0.800302</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-2.359776</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001375</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-2.580108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-1.413870</td>\n",
       "      <td>-0.338666</td>\n",
       "      <td>0.604737</td>\n",
       "      <td>1.186923</td>\n",
       "      <td>0.312637</td>\n",
       "      <td>-0.681557</td>\n",
       "      <td>0.821070</td>\n",
       "      <td>0.105468</td>\n",
       "      <td>0.413493</td>\n",
       "      <td>0.731104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.061748</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.518063</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.183864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1644 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Adda_cyclostationary_mean_tg_1w_3  Adda_cyclostationary_mean_rr_12w_1  \\\n",
       "0                            -0.862899                            1.560382   \n",
       "1                            -0.093639                            5.036114   \n",
       "2                            -0.524505                            3.177144   \n",
       "3                            -0.666293                            3.205993   \n",
       "4                            -0.416695                            2.498195   \n",
       "..                                 ...                                 ...   \n",
       "406                           1.568770                           -1.467261   \n",
       "407                           0.812306                           -0.715887   \n",
       "408                           0.876968                           -0.558495   \n",
       "409                          -0.723696                           -0.626439   \n",
       "410                          -1.413870                           -0.338666   \n",
       "\n",
       "     Adda_cyclostationary_mean_tg_16w_0  Adda_cyclostationary_mean_tg_24w_2  \\\n",
       "0                              1.711682                           -2.770704   \n",
       "1                              2.547788                           -0.879312   \n",
       "2                              1.634451                           -2.052028   \n",
       "3                              1.836713                           -1.425685   \n",
       "4                              1.795310                           -1.994518   \n",
       "..                                  ...                                 ...   \n",
       "406                            0.783570                            1.524212   \n",
       "407                            0.868596                            1.477729   \n",
       "408                            0.899390                            1.352693   \n",
       "409                            0.725991                            1.102009   \n",
       "410                            0.604737                            1.186923   \n",
       "\n",
       "     Adda_cyclostationary_mean_tg_24w_0  Adda_cyclostationary_mean_rr_24w_2  \\\n",
       "0                              1.914831                            1.558385   \n",
       "1                              2.856614                            5.651050   \n",
       "2                              1.827839                            3.585398   \n",
       "3                              2.055666                            3.473244   \n",
       "4                              2.009029                            2.635690   \n",
       "..                                  ...                                 ...   \n",
       "406                            0.639345                           -1.396357   \n",
       "407                            0.671680                           -0.906659   \n",
       "408                            0.504706                           -0.775360   \n",
       "409                            0.391753                           -0.669538   \n",
       "410                            0.312637                           -0.681557   \n",
       "\n",
       "     Adda_cyclostationary_mean_tg_16w_2  Adda_cyclostationary_mean_tg_8w_3  \\\n",
       "0                             -3.062159                          -2.717835   \n",
       "1                             -1.604230                          -0.773323   \n",
       "2                             -2.492491                          -1.882391   \n",
       "3                             -1.901370                          -1.316877   \n",
       "4                             -2.302021                          -1.671404   \n",
       "..                                  ...                                ...   \n",
       "406                            1.138232                           0.857006   \n",
       "407                            1.152253                           0.691913   \n",
       "408                            1.253158                           0.563242   \n",
       "409                            0.874675                          -0.309515   \n",
       "410                            0.821070                           0.105468   \n",
       "\n",
       "     Adda_cyclostationary_mean_tg_12w_2  Adda_cyclostationary_mean_tg_16w_1  \\\n",
       "0                             -2.894908                           -1.573558   \n",
       "1                             -1.521259                           -0.081890   \n",
       "2                             -2.358171                           -1.022712   \n",
       "3                             -1.801222                           -0.568594   \n",
       "4                             -2.178712                           -0.939871   \n",
       "..                                  ...                                 ...   \n",
       "406                            1.270194                            0.993754   \n",
       "407                            1.009645                            1.038541   \n",
       "408                            1.039944                            1.110398   \n",
       "409                            0.500579                            0.800302   \n",
       "410                            0.413493                            0.731104   \n",
       "\n",
       "     ...  Ticino_cyclostationary_mean_tg_0_Oglio_Iseo  \\\n",
       "0    ...                                         -0.0   \n",
       "1    ...                                          0.0   \n",
       "2    ...                                         -0.0   \n",
       "3    ...                                          0.0   \n",
       "4    ...                                         -0.0   \n",
       "..   ...                                          ...   \n",
       "406  ...                                          0.0   \n",
       "407  ...                                          0.0   \n",
       "408  ...                                          0.0   \n",
       "409  ...                                         -0.0   \n",
       "410  ...                                          0.0   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_0_Ticino  \\\n",
       "0                                  -0.000000   \n",
       "1                                   0.000000   \n",
       "2                                  -0.000000   \n",
       "3                                   0.000000   \n",
       "4                                  -0.000000   \n",
       "..                                       ...   \n",
       "406                                 1.481505   \n",
       "407                                 0.121450   \n",
       "408                                 0.865426   \n",
       "409                                -2.359776   \n",
       "410                                 0.061748   \n",
       "\n",
       "     Ticino_cyclostationary_mean_rr_4w_0_Adda  \\\n",
       "0                                    0.611605   \n",
       "1                                    1.691336   \n",
       "2                                    0.832271   \n",
       "3                                    0.859041   \n",
       "4                                    0.647203   \n",
       "..                                        ...   \n",
       "406                                 -0.000000   \n",
       "407                                 -0.000000   \n",
       "408                                  0.000000   \n",
       "409                                  0.000000   \n",
       "410                                  0.000000   \n",
       "\n",
       "     Ticino_cyclostationary_mean_rr_4w_0_Lambro_Olona  \\\n",
       "0                                                 0.0   \n",
       "1                                                 0.0   \n",
       "2                                                 0.0   \n",
       "3                                                 0.0   \n",
       "4                                                 0.0   \n",
       "..                                                ...   \n",
       "406                                              -0.0   \n",
       "407                                              -0.0   \n",
       "408                                               0.0   \n",
       "409                                               0.0   \n",
       "410                                               0.0   \n",
       "\n",
       "     Ticino_cyclostationary_mean_rr_4w_0_Oglio_Iseo  \\\n",
       "0                                               0.0   \n",
       "1                                               0.0   \n",
       "2                                               0.0   \n",
       "3                                               0.0   \n",
       "4                                               0.0   \n",
       "..                                              ...   \n",
       "406                                            -0.0   \n",
       "407                                            -0.0   \n",
       "408                                             0.0   \n",
       "409                                             0.0   \n",
       "410                                             0.0   \n",
       "\n",
       "     Ticino_cyclostationary_mean_rr_4w_0_Ticino  \\\n",
       "0                                      0.000000   \n",
       "1                                      0.000000   \n",
       "2                                      0.000000   \n",
       "3                                      0.000000   \n",
       "4                                      0.000000   \n",
       "..                                          ...   \n",
       "406                                   -1.023397   \n",
       "407                                   -0.154876   \n",
       "408                                    0.083449   \n",
       "409                                    0.001375   \n",
       "410                                    0.518063   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_1_Adda  \\\n",
       "0                                -0.442197   \n",
       "1                                 0.807518   \n",
       "2                                -1.081813   \n",
       "3                                 0.324392   \n",
       "4                                -0.553079   \n",
       "..                                     ...   \n",
       "406                               0.000000   \n",
       "407                               0.000000   \n",
       "408                               0.000000   \n",
       "409                              -0.000000   \n",
       "410                              -0.000000   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_1_Lambro_Olona  \\\n",
       "0                                             -0.0   \n",
       "1                                              0.0   \n",
       "2                                             -0.0   \n",
       "3                                              0.0   \n",
       "4                                             -0.0   \n",
       "..                                             ...   \n",
       "406                                            0.0   \n",
       "407                                            0.0   \n",
       "408                                            0.0   \n",
       "409                                           -0.0   \n",
       "410                                           -0.0   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_1_Oglio_Iseo  \\\n",
       "0                                           -0.0   \n",
       "1                                            0.0   \n",
       "2                                           -0.0   \n",
       "3                                            0.0   \n",
       "4                                           -0.0   \n",
       "..                                           ...   \n",
       "406                                          0.0   \n",
       "407                                          0.0   \n",
       "408                                          0.0   \n",
       "409                                         -0.0   \n",
       "410                                         -0.0   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_1_Ticino  \n",
       "0                                  -0.000000  \n",
       "1                                   0.000000  \n",
       "2                                  -0.000000  \n",
       "3                                   0.000000  \n",
       "4                                  -0.000000  \n",
       "..                                       ...  \n",
       "406                                 1.527659  \n",
       "407                                 0.019115  \n",
       "408                                 1.039841  \n",
       "409                                -2.580108  \n",
       "410                                -0.183864  \n",
       "\n",
       "[1644 rows x 129 columns]"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(clusterdf_train_withClass.shape[1]-len(clust_basins)):\n",
    "    for j in clust_basins:\n",
    "        clusterdf_train_withClass[clusterdf_train_withClass.columns[i]+'_'+j] = clusterdf_train_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "        clusterdf_val_withClass[clusterdf_val_withClass.columns[i]+'_'+j] = clusterdf_val_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "        clusterdf_test_withClass[clusterdf_test_withClass.columns[i]+'_'+j] = clusterdf_test_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "\n",
    "clusterdf_train_withClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "302ddc6b",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.20499319441165165\n",
      "-0.3968172263759986\n",
      "-0.2680275053692309\n",
      "-0.36298223709897326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_ALOT_ohe = LinearRegression()\n",
    "model_ALOT_ohe.fit(pd.concat((clusterdf_train_withClass,clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Adda==1].values)\n",
    "print(r2_score(targets_df_test['Adda'].values, res))\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Lambro_Olona==1].values)\n",
    "print(r2_score(targets_df_test['Lambro_Olona'].values, res))\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Oglio_Iseo==1].values)\n",
    "print(r2_score(targets_df_test['Oglio_Iseo'].values, res))\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Ticino==1].values)\n",
    "print(r2_score(targets_df_test['Ticino'].values, res))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f013ae1",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Adda - Lambro_Olona - Oglio_Iseo - Ticino: CMI best 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "b30215e6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "clust_basins = ['Adda', 'Lambro_Olona', 'Oglio_Iseo', 'Ticino']\n",
    "colnames = [x for x in best5_CMI_fulldf_train.columns if x.startswith('Adda') or x.startswith('Lambro_Olona') or x.startswith('Oglio_Iseo') or x.startswith('Ticino')]\n",
    "\n",
    "clusterdf_train_withClass = pd.DataFrame()\n",
    "clusterdf_val_withClass = pd.DataFrame()\n",
    "clusterdf_test_withClass = pd.DataFrame()\n",
    "\n",
    "for i in range(len(clust_basins)):\n",
    "    clusterdf_train_withClass = pd.concat((clusterdf_train_withClass,pd.concat((best5_CMI_fulldf_train[colnames],pd.DataFrame(1+i*np.ones(len(best5_CMI_fulldf_train)),columns=['basin'])),axis=1)),axis=0)\n",
    "    clusterdf_val_withClass = pd.concat((clusterdf_val_withClass,pd.concat((best5_CMI_fulldf_val[colnames],pd.DataFrame(1+i*np.ones(len(best5_CMI_fulldf_val)),columns=['basin'])),axis=1)),axis=0)\n",
    "    clusterdf_test_withClass = pd.concat((clusterdf_test_withClass,pd.concat((best5_CMI_fulldf_test[colnames],pd.DataFrame(1+i*np.ones(len(best5_CMI_fulldf_test)),columns=['basin'])),axis=1)),axis=0)\n",
    "\n",
    "for i in range(len(clust_basins)):\n",
    "    clusterdf_train_withClass[clust_basins[i]] = clusterdf_train_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    clusterdf_val_withClass[clust_basins[i]] = clusterdf_val_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    clusterdf_test_withClass[clust_basins[i]] = clusterdf_test_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "\n",
    "clusterdf_train_withClass = clusterdf_train_withClass.loc[:,clusterdf_train_withClass.columns != 'basin']\n",
    "clusterdf_val_withClass = clusterdf_val_withClass.loc[:,clusterdf_val_withClass.columns != 'basin']\n",
    "clusterdf_test_withClass = clusterdf_test_withClass.loc[:,clusterdf_test_withClass.columns != 'basin']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "e5d5fc02",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adda_cyclostationary_mean_tg_1w_3</th>\n",
       "      <th>Adda_cyclostationary_mean_rr_12w_1</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_16w_0</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_24w_2</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_24w_0</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_tg_6</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_rr_4w_1</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_tg_0</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_tg_4w_6</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_tg_4w_5</th>\n",
       "      <th>...</th>\n",
       "      <th>Oglio_Iseo_cyclostationary_mean_rr_16w_0</th>\n",
       "      <th>Oglio_Iseo_cyclostationary_mean_rr_8w_0</th>\n",
       "      <th>Oglio_Iseo_cyclostationary_mean_tg_1w_1</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_0</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_4w_0</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_1</th>\n",
       "      <th>Adda</th>\n",
       "      <th>Lambro_Olona</th>\n",
       "      <th>Oglio_Iseo</th>\n",
       "      <th>Ticino</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.862899</td>\n",
       "      <td>1.560382</td>\n",
       "      <td>1.711682</td>\n",
       "      <td>-2.770704</td>\n",
       "      <td>1.914831</td>\n",
       "      <td>-0.044884</td>\n",
       "      <td>1.663515</td>\n",
       "      <td>-0.277460</td>\n",
       "      <td>-0.075383</td>\n",
       "      <td>-0.156545</td>\n",
       "      <td>...</td>\n",
       "      <td>3.151206</td>\n",
       "      <td>2.453362</td>\n",
       "      <td>0.354242</td>\n",
       "      <td>-0.432799</td>\n",
       "      <td>0.611605</td>\n",
       "      <td>-0.442197</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.093639</td>\n",
       "      <td>5.036114</td>\n",
       "      <td>2.547788</td>\n",
       "      <td>-0.879312</td>\n",
       "      <td>2.856614</td>\n",
       "      <td>1.221277</td>\n",
       "      <td>2.277544</td>\n",
       "      <td>0.841342</td>\n",
       "      <td>0.882621</td>\n",
       "      <td>0.761360</td>\n",
       "      <td>...</td>\n",
       "      <td>4.248395</td>\n",
       "      <td>3.334410</td>\n",
       "      <td>0.814679</td>\n",
       "      <td>0.776085</td>\n",
       "      <td>1.691336</td>\n",
       "      <td>0.807518</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.524505</td>\n",
       "      <td>3.177144</td>\n",
       "      <td>1.634451</td>\n",
       "      <td>-2.052028</td>\n",
       "      <td>1.827839</td>\n",
       "      <td>-0.221646</td>\n",
       "      <td>1.355767</td>\n",
       "      <td>-0.526335</td>\n",
       "      <td>0.474126</td>\n",
       "      <td>0.269224</td>\n",
       "      <td>...</td>\n",
       "      <td>2.790351</td>\n",
       "      <td>2.198281</td>\n",
       "      <td>0.209296</td>\n",
       "      <td>-0.906320</td>\n",
       "      <td>0.832271</td>\n",
       "      <td>-1.081813</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.666293</td>\n",
       "      <td>3.205993</td>\n",
       "      <td>1.836713</td>\n",
       "      <td>-1.425685</td>\n",
       "      <td>2.055666</td>\n",
       "      <td>0.723165</td>\n",
       "      <td>1.429576</td>\n",
       "      <td>0.512276</td>\n",
       "      <td>0.627310</td>\n",
       "      <td>0.468910</td>\n",
       "      <td>...</td>\n",
       "      <td>2.608805</td>\n",
       "      <td>2.057737</td>\n",
       "      <td>-0.056410</td>\n",
       "      <td>0.529173</td>\n",
       "      <td>0.859041</td>\n",
       "      <td>0.324392</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.416695</td>\n",
       "      <td>2.498195</td>\n",
       "      <td>1.795310</td>\n",
       "      <td>-1.994518</td>\n",
       "      <td>2.009029</td>\n",
       "      <td>-0.122716</td>\n",
       "      <td>0.994844</td>\n",
       "      <td>-0.056656</td>\n",
       "      <td>0.463215</td>\n",
       "      <td>0.444387</td>\n",
       "      <td>...</td>\n",
       "      <td>1.808583</td>\n",
       "      <td>1.435161</td>\n",
       "      <td>0.188935</td>\n",
       "      <td>-0.687667</td>\n",
       "      <td>0.647203</td>\n",
       "      <td>-0.553079</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>1.568770</td>\n",
       "      <td>-1.467261</td>\n",
       "      <td>0.783570</td>\n",
       "      <td>1.524212</td>\n",
       "      <td>0.639345</td>\n",
       "      <td>1.014590</td>\n",
       "      <td>-1.098764</td>\n",
       "      <td>1.296972</td>\n",
       "      <td>-0.144871</td>\n",
       "      <td>0.565375</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.033965</td>\n",
       "      <td>-0.632957</td>\n",
       "      <td>1.178621</td>\n",
       "      <td>1.481505</td>\n",
       "      <td>-1.023397</td>\n",
       "      <td>1.527659</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>0.812306</td>\n",
       "      <td>-0.715887</td>\n",
       "      <td>0.868596</td>\n",
       "      <td>1.477729</td>\n",
       "      <td>0.671680</td>\n",
       "      <td>0.250478</td>\n",
       "      <td>-0.476556</td>\n",
       "      <td>0.495148</td>\n",
       "      <td>0.358805</td>\n",
       "      <td>1.260203</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.789153</td>\n",
       "      <td>-0.636576</td>\n",
       "      <td>0.874900</td>\n",
       "      <td>0.121450</td>\n",
       "      <td>-0.154876</td>\n",
       "      <td>0.019115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.876968</td>\n",
       "      <td>-0.558495</td>\n",
       "      <td>0.899390</td>\n",
       "      <td>1.352693</td>\n",
       "      <td>0.504706</td>\n",
       "      <td>0.305326</td>\n",
       "      <td>-0.152527</td>\n",
       "      <td>0.445862</td>\n",
       "      <td>0.439528</td>\n",
       "      <td>1.444956</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.735744</td>\n",
       "      <td>-0.408722</td>\n",
       "      <td>0.552941</td>\n",
       "      <td>0.865426</td>\n",
       "      <td>0.083449</td>\n",
       "      <td>1.039841</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>-0.723696</td>\n",
       "      <td>-0.626439</td>\n",
       "      <td>0.725991</td>\n",
       "      <td>1.102009</td>\n",
       "      <td>0.391753</td>\n",
       "      <td>-1.995198</td>\n",
       "      <td>-0.192534</td>\n",
       "      <td>-1.610957</td>\n",
       "      <td>0.109550</td>\n",
       "      <td>1.067782</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.704928</td>\n",
       "      <td>-0.283893</td>\n",
       "      <td>-0.656226</td>\n",
       "      <td>-2.359776</td>\n",
       "      <td>0.001375</td>\n",
       "      <td>-2.580108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-1.413870</td>\n",
       "      <td>-0.338666</td>\n",
       "      <td>0.604737</td>\n",
       "      <td>1.186923</td>\n",
       "      <td>0.312637</td>\n",
       "      <td>-0.591923</td>\n",
       "      <td>0.302357</td>\n",
       "      <td>-0.580276</td>\n",
       "      <td>-0.315172</td>\n",
       "      <td>0.501525</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.545666</td>\n",
       "      <td>-0.159524</td>\n",
       "      <td>-1.042254</td>\n",
       "      <td>0.061748</td>\n",
       "      <td>0.518063</td>\n",
       "      <td>-0.183864</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1644 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Adda_cyclostationary_mean_tg_1w_3  Adda_cyclostationary_mean_rr_12w_1  \\\n",
       "0                            -0.862899                            1.560382   \n",
       "1                            -0.093639                            5.036114   \n",
       "2                            -0.524505                            3.177144   \n",
       "3                            -0.666293                            3.205993   \n",
       "4                            -0.416695                            2.498195   \n",
       "..                                 ...                                 ...   \n",
       "406                           1.568770                           -1.467261   \n",
       "407                           0.812306                           -0.715887   \n",
       "408                           0.876968                           -0.558495   \n",
       "409                          -0.723696                           -0.626439   \n",
       "410                          -1.413870                           -0.338666   \n",
       "\n",
       "     Adda_cyclostationary_mean_tg_16w_0  Adda_cyclostationary_mean_tg_24w_2  \\\n",
       "0                              1.711682                           -2.770704   \n",
       "1                              2.547788                           -0.879312   \n",
       "2                              1.634451                           -2.052028   \n",
       "3                              1.836713                           -1.425685   \n",
       "4                              1.795310                           -1.994518   \n",
       "..                                  ...                                 ...   \n",
       "406                            0.783570                            1.524212   \n",
       "407                            0.868596                            1.477729   \n",
       "408                            0.899390                            1.352693   \n",
       "409                            0.725991                            1.102009   \n",
       "410                            0.604737                            1.186923   \n",
       "\n",
       "     Adda_cyclostationary_mean_tg_24w_0  \\\n",
       "0                              1.914831   \n",
       "1                              2.856614   \n",
       "2                              1.827839   \n",
       "3                              2.055666   \n",
       "4                              2.009029   \n",
       "..                                  ...   \n",
       "406                            0.639345   \n",
       "407                            0.671680   \n",
       "408                            0.504706   \n",
       "409                            0.391753   \n",
       "410                            0.312637   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_tg_6  \\\n",
       "0                                 -0.044884   \n",
       "1                                  1.221277   \n",
       "2                                 -0.221646   \n",
       "3                                  0.723165   \n",
       "4                                 -0.122716   \n",
       "..                                      ...   \n",
       "406                                1.014590   \n",
       "407                                0.250478   \n",
       "408                                0.305326   \n",
       "409                               -1.995198   \n",
       "410                               -0.591923   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_rr_4w_1  \\\n",
       "0                                     1.663515   \n",
       "1                                     2.277544   \n",
       "2                                     1.355767   \n",
       "3                                     1.429576   \n",
       "4                                     0.994844   \n",
       "..                                         ...   \n",
       "406                                  -1.098764   \n",
       "407                                  -0.476556   \n",
       "408                                  -0.152527   \n",
       "409                                  -0.192534   \n",
       "410                                   0.302357   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_tg_0  \\\n",
       "0                                 -0.277460   \n",
       "1                                  0.841342   \n",
       "2                                 -0.526335   \n",
       "3                                  0.512276   \n",
       "4                                 -0.056656   \n",
       "..                                      ...   \n",
       "406                                1.296972   \n",
       "407                                0.495148   \n",
       "408                                0.445862   \n",
       "409                               -1.610957   \n",
       "410                               -0.580276   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_tg_4w_6  \\\n",
       "0                                    -0.075383   \n",
       "1                                     0.882621   \n",
       "2                                     0.474126   \n",
       "3                                     0.627310   \n",
       "4                                     0.463215   \n",
       "..                                         ...   \n",
       "406                                  -0.144871   \n",
       "407                                   0.358805   \n",
       "408                                   0.439528   \n",
       "409                                   0.109550   \n",
       "410                                  -0.315172   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_tg_4w_5  ...  \\\n",
       "0                                    -0.156545  ...   \n",
       "1                                     0.761360  ...   \n",
       "2                                     0.269224  ...   \n",
       "3                                     0.468910  ...   \n",
       "4                                     0.444387  ...   \n",
       "..                                         ...  ...   \n",
       "406                                   0.565375  ...   \n",
       "407                                   1.260203  ...   \n",
       "408                                   1.444956  ...   \n",
       "409                                   1.067782  ...   \n",
       "410                                   0.501525  ...   \n",
       "\n",
       "     Oglio_Iseo_cyclostationary_mean_rr_16w_0  \\\n",
       "0                                    3.151206   \n",
       "1                                    4.248395   \n",
       "2                                    2.790351   \n",
       "3                                    2.608805   \n",
       "4                                    1.808583   \n",
       "..                                        ...   \n",
       "406                                 -1.033965   \n",
       "407                                 -0.789153   \n",
       "408                                 -0.735744   \n",
       "409                                 -0.704928   \n",
       "410                                 -0.545666   \n",
       "\n",
       "     Oglio_Iseo_cyclostationary_mean_rr_8w_0  \\\n",
       "0                                   2.453362   \n",
       "1                                   3.334410   \n",
       "2                                   2.198281   \n",
       "3                                   2.057737   \n",
       "4                                   1.435161   \n",
       "..                                       ...   \n",
       "406                                -0.632957   \n",
       "407                                -0.636576   \n",
       "408                                -0.408722   \n",
       "409                                -0.283893   \n",
       "410                                -0.159524   \n",
       "\n",
       "     Oglio_Iseo_cyclostationary_mean_tg_1w_1  \\\n",
       "0                                   0.354242   \n",
       "1                                   0.814679   \n",
       "2                                   0.209296   \n",
       "3                                  -0.056410   \n",
       "4                                   0.188935   \n",
       "..                                       ...   \n",
       "406                                 1.178621   \n",
       "407                                 0.874900   \n",
       "408                                 0.552941   \n",
       "409                                -0.656226   \n",
       "410                                -1.042254   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_0  Ticino_cyclostationary_mean_rr_4w_0  \\\n",
       "0                           -0.432799                             0.611605   \n",
       "1                            0.776085                             1.691336   \n",
       "2                           -0.906320                             0.832271   \n",
       "3                            0.529173                             0.859041   \n",
       "4                           -0.687667                             0.647203   \n",
       "..                                ...                                  ...   \n",
       "406                          1.481505                            -1.023397   \n",
       "407                          0.121450                            -0.154876   \n",
       "408                          0.865426                             0.083449   \n",
       "409                         -2.359776                             0.001375   \n",
       "410                          0.061748                             0.518063   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_1  Adda  Lambro_Olona  Oglio_Iseo  Ticino  \n",
       "0                           -0.442197     1             0           0       0  \n",
       "1                            0.807518     1             0           0       0  \n",
       "2                           -1.081813     1             0           0       0  \n",
       "3                            0.324392     1             0           0       0  \n",
       "4                           -0.553079     1             0           0       0  \n",
       "..                                ...   ...           ...         ...     ...  \n",
       "406                          1.527659     0             0           0       1  \n",
       "407                          0.019115     0             0           0       1  \n",
       "408                          1.039841     0             0           0       1  \n",
       "409                         -2.580108     0             0           0       1  \n",
       "410                         -0.183864     0             0           0       1  \n",
       "\n",
       "[1644 rows x 22 columns]"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterdf_train_withClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "af11e481",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "targets_df_train_unfolded = pd.DataFrame()\n",
    "targets_df_val_unfolded = pd.DataFrame()\n",
    "targets_df_test_unfolded = pd.DataFrame()\n",
    "\n",
    "for basin in clust_basins:\n",
    "    targets_df_train_unfolded =  pd.concat((targets_df_train_unfolded,targets_df_train[basin]),axis=0)\n",
    "    targets_df_val_unfolded =  pd.concat((targets_df_val_unfolded,targets_df_val[basin]),axis=0)\n",
    "    targets_df_test_unfolded =  pd.concat((targets_df_test_unfolded,targets_df_test[basin]),axis=0)\n",
    "targets_df_train_unfolded = targets_df_train_unfolded.reset_index(drop=True)\n",
    "targets_df_val_unfolded = targets_df_val_unfolded.reset_index(drop=True)\n",
    "targets_df_test_unfolded = targets_df_test_unfolded.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "edae7c73",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.546951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.277191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.534156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.666789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.447894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1639</th>\n",
       "      <td>-0.563495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1640</th>\n",
       "      <td>-0.291984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1641</th>\n",
       "      <td>0.770822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1642</th>\n",
       "      <td>-0.412164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643</th>\n",
       "      <td>-1.081585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1644 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0    -2.546951\n",
       "1    -0.277191\n",
       "2    -0.534156\n",
       "3    -0.666789\n",
       "4    -0.447894\n",
       "...        ...\n",
       "1639 -0.563495\n",
       "1640 -0.291984\n",
       "1641  0.770822\n",
       "1642 -0.412164\n",
       "1643 -1.081585\n",
       "\n",
       "[1644 rows x 1 columns]"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_df_train_unfolded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "b12d3a9c",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28265025081716755\n",
      "0.2624219499639573\n",
      "0.2676768314882756\n",
      "0.3019320480057843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_ALOT_ohe = LinearRegression()\n",
    "model_ALOT_ohe.fit(pd.concat((clusterdf_train_withClass,clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Adda==1].values)\n",
    "print(r2_score(targets_df_test['Adda'].values, res))\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Lambro_Olona==1].values)\n",
    "print(r2_score(targets_df_test['Lambro_Olona'].values, res))\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Oglio_Iseo==1].values)\n",
    "print(r2_score(targets_df_test['Oglio_Iseo'].values, res))\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Ticino==1].values)\n",
    "print(r2_score(targets_df_test['Ticino'].values, res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "f6c0346f",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2d0ac0340>]"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(res, color='blue')\n",
    "plt.plot(targets_df_test['Ticino'].values, color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a90367",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5b1be5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "6f472b36",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adda_cyclostationary_mean_tg_1w_3</th>\n",
       "      <th>Adda_cyclostationary_mean_rr_12w_1</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_16w_0</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_24w_2</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_24w_0</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_tg_6</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_rr_4w_1</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_tg_0</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_tg_4w_6</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_tg_4w_5</th>\n",
       "      <th>...</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_0_Oglio_Iseo</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_0_Ticino</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_4w_0_Adda</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_4w_0_Lambro_Olona</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_4w_0_Oglio_Iseo</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_4w_0_Ticino</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_1_Adda</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_1_Lambro_Olona</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_1_Oglio_Iseo</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_1_Ticino</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.862899</td>\n",
       "      <td>1.560382</td>\n",
       "      <td>1.711682</td>\n",
       "      <td>-2.770704</td>\n",
       "      <td>1.914831</td>\n",
       "      <td>-0.044884</td>\n",
       "      <td>1.663515</td>\n",
       "      <td>-0.277460</td>\n",
       "      <td>-0.075383</td>\n",
       "      <td>-0.156545</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.611605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.442197</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.093639</td>\n",
       "      <td>5.036114</td>\n",
       "      <td>2.547788</td>\n",
       "      <td>-0.879312</td>\n",
       "      <td>2.856614</td>\n",
       "      <td>1.221277</td>\n",
       "      <td>2.277544</td>\n",
       "      <td>0.841342</td>\n",
       "      <td>0.882621</td>\n",
       "      <td>0.761360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.691336</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.807518</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.524505</td>\n",
       "      <td>3.177144</td>\n",
       "      <td>1.634451</td>\n",
       "      <td>-2.052028</td>\n",
       "      <td>1.827839</td>\n",
       "      <td>-0.221646</td>\n",
       "      <td>1.355767</td>\n",
       "      <td>-0.526335</td>\n",
       "      <td>0.474126</td>\n",
       "      <td>0.269224</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.832271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.081813</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.666293</td>\n",
       "      <td>3.205993</td>\n",
       "      <td>1.836713</td>\n",
       "      <td>-1.425685</td>\n",
       "      <td>2.055666</td>\n",
       "      <td>0.723165</td>\n",
       "      <td>1.429576</td>\n",
       "      <td>0.512276</td>\n",
       "      <td>0.627310</td>\n",
       "      <td>0.468910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.859041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.324392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.416695</td>\n",
       "      <td>2.498195</td>\n",
       "      <td>1.795310</td>\n",
       "      <td>-1.994518</td>\n",
       "      <td>2.009029</td>\n",
       "      <td>-0.122716</td>\n",
       "      <td>0.994844</td>\n",
       "      <td>-0.056656</td>\n",
       "      <td>0.463215</td>\n",
       "      <td>0.444387</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.647203</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.553079</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>1.568770</td>\n",
       "      <td>-1.467261</td>\n",
       "      <td>0.783570</td>\n",
       "      <td>1.524212</td>\n",
       "      <td>0.639345</td>\n",
       "      <td>1.014590</td>\n",
       "      <td>-1.098764</td>\n",
       "      <td>1.296972</td>\n",
       "      <td>-0.144871</td>\n",
       "      <td>0.565375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.481505</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-1.023397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.527659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>0.812306</td>\n",
       "      <td>-0.715887</td>\n",
       "      <td>0.868596</td>\n",
       "      <td>1.477729</td>\n",
       "      <td>0.671680</td>\n",
       "      <td>0.250478</td>\n",
       "      <td>-0.476556</td>\n",
       "      <td>0.495148</td>\n",
       "      <td>0.358805</td>\n",
       "      <td>1.260203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.121450</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.154876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.876968</td>\n",
       "      <td>-0.558495</td>\n",
       "      <td>0.899390</td>\n",
       "      <td>1.352693</td>\n",
       "      <td>0.504706</td>\n",
       "      <td>0.305326</td>\n",
       "      <td>-0.152527</td>\n",
       "      <td>0.445862</td>\n",
       "      <td>0.439528</td>\n",
       "      <td>1.444956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.865426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083449</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.039841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>-0.723696</td>\n",
       "      <td>-0.626439</td>\n",
       "      <td>0.725991</td>\n",
       "      <td>1.102009</td>\n",
       "      <td>0.391753</td>\n",
       "      <td>-1.995198</td>\n",
       "      <td>-0.192534</td>\n",
       "      <td>-1.610957</td>\n",
       "      <td>0.109550</td>\n",
       "      <td>1.067782</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-2.359776</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001375</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-2.580108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-1.413870</td>\n",
       "      <td>-0.338666</td>\n",
       "      <td>0.604737</td>\n",
       "      <td>1.186923</td>\n",
       "      <td>0.312637</td>\n",
       "      <td>-0.591923</td>\n",
       "      <td>0.302357</td>\n",
       "      <td>-0.580276</td>\n",
       "      <td>-0.315172</td>\n",
       "      <td>0.501525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.061748</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.518063</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.183864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1644 rows × 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Adda_cyclostationary_mean_tg_1w_3  Adda_cyclostationary_mean_rr_12w_1  \\\n",
       "0                            -0.862899                            1.560382   \n",
       "1                            -0.093639                            5.036114   \n",
       "2                            -0.524505                            3.177144   \n",
       "3                            -0.666293                            3.205993   \n",
       "4                            -0.416695                            2.498195   \n",
       "..                                 ...                                 ...   \n",
       "406                           1.568770                           -1.467261   \n",
       "407                           0.812306                           -0.715887   \n",
       "408                           0.876968                           -0.558495   \n",
       "409                          -0.723696                           -0.626439   \n",
       "410                          -1.413870                           -0.338666   \n",
       "\n",
       "     Adda_cyclostationary_mean_tg_16w_0  Adda_cyclostationary_mean_tg_24w_2  \\\n",
       "0                              1.711682                           -2.770704   \n",
       "1                              2.547788                           -0.879312   \n",
       "2                              1.634451                           -2.052028   \n",
       "3                              1.836713                           -1.425685   \n",
       "4                              1.795310                           -1.994518   \n",
       "..                                  ...                                 ...   \n",
       "406                            0.783570                            1.524212   \n",
       "407                            0.868596                            1.477729   \n",
       "408                            0.899390                            1.352693   \n",
       "409                            0.725991                            1.102009   \n",
       "410                            0.604737                            1.186923   \n",
       "\n",
       "     Adda_cyclostationary_mean_tg_24w_0  \\\n",
       "0                              1.914831   \n",
       "1                              2.856614   \n",
       "2                              1.827839   \n",
       "3                              2.055666   \n",
       "4                              2.009029   \n",
       "..                                  ...   \n",
       "406                            0.639345   \n",
       "407                            0.671680   \n",
       "408                            0.504706   \n",
       "409                            0.391753   \n",
       "410                            0.312637   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_tg_6  \\\n",
       "0                                 -0.044884   \n",
       "1                                  1.221277   \n",
       "2                                 -0.221646   \n",
       "3                                  0.723165   \n",
       "4                                 -0.122716   \n",
       "..                                      ...   \n",
       "406                                1.014590   \n",
       "407                                0.250478   \n",
       "408                                0.305326   \n",
       "409                               -1.995198   \n",
       "410                               -0.591923   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_rr_4w_1  \\\n",
       "0                                     1.663515   \n",
       "1                                     2.277544   \n",
       "2                                     1.355767   \n",
       "3                                     1.429576   \n",
       "4                                     0.994844   \n",
       "..                                         ...   \n",
       "406                                  -1.098764   \n",
       "407                                  -0.476556   \n",
       "408                                  -0.152527   \n",
       "409                                  -0.192534   \n",
       "410                                   0.302357   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_tg_0  \\\n",
       "0                                 -0.277460   \n",
       "1                                  0.841342   \n",
       "2                                 -0.526335   \n",
       "3                                  0.512276   \n",
       "4                                 -0.056656   \n",
       "..                                      ...   \n",
       "406                                1.296972   \n",
       "407                                0.495148   \n",
       "408                                0.445862   \n",
       "409                               -1.610957   \n",
       "410                               -0.580276   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_tg_4w_6  \\\n",
       "0                                    -0.075383   \n",
       "1                                     0.882621   \n",
       "2                                     0.474126   \n",
       "3                                     0.627310   \n",
       "4                                     0.463215   \n",
       "..                                         ...   \n",
       "406                                  -0.144871   \n",
       "407                                   0.358805   \n",
       "408                                   0.439528   \n",
       "409                                   0.109550   \n",
       "410                                  -0.315172   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_tg_4w_5  ...  \\\n",
       "0                                    -0.156545  ...   \n",
       "1                                     0.761360  ...   \n",
       "2                                     0.269224  ...   \n",
       "3                                     0.468910  ...   \n",
       "4                                     0.444387  ...   \n",
       "..                                         ...  ...   \n",
       "406                                   0.565375  ...   \n",
       "407                                   1.260203  ...   \n",
       "408                                   1.444956  ...   \n",
       "409                                   1.067782  ...   \n",
       "410                                   0.501525  ...   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_0_Oglio_Iseo  \\\n",
       "0                                           -0.0   \n",
       "1                                            0.0   \n",
       "2                                           -0.0   \n",
       "3                                            0.0   \n",
       "4                                           -0.0   \n",
       "..                                           ...   \n",
       "406                                          0.0   \n",
       "407                                          0.0   \n",
       "408                                          0.0   \n",
       "409                                         -0.0   \n",
       "410                                          0.0   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_0_Ticino  \\\n",
       "0                                  -0.000000   \n",
       "1                                   0.000000   \n",
       "2                                  -0.000000   \n",
       "3                                   0.000000   \n",
       "4                                  -0.000000   \n",
       "..                                       ...   \n",
       "406                                 1.481505   \n",
       "407                                 0.121450   \n",
       "408                                 0.865426   \n",
       "409                                -2.359776   \n",
       "410                                 0.061748   \n",
       "\n",
       "     Ticino_cyclostationary_mean_rr_4w_0_Adda  \\\n",
       "0                                    0.611605   \n",
       "1                                    1.691336   \n",
       "2                                    0.832271   \n",
       "3                                    0.859041   \n",
       "4                                    0.647203   \n",
       "..                                        ...   \n",
       "406                                 -0.000000   \n",
       "407                                 -0.000000   \n",
       "408                                  0.000000   \n",
       "409                                  0.000000   \n",
       "410                                  0.000000   \n",
       "\n",
       "     Ticino_cyclostationary_mean_rr_4w_0_Lambro_Olona  \\\n",
       "0                                                 0.0   \n",
       "1                                                 0.0   \n",
       "2                                                 0.0   \n",
       "3                                                 0.0   \n",
       "4                                                 0.0   \n",
       "..                                                ...   \n",
       "406                                              -0.0   \n",
       "407                                              -0.0   \n",
       "408                                               0.0   \n",
       "409                                               0.0   \n",
       "410                                               0.0   \n",
       "\n",
       "     Ticino_cyclostationary_mean_rr_4w_0_Oglio_Iseo  \\\n",
       "0                                               0.0   \n",
       "1                                               0.0   \n",
       "2                                               0.0   \n",
       "3                                               0.0   \n",
       "4                                               0.0   \n",
       "..                                              ...   \n",
       "406                                            -0.0   \n",
       "407                                            -0.0   \n",
       "408                                             0.0   \n",
       "409                                             0.0   \n",
       "410                                             0.0   \n",
       "\n",
       "     Ticino_cyclostationary_mean_rr_4w_0_Ticino  \\\n",
       "0                                      0.000000   \n",
       "1                                      0.000000   \n",
       "2                                      0.000000   \n",
       "3                                      0.000000   \n",
       "4                                      0.000000   \n",
       "..                                          ...   \n",
       "406                                   -1.023397   \n",
       "407                                   -0.154876   \n",
       "408                                    0.083449   \n",
       "409                                    0.001375   \n",
       "410                                    0.518063   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_1_Adda  \\\n",
       "0                                -0.442197   \n",
       "1                                 0.807518   \n",
       "2                                -1.081813   \n",
       "3                                 0.324392   \n",
       "4                                -0.553079   \n",
       "..                                     ...   \n",
       "406                               0.000000   \n",
       "407                               0.000000   \n",
       "408                               0.000000   \n",
       "409                              -0.000000   \n",
       "410                              -0.000000   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_1_Lambro_Olona  \\\n",
       "0                                             -0.0   \n",
       "1                                              0.0   \n",
       "2                                             -0.0   \n",
       "3                                              0.0   \n",
       "4                                             -0.0   \n",
       "..                                             ...   \n",
       "406                                            0.0   \n",
       "407                                            0.0   \n",
       "408                                            0.0   \n",
       "409                                           -0.0   \n",
       "410                                           -0.0   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_1_Oglio_Iseo  \\\n",
       "0                                           -0.0   \n",
       "1                                            0.0   \n",
       "2                                           -0.0   \n",
       "3                                            0.0   \n",
       "4                                           -0.0   \n",
       "..                                           ...   \n",
       "406                                          0.0   \n",
       "407                                          0.0   \n",
       "408                                          0.0   \n",
       "409                                         -0.0   \n",
       "410                                         -0.0   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_1_Ticino  \n",
       "0                                  -0.000000  \n",
       "1                                   0.000000  \n",
       "2                                  -0.000000  \n",
       "3                                   0.000000  \n",
       "4                                  -0.000000  \n",
       "..                                       ...  \n",
       "406                                 1.527659  \n",
       "407                                 0.019115  \n",
       "408                                 1.039841  \n",
       "409                                -2.580108  \n",
       "410                                -0.183864  \n",
       "\n",
       "[1644 rows x 94 columns]"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(clusterdf_train_withClass.shape[1]-len(clust_basins)):\n",
    "    for j in clust_basins:\n",
    "        clusterdf_train_withClass[clusterdf_train_withClass.columns[i]+'_'+j] = clusterdf_train_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "        clusterdf_val_withClass[clusterdf_val_withClass.columns[i]+'_'+j] = clusterdf_val_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "        clusterdf_test_withClass[clusterdf_test_withClass.columns[i]+'_'+j] = clusterdf_test_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "\n",
    "clusterdf_train_withClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "86504764",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2934203975293319\n",
      "0.26426191622064354\n",
      "0.15121968885589177\n",
      "0.2495948097547407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_ALOT_ohe = LinearRegression()\n",
    "model_ALOT_ohe.fit(pd.concat((clusterdf_train_withClass,clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Adda==1].values)\n",
    "print(r2_score(targets_df_test['Adda'].values, res))\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Lambro_Olona==1].values)\n",
    "print(r2_score(targets_df_test['Lambro_Olona'].values, res))\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Oglio_Iseo==1].values)\n",
    "print(r2_score(targets_df_test['Oglio_Iseo'].values, res))\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Ticino==1].values)\n",
    "print(r2_score(targets_df_test['Ticino'].values, res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05da958f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49292d66",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Dora - Piemonte_Nord - Piemonte_Sud: wrapper best 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "792d7635",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "clust_basins = ['Dora', 'Piemonte_Nord', 'Piemonte_Sud']\n",
    "colnames = [x for x in best5_wrapper_fulldf_train.columns if x.startswith('Dora') or x.startswith('Piemonte_Nord') or x.startswith('Piemonte_Sud')]\n",
    "\n",
    "best5_wrapper_clusterdf_train_withClass = pd.DataFrame()\n",
    "best5_wrapper_clusterdf_val_withClass = pd.DataFrame()\n",
    "best5_wrapper_clusterdf_test_withClass = pd.DataFrame()\n",
    "\n",
    "for i in range(len(clust_basins)):\n",
    "    best5_wrapper_clusterdf_train_withClass = pd.concat((best5_wrapper_clusterdf_train_withClass,pd.concat((best5_wrapper_fulldf_train[colnames],pd.DataFrame(1+i*np.ones(len(best5_wrapper_fulldf_train)),columns=['basin'])),axis=1)),axis=0)\n",
    "    best5_wrapper_clusterdf_val_withClass = pd.concat((best5_wrapper_clusterdf_val_withClass,pd.concat((best5_wrapper_fulldf_val[colnames],pd.DataFrame(1+i*np.ones(len(best5_wrapper_fulldf_val)),columns=['basin'])),axis=1)),axis=0)\n",
    "    best5_wrapper_clusterdf_test_withClass = pd.concat((best5_wrapper_clusterdf_test_withClass,pd.concat((best5_wrapper_fulldf_test[colnames],pd.DataFrame(1+i*np.ones(len(best5_wrapper_fulldf_test)),columns=['basin'])),axis=1)),axis=0)\n",
    "\n",
    "for i in range(len(clust_basins)):\n",
    "    best5_wrapper_clusterdf_train_withClass[clust_basins[i]] = best5_wrapper_clusterdf_train_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    best5_wrapper_clusterdf_val_withClass[clust_basins[i]] = best5_wrapper_clusterdf_val_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    best5_wrapper_clusterdf_test_withClass[clust_basins[i]] = best5_wrapper_clusterdf_test_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "\n",
    "best5_wrapper_clusterdf_train_withClass = best5_wrapper_clusterdf_train_withClass.loc[:,best5_wrapper_clusterdf_train_withClass.columns != 'basin']\n",
    "best5_wrapper_clusterdf_val_withClass = best5_wrapper_clusterdf_val_withClass.loc[:,best5_wrapper_clusterdf_val_withClass.columns != 'basin']\n",
    "best5_wrapper_clusterdf_test_withClass = best5_wrapper_clusterdf_test_withClass.loc[:,best5_wrapper_clusterdf_test_withClass.columns != 'basin']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "3647d125",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dora_cyclostationary_mean_tg_1w_0</th>\n",
       "      <th>Dora_cyclostationary_mean_rr_4w_1</th>\n",
       "      <th>Dora_cyclostationary_mean_tg_1w_2</th>\n",
       "      <th>Dora_cyclostationary_mean_tg_4w_1</th>\n",
       "      <th>Dora_cyclostationary_mean_tg_4w_0</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_1w_3</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_rr_4w_0</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_rr_24w_0</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_24w_0</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_24w_1</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_tg_2</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_24w_1</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_1w_4</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_16w_1</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_16w_2</th>\n",
       "      <th>Dora</th>\n",
       "      <th>Piemonte_Nord</th>\n",
       "      <th>Piemonte_Sud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.858428</td>\n",
       "      <td>0.569944</td>\n",
       "      <td>-0.645734</td>\n",
       "      <td>-0.958059</td>\n",
       "      <td>-1.179177</td>\n",
       "      <td>-0.705198</td>\n",
       "      <td>0.531161</td>\n",
       "      <td>0.993156</td>\n",
       "      <td>-1.444933</td>\n",
       "      <td>-1.056852</td>\n",
       "      <td>-0.374151</td>\n",
       "      <td>1.722357</td>\n",
       "      <td>0.566795</td>\n",
       "      <td>5.503456</td>\n",
       "      <td>3.450706</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.144075</td>\n",
       "      <td>2.777501</td>\n",
       "      <td>-0.040254</td>\n",
       "      <td>0.064877</td>\n",
       "      <td>-0.154668</td>\n",
       "      <td>-0.040533</td>\n",
       "      <td>1.141736</td>\n",
       "      <td>2.145937</td>\n",
       "      <td>0.399738</td>\n",
       "      <td>0.702337</td>\n",
       "      <td>0.845319</td>\n",
       "      <td>2.568972</td>\n",
       "      <td>1.162632</td>\n",
       "      <td>5.284243</td>\n",
       "      <td>3.406378</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.543433</td>\n",
       "      <td>1.425829</td>\n",
       "      <td>-0.727940</td>\n",
       "      <td>-1.002116</td>\n",
       "      <td>-0.919496</td>\n",
       "      <td>-0.312340</td>\n",
       "      <td>0.600533</td>\n",
       "      <td>1.115539</td>\n",
       "      <td>-0.862634</td>\n",
       "      <td>-0.363026</td>\n",
       "      <td>-1.069465</td>\n",
       "      <td>1.502423</td>\n",
       "      <td>0.501665</td>\n",
       "      <td>3.124173</td>\n",
       "      <td>1.751610</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.723360</td>\n",
       "      <td>1.785519</td>\n",
       "      <td>-0.924722</td>\n",
       "      <td>-0.601101</td>\n",
       "      <td>-0.594848</td>\n",
       "      <td>-0.434823</td>\n",
       "      <td>0.613627</td>\n",
       "      <td>1.140701</td>\n",
       "      <td>0.012866</td>\n",
       "      <td>0.053932</td>\n",
       "      <td>0.510716</td>\n",
       "      <td>1.463618</td>\n",
       "      <td>-0.074694</td>\n",
       "      <td>2.734133</td>\n",
       "      <td>1.878484</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.540293</td>\n",
       "      <td>1.524603</td>\n",
       "      <td>-0.569035</td>\n",
       "      <td>-0.789653</td>\n",
       "      <td>-0.843317</td>\n",
       "      <td>-0.286705</td>\n",
       "      <td>0.408259</td>\n",
       "      <td>0.742092</td>\n",
       "      <td>-0.535961</td>\n",
       "      <td>-0.202521</td>\n",
       "      <td>-0.448734</td>\n",
       "      <td>0.854895</td>\n",
       "      <td>0.107268</td>\n",
       "      <td>1.874214</td>\n",
       "      <td>1.117130</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>1.462830</td>\n",
       "      <td>-0.520256</td>\n",
       "      <td>1.585661</td>\n",
       "      <td>0.807565</td>\n",
       "      <td>0.577376</td>\n",
       "      <td>1.346423</td>\n",
       "      <td>-0.938846</td>\n",
       "      <td>-1.118138</td>\n",
       "      <td>1.192105</td>\n",
       "      <td>0.686556</td>\n",
       "      <td>1.056166</td>\n",
       "      <td>-1.165656</td>\n",
       "      <td>-0.617574</td>\n",
       "      <td>-0.419856</td>\n",
       "      <td>0.118142</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>0.599620</td>\n",
       "      <td>-0.530550</td>\n",
       "      <td>0.724000</td>\n",
       "      <td>1.020805</td>\n",
       "      <td>0.776516</td>\n",
       "      <td>0.509539</td>\n",
       "      <td>-0.559070</td>\n",
       "      <td>-0.904049</td>\n",
       "      <td>1.080238</td>\n",
       "      <td>0.646899</td>\n",
       "      <td>0.308611</td>\n",
       "      <td>-0.855699</td>\n",
       "      <td>-0.290505</td>\n",
       "      <td>0.087685</td>\n",
       "      <td>0.753294</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.344849</td>\n",
       "      <td>0.031726</td>\n",
       "      <td>0.422436</td>\n",
       "      <td>0.910086</td>\n",
       "      <td>0.715672</td>\n",
       "      <td>0.236097</td>\n",
       "      <td>-0.113738</td>\n",
       "      <td>-0.769506</td>\n",
       "      <td>0.967415</td>\n",
       "      <td>0.491266</td>\n",
       "      <td>0.651470</td>\n",
       "      <td>-0.755765</td>\n",
       "      <td>-0.235027</td>\n",
       "      <td>0.110292</td>\n",
       "      <td>0.728345</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>-1.130239</td>\n",
       "      <td>-0.154282</td>\n",
       "      <td>-1.116372</td>\n",
       "      <td>0.237759</td>\n",
       "      <td>0.083901</td>\n",
       "      <td>-1.353830</td>\n",
       "      <td>-0.253229</td>\n",
       "      <td>-0.635866</td>\n",
       "      <td>0.608651</td>\n",
       "      <td>0.209678</td>\n",
       "      <td>-2.101458</td>\n",
       "      <td>-0.632667</td>\n",
       "      <td>-0.224584</td>\n",
       "      <td>0.111368</td>\n",
       "      <td>0.550634</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-1.598190</td>\n",
       "      <td>0.583732</td>\n",
       "      <td>-1.711036</td>\n",
       "      <td>-0.182408</td>\n",
       "      <td>-0.229108</td>\n",
       "      <td>-1.553763</td>\n",
       "      <td>0.301057</td>\n",
       "      <td>-0.646653</td>\n",
       "      <td>0.748061</td>\n",
       "      <td>0.239362</td>\n",
       "      <td>-0.328858</td>\n",
       "      <td>-0.605880</td>\n",
       "      <td>1.003973</td>\n",
       "      <td>0.582957</td>\n",
       "      <td>0.714648</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1233 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dora_cyclostationary_mean_tg_1w_0  Dora_cyclostationary_mean_rr_4w_1  \\\n",
       "0                            -0.858428                           0.569944   \n",
       "1                            -0.144075                           2.777501   \n",
       "2                            -0.543433                           1.425829   \n",
       "3                            -0.723360                           1.785519   \n",
       "4                            -0.540293                           1.524603   \n",
       "..                                 ...                                ...   \n",
       "406                           1.462830                          -0.520256   \n",
       "407                           0.599620                          -0.530550   \n",
       "408                           0.344849                           0.031726   \n",
       "409                          -1.130239                          -0.154282   \n",
       "410                          -1.598190                           0.583732   \n",
       "\n",
       "     Dora_cyclostationary_mean_tg_1w_2  Dora_cyclostationary_mean_tg_4w_1  \\\n",
       "0                            -0.645734                          -0.958059   \n",
       "1                            -0.040254                           0.064877   \n",
       "2                            -0.727940                          -1.002116   \n",
       "3                            -0.924722                          -0.601101   \n",
       "4                            -0.569035                          -0.789653   \n",
       "..                                 ...                                ...   \n",
       "406                           1.585661                           0.807565   \n",
       "407                           0.724000                           1.020805   \n",
       "408                           0.422436                           0.910086   \n",
       "409                          -1.116372                           0.237759   \n",
       "410                          -1.711036                          -0.182408   \n",
       "\n",
       "     Dora_cyclostationary_mean_tg_4w_0  \\\n",
       "0                            -1.179177   \n",
       "1                            -0.154668   \n",
       "2                            -0.919496   \n",
       "3                            -0.594848   \n",
       "4                            -0.843317   \n",
       "..                                 ...   \n",
       "406                           0.577376   \n",
       "407                           0.776516   \n",
       "408                           0.715672   \n",
       "409                           0.083901   \n",
       "410                          -0.229108   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_1w_3  \\\n",
       "0                                     -0.705198   \n",
       "1                                     -0.040533   \n",
       "2                                     -0.312340   \n",
       "3                                     -0.434823   \n",
       "4                                     -0.286705   \n",
       "..                                          ...   \n",
       "406                                    1.346423   \n",
       "407                                    0.509539   \n",
       "408                                    0.236097   \n",
       "409                                   -1.353830   \n",
       "410                                   -1.553763   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_rr_4w_0  \\\n",
       "0                                      0.531161   \n",
       "1                                      1.141736   \n",
       "2                                      0.600533   \n",
       "3                                      0.613627   \n",
       "4                                      0.408259   \n",
       "..                                          ...   \n",
       "406                                   -0.938846   \n",
       "407                                   -0.559070   \n",
       "408                                   -0.113738   \n",
       "409                                   -0.253229   \n",
       "410                                    0.301057   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_rr_24w_0  \\\n",
       "0                                       0.993156   \n",
       "1                                       2.145937   \n",
       "2                                       1.115539   \n",
       "3                                       1.140701   \n",
       "4                                       0.742092   \n",
       "..                                           ...   \n",
       "406                                    -1.118138   \n",
       "407                                    -0.904049   \n",
       "408                                    -0.769506   \n",
       "409                                    -0.635866   \n",
       "410                                    -0.646653   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_24w_0  \\\n",
       "0                                      -1.444933   \n",
       "1                                       0.399738   \n",
       "2                                      -0.862634   \n",
       "3                                       0.012866   \n",
       "4                                      -0.535961   \n",
       "..                                           ...   \n",
       "406                                     1.192105   \n",
       "407                                     1.080238   \n",
       "408                                     0.967415   \n",
       "409                                     0.608651   \n",
       "410                                     0.748061   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_24w_1  \\\n",
       "0                                      -1.056852   \n",
       "1                                       0.702337   \n",
       "2                                      -0.363026   \n",
       "3                                       0.053932   \n",
       "4                                      -0.202521   \n",
       "..                                           ...   \n",
       "406                                     0.686556   \n",
       "407                                     0.646899   \n",
       "408                                     0.491266   \n",
       "409                                     0.209678   \n",
       "410                                     0.239362   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_tg_2  \\\n",
       "0                                 -0.374151   \n",
       "1                                  0.845319   \n",
       "2                                 -1.069465   \n",
       "3                                  0.510716   \n",
       "4                                 -0.448734   \n",
       "..                                      ...   \n",
       "406                                1.056166   \n",
       "407                                0.308611   \n",
       "408                                0.651470   \n",
       "409                               -2.101458   \n",
       "410                               -0.328858   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_24w_1  \\\n",
       "0                                      1.722357   \n",
       "1                                      2.568972   \n",
       "2                                      1.502423   \n",
       "3                                      1.463618   \n",
       "4                                      0.854895   \n",
       "..                                          ...   \n",
       "406                                   -1.165656   \n",
       "407                                   -0.855699   \n",
       "408                                   -0.755765   \n",
       "409                                   -0.632667   \n",
       "410                                   -0.605880   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_1w_4  \\\n",
       "0                                     0.566795   \n",
       "1                                     1.162632   \n",
       "2                                     0.501665   \n",
       "3                                    -0.074694   \n",
       "4                                     0.107268   \n",
       "..                                         ...   \n",
       "406                                  -0.617574   \n",
       "407                                  -0.290505   \n",
       "408                                  -0.235027   \n",
       "409                                  -0.224584   \n",
       "410                                   1.003973   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_16w_1  \\\n",
       "0                                      5.503456   \n",
       "1                                      5.284243   \n",
       "2                                      3.124173   \n",
       "3                                      2.734133   \n",
       "4                                      1.874214   \n",
       "..                                          ...   \n",
       "406                                   -0.419856   \n",
       "407                                    0.087685   \n",
       "408                                    0.110292   \n",
       "409                                    0.111368   \n",
       "410                                    0.582957   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_16w_2  Dora  Piemonte_Nord  \\\n",
       "0                                      3.450706     1              0   \n",
       "1                                      3.406378     1              0   \n",
       "2                                      1.751610     1              0   \n",
       "3                                      1.878484     1              0   \n",
       "4                                      1.117130     1              0   \n",
       "..                                          ...   ...            ...   \n",
       "406                                    0.118142     0              0   \n",
       "407                                    0.753294     0              0   \n",
       "408                                    0.728345     0              0   \n",
       "409                                    0.550634     0              0   \n",
       "410                                    0.714648     0              0   \n",
       "\n",
       "     Piemonte_Sud  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "..            ...  \n",
       "406             1  \n",
       "407             1  \n",
       "408             1  \n",
       "409             1  \n",
       "410             1  \n",
       "\n",
       "[1233 rows x 18 columns]"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best5_wrapper_clusterdf_train_withClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "5e6bfe28",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "targets_df_train_unfolded = pd.DataFrame()\n",
    "targets_df_val_unfolded = pd.DataFrame()\n",
    "targets_df_test_unfolded = pd.DataFrame()\n",
    "\n",
    "for basin in clust_basins:\n",
    "    targets_df_train_unfolded =  pd.concat((targets_df_train_unfolded,targets_df_train[basin]),axis=0)\n",
    "    targets_df_val_unfolded =  pd.concat((targets_df_val_unfolded,targets_df_val[basin]),axis=0)\n",
    "    targets_df_test_unfolded =  pd.concat((targets_df_test_unfolded,targets_df_test[basin]),axis=0)\n",
    "targets_df_train_unfolded = targets_df_train_unfolded.reset_index(drop=True)\n",
    "targets_df_val_unfolded = targets_df_val_unfolded.reset_index(drop=True)\n",
    "targets_df_test_unfolded = targets_df_test_unfolded.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "51a86a15",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.32287659170495364\n",
      "-0.20871592974219433\n",
      "-0.24715940372280998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_DPNPS_ohe = LinearRegression()\n",
    "model_DPNPS_ohe.fit(pd.concat((best5_wrapper_clusterdf_train_withClass,best5_wrapper_clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_DPNPS_ohe.predict(best5_wrapper_clusterdf_test_withClass.loc[best5_wrapper_clusterdf_test_withClass.Dora==1].values)\n",
    "print(r2_score(targets_df_test['Dora'].values, res))\n",
    "res = model_DPNPS_ohe.predict(best5_wrapper_clusterdf_test_withClass.loc[best5_wrapper_clusterdf_test_withClass.Piemonte_Nord==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Nord'].values, res))\n",
    "res = model_DPNPS_ohe.predict(best5_wrapper_clusterdf_test_withClass.loc[best5_wrapper_clusterdf_test_withClass.Piemonte_Sud==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Sud'].values, res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "be656261",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dora_cyclostationary_mean_tg_1w_0</th>\n",
       "      <th>Dora_cyclostationary_mean_rr_4w_1</th>\n",
       "      <th>Dora_cyclostationary_mean_tg_1w_2</th>\n",
       "      <th>Dora_cyclostationary_mean_tg_4w_1</th>\n",
       "      <th>Dora_cyclostationary_mean_tg_4w_0</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_1w_3</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_rr_4w_0</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_rr_24w_0</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_24w_0</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_24w_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_24w_1_Piemonte_Sud</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_1w_4_Dora</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_1w_4_Piemonte_Nord</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_1w_4_Piemonte_Sud</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_16w_1_Dora</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_16w_1_Piemonte_Nord</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_16w_1_Piemonte_Sud</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_16w_2_Dora</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_16w_2_Piemonte_Nord</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_16w_2_Piemonte_Sud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.858428</td>\n",
       "      <td>0.569944</td>\n",
       "      <td>-0.645734</td>\n",
       "      <td>-0.958059</td>\n",
       "      <td>-1.179177</td>\n",
       "      <td>-0.705198</td>\n",
       "      <td>0.531161</td>\n",
       "      <td>0.993156</td>\n",
       "      <td>-1.444933</td>\n",
       "      <td>-1.056852</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.566795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.503456</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.450706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.144075</td>\n",
       "      <td>2.777501</td>\n",
       "      <td>-0.040254</td>\n",
       "      <td>0.064877</td>\n",
       "      <td>-0.154668</td>\n",
       "      <td>-0.040533</td>\n",
       "      <td>1.141736</td>\n",
       "      <td>2.145937</td>\n",
       "      <td>0.399738</td>\n",
       "      <td>0.702337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.162632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.284243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.406378</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.543433</td>\n",
       "      <td>1.425829</td>\n",
       "      <td>-0.727940</td>\n",
       "      <td>-1.002116</td>\n",
       "      <td>-0.919496</td>\n",
       "      <td>-0.312340</td>\n",
       "      <td>0.600533</td>\n",
       "      <td>1.115539</td>\n",
       "      <td>-0.862634</td>\n",
       "      <td>-0.363026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.501665</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.124173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.751610</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.723360</td>\n",
       "      <td>1.785519</td>\n",
       "      <td>-0.924722</td>\n",
       "      <td>-0.601101</td>\n",
       "      <td>-0.594848</td>\n",
       "      <td>-0.434823</td>\n",
       "      <td>0.613627</td>\n",
       "      <td>1.140701</td>\n",
       "      <td>0.012866</td>\n",
       "      <td>0.053932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.074694</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>2.734133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.878484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.540293</td>\n",
       "      <td>1.524603</td>\n",
       "      <td>-0.569035</td>\n",
       "      <td>-0.789653</td>\n",
       "      <td>-0.843317</td>\n",
       "      <td>-0.286705</td>\n",
       "      <td>0.408259</td>\n",
       "      <td>0.742092</td>\n",
       "      <td>-0.535961</td>\n",
       "      <td>-0.202521</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.107268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.874214</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.117130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>1.462830</td>\n",
       "      <td>-0.520256</td>\n",
       "      <td>1.585661</td>\n",
       "      <td>0.807565</td>\n",
       "      <td>0.577376</td>\n",
       "      <td>1.346423</td>\n",
       "      <td>-0.938846</td>\n",
       "      <td>-1.118138</td>\n",
       "      <td>1.192105</td>\n",
       "      <td>0.686556</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.165656</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.617574</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.419856</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.118142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>0.599620</td>\n",
       "      <td>-0.530550</td>\n",
       "      <td>0.724000</td>\n",
       "      <td>1.020805</td>\n",
       "      <td>0.776516</td>\n",
       "      <td>0.509539</td>\n",
       "      <td>-0.559070</td>\n",
       "      <td>-0.904049</td>\n",
       "      <td>1.080238</td>\n",
       "      <td>0.646899</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.855699</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.290505</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.087685</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.753294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.344849</td>\n",
       "      <td>0.031726</td>\n",
       "      <td>0.422436</td>\n",
       "      <td>0.910086</td>\n",
       "      <td>0.715672</td>\n",
       "      <td>0.236097</td>\n",
       "      <td>-0.113738</td>\n",
       "      <td>-0.769506</td>\n",
       "      <td>0.967415</td>\n",
       "      <td>0.491266</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.755765</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.235027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.110292</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.728345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>-1.130239</td>\n",
       "      <td>-0.154282</td>\n",
       "      <td>-1.116372</td>\n",
       "      <td>0.237759</td>\n",
       "      <td>0.083901</td>\n",
       "      <td>-1.353830</td>\n",
       "      <td>-0.253229</td>\n",
       "      <td>-0.635866</td>\n",
       "      <td>0.608651</td>\n",
       "      <td>0.209678</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.632667</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.224584</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111368</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.550634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-1.598190</td>\n",
       "      <td>0.583732</td>\n",
       "      <td>-1.711036</td>\n",
       "      <td>-0.182408</td>\n",
       "      <td>-0.229108</td>\n",
       "      <td>-1.553763</td>\n",
       "      <td>0.301057</td>\n",
       "      <td>-0.646653</td>\n",
       "      <td>0.748061</td>\n",
       "      <td>0.239362</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.605880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.003973</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.582957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.714648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1233 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dora_cyclostationary_mean_tg_1w_0  Dora_cyclostationary_mean_rr_4w_1  \\\n",
       "0                            -0.858428                           0.569944   \n",
       "1                            -0.144075                           2.777501   \n",
       "2                            -0.543433                           1.425829   \n",
       "3                            -0.723360                           1.785519   \n",
       "4                            -0.540293                           1.524603   \n",
       "..                                 ...                                ...   \n",
       "406                           1.462830                          -0.520256   \n",
       "407                           0.599620                          -0.530550   \n",
       "408                           0.344849                           0.031726   \n",
       "409                          -1.130239                          -0.154282   \n",
       "410                          -1.598190                           0.583732   \n",
       "\n",
       "     Dora_cyclostationary_mean_tg_1w_2  Dora_cyclostationary_mean_tg_4w_1  \\\n",
       "0                            -0.645734                          -0.958059   \n",
       "1                            -0.040254                           0.064877   \n",
       "2                            -0.727940                          -1.002116   \n",
       "3                            -0.924722                          -0.601101   \n",
       "4                            -0.569035                          -0.789653   \n",
       "..                                 ...                                ...   \n",
       "406                           1.585661                           0.807565   \n",
       "407                           0.724000                           1.020805   \n",
       "408                           0.422436                           0.910086   \n",
       "409                          -1.116372                           0.237759   \n",
       "410                          -1.711036                          -0.182408   \n",
       "\n",
       "     Dora_cyclostationary_mean_tg_4w_0  \\\n",
       "0                            -1.179177   \n",
       "1                            -0.154668   \n",
       "2                            -0.919496   \n",
       "3                            -0.594848   \n",
       "4                            -0.843317   \n",
       "..                                 ...   \n",
       "406                           0.577376   \n",
       "407                           0.776516   \n",
       "408                           0.715672   \n",
       "409                           0.083901   \n",
       "410                          -0.229108   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_1w_3  \\\n",
       "0                                     -0.705198   \n",
       "1                                     -0.040533   \n",
       "2                                     -0.312340   \n",
       "3                                     -0.434823   \n",
       "4                                     -0.286705   \n",
       "..                                          ...   \n",
       "406                                    1.346423   \n",
       "407                                    0.509539   \n",
       "408                                    0.236097   \n",
       "409                                   -1.353830   \n",
       "410                                   -1.553763   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_rr_4w_0  \\\n",
       "0                                      0.531161   \n",
       "1                                      1.141736   \n",
       "2                                      0.600533   \n",
       "3                                      0.613627   \n",
       "4                                      0.408259   \n",
       "..                                          ...   \n",
       "406                                   -0.938846   \n",
       "407                                   -0.559070   \n",
       "408                                   -0.113738   \n",
       "409                                   -0.253229   \n",
       "410                                    0.301057   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_rr_24w_0  \\\n",
       "0                                       0.993156   \n",
       "1                                       2.145937   \n",
       "2                                       1.115539   \n",
       "3                                       1.140701   \n",
       "4                                       0.742092   \n",
       "..                                           ...   \n",
       "406                                    -1.118138   \n",
       "407                                    -0.904049   \n",
       "408                                    -0.769506   \n",
       "409                                    -0.635866   \n",
       "410                                    -0.646653   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_24w_0  \\\n",
       "0                                      -1.444933   \n",
       "1                                       0.399738   \n",
       "2                                      -0.862634   \n",
       "3                                       0.012866   \n",
       "4                                      -0.535961   \n",
       "..                                           ...   \n",
       "406                                     1.192105   \n",
       "407                                     1.080238   \n",
       "408                                     0.967415   \n",
       "409                                     0.608651   \n",
       "410                                     0.748061   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_24w_1  ...  \\\n",
       "0                                      -1.056852  ...   \n",
       "1                                       0.702337  ...   \n",
       "2                                      -0.363026  ...   \n",
       "3                                       0.053932  ...   \n",
       "4                                      -0.202521  ...   \n",
       "..                                           ...  ...   \n",
       "406                                     0.686556  ...   \n",
       "407                                     0.646899  ...   \n",
       "408                                     0.491266  ...   \n",
       "409                                     0.209678  ...   \n",
       "410                                     0.239362  ...   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_24w_1_Piemonte_Sud  \\\n",
       "0                                             0.000000         \n",
       "1                                             0.000000         \n",
       "2                                             0.000000         \n",
       "3                                             0.000000         \n",
       "4                                             0.000000         \n",
       "..                                                 ...         \n",
       "406                                          -1.165656         \n",
       "407                                          -0.855699         \n",
       "408                                          -0.755765         \n",
       "409                                          -0.632667         \n",
       "410                                          -0.605880         \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_1w_4_Dora  \\\n",
       "0                                          0.566795   \n",
       "1                                          1.162632   \n",
       "2                                          0.501665   \n",
       "3                                         -0.074694   \n",
       "4                                          0.107268   \n",
       "..                                              ...   \n",
       "406                                       -0.000000   \n",
       "407                                       -0.000000   \n",
       "408                                       -0.000000   \n",
       "409                                       -0.000000   \n",
       "410                                        0.000000   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_1w_4_Piemonte_Nord  \\\n",
       "0                                                  0.0         \n",
       "1                                                  0.0         \n",
       "2                                                  0.0         \n",
       "3                                                 -0.0         \n",
       "4                                                  0.0         \n",
       "..                                                 ...         \n",
       "406                                               -0.0         \n",
       "407                                               -0.0         \n",
       "408                                               -0.0         \n",
       "409                                               -0.0         \n",
       "410                                                0.0         \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_1w_4_Piemonte_Sud  \\\n",
       "0                                             0.000000        \n",
       "1                                             0.000000        \n",
       "2                                             0.000000        \n",
       "3                                            -0.000000        \n",
       "4                                             0.000000        \n",
       "..                                                 ...        \n",
       "406                                          -0.617574        \n",
       "407                                          -0.290505        \n",
       "408                                          -0.235027        \n",
       "409                                          -0.224584        \n",
       "410                                           1.003973        \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_16w_1_Dora  \\\n",
       "0                                           5.503456   \n",
       "1                                           5.284243   \n",
       "2                                           3.124173   \n",
       "3                                           2.734133   \n",
       "4                                           1.874214   \n",
       "..                                               ...   \n",
       "406                                        -0.000000   \n",
       "407                                         0.000000   \n",
       "408                                         0.000000   \n",
       "409                                         0.000000   \n",
       "410                                         0.000000   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_16w_1_Piemonte_Nord  \\\n",
       "0                                                  0.0          \n",
       "1                                                  0.0          \n",
       "2                                                  0.0          \n",
       "3                                                  0.0          \n",
       "4                                                  0.0          \n",
       "..                                                 ...          \n",
       "406                                               -0.0          \n",
       "407                                                0.0          \n",
       "408                                                0.0          \n",
       "409                                                0.0          \n",
       "410                                                0.0          \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_16w_1_Piemonte_Sud  \\\n",
       "0                                             0.000000         \n",
       "1                                             0.000000         \n",
       "2                                             0.000000         \n",
       "3                                             0.000000         \n",
       "4                                             0.000000         \n",
       "..                                                 ...         \n",
       "406                                          -0.419856         \n",
       "407                                           0.087685         \n",
       "408                                           0.110292         \n",
       "409                                           0.111368         \n",
       "410                                           0.582957         \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_16w_2_Dora  \\\n",
       "0                                           3.450706   \n",
       "1                                           3.406378   \n",
       "2                                           1.751610   \n",
       "3                                           1.878484   \n",
       "4                                           1.117130   \n",
       "..                                               ...   \n",
       "406                                         0.000000   \n",
       "407                                         0.000000   \n",
       "408                                         0.000000   \n",
       "409                                         0.000000   \n",
       "410                                         0.000000   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_16w_2_Piemonte_Nord  \\\n",
       "0                                                  0.0          \n",
       "1                                                  0.0          \n",
       "2                                                  0.0          \n",
       "3                                                  0.0          \n",
       "4                                                  0.0          \n",
       "..                                                 ...          \n",
       "406                                                0.0          \n",
       "407                                                0.0          \n",
       "408                                                0.0          \n",
       "409                                                0.0          \n",
       "410                                                0.0          \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_16w_2_Piemonte_Sud  \n",
       "0                                             0.000000        \n",
       "1                                             0.000000        \n",
       "2                                             0.000000        \n",
       "3                                             0.000000        \n",
       "4                                             0.000000        \n",
       "..                                                 ...        \n",
       "406                                           0.118142        \n",
       "407                                           0.753294        \n",
       "408                                           0.728345        \n",
       "409                                           0.550634        \n",
       "410                                           0.714648        \n",
       "\n",
       "[1233 rows x 63 columns]"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(best5_wrapper_clusterdf_train_withClass.shape[1]-len(clust_basins)):\n",
    "    for j in clust_basins:\n",
    "        best5_wrapper_clusterdf_train_withClass[best5_wrapper_clusterdf_train_withClass.columns[i]+'_'+j] = best5_wrapper_clusterdf_train_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "        best5_wrapper_clusterdf_val_withClass[best5_wrapper_clusterdf_val_withClass.columns[i]+'_'+j] = best5_wrapper_clusterdf_val_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "        best5_wrapper_clusterdf_test_withClass[best5_wrapper_clusterdf_test_withClass.columns[i]+'_'+j] = best5_wrapper_clusterdf_test_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "\n",
    "best5_wrapper_clusterdf_train_withClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "cb74d5a6",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.4605342062519393\n",
      "-0.20089066605171646\n",
      "-0.12280727670971792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_DPNPS_ohe = LinearRegression()\n",
    "model_DPNPS_ohe.fit(pd.concat((best5_wrapper_clusterdf_train_withClass,best5_wrapper_clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_DPNPS_ohe.predict(best5_wrapper_clusterdf_test_withClass.loc[best5_wrapper_clusterdf_test_withClass.Dora==1].values)\n",
    "print(r2_score(targets_df_test['Dora'].values, res))\n",
    "res = model_DPNPS_ohe.predict(best5_wrapper_clusterdf_test_withClass.loc[best5_wrapper_clusterdf_test_withClass.Piemonte_Nord==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Nord'].values, res))\n",
    "res = model_DPNPS_ohe.predict(best5_wrapper_clusterdf_test_withClass.loc[best5_wrapper_clusterdf_test_withClass.Piemonte_Sud==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Sud'].values, res))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc406cae",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Dora - Piemonte_Nord - Piemonte_Sud: CMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "07b350b7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "clust_basins = ['Dora', 'Piemonte_Nord', 'Piemonte_Sud']\n",
    "colnames = [x for x in CMI_fulldf_train.columns if x.startswith('Dora') or x.startswith('Piemonte_Nord') or x.startswith('Piemonte_Sud')]\n",
    "\n",
    "clusterdf_train_withClass = pd.DataFrame()\n",
    "clusterdf_val_withClass = pd.DataFrame()\n",
    "clusterdf_test_withClass = pd.DataFrame()\n",
    "\n",
    "for i in range(len(clust_basins)):\n",
    "    clusterdf_train_withClass = pd.concat((clusterdf_train_withClass,pd.concat((CMI_fulldf_train[colnames],pd.DataFrame(1+i*np.ones(len(CMI_fulldf_train)),columns=['basin'])),axis=1)),axis=0)\n",
    "    clusterdf_val_withClass = pd.concat((clusterdf_val_withClass,pd.concat((CMI_fulldf_val[colnames],pd.DataFrame(1+i*np.ones(len(CMI_fulldf_val)),columns=['basin'])),axis=1)),axis=0)\n",
    "    clusterdf_test_withClass = pd.concat((clusterdf_test_withClass,pd.concat((CMI_fulldf_test[colnames],pd.DataFrame(1+i*np.ones(len(CMI_fulldf_test)),columns=['basin'])),axis=1)),axis=0)\n",
    "\n",
    "for i in range(len(clust_basins)):\n",
    "    clusterdf_train_withClass[clust_basins[i]] = clusterdf_train_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    clusterdf_val_withClass[clust_basins[i]] = clusterdf_val_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    clusterdf_test_withClass[clust_basins[i]] = clusterdf_test_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "\n",
    "clusterdf_train_withClass = clusterdf_train_withClass.loc[:,clusterdf_train_withClass.columns != 'basin']\n",
    "clusterdf_val_withClass = clusterdf_val_withClass.loc[:,clusterdf_val_withClass.columns != 'basin']\n",
    "clusterdf_test_withClass = clusterdf_test_withClass.loc[:,clusterdf_test_withClass.columns != 'basin']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "377be712",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dora_cyclostationary_mean_tg_4w_1</th>\n",
       "      <th>Dora_cyclostationary_mean_tg_12w_0</th>\n",
       "      <th>Dora_cyclostationary_mean_rr_4w_0</th>\n",
       "      <th>Dora_cyclostationary_mean_tg_24w_1</th>\n",
       "      <th>Dora_cyclostationary_mean_tg_24w_2</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_3</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_rr_4w_0</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_1w_1</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_1w_3</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_1w_4</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_tg_0</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_24w_0</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_8w_0</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_12w_1</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_tg_1w_0</th>\n",
       "      <th>Dora</th>\n",
       "      <th>Piemonte_Nord</th>\n",
       "      <th>Piemonte_Sud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.958059</td>\n",
       "      <td>-1.692206</td>\n",
       "      <td>-0.181114</td>\n",
       "      <td>-1.852227</td>\n",
       "      <td>-1.694637</td>\n",
       "      <td>-0.483868</td>\n",
       "      <td>0.531161</td>\n",
       "      <td>-0.070058</td>\n",
       "      <td>-0.705198</td>\n",
       "      <td>-0.039471</td>\n",
       "      <td>-0.449672</td>\n",
       "      <td>3.146477</td>\n",
       "      <td>1.939769</td>\n",
       "      <td>3.863262</td>\n",
       "      <td>-0.551685</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.064877</td>\n",
       "      <td>-0.279226</td>\n",
       "      <td>0.886182</td>\n",
       "      <td>-0.351196</td>\n",
       "      <td>0.267105</td>\n",
       "      <td>0.673096</td>\n",
       "      <td>1.141736</td>\n",
       "      <td>0.669777</td>\n",
       "      <td>-0.040533</td>\n",
       "      <td>0.697310</td>\n",
       "      <td>0.880344</td>\n",
       "      <td>3.822355</td>\n",
       "      <td>2.431148</td>\n",
       "      <td>4.345114</td>\n",
       "      <td>0.256218</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.002116</td>\n",
       "      <td>-1.256740</td>\n",
       "      <td>0.223731</td>\n",
       "      <td>-2.234919</td>\n",
       "      <td>-1.713098</td>\n",
       "      <td>-0.898083</td>\n",
       "      <td>0.600533</td>\n",
       "      <td>0.518292</td>\n",
       "      <td>-0.312340</td>\n",
       "      <td>0.527444</td>\n",
       "      <td>-0.833249</td>\n",
       "      <td>2.115109</td>\n",
       "      <td>1.348554</td>\n",
       "      <td>2.533689</td>\n",
       "      <td>0.029187</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.601101</td>\n",
       "      <td>-0.825053</td>\n",
       "      <td>0.383765</td>\n",
       "      <td>-1.590347</td>\n",
       "      <td>-0.953714</td>\n",
       "      <td>0.358463</td>\n",
       "      <td>0.613627</td>\n",
       "      <td>0.245062</td>\n",
       "      <td>-0.434823</td>\n",
       "      <td>0.271867</td>\n",
       "      <td>0.865639</td>\n",
       "      <td>2.006293</td>\n",
       "      <td>1.282061</td>\n",
       "      <td>2.314067</td>\n",
       "      <td>0.023661</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.789653</td>\n",
       "      <td>-1.182962</td>\n",
       "      <td>0.295643</td>\n",
       "      <td>-1.665547</td>\n",
       "      <td>-1.374058</td>\n",
       "      <td>-0.555381</td>\n",
       "      <td>0.408259</td>\n",
       "      <td>0.468525</td>\n",
       "      <td>-0.286705</td>\n",
       "      <td>0.537510</td>\n",
       "      <td>-0.246418</td>\n",
       "      <td>1.307787</td>\n",
       "      <td>0.836693</td>\n",
       "      <td>1.603089</td>\n",
       "      <td>0.376389</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>0.807565</td>\n",
       "      <td>1.079275</td>\n",
       "      <td>-0.712766</td>\n",
       "      <td>1.021359</td>\n",
       "      <td>0.953999</td>\n",
       "      <td>0.862196</td>\n",
       "      <td>-0.938846</td>\n",
       "      <td>0.949782</td>\n",
       "      <td>1.346423</td>\n",
       "      <td>0.952736</td>\n",
       "      <td>1.374448</td>\n",
       "      <td>-0.767792</td>\n",
       "      <td>-0.476107</td>\n",
       "      <td>-0.467565</td>\n",
       "      <td>1.427917</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>1.020805</td>\n",
       "      <td>0.749908</td>\n",
       "      <td>-0.597343</td>\n",
       "      <td>1.000397</td>\n",
       "      <td>0.900047</td>\n",
       "      <td>-0.160042</td>\n",
       "      <td>-0.559070</td>\n",
       "      <td>0.569543</td>\n",
       "      <td>0.509539</td>\n",
       "      <td>0.579810</td>\n",
       "      <td>-0.119108</td>\n",
       "      <td>-0.482430</td>\n",
       "      <td>-0.420562</td>\n",
       "      <td>0.030758</td>\n",
       "      <td>0.760111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.910086</td>\n",
       "      <td>0.754701</td>\n",
       "      <td>-0.152386</td>\n",
       "      <td>0.925106</td>\n",
       "      <td>0.802985</td>\n",
       "      <td>0.528382</td>\n",
       "      <td>-0.113738</td>\n",
       "      <td>0.111790</td>\n",
       "      <td>0.236097</td>\n",
       "      <td>0.086513</td>\n",
       "      <td>0.643035</td>\n",
       "      <td>-0.396456</td>\n",
       "      <td>-0.215110</td>\n",
       "      <td>0.110519</td>\n",
       "      <td>0.315694</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>0.237759</td>\n",
       "      <td>0.155479</td>\n",
       "      <td>-0.396304</td>\n",
       "      <td>0.610253</td>\n",
       "      <td>0.441811</td>\n",
       "      <td>-2.715411</td>\n",
       "      <td>-0.253229</td>\n",
       "      <td>-1.115423</td>\n",
       "      <td>-1.353830</td>\n",
       "      <td>-1.099133</td>\n",
       "      <td>-2.247923</td>\n",
       "      <td>-0.311937</td>\n",
       "      <td>-0.353737</td>\n",
       "      <td>0.230804</td>\n",
       "      <td>-0.971253</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-0.182408</td>\n",
       "      <td>0.098752</td>\n",
       "      <td>0.173050</td>\n",
       "      <td>0.674977</td>\n",
       "      <td>0.536299</td>\n",
       "      <td>0.147712</td>\n",
       "      <td>0.301057</td>\n",
       "      <td>-1.606865</td>\n",
       "      <td>-1.553763</td>\n",
       "      <td>-1.579153</td>\n",
       "      <td>-0.167457</td>\n",
       "      <td>-0.130149</td>\n",
       "      <td>0.044753</td>\n",
       "      <td>0.566531</td>\n",
       "      <td>-1.460435</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1233 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dora_cyclostationary_mean_tg_4w_1  Dora_cyclostationary_mean_tg_12w_0  \\\n",
       "0                            -0.958059                           -1.692206   \n",
       "1                             0.064877                           -0.279226   \n",
       "2                            -1.002116                           -1.256740   \n",
       "3                            -0.601101                           -0.825053   \n",
       "4                            -0.789653                           -1.182962   \n",
       "..                                 ...                                 ...   \n",
       "406                           0.807565                            1.079275   \n",
       "407                           1.020805                            0.749908   \n",
       "408                           0.910086                            0.754701   \n",
       "409                           0.237759                            0.155479   \n",
       "410                          -0.182408                            0.098752   \n",
       "\n",
       "     Dora_cyclostationary_mean_rr_4w_0  Dora_cyclostationary_mean_tg_24w_1  \\\n",
       "0                            -0.181114                           -1.852227   \n",
       "1                             0.886182                           -0.351196   \n",
       "2                             0.223731                           -2.234919   \n",
       "3                             0.383765                           -1.590347   \n",
       "4                             0.295643                           -1.665547   \n",
       "..                                 ...                                 ...   \n",
       "406                          -0.712766                            1.021359   \n",
       "407                          -0.597343                            1.000397   \n",
       "408                          -0.152386                            0.925106   \n",
       "409                          -0.396304                            0.610253   \n",
       "410                           0.173050                            0.674977   \n",
       "\n",
       "     Dora_cyclostationary_mean_tg_24w_2  \\\n",
       "0                             -1.694637   \n",
       "1                              0.267105   \n",
       "2                             -1.713098   \n",
       "3                             -0.953714   \n",
       "4                             -1.374058   \n",
       "..                                  ...   \n",
       "406                            0.953999   \n",
       "407                            0.900047   \n",
       "408                            0.802985   \n",
       "409                            0.441811   \n",
       "410                            0.536299   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_3  \\\n",
       "0                                  -0.483868   \n",
       "1                                   0.673096   \n",
       "2                                  -0.898083   \n",
       "3                                   0.358463   \n",
       "4                                  -0.555381   \n",
       "..                                       ...   \n",
       "406                                 0.862196   \n",
       "407                                -0.160042   \n",
       "408                                 0.528382   \n",
       "409                                -2.715411   \n",
       "410                                 0.147712   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_rr_4w_0  \\\n",
       "0                                      0.531161   \n",
       "1                                      1.141736   \n",
       "2                                      0.600533   \n",
       "3                                      0.613627   \n",
       "4                                      0.408259   \n",
       "..                                          ...   \n",
       "406                                   -0.938846   \n",
       "407                                   -0.559070   \n",
       "408                                   -0.113738   \n",
       "409                                   -0.253229   \n",
       "410                                    0.301057   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_1w_1  \\\n",
       "0                                     -0.070058   \n",
       "1                                      0.669777   \n",
       "2                                      0.518292   \n",
       "3                                      0.245062   \n",
       "4                                      0.468525   \n",
       "..                                          ...   \n",
       "406                                    0.949782   \n",
       "407                                    0.569543   \n",
       "408                                    0.111790   \n",
       "409                                   -1.115423   \n",
       "410                                   -1.606865   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_1w_3  \\\n",
       "0                                     -0.705198   \n",
       "1                                     -0.040533   \n",
       "2                                     -0.312340   \n",
       "3                                     -0.434823   \n",
       "4                                     -0.286705   \n",
       "..                                          ...   \n",
       "406                                    1.346423   \n",
       "407                                    0.509539   \n",
       "408                                    0.236097   \n",
       "409                                   -1.353830   \n",
       "410                                   -1.553763   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_1w_4  \\\n",
       "0                                     -0.039471   \n",
       "1                                      0.697310   \n",
       "2                                      0.527444   \n",
       "3                                      0.271867   \n",
       "4                                      0.537510   \n",
       "..                                          ...   \n",
       "406                                    0.952736   \n",
       "407                                    0.579810   \n",
       "408                                    0.086513   \n",
       "409                                   -1.099133   \n",
       "410                                   -1.579153   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_tg_0  \\\n",
       "0                                 -0.449672   \n",
       "1                                  0.880344   \n",
       "2                                 -0.833249   \n",
       "3                                  0.865639   \n",
       "4                                 -0.246418   \n",
       "..                                      ...   \n",
       "406                                1.374448   \n",
       "407                               -0.119108   \n",
       "408                                0.643035   \n",
       "409                               -2.247923   \n",
       "410                               -0.167457   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_24w_0  \\\n",
       "0                                      3.146477   \n",
       "1                                      3.822355   \n",
       "2                                      2.115109   \n",
       "3                                      2.006293   \n",
       "4                                      1.307787   \n",
       "..                                          ...   \n",
       "406                                   -0.767792   \n",
       "407                                   -0.482430   \n",
       "408                                   -0.396456   \n",
       "409                                   -0.311937   \n",
       "410                                   -0.130149   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_8w_0  \\\n",
       "0                                     1.939769   \n",
       "1                                     2.431148   \n",
       "2                                     1.348554   \n",
       "3                                     1.282061   \n",
       "4                                     0.836693   \n",
       "..                                         ...   \n",
       "406                                  -0.476107   \n",
       "407                                  -0.420562   \n",
       "408                                  -0.215110   \n",
       "409                                  -0.353737   \n",
       "410                                   0.044753   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_12w_1  \\\n",
       "0                                      3.863262   \n",
       "1                                      4.345114   \n",
       "2                                      2.533689   \n",
       "3                                      2.314067   \n",
       "4                                      1.603089   \n",
       "..                                          ...   \n",
       "406                                   -0.467565   \n",
       "407                                    0.030758   \n",
       "408                                    0.110519   \n",
       "409                                    0.230804   \n",
       "410                                    0.566531   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_tg_1w_0  Dora  Piemonte_Nord  \\\n",
       "0                                    -0.551685     1              0   \n",
       "1                                     0.256218     1              0   \n",
       "2                                     0.029187     1              0   \n",
       "3                                     0.023661     1              0   \n",
       "4                                     0.376389     1              0   \n",
       "..                                         ...   ...            ...   \n",
       "406                                   1.427917     0              0   \n",
       "407                                   0.760111     0              0   \n",
       "408                                   0.315694     0              0   \n",
       "409                                  -0.971253     0              0   \n",
       "410                                  -1.460435     0              0   \n",
       "\n",
       "     Piemonte_Sud  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "..            ...  \n",
       "406             1  \n",
       "407             1  \n",
       "408             1  \n",
       "409             1  \n",
       "410             1  \n",
       "\n",
       "[1233 rows x 18 columns]"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterdf_train_withClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "06181670",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "targets_df_train_unfolded = pd.DataFrame()\n",
    "targets_df_val_unfolded = pd.DataFrame()\n",
    "targets_df_test_unfolded = pd.DataFrame()\n",
    "\n",
    "for basin in clust_basins:\n",
    "    targets_df_train_unfolded =  pd.concat((targets_df_train_unfolded,targets_df_train[basin]),axis=0)\n",
    "    targets_df_val_unfolded =  pd.concat((targets_df_val_unfolded,targets_df_val[basin]),axis=0)\n",
    "    targets_df_test_unfolded =  pd.concat((targets_df_test_unfolded,targets_df_test[basin]),axis=0)\n",
    "targets_df_train_unfolded = targets_df_train_unfolded.reset_index(drop=True)\n",
    "targets_df_val_unfolded = targets_df_val_unfolded.reset_index(drop=True)\n",
    "targets_df_test_unfolded = targets_df_test_unfolded.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "71eb99d6",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.6392008270590532\n",
      "-0.4196218844269948\n",
      "-0.49841482385224056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_DPNPS_ohe = LinearRegression()\n",
    "model_DPNPS_ohe.fit(pd.concat((clusterdf_train_withClass,clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_DPNPS_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Dora==1].values)\n",
    "print(r2_score(targets_df_test['Dora'].values, res))\n",
    "res = model_DPNPS_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Piemonte_Nord==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Nord'].values, res))\n",
    "res = model_DPNPS_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Piemonte_Sud==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Sud'].values, res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "c8b24f47",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dora_cyclostationary_mean_tg_4w_1</th>\n",
       "      <th>Dora_cyclostationary_mean_tg_12w_0</th>\n",
       "      <th>Dora_cyclostationary_mean_rr_4w_0</th>\n",
       "      <th>Dora_cyclostationary_mean_tg_24w_1</th>\n",
       "      <th>Dora_cyclostationary_mean_tg_24w_2</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_3</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_rr_4w_0</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_1w_1</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_1w_3</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_1w_4</th>\n",
       "      <th>...</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_24w_0_Piemonte_Sud</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_8w_0_Dora</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_8w_0_Piemonte_Nord</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_8w_0_Piemonte_Sud</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_12w_1_Dora</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_12w_1_Piemonte_Nord</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_12w_1_Piemonte_Sud</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_tg_1w_0_Dora</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_tg_1w_0_Piemonte_Nord</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_tg_1w_0_Piemonte_Sud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.958059</td>\n",
       "      <td>-1.692206</td>\n",
       "      <td>-0.181114</td>\n",
       "      <td>-1.852227</td>\n",
       "      <td>-1.694637</td>\n",
       "      <td>-0.483868</td>\n",
       "      <td>0.531161</td>\n",
       "      <td>-0.070058</td>\n",
       "      <td>-0.705198</td>\n",
       "      <td>-0.039471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.939769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.863262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.551685</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.064877</td>\n",
       "      <td>-0.279226</td>\n",
       "      <td>0.886182</td>\n",
       "      <td>-0.351196</td>\n",
       "      <td>0.267105</td>\n",
       "      <td>0.673096</td>\n",
       "      <td>1.141736</td>\n",
       "      <td>0.669777</td>\n",
       "      <td>-0.040533</td>\n",
       "      <td>0.697310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.431148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.345114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.256218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.002116</td>\n",
       "      <td>-1.256740</td>\n",
       "      <td>0.223731</td>\n",
       "      <td>-2.234919</td>\n",
       "      <td>-1.713098</td>\n",
       "      <td>-0.898083</td>\n",
       "      <td>0.600533</td>\n",
       "      <td>0.518292</td>\n",
       "      <td>-0.312340</td>\n",
       "      <td>0.527444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.348554</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.533689</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.601101</td>\n",
       "      <td>-0.825053</td>\n",
       "      <td>0.383765</td>\n",
       "      <td>-1.590347</td>\n",
       "      <td>-0.953714</td>\n",
       "      <td>0.358463</td>\n",
       "      <td>0.613627</td>\n",
       "      <td>0.245062</td>\n",
       "      <td>-0.434823</td>\n",
       "      <td>0.271867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.282061</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.314067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023661</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.789653</td>\n",
       "      <td>-1.182962</td>\n",
       "      <td>0.295643</td>\n",
       "      <td>-1.665547</td>\n",
       "      <td>-1.374058</td>\n",
       "      <td>-0.555381</td>\n",
       "      <td>0.408259</td>\n",
       "      <td>0.468525</td>\n",
       "      <td>-0.286705</td>\n",
       "      <td>0.537510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.836693</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.603089</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.376389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>0.807565</td>\n",
       "      <td>1.079275</td>\n",
       "      <td>-0.712766</td>\n",
       "      <td>1.021359</td>\n",
       "      <td>0.953999</td>\n",
       "      <td>0.862196</td>\n",
       "      <td>-0.938846</td>\n",
       "      <td>0.949782</td>\n",
       "      <td>1.346423</td>\n",
       "      <td>0.952736</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.767792</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.476107</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.467565</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.427917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>1.020805</td>\n",
       "      <td>0.749908</td>\n",
       "      <td>-0.597343</td>\n",
       "      <td>1.000397</td>\n",
       "      <td>0.900047</td>\n",
       "      <td>-0.160042</td>\n",
       "      <td>-0.559070</td>\n",
       "      <td>0.569543</td>\n",
       "      <td>0.509539</td>\n",
       "      <td>0.579810</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.482430</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.420562</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.760111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.910086</td>\n",
       "      <td>0.754701</td>\n",
       "      <td>-0.152386</td>\n",
       "      <td>0.925106</td>\n",
       "      <td>0.802985</td>\n",
       "      <td>0.528382</td>\n",
       "      <td>-0.113738</td>\n",
       "      <td>0.111790</td>\n",
       "      <td>0.236097</td>\n",
       "      <td>0.086513</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.396456</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.215110</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.110519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.315694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>0.237759</td>\n",
       "      <td>0.155479</td>\n",
       "      <td>-0.396304</td>\n",
       "      <td>0.610253</td>\n",
       "      <td>0.441811</td>\n",
       "      <td>-2.715411</td>\n",
       "      <td>-0.253229</td>\n",
       "      <td>-1.115423</td>\n",
       "      <td>-1.353830</td>\n",
       "      <td>-1.099133</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.311937</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.353737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.230804</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.971253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-0.182408</td>\n",
       "      <td>0.098752</td>\n",
       "      <td>0.173050</td>\n",
       "      <td>0.674977</td>\n",
       "      <td>0.536299</td>\n",
       "      <td>0.147712</td>\n",
       "      <td>0.301057</td>\n",
       "      <td>-1.606865</td>\n",
       "      <td>-1.553763</td>\n",
       "      <td>-1.579153</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.130149</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.566531</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-1.460435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1233 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dora_cyclostationary_mean_tg_4w_1  Dora_cyclostationary_mean_tg_12w_0  \\\n",
       "0                            -0.958059                           -1.692206   \n",
       "1                             0.064877                           -0.279226   \n",
       "2                            -1.002116                           -1.256740   \n",
       "3                            -0.601101                           -0.825053   \n",
       "4                            -0.789653                           -1.182962   \n",
       "..                                 ...                                 ...   \n",
       "406                           0.807565                            1.079275   \n",
       "407                           1.020805                            0.749908   \n",
       "408                           0.910086                            0.754701   \n",
       "409                           0.237759                            0.155479   \n",
       "410                          -0.182408                            0.098752   \n",
       "\n",
       "     Dora_cyclostationary_mean_rr_4w_0  Dora_cyclostationary_mean_tg_24w_1  \\\n",
       "0                            -0.181114                           -1.852227   \n",
       "1                             0.886182                           -0.351196   \n",
       "2                             0.223731                           -2.234919   \n",
       "3                             0.383765                           -1.590347   \n",
       "4                             0.295643                           -1.665547   \n",
       "..                                 ...                                 ...   \n",
       "406                          -0.712766                            1.021359   \n",
       "407                          -0.597343                            1.000397   \n",
       "408                          -0.152386                            0.925106   \n",
       "409                          -0.396304                            0.610253   \n",
       "410                           0.173050                            0.674977   \n",
       "\n",
       "     Dora_cyclostationary_mean_tg_24w_2  \\\n",
       "0                             -1.694637   \n",
       "1                              0.267105   \n",
       "2                             -1.713098   \n",
       "3                             -0.953714   \n",
       "4                             -1.374058   \n",
       "..                                  ...   \n",
       "406                            0.953999   \n",
       "407                            0.900047   \n",
       "408                            0.802985   \n",
       "409                            0.441811   \n",
       "410                            0.536299   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_3  \\\n",
       "0                                  -0.483868   \n",
       "1                                   0.673096   \n",
       "2                                  -0.898083   \n",
       "3                                   0.358463   \n",
       "4                                  -0.555381   \n",
       "..                                       ...   \n",
       "406                                 0.862196   \n",
       "407                                -0.160042   \n",
       "408                                 0.528382   \n",
       "409                                -2.715411   \n",
       "410                                 0.147712   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_rr_4w_0  \\\n",
       "0                                      0.531161   \n",
       "1                                      1.141736   \n",
       "2                                      0.600533   \n",
       "3                                      0.613627   \n",
       "4                                      0.408259   \n",
       "..                                          ...   \n",
       "406                                   -0.938846   \n",
       "407                                   -0.559070   \n",
       "408                                   -0.113738   \n",
       "409                                   -0.253229   \n",
       "410                                    0.301057   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_1w_1  \\\n",
       "0                                     -0.070058   \n",
       "1                                      0.669777   \n",
       "2                                      0.518292   \n",
       "3                                      0.245062   \n",
       "4                                      0.468525   \n",
       "..                                          ...   \n",
       "406                                    0.949782   \n",
       "407                                    0.569543   \n",
       "408                                    0.111790   \n",
       "409                                   -1.115423   \n",
       "410                                   -1.606865   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_1w_3  \\\n",
       "0                                     -0.705198   \n",
       "1                                     -0.040533   \n",
       "2                                     -0.312340   \n",
       "3                                     -0.434823   \n",
       "4                                     -0.286705   \n",
       "..                                          ...   \n",
       "406                                    1.346423   \n",
       "407                                    0.509539   \n",
       "408                                    0.236097   \n",
       "409                                   -1.353830   \n",
       "410                                   -1.553763   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_1w_4  ...  \\\n",
       "0                                     -0.039471  ...   \n",
       "1                                      0.697310  ...   \n",
       "2                                      0.527444  ...   \n",
       "3                                      0.271867  ...   \n",
       "4                                      0.537510  ...   \n",
       "..                                          ...  ...   \n",
       "406                                    0.952736  ...   \n",
       "407                                    0.579810  ...   \n",
       "408                                    0.086513  ...   \n",
       "409                                   -1.099133  ...   \n",
       "410                                   -1.579153  ...   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_24w_0_Piemonte_Sud  \\\n",
       "0                                             0.000000         \n",
       "1                                             0.000000         \n",
       "2                                             0.000000         \n",
       "3                                             0.000000         \n",
       "4                                             0.000000         \n",
       "..                                                 ...         \n",
       "406                                          -0.767792         \n",
       "407                                          -0.482430         \n",
       "408                                          -0.396456         \n",
       "409                                          -0.311937         \n",
       "410                                          -0.130149         \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_8w_0_Dora  \\\n",
       "0                                          1.939769   \n",
       "1                                          2.431148   \n",
       "2                                          1.348554   \n",
       "3                                          1.282061   \n",
       "4                                          0.836693   \n",
       "..                                              ...   \n",
       "406                                       -0.000000   \n",
       "407                                       -0.000000   \n",
       "408                                       -0.000000   \n",
       "409                                       -0.000000   \n",
       "410                                        0.000000   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_8w_0_Piemonte_Nord  \\\n",
       "0                                                  0.0         \n",
       "1                                                  0.0         \n",
       "2                                                  0.0         \n",
       "3                                                  0.0         \n",
       "4                                                  0.0         \n",
       "..                                                 ...         \n",
       "406                                               -0.0         \n",
       "407                                               -0.0         \n",
       "408                                               -0.0         \n",
       "409                                               -0.0         \n",
       "410                                                0.0         \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_8w_0_Piemonte_Sud  \\\n",
       "0                                             0.000000        \n",
       "1                                             0.000000        \n",
       "2                                             0.000000        \n",
       "3                                             0.000000        \n",
       "4                                             0.000000        \n",
       "..                                                 ...        \n",
       "406                                          -0.476107        \n",
       "407                                          -0.420562        \n",
       "408                                          -0.215110        \n",
       "409                                          -0.353737        \n",
       "410                                           0.044753        \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_12w_1_Dora  \\\n",
       "0                                           3.863262   \n",
       "1                                           4.345114   \n",
       "2                                           2.533689   \n",
       "3                                           2.314067   \n",
       "4                                           1.603089   \n",
       "..                                               ...   \n",
       "406                                        -0.000000   \n",
       "407                                         0.000000   \n",
       "408                                         0.000000   \n",
       "409                                         0.000000   \n",
       "410                                         0.000000   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_12w_1_Piemonte_Nord  \\\n",
       "0                                                  0.0          \n",
       "1                                                  0.0          \n",
       "2                                                  0.0          \n",
       "3                                                  0.0          \n",
       "4                                                  0.0          \n",
       "..                                                 ...          \n",
       "406                                               -0.0          \n",
       "407                                                0.0          \n",
       "408                                                0.0          \n",
       "409                                                0.0          \n",
       "410                                                0.0          \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_12w_1_Piemonte_Sud  \\\n",
       "0                                             0.000000         \n",
       "1                                             0.000000         \n",
       "2                                             0.000000         \n",
       "3                                             0.000000         \n",
       "4                                             0.000000         \n",
       "..                                                 ...         \n",
       "406                                          -0.467565         \n",
       "407                                           0.030758         \n",
       "408                                           0.110519         \n",
       "409                                           0.230804         \n",
       "410                                           0.566531         \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_tg_1w_0_Dora  \\\n",
       "0                                         -0.551685   \n",
       "1                                          0.256218   \n",
       "2                                          0.029187   \n",
       "3                                          0.023661   \n",
       "4                                          0.376389   \n",
       "..                                              ...   \n",
       "406                                        0.000000   \n",
       "407                                        0.000000   \n",
       "408                                        0.000000   \n",
       "409                                       -0.000000   \n",
       "410                                       -0.000000   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_tg_1w_0_Piemonte_Nord  \\\n",
       "0                                                 -0.0         \n",
       "1                                                  0.0         \n",
       "2                                                  0.0         \n",
       "3                                                  0.0         \n",
       "4                                                  0.0         \n",
       "..                                                 ...         \n",
       "406                                                0.0         \n",
       "407                                                0.0         \n",
       "408                                                0.0         \n",
       "409                                               -0.0         \n",
       "410                                               -0.0         \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_tg_1w_0_Piemonte_Sud  \n",
       "0                                            -0.000000       \n",
       "1                                             0.000000       \n",
       "2                                             0.000000       \n",
       "3                                             0.000000       \n",
       "4                                             0.000000       \n",
       "..                                                 ...       \n",
       "406                                           1.427917       \n",
       "407                                           0.760111       \n",
       "408                                           0.315694       \n",
       "409                                          -0.971253       \n",
       "410                                          -1.460435       \n",
       "\n",
       "[1233 rows x 63 columns]"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(clusterdf_train_withClass.shape[1]-len(clust_basins)):\n",
    "    for j in clust_basins:\n",
    "        clusterdf_train_withClass[clusterdf_train_withClass.columns[i]+'_'+j] = clusterdf_train_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "        clusterdf_val_withClass[clusterdf_val_withClass.columns[i]+'_'+j] = clusterdf_val_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "        clusterdf_test_withClass[clusterdf_test_withClass.columns[i]+'_'+j] = clusterdf_test_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "\n",
    "clusterdf_train_withClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "66540431",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.4233289032849736\n",
      "-0.18216047822349557\n",
      "-0.3055385087801512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_DPNPS_ohe = LinearRegression()\n",
    "model_DPNPS_ohe.fit(pd.concat((clusterdf_train_withClass,clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_DPNPS_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Dora==1].values)\n",
    "print(r2_score(targets_df_test['Dora'].values, res))\n",
    "res = model_DPNPS_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Piemonte_Nord==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Nord'].values, res))\n",
    "res = model_DPNPS_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Piemonte_Sud==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Sud'].values, res))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84096a5d",
   "metadata": {},
   "source": [
    "### Dora - Piemonte_Nord - Piemonte_Sud: CMI best 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "32be3d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_basins = ['Dora', 'Piemonte_Nord', 'Piemonte_Sud']\n",
    "colnames = [x for x in best5_CMI_fulldf_train.columns if x.startswith('Dora') or x.startswith('Piemonte_Nord') or x.startswith('Piemonte_Sud')]\n",
    "\n",
    "clusterdf_train_withClass = pd.DataFrame()\n",
    "clusterdf_val_withClass = pd.DataFrame()\n",
    "clusterdf_test_withClass = pd.DataFrame()\n",
    "\n",
    "for i in range(len(clust_basins)):\n",
    "    clusterdf_train_withClass = pd.concat((clusterdf_train_withClass,pd.concat((best5_CMI_fulldf_train[colnames],pd.DataFrame(1+i*np.ones(len(best5_CMI_fulldf_train)),columns=['basin'])),axis=1)),axis=0)\n",
    "    clusterdf_val_withClass = pd.concat((clusterdf_val_withClass,pd.concat((best5_CMI_fulldf_val[colnames],pd.DataFrame(1+i*np.ones(len(best5_CMI_fulldf_val)),columns=['basin'])),axis=1)),axis=0)\n",
    "    clusterdf_test_withClass = pd.concat((clusterdf_test_withClass,pd.concat((best5_CMI_fulldf_test[colnames],pd.DataFrame(1+i*np.ones(len(best5_CMI_fulldf_test)),columns=['basin'])),axis=1)),axis=0)\n",
    "\n",
    "for i in range(len(clust_basins)):\n",
    "    clusterdf_train_withClass[clust_basins[i]] = clusterdf_train_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    clusterdf_val_withClass[clust_basins[i]] = clusterdf_val_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    clusterdf_test_withClass[clust_basins[i]] = clusterdf_test_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "\n",
    "clusterdf_train_withClass = clusterdf_train_withClass.loc[:,clusterdf_train_withClass.columns != 'basin']\n",
    "clusterdf_val_withClass = clusterdf_val_withClass.loc[:,clusterdf_val_withClass.columns != 'basin']\n",
    "clusterdf_test_withClass = clusterdf_test_withClass.loc[:,clusterdf_test_withClass.columns != 'basin']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "ad2802ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dora_cyclostationary_mean_tg_4w_1</th>\n",
       "      <th>Dora_cyclostationary_mean_tg_12w_0</th>\n",
       "      <th>Dora_cyclostationary_mean_rr_4w_0</th>\n",
       "      <th>Dora_cyclostationary_mean_tg_24w_1</th>\n",
       "      <th>Dora_cyclostationary_mean_tg_24w_2</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_3</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_rr_4w_0</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_1w_1</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_1w_3</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_1w_4</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_tg_0</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_24w_0</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_8w_0</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_12w_1</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_tg_1w_0</th>\n",
       "      <th>Dora</th>\n",
       "      <th>Piemonte_Nord</th>\n",
       "      <th>Piemonte_Sud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.958059</td>\n",
       "      <td>-1.692206</td>\n",
       "      <td>-0.181114</td>\n",
       "      <td>-1.852227</td>\n",
       "      <td>-1.694637</td>\n",
       "      <td>-0.483868</td>\n",
       "      <td>0.531161</td>\n",
       "      <td>-0.070058</td>\n",
       "      <td>-0.705198</td>\n",
       "      <td>-0.039471</td>\n",
       "      <td>-0.449672</td>\n",
       "      <td>3.146477</td>\n",
       "      <td>1.939769</td>\n",
       "      <td>3.863262</td>\n",
       "      <td>-0.551685</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.064877</td>\n",
       "      <td>-0.279226</td>\n",
       "      <td>0.886182</td>\n",
       "      <td>-0.351196</td>\n",
       "      <td>0.267105</td>\n",
       "      <td>0.673096</td>\n",
       "      <td>1.141736</td>\n",
       "      <td>0.669777</td>\n",
       "      <td>-0.040533</td>\n",
       "      <td>0.697310</td>\n",
       "      <td>0.880344</td>\n",
       "      <td>3.822355</td>\n",
       "      <td>2.431148</td>\n",
       "      <td>4.345114</td>\n",
       "      <td>0.256218</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.002116</td>\n",
       "      <td>-1.256740</td>\n",
       "      <td>0.223731</td>\n",
       "      <td>-2.234919</td>\n",
       "      <td>-1.713098</td>\n",
       "      <td>-0.898083</td>\n",
       "      <td>0.600533</td>\n",
       "      <td>0.518292</td>\n",
       "      <td>-0.312340</td>\n",
       "      <td>0.527444</td>\n",
       "      <td>-0.833249</td>\n",
       "      <td>2.115109</td>\n",
       "      <td>1.348554</td>\n",
       "      <td>2.533689</td>\n",
       "      <td>0.029187</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.601101</td>\n",
       "      <td>-0.825053</td>\n",
       "      <td>0.383765</td>\n",
       "      <td>-1.590347</td>\n",
       "      <td>-0.953714</td>\n",
       "      <td>0.358463</td>\n",
       "      <td>0.613627</td>\n",
       "      <td>0.245062</td>\n",
       "      <td>-0.434823</td>\n",
       "      <td>0.271867</td>\n",
       "      <td>0.865639</td>\n",
       "      <td>2.006293</td>\n",
       "      <td>1.282061</td>\n",
       "      <td>2.314067</td>\n",
       "      <td>0.023661</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.789653</td>\n",
       "      <td>-1.182962</td>\n",
       "      <td>0.295643</td>\n",
       "      <td>-1.665547</td>\n",
       "      <td>-1.374058</td>\n",
       "      <td>-0.555381</td>\n",
       "      <td>0.408259</td>\n",
       "      <td>0.468525</td>\n",
       "      <td>-0.286705</td>\n",
       "      <td>0.537510</td>\n",
       "      <td>-0.246418</td>\n",
       "      <td>1.307787</td>\n",
       "      <td>0.836693</td>\n",
       "      <td>1.603089</td>\n",
       "      <td>0.376389</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>0.807565</td>\n",
       "      <td>1.079275</td>\n",
       "      <td>-0.712766</td>\n",
       "      <td>1.021359</td>\n",
       "      <td>0.953999</td>\n",
       "      <td>0.862196</td>\n",
       "      <td>-0.938846</td>\n",
       "      <td>0.949782</td>\n",
       "      <td>1.346423</td>\n",
       "      <td>0.952736</td>\n",
       "      <td>1.374448</td>\n",
       "      <td>-0.767792</td>\n",
       "      <td>-0.476107</td>\n",
       "      <td>-0.467565</td>\n",
       "      <td>1.427917</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>1.020805</td>\n",
       "      <td>0.749908</td>\n",
       "      <td>-0.597343</td>\n",
       "      <td>1.000397</td>\n",
       "      <td>0.900047</td>\n",
       "      <td>-0.160042</td>\n",
       "      <td>-0.559070</td>\n",
       "      <td>0.569543</td>\n",
       "      <td>0.509539</td>\n",
       "      <td>0.579810</td>\n",
       "      <td>-0.119108</td>\n",
       "      <td>-0.482430</td>\n",
       "      <td>-0.420562</td>\n",
       "      <td>0.030758</td>\n",
       "      <td>0.760111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.910086</td>\n",
       "      <td>0.754701</td>\n",
       "      <td>-0.152386</td>\n",
       "      <td>0.925106</td>\n",
       "      <td>0.802985</td>\n",
       "      <td>0.528382</td>\n",
       "      <td>-0.113738</td>\n",
       "      <td>0.111790</td>\n",
       "      <td>0.236097</td>\n",
       "      <td>0.086513</td>\n",
       "      <td>0.643035</td>\n",
       "      <td>-0.396456</td>\n",
       "      <td>-0.215110</td>\n",
       "      <td>0.110519</td>\n",
       "      <td>0.315694</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>0.237759</td>\n",
       "      <td>0.155479</td>\n",
       "      <td>-0.396304</td>\n",
       "      <td>0.610253</td>\n",
       "      <td>0.441811</td>\n",
       "      <td>-2.715411</td>\n",
       "      <td>-0.253229</td>\n",
       "      <td>-1.115423</td>\n",
       "      <td>-1.353830</td>\n",
       "      <td>-1.099133</td>\n",
       "      <td>-2.247923</td>\n",
       "      <td>-0.311937</td>\n",
       "      <td>-0.353737</td>\n",
       "      <td>0.230804</td>\n",
       "      <td>-0.971253</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-0.182408</td>\n",
       "      <td>0.098752</td>\n",
       "      <td>0.173050</td>\n",
       "      <td>0.674977</td>\n",
       "      <td>0.536299</td>\n",
       "      <td>0.147712</td>\n",
       "      <td>0.301057</td>\n",
       "      <td>-1.606865</td>\n",
       "      <td>-1.553763</td>\n",
       "      <td>-1.579153</td>\n",
       "      <td>-0.167457</td>\n",
       "      <td>-0.130149</td>\n",
       "      <td>0.044753</td>\n",
       "      <td>0.566531</td>\n",
       "      <td>-1.460435</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1233 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dora_cyclostationary_mean_tg_4w_1  Dora_cyclostationary_mean_tg_12w_0  \\\n",
       "0                            -0.958059                           -1.692206   \n",
       "1                             0.064877                           -0.279226   \n",
       "2                            -1.002116                           -1.256740   \n",
       "3                            -0.601101                           -0.825053   \n",
       "4                            -0.789653                           -1.182962   \n",
       "..                                 ...                                 ...   \n",
       "406                           0.807565                            1.079275   \n",
       "407                           1.020805                            0.749908   \n",
       "408                           0.910086                            0.754701   \n",
       "409                           0.237759                            0.155479   \n",
       "410                          -0.182408                            0.098752   \n",
       "\n",
       "     Dora_cyclostationary_mean_rr_4w_0  Dora_cyclostationary_mean_tg_24w_1  \\\n",
       "0                            -0.181114                           -1.852227   \n",
       "1                             0.886182                           -0.351196   \n",
       "2                             0.223731                           -2.234919   \n",
       "3                             0.383765                           -1.590347   \n",
       "4                             0.295643                           -1.665547   \n",
       "..                                 ...                                 ...   \n",
       "406                          -0.712766                            1.021359   \n",
       "407                          -0.597343                            1.000397   \n",
       "408                          -0.152386                            0.925106   \n",
       "409                          -0.396304                            0.610253   \n",
       "410                           0.173050                            0.674977   \n",
       "\n",
       "     Dora_cyclostationary_mean_tg_24w_2  \\\n",
       "0                             -1.694637   \n",
       "1                              0.267105   \n",
       "2                             -1.713098   \n",
       "3                             -0.953714   \n",
       "4                             -1.374058   \n",
       "..                                  ...   \n",
       "406                            0.953999   \n",
       "407                            0.900047   \n",
       "408                            0.802985   \n",
       "409                            0.441811   \n",
       "410                            0.536299   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_3  \\\n",
       "0                                  -0.483868   \n",
       "1                                   0.673096   \n",
       "2                                  -0.898083   \n",
       "3                                   0.358463   \n",
       "4                                  -0.555381   \n",
       "..                                       ...   \n",
       "406                                 0.862196   \n",
       "407                                -0.160042   \n",
       "408                                 0.528382   \n",
       "409                                -2.715411   \n",
       "410                                 0.147712   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_rr_4w_0  \\\n",
       "0                                      0.531161   \n",
       "1                                      1.141736   \n",
       "2                                      0.600533   \n",
       "3                                      0.613627   \n",
       "4                                      0.408259   \n",
       "..                                          ...   \n",
       "406                                   -0.938846   \n",
       "407                                   -0.559070   \n",
       "408                                   -0.113738   \n",
       "409                                   -0.253229   \n",
       "410                                    0.301057   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_1w_1  \\\n",
       "0                                     -0.070058   \n",
       "1                                      0.669777   \n",
       "2                                      0.518292   \n",
       "3                                      0.245062   \n",
       "4                                      0.468525   \n",
       "..                                          ...   \n",
       "406                                    0.949782   \n",
       "407                                    0.569543   \n",
       "408                                    0.111790   \n",
       "409                                   -1.115423   \n",
       "410                                   -1.606865   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_1w_3  \\\n",
       "0                                     -0.705198   \n",
       "1                                     -0.040533   \n",
       "2                                     -0.312340   \n",
       "3                                     -0.434823   \n",
       "4                                     -0.286705   \n",
       "..                                          ...   \n",
       "406                                    1.346423   \n",
       "407                                    0.509539   \n",
       "408                                    0.236097   \n",
       "409                                   -1.353830   \n",
       "410                                   -1.553763   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_1w_4  \\\n",
       "0                                     -0.039471   \n",
       "1                                      0.697310   \n",
       "2                                      0.527444   \n",
       "3                                      0.271867   \n",
       "4                                      0.537510   \n",
       "..                                          ...   \n",
       "406                                    0.952736   \n",
       "407                                    0.579810   \n",
       "408                                    0.086513   \n",
       "409                                   -1.099133   \n",
       "410                                   -1.579153   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_tg_0  \\\n",
       "0                                 -0.449672   \n",
       "1                                  0.880344   \n",
       "2                                 -0.833249   \n",
       "3                                  0.865639   \n",
       "4                                 -0.246418   \n",
       "..                                      ...   \n",
       "406                                1.374448   \n",
       "407                               -0.119108   \n",
       "408                                0.643035   \n",
       "409                               -2.247923   \n",
       "410                               -0.167457   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_24w_0  \\\n",
       "0                                      3.146477   \n",
       "1                                      3.822355   \n",
       "2                                      2.115109   \n",
       "3                                      2.006293   \n",
       "4                                      1.307787   \n",
       "..                                          ...   \n",
       "406                                   -0.767792   \n",
       "407                                   -0.482430   \n",
       "408                                   -0.396456   \n",
       "409                                   -0.311937   \n",
       "410                                   -0.130149   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_8w_0  \\\n",
       "0                                     1.939769   \n",
       "1                                     2.431148   \n",
       "2                                     1.348554   \n",
       "3                                     1.282061   \n",
       "4                                     0.836693   \n",
       "..                                         ...   \n",
       "406                                  -0.476107   \n",
       "407                                  -0.420562   \n",
       "408                                  -0.215110   \n",
       "409                                  -0.353737   \n",
       "410                                   0.044753   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_12w_1  \\\n",
       "0                                      3.863262   \n",
       "1                                      4.345114   \n",
       "2                                      2.533689   \n",
       "3                                      2.314067   \n",
       "4                                      1.603089   \n",
       "..                                          ...   \n",
       "406                                   -0.467565   \n",
       "407                                    0.030758   \n",
       "408                                    0.110519   \n",
       "409                                    0.230804   \n",
       "410                                    0.566531   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_tg_1w_0  Dora  Piemonte_Nord  \\\n",
       "0                                    -0.551685     1              0   \n",
       "1                                     0.256218     1              0   \n",
       "2                                     0.029187     1              0   \n",
       "3                                     0.023661     1              0   \n",
       "4                                     0.376389     1              0   \n",
       "..                                         ...   ...            ...   \n",
       "406                                   1.427917     0              0   \n",
       "407                                   0.760111     0              0   \n",
       "408                                   0.315694     0              0   \n",
       "409                                  -0.971253     0              0   \n",
       "410                                  -1.460435     0              0   \n",
       "\n",
       "     Piemonte_Sud  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "..            ...  \n",
       "406             1  \n",
       "407             1  \n",
       "408             1  \n",
       "409             1  \n",
       "410             1  \n",
       "\n",
       "[1233 rows x 18 columns]"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterdf_train_withClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "15a20e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_df_train_unfolded = pd.DataFrame()\n",
    "targets_df_val_unfolded = pd.DataFrame()\n",
    "targets_df_test_unfolded = pd.DataFrame()\n",
    "\n",
    "for basin in clust_basins:\n",
    "    targets_df_train_unfolded =  pd.concat((targets_df_train_unfolded,targets_df_train[basin]),axis=0)\n",
    "    targets_df_val_unfolded =  pd.concat((targets_df_val_unfolded,targets_df_val[basin]),axis=0)\n",
    "    targets_df_test_unfolded =  pd.concat((targets_df_test_unfolded,targets_df_test[basin]),axis=0)\n",
    "targets_df_train_unfolded = targets_df_train_unfolded.reset_index(drop=True)\n",
    "targets_df_val_unfolded = targets_df_val_unfolded.reset_index(drop=True)\n",
    "targets_df_test_unfolded = targets_df_test_unfolded.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "cbcadb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.6392008270590532\n",
      "-0.4196218844269948\n",
      "-0.49841482385224056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_DPNPS_ohe = LinearRegression()\n",
    "model_DPNPS_ohe.fit(pd.concat((clusterdf_train_withClass,clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_DPNPS_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Dora==1].values)\n",
    "print(r2_score(targets_df_test['Dora'].values, res))\n",
    "res = model_DPNPS_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Piemonte_Nord==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Nord'].values, res))\n",
    "res = model_DPNPS_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Piemonte_Sud==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Sud'].values, res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "47a4cece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.01504430512315813\n",
      "0.13117472371892347\n",
      "0.05676185616132012\n",
      "-0.03601767681354562\n",
      "-0.005255834060018172\n",
      "-0.0031161954632632494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but Lasso was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but Lasso was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but Lasso was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "### Ridge and Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "model_DPNPS_ridge = Ridge(alpha=1000.0)\n",
    "model_DPNPS_ridge.fit(pd.concat((clusterdf_train_withClass,clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_DPNPS_ridge.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Dora==1].values)\n",
    "print(r2_score(targets_df_test['Dora'].values, res))\n",
    "res = model_DPNPS_ridge.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Piemonte_Nord==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Nord'].values, res))\n",
    "res = model_DPNPS_ridge.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Piemonte_Sud==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Sud'].values, res))\n",
    "\n",
    "### Ridge and Lasso\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "model_DPNPS_Lasso = Lasso(alpha=1.0)\n",
    "model_DPNPS_Lasso.fit(pd.concat((clusterdf_train_withClass,clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_DPNPS_Lasso.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Dora==1].values)\n",
    "print(r2_score(targets_df_test['Dora'].values, res))\n",
    "res = model_DPNPS_Lasso.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Piemonte_Nord==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Nord'].values, res))\n",
    "res = model_DPNPS_Lasso.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Piemonte_Sud==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Sud'].values, res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "f2ccda3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02711149, -0.03885853,  0.07353019,  0.07686813,  0.02255927,\n",
       "        -0.09960836,  0.0584774 , -0.03485143, -0.06731712, -0.02067332,\n",
       "        -0.06599726,  0.09936724, -0.00150094, -0.02554435, -0.0359069 ,\n",
       "        -0.01003827,  0.0052231 ,  0.00481518]])"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_DPNPS_ridge.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "b1ea21d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2d0f140d0>]"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(targets_df_test['Piemonte_Sud'].values)\n",
    "plt.plot(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "ba9a9bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dora_cyclostationary_mean_tg_4w_1</th>\n",
       "      <th>Dora_cyclostationary_mean_tg_12w_0</th>\n",
       "      <th>Dora_cyclostationary_mean_rr_4w_0</th>\n",
       "      <th>Dora_cyclostationary_mean_tg_24w_1</th>\n",
       "      <th>Dora_cyclostationary_mean_tg_24w_2</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_3</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_rr_4w_0</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_1w_1</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_1w_3</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_1w_4</th>\n",
       "      <th>...</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_24w_0_Piemonte_Sud</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_8w_0_Dora</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_8w_0_Piemonte_Nord</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_8w_0_Piemonte_Sud</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_12w_1_Dora</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_12w_1_Piemonte_Nord</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_12w_1_Piemonte_Sud</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_tg_1w_0_Dora</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_tg_1w_0_Piemonte_Nord</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_tg_1w_0_Piemonte_Sud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.958059</td>\n",
       "      <td>-1.692206</td>\n",
       "      <td>-0.181114</td>\n",
       "      <td>-1.852227</td>\n",
       "      <td>-1.694637</td>\n",
       "      <td>-0.483868</td>\n",
       "      <td>0.531161</td>\n",
       "      <td>-0.070058</td>\n",
       "      <td>-0.705198</td>\n",
       "      <td>-0.039471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.939769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.863262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.551685</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.064877</td>\n",
       "      <td>-0.279226</td>\n",
       "      <td>0.886182</td>\n",
       "      <td>-0.351196</td>\n",
       "      <td>0.267105</td>\n",
       "      <td>0.673096</td>\n",
       "      <td>1.141736</td>\n",
       "      <td>0.669777</td>\n",
       "      <td>-0.040533</td>\n",
       "      <td>0.697310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.431148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.345114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.256218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.002116</td>\n",
       "      <td>-1.256740</td>\n",
       "      <td>0.223731</td>\n",
       "      <td>-2.234919</td>\n",
       "      <td>-1.713098</td>\n",
       "      <td>-0.898083</td>\n",
       "      <td>0.600533</td>\n",
       "      <td>0.518292</td>\n",
       "      <td>-0.312340</td>\n",
       "      <td>0.527444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.348554</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.533689</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.601101</td>\n",
       "      <td>-0.825053</td>\n",
       "      <td>0.383765</td>\n",
       "      <td>-1.590347</td>\n",
       "      <td>-0.953714</td>\n",
       "      <td>0.358463</td>\n",
       "      <td>0.613627</td>\n",
       "      <td>0.245062</td>\n",
       "      <td>-0.434823</td>\n",
       "      <td>0.271867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.282061</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.314067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023661</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.789653</td>\n",
       "      <td>-1.182962</td>\n",
       "      <td>0.295643</td>\n",
       "      <td>-1.665547</td>\n",
       "      <td>-1.374058</td>\n",
       "      <td>-0.555381</td>\n",
       "      <td>0.408259</td>\n",
       "      <td>0.468525</td>\n",
       "      <td>-0.286705</td>\n",
       "      <td>0.537510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.836693</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.603089</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.376389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>0.807565</td>\n",
       "      <td>1.079275</td>\n",
       "      <td>-0.712766</td>\n",
       "      <td>1.021359</td>\n",
       "      <td>0.953999</td>\n",
       "      <td>0.862196</td>\n",
       "      <td>-0.938846</td>\n",
       "      <td>0.949782</td>\n",
       "      <td>1.346423</td>\n",
       "      <td>0.952736</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.767792</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.476107</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.467565</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.427917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>1.020805</td>\n",
       "      <td>0.749908</td>\n",
       "      <td>-0.597343</td>\n",
       "      <td>1.000397</td>\n",
       "      <td>0.900047</td>\n",
       "      <td>-0.160042</td>\n",
       "      <td>-0.559070</td>\n",
       "      <td>0.569543</td>\n",
       "      <td>0.509539</td>\n",
       "      <td>0.579810</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.482430</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.420562</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.760111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.910086</td>\n",
       "      <td>0.754701</td>\n",
       "      <td>-0.152386</td>\n",
       "      <td>0.925106</td>\n",
       "      <td>0.802985</td>\n",
       "      <td>0.528382</td>\n",
       "      <td>-0.113738</td>\n",
       "      <td>0.111790</td>\n",
       "      <td>0.236097</td>\n",
       "      <td>0.086513</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.396456</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.215110</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.110519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.315694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>0.237759</td>\n",
       "      <td>0.155479</td>\n",
       "      <td>-0.396304</td>\n",
       "      <td>0.610253</td>\n",
       "      <td>0.441811</td>\n",
       "      <td>-2.715411</td>\n",
       "      <td>-0.253229</td>\n",
       "      <td>-1.115423</td>\n",
       "      <td>-1.353830</td>\n",
       "      <td>-1.099133</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.311937</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.353737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.230804</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.971253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-0.182408</td>\n",
       "      <td>0.098752</td>\n",
       "      <td>0.173050</td>\n",
       "      <td>0.674977</td>\n",
       "      <td>0.536299</td>\n",
       "      <td>0.147712</td>\n",
       "      <td>0.301057</td>\n",
       "      <td>-1.606865</td>\n",
       "      <td>-1.553763</td>\n",
       "      <td>-1.579153</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.130149</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.566531</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-1.460435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1233 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dora_cyclostationary_mean_tg_4w_1  Dora_cyclostationary_mean_tg_12w_0  \\\n",
       "0                            -0.958059                           -1.692206   \n",
       "1                             0.064877                           -0.279226   \n",
       "2                            -1.002116                           -1.256740   \n",
       "3                            -0.601101                           -0.825053   \n",
       "4                            -0.789653                           -1.182962   \n",
       "..                                 ...                                 ...   \n",
       "406                           0.807565                            1.079275   \n",
       "407                           1.020805                            0.749908   \n",
       "408                           0.910086                            0.754701   \n",
       "409                           0.237759                            0.155479   \n",
       "410                          -0.182408                            0.098752   \n",
       "\n",
       "     Dora_cyclostationary_mean_rr_4w_0  Dora_cyclostationary_mean_tg_24w_1  \\\n",
       "0                            -0.181114                           -1.852227   \n",
       "1                             0.886182                           -0.351196   \n",
       "2                             0.223731                           -2.234919   \n",
       "3                             0.383765                           -1.590347   \n",
       "4                             0.295643                           -1.665547   \n",
       "..                                 ...                                 ...   \n",
       "406                          -0.712766                            1.021359   \n",
       "407                          -0.597343                            1.000397   \n",
       "408                          -0.152386                            0.925106   \n",
       "409                          -0.396304                            0.610253   \n",
       "410                           0.173050                            0.674977   \n",
       "\n",
       "     Dora_cyclostationary_mean_tg_24w_2  \\\n",
       "0                             -1.694637   \n",
       "1                              0.267105   \n",
       "2                             -1.713098   \n",
       "3                             -0.953714   \n",
       "4                             -1.374058   \n",
       "..                                  ...   \n",
       "406                            0.953999   \n",
       "407                            0.900047   \n",
       "408                            0.802985   \n",
       "409                            0.441811   \n",
       "410                            0.536299   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_3  \\\n",
       "0                                  -0.483868   \n",
       "1                                   0.673096   \n",
       "2                                  -0.898083   \n",
       "3                                   0.358463   \n",
       "4                                  -0.555381   \n",
       "..                                       ...   \n",
       "406                                 0.862196   \n",
       "407                                -0.160042   \n",
       "408                                 0.528382   \n",
       "409                                -2.715411   \n",
       "410                                 0.147712   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_rr_4w_0  \\\n",
       "0                                      0.531161   \n",
       "1                                      1.141736   \n",
       "2                                      0.600533   \n",
       "3                                      0.613627   \n",
       "4                                      0.408259   \n",
       "..                                          ...   \n",
       "406                                   -0.938846   \n",
       "407                                   -0.559070   \n",
       "408                                   -0.113738   \n",
       "409                                   -0.253229   \n",
       "410                                    0.301057   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_1w_1  \\\n",
       "0                                     -0.070058   \n",
       "1                                      0.669777   \n",
       "2                                      0.518292   \n",
       "3                                      0.245062   \n",
       "4                                      0.468525   \n",
       "..                                          ...   \n",
       "406                                    0.949782   \n",
       "407                                    0.569543   \n",
       "408                                    0.111790   \n",
       "409                                   -1.115423   \n",
       "410                                   -1.606865   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_1w_3  \\\n",
       "0                                     -0.705198   \n",
       "1                                     -0.040533   \n",
       "2                                     -0.312340   \n",
       "3                                     -0.434823   \n",
       "4                                     -0.286705   \n",
       "..                                          ...   \n",
       "406                                    1.346423   \n",
       "407                                    0.509539   \n",
       "408                                    0.236097   \n",
       "409                                   -1.353830   \n",
       "410                                   -1.553763   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_1w_4  ...  \\\n",
       "0                                     -0.039471  ...   \n",
       "1                                      0.697310  ...   \n",
       "2                                      0.527444  ...   \n",
       "3                                      0.271867  ...   \n",
       "4                                      0.537510  ...   \n",
       "..                                          ...  ...   \n",
       "406                                    0.952736  ...   \n",
       "407                                    0.579810  ...   \n",
       "408                                    0.086513  ...   \n",
       "409                                   -1.099133  ...   \n",
       "410                                   -1.579153  ...   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_24w_0_Piemonte_Sud  \\\n",
       "0                                             0.000000         \n",
       "1                                             0.000000         \n",
       "2                                             0.000000         \n",
       "3                                             0.000000         \n",
       "4                                             0.000000         \n",
       "..                                                 ...         \n",
       "406                                          -0.767792         \n",
       "407                                          -0.482430         \n",
       "408                                          -0.396456         \n",
       "409                                          -0.311937         \n",
       "410                                          -0.130149         \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_8w_0_Dora  \\\n",
       "0                                          1.939769   \n",
       "1                                          2.431148   \n",
       "2                                          1.348554   \n",
       "3                                          1.282061   \n",
       "4                                          0.836693   \n",
       "..                                              ...   \n",
       "406                                       -0.000000   \n",
       "407                                       -0.000000   \n",
       "408                                       -0.000000   \n",
       "409                                       -0.000000   \n",
       "410                                        0.000000   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_8w_0_Piemonte_Nord  \\\n",
       "0                                                  0.0         \n",
       "1                                                  0.0         \n",
       "2                                                  0.0         \n",
       "3                                                  0.0         \n",
       "4                                                  0.0         \n",
       "..                                                 ...         \n",
       "406                                               -0.0         \n",
       "407                                               -0.0         \n",
       "408                                               -0.0         \n",
       "409                                               -0.0         \n",
       "410                                                0.0         \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_8w_0_Piemonte_Sud  \\\n",
       "0                                             0.000000        \n",
       "1                                             0.000000        \n",
       "2                                             0.000000        \n",
       "3                                             0.000000        \n",
       "4                                             0.000000        \n",
       "..                                                 ...        \n",
       "406                                          -0.476107        \n",
       "407                                          -0.420562        \n",
       "408                                          -0.215110        \n",
       "409                                          -0.353737        \n",
       "410                                           0.044753        \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_12w_1_Dora  \\\n",
       "0                                           3.863262   \n",
       "1                                           4.345114   \n",
       "2                                           2.533689   \n",
       "3                                           2.314067   \n",
       "4                                           1.603089   \n",
       "..                                               ...   \n",
       "406                                        -0.000000   \n",
       "407                                         0.000000   \n",
       "408                                         0.000000   \n",
       "409                                         0.000000   \n",
       "410                                         0.000000   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_12w_1_Piemonte_Nord  \\\n",
       "0                                                  0.0          \n",
       "1                                                  0.0          \n",
       "2                                                  0.0          \n",
       "3                                                  0.0          \n",
       "4                                                  0.0          \n",
       "..                                                 ...          \n",
       "406                                               -0.0          \n",
       "407                                                0.0          \n",
       "408                                                0.0          \n",
       "409                                                0.0          \n",
       "410                                                0.0          \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_12w_1_Piemonte_Sud  \\\n",
       "0                                             0.000000         \n",
       "1                                             0.000000         \n",
       "2                                             0.000000         \n",
       "3                                             0.000000         \n",
       "4                                             0.000000         \n",
       "..                                                 ...         \n",
       "406                                          -0.467565         \n",
       "407                                           0.030758         \n",
       "408                                           0.110519         \n",
       "409                                           0.230804         \n",
       "410                                           0.566531         \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_tg_1w_0_Dora  \\\n",
       "0                                         -0.551685   \n",
       "1                                          0.256218   \n",
       "2                                          0.029187   \n",
       "3                                          0.023661   \n",
       "4                                          0.376389   \n",
       "..                                              ...   \n",
       "406                                        0.000000   \n",
       "407                                        0.000000   \n",
       "408                                        0.000000   \n",
       "409                                       -0.000000   \n",
       "410                                       -0.000000   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_tg_1w_0_Piemonte_Nord  \\\n",
       "0                                                 -0.0         \n",
       "1                                                  0.0         \n",
       "2                                                  0.0         \n",
       "3                                                  0.0         \n",
       "4                                                  0.0         \n",
       "..                                                 ...         \n",
       "406                                                0.0         \n",
       "407                                                0.0         \n",
       "408                                                0.0         \n",
       "409                                               -0.0         \n",
       "410                                               -0.0         \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_tg_1w_0_Piemonte_Sud  \n",
       "0                                            -0.000000       \n",
       "1                                             0.000000       \n",
       "2                                             0.000000       \n",
       "3                                             0.000000       \n",
       "4                                             0.000000       \n",
       "..                                                 ...       \n",
       "406                                           1.427917       \n",
       "407                                           0.760111       \n",
       "408                                           0.315694       \n",
       "409                                          -0.971253       \n",
       "410                                          -1.460435       \n",
       "\n",
       "[1233 rows x 63 columns]"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(clusterdf_train_withClass.shape[1]-len(clust_basins)):\n",
    "    for j in clust_basins:\n",
    "        clusterdf_train_withClass[clusterdf_train_withClass.columns[i]+'_'+j] = clusterdf_train_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "        clusterdf_val_withClass[clusterdf_val_withClass.columns[i]+'_'+j] = clusterdf_val_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "        clusterdf_test_withClass[clusterdf_test_withClass.columns[i]+'_'+j] = clusterdf_test_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "\n",
    "clusterdf_train_withClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "dde60360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.4233289032849736\n",
      "-0.18216047822349557\n",
      "-0.3055385087801512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_DPNPS_ohe = LinearRegression()\n",
    "model_DPNPS_ohe.fit(pd.concat((clusterdf_train_withClass,clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_DPNPS_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Dora==1].values)\n",
    "print(r2_score(targets_df_test['Dora'].values, res))\n",
    "res = model_DPNPS_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Piemonte_Nord==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Nord'].values, res))\n",
    "res = model_DPNPS_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Piemonte_Sud==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Sud'].values, res))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a00950",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Piemonte_Nord - Piemonte_Sud: CMI best 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "1207333f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "clust_basins = ['Piemonte_Nord', 'Piemonte_Sud']\n",
    "colnames = [x for x in best5_CMI_fulldf_train.columns if x.startswith('Piemonte_Nord') or x.startswith('Piemonte_Sud')]\n",
    "\n",
    "clusterdf_train_withClass = pd.DataFrame()\n",
    "clusterdf_val_withClass = pd.DataFrame()\n",
    "clusterdf_test_withClass = pd.DataFrame()\n",
    "\n",
    "for i in range(len(clust_basins)):\n",
    "    clusterdf_train_withClass = pd.concat((clusterdf_train_withClass,pd.concat((best5_CMI_fulldf_train[colnames],pd.DataFrame(1+i*np.ones(len(best5_CMI_fulldf_train)),columns=['basin'])),axis=1)),axis=0)\n",
    "    clusterdf_val_withClass = pd.concat((clusterdf_val_withClass,pd.concat((best5_CMI_fulldf_val[colnames],pd.DataFrame(1+i*np.ones(len(best5_CMI_fulldf_val)),columns=['basin'])),axis=1)),axis=0)\n",
    "    clusterdf_test_withClass = pd.concat((clusterdf_test_withClass,pd.concat((best5_CMI_fulldf_test[colnames],pd.DataFrame(1+i*np.ones(len(best5_CMI_fulldf_test)),columns=['basin'])),axis=1)),axis=0)\n",
    "\n",
    "for i in range(len(clust_basins)):\n",
    "    clusterdf_train_withClass[clust_basins[i]] = clusterdf_train_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    clusterdf_val_withClass[clust_basins[i]] = clusterdf_val_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    clusterdf_test_withClass[clust_basins[i]] = clusterdf_test_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "\n",
    "clusterdf_train_withClass = clusterdf_train_withClass.loc[:,clusterdf_train_withClass.columns != 'basin']\n",
    "clusterdf_val_withClass = clusterdf_val_withClass.loc[:,clusterdf_val_withClass.columns != 'basin']\n",
    "clusterdf_test_withClass = clusterdf_test_withClass.loc[:,clusterdf_test_withClass.columns != 'basin']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "588c324b",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_3</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_rr_4w_0</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_1w_1</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_1w_3</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_1w_4</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_tg_0</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_24w_0</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_8w_0</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_12w_1</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_tg_1w_0</th>\n",
       "      <th>Piemonte_Nord</th>\n",
       "      <th>Piemonte_Sud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.483868</td>\n",
       "      <td>0.531161</td>\n",
       "      <td>-0.070058</td>\n",
       "      <td>-0.705198</td>\n",
       "      <td>-0.039471</td>\n",
       "      <td>-0.449672</td>\n",
       "      <td>3.146477</td>\n",
       "      <td>1.939769</td>\n",
       "      <td>3.863262</td>\n",
       "      <td>-0.551685</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.673096</td>\n",
       "      <td>1.141736</td>\n",
       "      <td>0.669777</td>\n",
       "      <td>-0.040533</td>\n",
       "      <td>0.697310</td>\n",
       "      <td>0.880344</td>\n",
       "      <td>3.822355</td>\n",
       "      <td>2.431148</td>\n",
       "      <td>4.345114</td>\n",
       "      <td>0.256218</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.898083</td>\n",
       "      <td>0.600533</td>\n",
       "      <td>0.518292</td>\n",
       "      <td>-0.312340</td>\n",
       "      <td>0.527444</td>\n",
       "      <td>-0.833249</td>\n",
       "      <td>2.115109</td>\n",
       "      <td>1.348554</td>\n",
       "      <td>2.533689</td>\n",
       "      <td>0.029187</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.358463</td>\n",
       "      <td>0.613627</td>\n",
       "      <td>0.245062</td>\n",
       "      <td>-0.434823</td>\n",
       "      <td>0.271867</td>\n",
       "      <td>0.865639</td>\n",
       "      <td>2.006293</td>\n",
       "      <td>1.282061</td>\n",
       "      <td>2.314067</td>\n",
       "      <td>0.023661</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.555381</td>\n",
       "      <td>0.408259</td>\n",
       "      <td>0.468525</td>\n",
       "      <td>-0.286705</td>\n",
       "      <td>0.537510</td>\n",
       "      <td>-0.246418</td>\n",
       "      <td>1.307787</td>\n",
       "      <td>0.836693</td>\n",
       "      <td>1.603089</td>\n",
       "      <td>0.376389</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>0.862196</td>\n",
       "      <td>-0.938846</td>\n",
       "      <td>0.949782</td>\n",
       "      <td>1.346423</td>\n",
       "      <td>0.952736</td>\n",
       "      <td>1.374448</td>\n",
       "      <td>-0.767792</td>\n",
       "      <td>-0.476107</td>\n",
       "      <td>-0.467565</td>\n",
       "      <td>1.427917</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>-0.160042</td>\n",
       "      <td>-0.559070</td>\n",
       "      <td>0.569543</td>\n",
       "      <td>0.509539</td>\n",
       "      <td>0.579810</td>\n",
       "      <td>-0.119108</td>\n",
       "      <td>-0.482430</td>\n",
       "      <td>-0.420562</td>\n",
       "      <td>0.030758</td>\n",
       "      <td>0.760111</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.528382</td>\n",
       "      <td>-0.113738</td>\n",
       "      <td>0.111790</td>\n",
       "      <td>0.236097</td>\n",
       "      <td>0.086513</td>\n",
       "      <td>0.643035</td>\n",
       "      <td>-0.396456</td>\n",
       "      <td>-0.215110</td>\n",
       "      <td>0.110519</td>\n",
       "      <td>0.315694</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>-2.715411</td>\n",
       "      <td>-0.253229</td>\n",
       "      <td>-1.115423</td>\n",
       "      <td>-1.353830</td>\n",
       "      <td>-1.099133</td>\n",
       "      <td>-2.247923</td>\n",
       "      <td>-0.311937</td>\n",
       "      <td>-0.353737</td>\n",
       "      <td>0.230804</td>\n",
       "      <td>-0.971253</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>0.147712</td>\n",
       "      <td>0.301057</td>\n",
       "      <td>-1.606865</td>\n",
       "      <td>-1.553763</td>\n",
       "      <td>-1.579153</td>\n",
       "      <td>-0.167457</td>\n",
       "      <td>-0.130149</td>\n",
       "      <td>0.044753</td>\n",
       "      <td>0.566531</td>\n",
       "      <td>-1.460435</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>822 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Piemonte_Nord_cyclostationary_mean_tg_3  \\\n",
       "0                                  -0.483868   \n",
       "1                                   0.673096   \n",
       "2                                  -0.898083   \n",
       "3                                   0.358463   \n",
       "4                                  -0.555381   \n",
       "..                                       ...   \n",
       "406                                 0.862196   \n",
       "407                                -0.160042   \n",
       "408                                 0.528382   \n",
       "409                                -2.715411   \n",
       "410                                 0.147712   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_rr_4w_0  \\\n",
       "0                                      0.531161   \n",
       "1                                      1.141736   \n",
       "2                                      0.600533   \n",
       "3                                      0.613627   \n",
       "4                                      0.408259   \n",
       "..                                          ...   \n",
       "406                                   -0.938846   \n",
       "407                                   -0.559070   \n",
       "408                                   -0.113738   \n",
       "409                                   -0.253229   \n",
       "410                                    0.301057   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_1w_1  \\\n",
       "0                                     -0.070058   \n",
       "1                                      0.669777   \n",
       "2                                      0.518292   \n",
       "3                                      0.245062   \n",
       "4                                      0.468525   \n",
       "..                                          ...   \n",
       "406                                    0.949782   \n",
       "407                                    0.569543   \n",
       "408                                    0.111790   \n",
       "409                                   -1.115423   \n",
       "410                                   -1.606865   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_1w_3  \\\n",
       "0                                     -0.705198   \n",
       "1                                     -0.040533   \n",
       "2                                     -0.312340   \n",
       "3                                     -0.434823   \n",
       "4                                     -0.286705   \n",
       "..                                          ...   \n",
       "406                                    1.346423   \n",
       "407                                    0.509539   \n",
       "408                                    0.236097   \n",
       "409                                   -1.353830   \n",
       "410                                   -1.553763   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_1w_4  \\\n",
       "0                                     -0.039471   \n",
       "1                                      0.697310   \n",
       "2                                      0.527444   \n",
       "3                                      0.271867   \n",
       "4                                      0.537510   \n",
       "..                                          ...   \n",
       "406                                    0.952736   \n",
       "407                                    0.579810   \n",
       "408                                    0.086513   \n",
       "409                                   -1.099133   \n",
       "410                                   -1.579153   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_tg_0  \\\n",
       "0                                 -0.449672   \n",
       "1                                  0.880344   \n",
       "2                                 -0.833249   \n",
       "3                                  0.865639   \n",
       "4                                 -0.246418   \n",
       "..                                      ...   \n",
       "406                                1.374448   \n",
       "407                               -0.119108   \n",
       "408                                0.643035   \n",
       "409                               -2.247923   \n",
       "410                               -0.167457   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_24w_0  \\\n",
       "0                                      3.146477   \n",
       "1                                      3.822355   \n",
       "2                                      2.115109   \n",
       "3                                      2.006293   \n",
       "4                                      1.307787   \n",
       "..                                          ...   \n",
       "406                                   -0.767792   \n",
       "407                                   -0.482430   \n",
       "408                                   -0.396456   \n",
       "409                                   -0.311937   \n",
       "410                                   -0.130149   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_8w_0  \\\n",
       "0                                     1.939769   \n",
       "1                                     2.431148   \n",
       "2                                     1.348554   \n",
       "3                                     1.282061   \n",
       "4                                     0.836693   \n",
       "..                                         ...   \n",
       "406                                  -0.476107   \n",
       "407                                  -0.420562   \n",
       "408                                  -0.215110   \n",
       "409                                  -0.353737   \n",
       "410                                   0.044753   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_12w_1  \\\n",
       "0                                      3.863262   \n",
       "1                                      4.345114   \n",
       "2                                      2.533689   \n",
       "3                                      2.314067   \n",
       "4                                      1.603089   \n",
       "..                                          ...   \n",
       "406                                   -0.467565   \n",
       "407                                    0.030758   \n",
       "408                                    0.110519   \n",
       "409                                    0.230804   \n",
       "410                                    0.566531   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_tg_1w_0  Piemonte_Nord  Piemonte_Sud  \n",
       "0                                    -0.551685              1             0  \n",
       "1                                     0.256218              1             0  \n",
       "2                                     0.029187              1             0  \n",
       "3                                     0.023661              1             0  \n",
       "4                                     0.376389              1             0  \n",
       "..                                         ...            ...           ...  \n",
       "406                                   1.427917              0             1  \n",
       "407                                   0.760111              0             1  \n",
       "408                                   0.315694              0             1  \n",
       "409                                  -0.971253              0             1  \n",
       "410                                  -1.460435              0             1  \n",
       "\n",
       "[822 rows x 12 columns]"
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterdf_train_withClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "28cd60f2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "targets_df_train_unfolded = pd.DataFrame()\n",
    "targets_df_val_unfolded = pd.DataFrame()\n",
    "targets_df_test_unfolded = pd.DataFrame()\n",
    "\n",
    "for basin in clust_basins:\n",
    "    targets_df_train_unfolded =  pd.concat((targets_df_train_unfolded,targets_df_train[basin]),axis=0)\n",
    "    targets_df_val_unfolded =  pd.concat((targets_df_val_unfolded,targets_df_val[basin]),axis=0)\n",
    "    targets_df_test_unfolded =  pd.concat((targets_df_test_unfolded,targets_df_test[basin]),axis=0)\n",
    "targets_df_train_unfolded = targets_df_train_unfolded.reset_index(drop=True)\n",
    "targets_df_val_unfolded = targets_df_val_unfolded.reset_index(drop=True)\n",
    "targets_df_test_unfolded = targets_df_test_unfolded.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "8d88b20f",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.146332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.371173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.379474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.099118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.292244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>-0.021388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>-0.086330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>0.576347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>0.146632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>-0.818877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>822 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0   -1.146332\n",
       "1    0.371173\n",
       "2    0.379474\n",
       "3   -0.099118\n",
       "4   -0.292244\n",
       "..        ...\n",
       "817 -0.021388\n",
       "818 -0.086330\n",
       "819  0.576347\n",
       "820  0.146632\n",
       "821 -0.818877\n",
       "\n",
       "[822 rows x 1 columns]"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_df_train_unfolded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "9fb82d0d",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06977081725961665\n",
      "-0.01398677438947682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_DPNPS_ohe = LinearRegression()\n",
    "model_DPNPS_ohe.fit(pd.concat((clusterdf_train_withClass,clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_DPNPS_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Piemonte_Nord==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Nord'].values, res))\n",
    "res = model_DPNPS_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Piemonte_Sud==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Sud'].values, res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858ef598",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "06befe0a",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_3</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_rr_4w_0</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_1w_1</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_1w_3</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_1w_4</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_tg_0</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_24w_0</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_8w_0</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_12w_1</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_tg_1w_0</th>\n",
       "      <th>...</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_tg_0_Piemonte_Nord</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_tg_0_Piemonte_Sud</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_24w_0_Piemonte_Nord</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_24w_0_Piemonte_Sud</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_8w_0_Piemonte_Nord</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_8w_0_Piemonte_Sud</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_12w_1_Piemonte_Nord</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_12w_1_Piemonte_Sud</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_tg_1w_0_Piemonte_Nord</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_tg_1w_0_Piemonte_Sud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.483868</td>\n",
       "      <td>0.531161</td>\n",
       "      <td>-0.070058</td>\n",
       "      <td>-0.705198</td>\n",
       "      <td>-0.039471</td>\n",
       "      <td>-0.449672</td>\n",
       "      <td>3.146477</td>\n",
       "      <td>1.939769</td>\n",
       "      <td>3.863262</td>\n",
       "      <td>-0.551685</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.449672</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>3.146477</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.939769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.863262</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.551685</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.673096</td>\n",
       "      <td>1.141736</td>\n",
       "      <td>0.669777</td>\n",
       "      <td>-0.040533</td>\n",
       "      <td>0.697310</td>\n",
       "      <td>0.880344</td>\n",
       "      <td>3.822355</td>\n",
       "      <td>2.431148</td>\n",
       "      <td>4.345114</td>\n",
       "      <td>0.256218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.880344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.822355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.431148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.345114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.256218</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.898083</td>\n",
       "      <td>0.600533</td>\n",
       "      <td>0.518292</td>\n",
       "      <td>-0.312340</td>\n",
       "      <td>0.527444</td>\n",
       "      <td>-0.833249</td>\n",
       "      <td>2.115109</td>\n",
       "      <td>1.348554</td>\n",
       "      <td>2.533689</td>\n",
       "      <td>0.029187</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.833249</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>2.115109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.348554</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.533689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029187</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.358463</td>\n",
       "      <td>0.613627</td>\n",
       "      <td>0.245062</td>\n",
       "      <td>-0.434823</td>\n",
       "      <td>0.271867</td>\n",
       "      <td>0.865639</td>\n",
       "      <td>2.006293</td>\n",
       "      <td>1.282061</td>\n",
       "      <td>2.314067</td>\n",
       "      <td>0.023661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.865639</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.006293</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.282061</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.314067</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023661</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.555381</td>\n",
       "      <td>0.408259</td>\n",
       "      <td>0.468525</td>\n",
       "      <td>-0.286705</td>\n",
       "      <td>0.537510</td>\n",
       "      <td>-0.246418</td>\n",
       "      <td>1.307787</td>\n",
       "      <td>0.836693</td>\n",
       "      <td>1.603089</td>\n",
       "      <td>0.376389</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.246418</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.307787</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.836693</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.603089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.376389</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>0.862196</td>\n",
       "      <td>-0.938846</td>\n",
       "      <td>0.949782</td>\n",
       "      <td>1.346423</td>\n",
       "      <td>0.952736</td>\n",
       "      <td>1.374448</td>\n",
       "      <td>-0.767792</td>\n",
       "      <td>-0.476107</td>\n",
       "      <td>-0.467565</td>\n",
       "      <td>1.427917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.374448</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.767792</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.476107</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.467565</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.427917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>-0.160042</td>\n",
       "      <td>-0.559070</td>\n",
       "      <td>0.569543</td>\n",
       "      <td>0.509539</td>\n",
       "      <td>0.579810</td>\n",
       "      <td>-0.119108</td>\n",
       "      <td>-0.482430</td>\n",
       "      <td>-0.420562</td>\n",
       "      <td>0.030758</td>\n",
       "      <td>0.760111</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.119108</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.482430</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.420562</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.760111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.528382</td>\n",
       "      <td>-0.113738</td>\n",
       "      <td>0.111790</td>\n",
       "      <td>0.236097</td>\n",
       "      <td>0.086513</td>\n",
       "      <td>0.643035</td>\n",
       "      <td>-0.396456</td>\n",
       "      <td>-0.215110</td>\n",
       "      <td>0.110519</td>\n",
       "      <td>0.315694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.643035</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.396456</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.215110</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.110519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.315694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>-2.715411</td>\n",
       "      <td>-0.253229</td>\n",
       "      <td>-1.115423</td>\n",
       "      <td>-1.353830</td>\n",
       "      <td>-1.099133</td>\n",
       "      <td>-2.247923</td>\n",
       "      <td>-0.311937</td>\n",
       "      <td>-0.353737</td>\n",
       "      <td>0.230804</td>\n",
       "      <td>-0.971253</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-2.247923</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.311937</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.353737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.230804</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.971253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>0.147712</td>\n",
       "      <td>0.301057</td>\n",
       "      <td>-1.606865</td>\n",
       "      <td>-1.553763</td>\n",
       "      <td>-1.579153</td>\n",
       "      <td>-0.167457</td>\n",
       "      <td>-0.130149</td>\n",
       "      <td>0.044753</td>\n",
       "      <td>0.566531</td>\n",
       "      <td>-1.460435</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.167457</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.130149</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.566531</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-1.460435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>822 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Piemonte_Nord_cyclostationary_mean_tg_3  \\\n",
       "0                                  -0.483868   \n",
       "1                                   0.673096   \n",
       "2                                  -0.898083   \n",
       "3                                   0.358463   \n",
       "4                                  -0.555381   \n",
       "..                                       ...   \n",
       "406                                 0.862196   \n",
       "407                                -0.160042   \n",
       "408                                 0.528382   \n",
       "409                                -2.715411   \n",
       "410                                 0.147712   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_rr_4w_0  \\\n",
       "0                                      0.531161   \n",
       "1                                      1.141736   \n",
       "2                                      0.600533   \n",
       "3                                      0.613627   \n",
       "4                                      0.408259   \n",
       "..                                          ...   \n",
       "406                                   -0.938846   \n",
       "407                                   -0.559070   \n",
       "408                                   -0.113738   \n",
       "409                                   -0.253229   \n",
       "410                                    0.301057   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_1w_1  \\\n",
       "0                                     -0.070058   \n",
       "1                                      0.669777   \n",
       "2                                      0.518292   \n",
       "3                                      0.245062   \n",
       "4                                      0.468525   \n",
       "..                                          ...   \n",
       "406                                    0.949782   \n",
       "407                                    0.569543   \n",
       "408                                    0.111790   \n",
       "409                                   -1.115423   \n",
       "410                                   -1.606865   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_1w_3  \\\n",
       "0                                     -0.705198   \n",
       "1                                     -0.040533   \n",
       "2                                     -0.312340   \n",
       "3                                     -0.434823   \n",
       "4                                     -0.286705   \n",
       "..                                          ...   \n",
       "406                                    1.346423   \n",
       "407                                    0.509539   \n",
       "408                                    0.236097   \n",
       "409                                   -1.353830   \n",
       "410                                   -1.553763   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_1w_4  \\\n",
       "0                                     -0.039471   \n",
       "1                                      0.697310   \n",
       "2                                      0.527444   \n",
       "3                                      0.271867   \n",
       "4                                      0.537510   \n",
       "..                                          ...   \n",
       "406                                    0.952736   \n",
       "407                                    0.579810   \n",
       "408                                    0.086513   \n",
       "409                                   -1.099133   \n",
       "410                                   -1.579153   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_tg_0  \\\n",
       "0                                 -0.449672   \n",
       "1                                  0.880344   \n",
       "2                                 -0.833249   \n",
       "3                                  0.865639   \n",
       "4                                 -0.246418   \n",
       "..                                      ...   \n",
       "406                                1.374448   \n",
       "407                               -0.119108   \n",
       "408                                0.643035   \n",
       "409                               -2.247923   \n",
       "410                               -0.167457   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_24w_0  \\\n",
       "0                                      3.146477   \n",
       "1                                      3.822355   \n",
       "2                                      2.115109   \n",
       "3                                      2.006293   \n",
       "4                                      1.307787   \n",
       "..                                          ...   \n",
       "406                                   -0.767792   \n",
       "407                                   -0.482430   \n",
       "408                                   -0.396456   \n",
       "409                                   -0.311937   \n",
       "410                                   -0.130149   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_8w_0  \\\n",
       "0                                     1.939769   \n",
       "1                                     2.431148   \n",
       "2                                     1.348554   \n",
       "3                                     1.282061   \n",
       "4                                     0.836693   \n",
       "..                                         ...   \n",
       "406                                  -0.476107   \n",
       "407                                  -0.420562   \n",
       "408                                  -0.215110   \n",
       "409                                  -0.353737   \n",
       "410                                   0.044753   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_12w_1  \\\n",
       "0                                      3.863262   \n",
       "1                                      4.345114   \n",
       "2                                      2.533689   \n",
       "3                                      2.314067   \n",
       "4                                      1.603089   \n",
       "..                                          ...   \n",
       "406                                   -0.467565   \n",
       "407                                    0.030758   \n",
       "408                                    0.110519   \n",
       "409                                    0.230804   \n",
       "410                                    0.566531   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_tg_1w_0  ...  \\\n",
       "0                                    -0.551685  ...   \n",
       "1                                     0.256218  ...   \n",
       "2                                     0.029187  ...   \n",
       "3                                     0.023661  ...   \n",
       "4                                     0.376389  ...   \n",
       "..                                         ...  ...   \n",
       "406                                   1.427917  ...   \n",
       "407                                   0.760111  ...   \n",
       "408                                   0.315694  ...   \n",
       "409                                  -0.971253  ...   \n",
       "410                                  -1.460435  ...   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_tg_0_Piemonte_Nord  \\\n",
       "0                                            -0.449672      \n",
       "1                                             0.880344      \n",
       "2                                            -0.833249      \n",
       "3                                             0.865639      \n",
       "4                                            -0.246418      \n",
       "..                                                 ...      \n",
       "406                                           0.000000      \n",
       "407                                          -0.000000      \n",
       "408                                           0.000000      \n",
       "409                                          -0.000000      \n",
       "410                                          -0.000000      \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_tg_0_Piemonte_Sud  \\\n",
       "0                                            -0.000000     \n",
       "1                                             0.000000     \n",
       "2                                            -0.000000     \n",
       "3                                             0.000000     \n",
       "4                                            -0.000000     \n",
       "..                                                 ...     \n",
       "406                                           1.374448     \n",
       "407                                          -0.119108     \n",
       "408                                           0.643035     \n",
       "409                                          -2.247923     \n",
       "410                                          -0.167457     \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_24w_0_Piemonte_Nord  \\\n",
       "0                                             3.146477          \n",
       "1                                             3.822355          \n",
       "2                                             2.115109          \n",
       "3                                             2.006293          \n",
       "4                                             1.307787          \n",
       "..                                                 ...          \n",
       "406                                          -0.000000          \n",
       "407                                          -0.000000          \n",
       "408                                          -0.000000          \n",
       "409                                          -0.000000          \n",
       "410                                          -0.000000          \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_24w_0_Piemonte_Sud  \\\n",
       "0                                             0.000000         \n",
       "1                                             0.000000         \n",
       "2                                             0.000000         \n",
       "3                                             0.000000         \n",
       "4                                             0.000000         \n",
       "..                                                 ...         \n",
       "406                                          -0.767792         \n",
       "407                                          -0.482430         \n",
       "408                                          -0.396456         \n",
       "409                                          -0.311937         \n",
       "410                                          -0.130149         \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_8w_0_Piemonte_Nord  \\\n",
       "0                                             1.939769         \n",
       "1                                             2.431148         \n",
       "2                                             1.348554         \n",
       "3                                             1.282061         \n",
       "4                                             0.836693         \n",
       "..                                                 ...         \n",
       "406                                          -0.000000         \n",
       "407                                          -0.000000         \n",
       "408                                          -0.000000         \n",
       "409                                          -0.000000         \n",
       "410                                           0.000000         \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_8w_0_Piemonte_Sud  \\\n",
       "0                                             0.000000        \n",
       "1                                             0.000000        \n",
       "2                                             0.000000        \n",
       "3                                             0.000000        \n",
       "4                                             0.000000        \n",
       "..                                                 ...        \n",
       "406                                          -0.476107        \n",
       "407                                          -0.420562        \n",
       "408                                          -0.215110        \n",
       "409                                          -0.353737        \n",
       "410                                           0.044753        \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_12w_1_Piemonte_Nord  \\\n",
       "0                                             3.863262          \n",
       "1                                             4.345114          \n",
       "2                                             2.533689          \n",
       "3                                             2.314067          \n",
       "4                                             1.603089          \n",
       "..                                                 ...          \n",
       "406                                          -0.000000          \n",
       "407                                           0.000000          \n",
       "408                                           0.000000          \n",
       "409                                           0.000000          \n",
       "410                                           0.000000          \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_12w_1_Piemonte_Sud  \\\n",
       "0                                             0.000000         \n",
       "1                                             0.000000         \n",
       "2                                             0.000000         \n",
       "3                                             0.000000         \n",
       "4                                             0.000000         \n",
       "..                                                 ...         \n",
       "406                                          -0.467565         \n",
       "407                                           0.030758         \n",
       "408                                           0.110519         \n",
       "409                                           0.230804         \n",
       "410                                           0.566531         \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_tg_1w_0_Piemonte_Nord  \\\n",
       "0                                            -0.551685         \n",
       "1                                             0.256218         \n",
       "2                                             0.029187         \n",
       "3                                             0.023661         \n",
       "4                                             0.376389         \n",
       "..                                                 ...         \n",
       "406                                           0.000000         \n",
       "407                                           0.000000         \n",
       "408                                           0.000000         \n",
       "409                                          -0.000000         \n",
       "410                                          -0.000000         \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_tg_1w_0_Piemonte_Sud  \n",
       "0                                            -0.000000       \n",
       "1                                             0.000000       \n",
       "2                                             0.000000       \n",
       "3                                             0.000000       \n",
       "4                                             0.000000       \n",
       "..                                                 ...       \n",
       "406                                           1.427917       \n",
       "407                                           0.760111       \n",
       "408                                           0.315694       \n",
       "409                                          -0.971253       \n",
       "410                                          -1.460435       \n",
       "\n",
       "[822 rows x 32 columns]"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(clusterdf_train_withClass.shape[1]-len(clust_basins)):\n",
    "    for j in clust_basins:\n",
    "        clusterdf_train_withClass[clusterdf_train_withClass.columns[i]+'_'+j] = clusterdf_train_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "        clusterdf_val_withClass[clusterdf_val_withClass.columns[i]+'_'+j] = clusterdf_val_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "        clusterdf_test_withClass[clusterdf_test_withClass.columns[i]+'_'+j] = clusterdf_test_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "\n",
    "clusterdf_train_withClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "de402c36",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04132440440468077\n",
      "0.017446449998085978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_DPNPS_ohe = LinearRegression()\n",
    "model_DPNPS_ohe.fit(pd.concat((clusterdf_train_withClass,clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_DPNPS_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Piemonte_Nord==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Nord'].values, res))\n",
    "res = model_DPNPS_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Piemonte_Sud==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Sud'].values, res))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff2d510",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Adda - Lambro_Olona - Oglio_Iseo - Ticino - Piemonte Sud - Piemonte Nord: CMI best 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "46954b61",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "clust_basins = ['Adda', 'Lambro_Olona', 'Oglio_Iseo', 'Ticino', 'Piemonte_Nord', 'Piemonte_Sud']\n",
    "colnames = [x for x in best5_CMI_fulldf_train.columns if x.startswith('Adda') or x.startswith('Lambro_Olona') or x.startswith('Oglio_Iseo') or x.startswith('Ticino') or x.startswith('Piemonte_Nord') or x.startswith('Piemonte_Sud')]\n",
    "\n",
    "clusterdf_train_withClass = pd.DataFrame()\n",
    "clusterdf_val_withClass = pd.DataFrame()\n",
    "clusterdf_test_withClass = pd.DataFrame()\n",
    "\n",
    "for i in range(len(clust_basins)):\n",
    "    clusterdf_train_withClass = pd.concat((clusterdf_train_withClass,pd.concat((best5_CMI_fulldf_train[colnames],pd.DataFrame(1+i*np.ones(len(best5_CMI_fulldf_train)),columns=['basin'])),axis=1)),axis=0)\n",
    "    clusterdf_val_withClass = pd.concat((clusterdf_val_withClass,pd.concat((best5_CMI_fulldf_val[colnames],pd.DataFrame(1+i*np.ones(len(best5_CMI_fulldf_val)),columns=['basin'])),axis=1)),axis=0)\n",
    "    clusterdf_test_withClass = pd.concat((clusterdf_test_withClass,pd.concat((best5_CMI_fulldf_test[colnames],pd.DataFrame(1+i*np.ones(len(best5_CMI_fulldf_test)),columns=['basin'])),axis=1)),axis=0)\n",
    "\n",
    "for i in range(len(clust_basins)):\n",
    "    clusterdf_train_withClass[clust_basins[i]] = clusterdf_train_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    clusterdf_val_withClass[clust_basins[i]] = clusterdf_val_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    clusterdf_test_withClass[clust_basins[i]] = clusterdf_test_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "\n",
    "clusterdf_train_withClass = clusterdf_train_withClass.loc[:,clusterdf_train_withClass.columns != 'basin']\n",
    "clusterdf_val_withClass = clusterdf_val_withClass.loc[:,clusterdf_val_withClass.columns != 'basin']\n",
    "clusterdf_test_withClass = clusterdf_test_withClass.loc[:,clusterdf_test_withClass.columns != 'basin']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "c899cc5a",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adda_cyclostationary_mean_tg_1w_3</th>\n",
       "      <th>Adda_cyclostationary_mean_rr_12w_1</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_16w_0</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_24w_2</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_24w_0</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_tg_6</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_rr_4w_1</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_tg_0</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_tg_4w_6</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_tg_4w_5</th>\n",
       "      <th>...</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_tg_1w_0</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_0</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_4w_0</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_1</th>\n",
       "      <th>Adda</th>\n",
       "      <th>Lambro_Olona</th>\n",
       "      <th>Oglio_Iseo</th>\n",
       "      <th>Ticino</th>\n",
       "      <th>Piemonte_Nord</th>\n",
       "      <th>Piemonte_Sud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.862899</td>\n",
       "      <td>1.560382</td>\n",
       "      <td>1.711682</td>\n",
       "      <td>-2.770704</td>\n",
       "      <td>1.914831</td>\n",
       "      <td>-0.044884</td>\n",
       "      <td>1.663515</td>\n",
       "      <td>-0.277460</td>\n",
       "      <td>-0.075383</td>\n",
       "      <td>-0.156545</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.551685</td>\n",
       "      <td>-0.432799</td>\n",
       "      <td>0.611605</td>\n",
       "      <td>-0.442197</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.093639</td>\n",
       "      <td>5.036114</td>\n",
       "      <td>2.547788</td>\n",
       "      <td>-0.879312</td>\n",
       "      <td>2.856614</td>\n",
       "      <td>1.221277</td>\n",
       "      <td>2.277544</td>\n",
       "      <td>0.841342</td>\n",
       "      <td>0.882621</td>\n",
       "      <td>0.761360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.256218</td>\n",
       "      <td>0.776085</td>\n",
       "      <td>1.691336</td>\n",
       "      <td>0.807518</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.524505</td>\n",
       "      <td>3.177144</td>\n",
       "      <td>1.634451</td>\n",
       "      <td>-2.052028</td>\n",
       "      <td>1.827839</td>\n",
       "      <td>-0.221646</td>\n",
       "      <td>1.355767</td>\n",
       "      <td>-0.526335</td>\n",
       "      <td>0.474126</td>\n",
       "      <td>0.269224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029187</td>\n",
       "      <td>-0.906320</td>\n",
       "      <td>0.832271</td>\n",
       "      <td>-1.081813</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.666293</td>\n",
       "      <td>3.205993</td>\n",
       "      <td>1.836713</td>\n",
       "      <td>-1.425685</td>\n",
       "      <td>2.055666</td>\n",
       "      <td>0.723165</td>\n",
       "      <td>1.429576</td>\n",
       "      <td>0.512276</td>\n",
       "      <td>0.627310</td>\n",
       "      <td>0.468910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023661</td>\n",
       "      <td>0.529173</td>\n",
       "      <td>0.859041</td>\n",
       "      <td>0.324392</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.416695</td>\n",
       "      <td>2.498195</td>\n",
       "      <td>1.795310</td>\n",
       "      <td>-1.994518</td>\n",
       "      <td>2.009029</td>\n",
       "      <td>-0.122716</td>\n",
       "      <td>0.994844</td>\n",
       "      <td>-0.056656</td>\n",
       "      <td>0.463215</td>\n",
       "      <td>0.444387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.376389</td>\n",
       "      <td>-0.687667</td>\n",
       "      <td>0.647203</td>\n",
       "      <td>-0.553079</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>1.568770</td>\n",
       "      <td>-1.467261</td>\n",
       "      <td>0.783570</td>\n",
       "      <td>1.524212</td>\n",
       "      <td>0.639345</td>\n",
       "      <td>1.014590</td>\n",
       "      <td>-1.098764</td>\n",
       "      <td>1.296972</td>\n",
       "      <td>-0.144871</td>\n",
       "      <td>0.565375</td>\n",
       "      <td>...</td>\n",
       "      <td>1.427917</td>\n",
       "      <td>1.481505</td>\n",
       "      <td>-1.023397</td>\n",
       "      <td>1.527659</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>0.812306</td>\n",
       "      <td>-0.715887</td>\n",
       "      <td>0.868596</td>\n",
       "      <td>1.477729</td>\n",
       "      <td>0.671680</td>\n",
       "      <td>0.250478</td>\n",
       "      <td>-0.476556</td>\n",
       "      <td>0.495148</td>\n",
       "      <td>0.358805</td>\n",
       "      <td>1.260203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.760111</td>\n",
       "      <td>0.121450</td>\n",
       "      <td>-0.154876</td>\n",
       "      <td>0.019115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.876968</td>\n",
       "      <td>-0.558495</td>\n",
       "      <td>0.899390</td>\n",
       "      <td>1.352693</td>\n",
       "      <td>0.504706</td>\n",
       "      <td>0.305326</td>\n",
       "      <td>-0.152527</td>\n",
       "      <td>0.445862</td>\n",
       "      <td>0.439528</td>\n",
       "      <td>1.444956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.315694</td>\n",
       "      <td>0.865426</td>\n",
       "      <td>0.083449</td>\n",
       "      <td>1.039841</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>-0.723696</td>\n",
       "      <td>-0.626439</td>\n",
       "      <td>0.725991</td>\n",
       "      <td>1.102009</td>\n",
       "      <td>0.391753</td>\n",
       "      <td>-1.995198</td>\n",
       "      <td>-0.192534</td>\n",
       "      <td>-1.610957</td>\n",
       "      <td>0.109550</td>\n",
       "      <td>1.067782</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.971253</td>\n",
       "      <td>-2.359776</td>\n",
       "      <td>0.001375</td>\n",
       "      <td>-2.580108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-1.413870</td>\n",
       "      <td>-0.338666</td>\n",
       "      <td>0.604737</td>\n",
       "      <td>1.186923</td>\n",
       "      <td>0.312637</td>\n",
       "      <td>-0.591923</td>\n",
       "      <td>0.302357</td>\n",
       "      <td>-0.580276</td>\n",
       "      <td>-0.315172</td>\n",
       "      <td>0.501525</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.460435</td>\n",
       "      <td>0.061748</td>\n",
       "      <td>0.518063</td>\n",
       "      <td>-0.183864</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2466 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Adda_cyclostationary_mean_tg_1w_3  Adda_cyclostationary_mean_rr_12w_1  \\\n",
       "0                            -0.862899                            1.560382   \n",
       "1                            -0.093639                            5.036114   \n",
       "2                            -0.524505                            3.177144   \n",
       "3                            -0.666293                            3.205993   \n",
       "4                            -0.416695                            2.498195   \n",
       "..                                 ...                                 ...   \n",
       "406                           1.568770                           -1.467261   \n",
       "407                           0.812306                           -0.715887   \n",
       "408                           0.876968                           -0.558495   \n",
       "409                          -0.723696                           -0.626439   \n",
       "410                          -1.413870                           -0.338666   \n",
       "\n",
       "     Adda_cyclostationary_mean_tg_16w_0  Adda_cyclostationary_mean_tg_24w_2  \\\n",
       "0                              1.711682                           -2.770704   \n",
       "1                              2.547788                           -0.879312   \n",
       "2                              1.634451                           -2.052028   \n",
       "3                              1.836713                           -1.425685   \n",
       "4                              1.795310                           -1.994518   \n",
       "..                                  ...                                 ...   \n",
       "406                            0.783570                            1.524212   \n",
       "407                            0.868596                            1.477729   \n",
       "408                            0.899390                            1.352693   \n",
       "409                            0.725991                            1.102009   \n",
       "410                            0.604737                            1.186923   \n",
       "\n",
       "     Adda_cyclostationary_mean_tg_24w_0  \\\n",
       "0                              1.914831   \n",
       "1                              2.856614   \n",
       "2                              1.827839   \n",
       "3                              2.055666   \n",
       "4                              2.009029   \n",
       "..                                  ...   \n",
       "406                            0.639345   \n",
       "407                            0.671680   \n",
       "408                            0.504706   \n",
       "409                            0.391753   \n",
       "410                            0.312637   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_tg_6  \\\n",
       "0                                 -0.044884   \n",
       "1                                  1.221277   \n",
       "2                                 -0.221646   \n",
       "3                                  0.723165   \n",
       "4                                 -0.122716   \n",
       "..                                      ...   \n",
       "406                                1.014590   \n",
       "407                                0.250478   \n",
       "408                                0.305326   \n",
       "409                               -1.995198   \n",
       "410                               -0.591923   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_rr_4w_1  \\\n",
       "0                                     1.663515   \n",
       "1                                     2.277544   \n",
       "2                                     1.355767   \n",
       "3                                     1.429576   \n",
       "4                                     0.994844   \n",
       "..                                         ...   \n",
       "406                                  -1.098764   \n",
       "407                                  -0.476556   \n",
       "408                                  -0.152527   \n",
       "409                                  -0.192534   \n",
       "410                                   0.302357   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_tg_0  \\\n",
       "0                                 -0.277460   \n",
       "1                                  0.841342   \n",
       "2                                 -0.526335   \n",
       "3                                  0.512276   \n",
       "4                                 -0.056656   \n",
       "..                                      ...   \n",
       "406                                1.296972   \n",
       "407                                0.495148   \n",
       "408                                0.445862   \n",
       "409                               -1.610957   \n",
       "410                               -0.580276   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_tg_4w_6  \\\n",
       "0                                    -0.075383   \n",
       "1                                     0.882621   \n",
       "2                                     0.474126   \n",
       "3                                     0.627310   \n",
       "4                                     0.463215   \n",
       "..                                         ...   \n",
       "406                                  -0.144871   \n",
       "407                                   0.358805   \n",
       "408                                   0.439528   \n",
       "409                                   0.109550   \n",
       "410                                  -0.315172   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_tg_4w_5  ...  \\\n",
       "0                                    -0.156545  ...   \n",
       "1                                     0.761360  ...   \n",
       "2                                     0.269224  ...   \n",
       "3                                     0.468910  ...   \n",
       "4                                     0.444387  ...   \n",
       "..                                         ...  ...   \n",
       "406                                   0.565375  ...   \n",
       "407                                   1.260203  ...   \n",
       "408                                   1.444956  ...   \n",
       "409                                   1.067782  ...   \n",
       "410                                   0.501525  ...   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_tg_1w_0  \\\n",
       "0                                    -0.551685   \n",
       "1                                     0.256218   \n",
       "2                                     0.029187   \n",
       "3                                     0.023661   \n",
       "4                                     0.376389   \n",
       "..                                         ...   \n",
       "406                                   1.427917   \n",
       "407                                   0.760111   \n",
       "408                                   0.315694   \n",
       "409                                  -0.971253   \n",
       "410                                  -1.460435   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_0  Ticino_cyclostationary_mean_rr_4w_0  \\\n",
       "0                           -0.432799                             0.611605   \n",
       "1                            0.776085                             1.691336   \n",
       "2                           -0.906320                             0.832271   \n",
       "3                            0.529173                             0.859041   \n",
       "4                           -0.687667                             0.647203   \n",
       "..                                ...                                  ...   \n",
       "406                          1.481505                            -1.023397   \n",
       "407                          0.121450                            -0.154876   \n",
       "408                          0.865426                             0.083449   \n",
       "409                         -2.359776                             0.001375   \n",
       "410                          0.061748                             0.518063   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_1  Adda  Lambro_Olona  Oglio_Iseo  Ticino  \\\n",
       "0                           -0.442197     1             0           0       0   \n",
       "1                            0.807518     1             0           0       0   \n",
       "2                           -1.081813     1             0           0       0   \n",
       "3                            0.324392     1             0           0       0   \n",
       "4                           -0.553079     1             0           0       0   \n",
       "..                                ...   ...           ...         ...     ...   \n",
       "406                          1.527659     0             0           0       0   \n",
       "407                          0.019115     0             0           0       0   \n",
       "408                          1.039841     0             0           0       0   \n",
       "409                         -2.580108     0             0           0       0   \n",
       "410                         -0.183864     0             0           0       0   \n",
       "\n",
       "     Piemonte_Nord  Piemonte_Sud  \n",
       "0                0             0  \n",
       "1                0             0  \n",
       "2                0             0  \n",
       "3                0             0  \n",
       "4                0             0  \n",
       "..             ...           ...  \n",
       "406              0             1  \n",
       "407              0             1  \n",
       "408              0             1  \n",
       "409              0             1  \n",
       "410              0             1  \n",
       "\n",
       "[2466 rows x 34 columns]"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterdf_train_withClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "949bb9ab",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "targets_df_train_unfolded = pd.DataFrame()\n",
    "targets_df_val_unfolded = pd.DataFrame()\n",
    "targets_df_test_unfolded = pd.DataFrame()\n",
    "\n",
    "for basin in clust_basins:\n",
    "    targets_df_train_unfolded =  pd.concat((targets_df_train_unfolded,targets_df_train[basin]),axis=0)\n",
    "    targets_df_val_unfolded =  pd.concat((targets_df_val_unfolded,targets_df_val[basin]),axis=0)\n",
    "    targets_df_test_unfolded =  pd.concat((targets_df_test_unfolded,targets_df_test[basin]),axis=0)\n",
    "targets_df_train_unfolded = targets_df_train_unfolded.reset_index(drop=True)\n",
    "targets_df_val_unfolded = targets_df_val_unfolded.reset_index(drop=True)\n",
    "targets_df_test_unfolded = targets_df_test_unfolded.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "e75cfd95",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.546951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.277191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.534156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.666789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.447894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2461</th>\n",
       "      <td>-0.021388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2462</th>\n",
       "      <td>-0.086330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2463</th>\n",
       "      <td>0.576347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2464</th>\n",
       "      <td>0.146632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2465</th>\n",
       "      <td>-0.818877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2466 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0    -2.546951\n",
       "1    -0.277191\n",
       "2    -0.534156\n",
       "3    -0.666789\n",
       "4    -0.447894\n",
       "...        ...\n",
       "2461 -0.021388\n",
       "2462 -0.086330\n",
       "2463  0.576347\n",
       "2464  0.146632\n",
       "2465 -0.818877\n",
       "\n",
       "[2466 rows x 1 columns]"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_df_train_unfolded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "1d00904c",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11462100115005325\n",
      "0.021193225708093122\n",
      "0.07493349366613022\n",
      "0.10994573262591845\n",
      "0.06505433486884604\n",
      "-0.04293174762262808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_ALOT_ohe = LinearRegression()\n",
    "model_ALOT_ohe.fit(pd.concat((clusterdf_train_withClass,clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Adda==1].values)\n",
    "print(r2_score(targets_df_test['Adda'].values, res))\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Lambro_Olona==1].values)\n",
    "print(r2_score(targets_df_test['Lambro_Olona'].values, res))\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Oglio_Iseo==1].values)\n",
    "print(r2_score(targets_df_test['Oglio_Iseo'].values, res))\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Ticino==1].values)\n",
    "print(r2_score(targets_df_test['Ticino'].values, res))\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Piemonte_Nord==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Nord'].values, res))\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Piemonte_Sud==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Sud'].values, res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "c6ac79d1",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adda_cyclostationary_mean_tg_1w_3</th>\n",
       "      <th>Adda_cyclostationary_mean_rr_12w_1</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_16w_0</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_24w_2</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_24w_0</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_tg_6</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_rr_4w_1</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_tg_0</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_tg_4w_6</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_tg_4w_5</th>\n",
       "      <th>...</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_0_Oglio_Iseo</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_0_Ticino</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_4w_0_Adda</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_4w_0_Lambro_Olona</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_4w_0_Oglio_Iseo</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_4w_0_Ticino</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_1_Adda</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_1_Lambro_Olona</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_1_Oglio_Iseo</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_1_Ticino</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.862899</td>\n",
       "      <td>1.560382</td>\n",
       "      <td>1.711682</td>\n",
       "      <td>-2.770704</td>\n",
       "      <td>1.914831</td>\n",
       "      <td>-0.044884</td>\n",
       "      <td>1.663515</td>\n",
       "      <td>-0.277460</td>\n",
       "      <td>-0.075383</td>\n",
       "      <td>-0.156545</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.611605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.442197</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.093639</td>\n",
       "      <td>5.036114</td>\n",
       "      <td>2.547788</td>\n",
       "      <td>-0.879312</td>\n",
       "      <td>2.856614</td>\n",
       "      <td>1.221277</td>\n",
       "      <td>2.277544</td>\n",
       "      <td>0.841342</td>\n",
       "      <td>0.882621</td>\n",
       "      <td>0.761360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.691336</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.807518</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.524505</td>\n",
       "      <td>3.177144</td>\n",
       "      <td>1.634451</td>\n",
       "      <td>-2.052028</td>\n",
       "      <td>1.827839</td>\n",
       "      <td>-0.221646</td>\n",
       "      <td>1.355767</td>\n",
       "      <td>-0.526335</td>\n",
       "      <td>0.474126</td>\n",
       "      <td>0.269224</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.832271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.081813</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.666293</td>\n",
       "      <td>3.205993</td>\n",
       "      <td>1.836713</td>\n",
       "      <td>-1.425685</td>\n",
       "      <td>2.055666</td>\n",
       "      <td>0.723165</td>\n",
       "      <td>1.429576</td>\n",
       "      <td>0.512276</td>\n",
       "      <td>0.627310</td>\n",
       "      <td>0.468910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.859041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.324392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.416695</td>\n",
       "      <td>2.498195</td>\n",
       "      <td>1.795310</td>\n",
       "      <td>-1.994518</td>\n",
       "      <td>2.009029</td>\n",
       "      <td>-0.122716</td>\n",
       "      <td>0.994844</td>\n",
       "      <td>-0.056656</td>\n",
       "      <td>0.463215</td>\n",
       "      <td>0.444387</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.647203</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.553079</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>1.568770</td>\n",
       "      <td>-1.467261</td>\n",
       "      <td>0.783570</td>\n",
       "      <td>1.524212</td>\n",
       "      <td>0.639345</td>\n",
       "      <td>1.014590</td>\n",
       "      <td>-1.098764</td>\n",
       "      <td>1.296972</td>\n",
       "      <td>-0.144871</td>\n",
       "      <td>0.565375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.481505</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-1.023397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.527659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>0.812306</td>\n",
       "      <td>-0.715887</td>\n",
       "      <td>0.868596</td>\n",
       "      <td>1.477729</td>\n",
       "      <td>0.671680</td>\n",
       "      <td>0.250478</td>\n",
       "      <td>-0.476556</td>\n",
       "      <td>0.495148</td>\n",
       "      <td>0.358805</td>\n",
       "      <td>1.260203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.121450</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.154876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.876968</td>\n",
       "      <td>-0.558495</td>\n",
       "      <td>0.899390</td>\n",
       "      <td>1.352693</td>\n",
       "      <td>0.504706</td>\n",
       "      <td>0.305326</td>\n",
       "      <td>-0.152527</td>\n",
       "      <td>0.445862</td>\n",
       "      <td>0.439528</td>\n",
       "      <td>1.444956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.865426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083449</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.039841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>-0.723696</td>\n",
       "      <td>-0.626439</td>\n",
       "      <td>0.725991</td>\n",
       "      <td>1.102009</td>\n",
       "      <td>0.391753</td>\n",
       "      <td>-1.995198</td>\n",
       "      <td>-0.192534</td>\n",
       "      <td>-1.610957</td>\n",
       "      <td>0.109550</td>\n",
       "      <td>1.067782</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-2.359776</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001375</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-2.580108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-1.413870</td>\n",
       "      <td>-0.338666</td>\n",
       "      <td>0.604737</td>\n",
       "      <td>1.186923</td>\n",
       "      <td>0.312637</td>\n",
       "      <td>-0.591923</td>\n",
       "      <td>0.302357</td>\n",
       "      <td>-0.580276</td>\n",
       "      <td>-0.315172</td>\n",
       "      <td>0.501525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.061748</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.518063</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.183864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1644 rows × 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Adda_cyclostationary_mean_tg_1w_3  Adda_cyclostationary_mean_rr_12w_1  \\\n",
       "0                            -0.862899                            1.560382   \n",
       "1                            -0.093639                            5.036114   \n",
       "2                            -0.524505                            3.177144   \n",
       "3                            -0.666293                            3.205993   \n",
       "4                            -0.416695                            2.498195   \n",
       "..                                 ...                                 ...   \n",
       "406                           1.568770                           -1.467261   \n",
       "407                           0.812306                           -0.715887   \n",
       "408                           0.876968                           -0.558495   \n",
       "409                          -0.723696                           -0.626439   \n",
       "410                          -1.413870                           -0.338666   \n",
       "\n",
       "     Adda_cyclostationary_mean_tg_16w_0  Adda_cyclostationary_mean_tg_24w_2  \\\n",
       "0                              1.711682                           -2.770704   \n",
       "1                              2.547788                           -0.879312   \n",
       "2                              1.634451                           -2.052028   \n",
       "3                              1.836713                           -1.425685   \n",
       "4                              1.795310                           -1.994518   \n",
       "..                                  ...                                 ...   \n",
       "406                            0.783570                            1.524212   \n",
       "407                            0.868596                            1.477729   \n",
       "408                            0.899390                            1.352693   \n",
       "409                            0.725991                            1.102009   \n",
       "410                            0.604737                            1.186923   \n",
       "\n",
       "     Adda_cyclostationary_mean_tg_24w_0  \\\n",
       "0                              1.914831   \n",
       "1                              2.856614   \n",
       "2                              1.827839   \n",
       "3                              2.055666   \n",
       "4                              2.009029   \n",
       "..                                  ...   \n",
       "406                            0.639345   \n",
       "407                            0.671680   \n",
       "408                            0.504706   \n",
       "409                            0.391753   \n",
       "410                            0.312637   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_tg_6  \\\n",
       "0                                 -0.044884   \n",
       "1                                  1.221277   \n",
       "2                                 -0.221646   \n",
       "3                                  0.723165   \n",
       "4                                 -0.122716   \n",
       "..                                      ...   \n",
       "406                                1.014590   \n",
       "407                                0.250478   \n",
       "408                                0.305326   \n",
       "409                               -1.995198   \n",
       "410                               -0.591923   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_rr_4w_1  \\\n",
       "0                                     1.663515   \n",
       "1                                     2.277544   \n",
       "2                                     1.355767   \n",
       "3                                     1.429576   \n",
       "4                                     0.994844   \n",
       "..                                         ...   \n",
       "406                                  -1.098764   \n",
       "407                                  -0.476556   \n",
       "408                                  -0.152527   \n",
       "409                                  -0.192534   \n",
       "410                                   0.302357   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_tg_0  \\\n",
       "0                                 -0.277460   \n",
       "1                                  0.841342   \n",
       "2                                 -0.526335   \n",
       "3                                  0.512276   \n",
       "4                                 -0.056656   \n",
       "..                                      ...   \n",
       "406                                1.296972   \n",
       "407                                0.495148   \n",
       "408                                0.445862   \n",
       "409                               -1.610957   \n",
       "410                               -0.580276   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_tg_4w_6  \\\n",
       "0                                    -0.075383   \n",
       "1                                     0.882621   \n",
       "2                                     0.474126   \n",
       "3                                     0.627310   \n",
       "4                                     0.463215   \n",
       "..                                         ...   \n",
       "406                                  -0.144871   \n",
       "407                                   0.358805   \n",
       "408                                   0.439528   \n",
       "409                                   0.109550   \n",
       "410                                  -0.315172   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_tg_4w_5  ...  \\\n",
       "0                                    -0.156545  ...   \n",
       "1                                     0.761360  ...   \n",
       "2                                     0.269224  ...   \n",
       "3                                     0.468910  ...   \n",
       "4                                     0.444387  ...   \n",
       "..                                         ...  ...   \n",
       "406                                   0.565375  ...   \n",
       "407                                   1.260203  ...   \n",
       "408                                   1.444956  ...   \n",
       "409                                   1.067782  ...   \n",
       "410                                   0.501525  ...   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_0_Oglio_Iseo  \\\n",
       "0                                           -0.0   \n",
       "1                                            0.0   \n",
       "2                                           -0.0   \n",
       "3                                            0.0   \n",
       "4                                           -0.0   \n",
       "..                                           ...   \n",
       "406                                          0.0   \n",
       "407                                          0.0   \n",
       "408                                          0.0   \n",
       "409                                         -0.0   \n",
       "410                                          0.0   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_0_Ticino  \\\n",
       "0                                  -0.000000   \n",
       "1                                   0.000000   \n",
       "2                                  -0.000000   \n",
       "3                                   0.000000   \n",
       "4                                  -0.000000   \n",
       "..                                       ...   \n",
       "406                                 1.481505   \n",
       "407                                 0.121450   \n",
       "408                                 0.865426   \n",
       "409                                -2.359776   \n",
       "410                                 0.061748   \n",
       "\n",
       "     Ticino_cyclostationary_mean_rr_4w_0_Adda  \\\n",
       "0                                    0.611605   \n",
       "1                                    1.691336   \n",
       "2                                    0.832271   \n",
       "3                                    0.859041   \n",
       "4                                    0.647203   \n",
       "..                                        ...   \n",
       "406                                 -0.000000   \n",
       "407                                 -0.000000   \n",
       "408                                  0.000000   \n",
       "409                                  0.000000   \n",
       "410                                  0.000000   \n",
       "\n",
       "     Ticino_cyclostationary_mean_rr_4w_0_Lambro_Olona  \\\n",
       "0                                                 0.0   \n",
       "1                                                 0.0   \n",
       "2                                                 0.0   \n",
       "3                                                 0.0   \n",
       "4                                                 0.0   \n",
       "..                                                ...   \n",
       "406                                              -0.0   \n",
       "407                                              -0.0   \n",
       "408                                               0.0   \n",
       "409                                               0.0   \n",
       "410                                               0.0   \n",
       "\n",
       "     Ticino_cyclostationary_mean_rr_4w_0_Oglio_Iseo  \\\n",
       "0                                               0.0   \n",
       "1                                               0.0   \n",
       "2                                               0.0   \n",
       "3                                               0.0   \n",
       "4                                               0.0   \n",
       "..                                              ...   \n",
       "406                                            -0.0   \n",
       "407                                            -0.0   \n",
       "408                                             0.0   \n",
       "409                                             0.0   \n",
       "410                                             0.0   \n",
       "\n",
       "     Ticino_cyclostationary_mean_rr_4w_0_Ticino  \\\n",
       "0                                      0.000000   \n",
       "1                                      0.000000   \n",
       "2                                      0.000000   \n",
       "3                                      0.000000   \n",
       "4                                      0.000000   \n",
       "..                                          ...   \n",
       "406                                   -1.023397   \n",
       "407                                   -0.154876   \n",
       "408                                    0.083449   \n",
       "409                                    0.001375   \n",
       "410                                    0.518063   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_1_Adda  \\\n",
       "0                                -0.442197   \n",
       "1                                 0.807518   \n",
       "2                                -1.081813   \n",
       "3                                 0.324392   \n",
       "4                                -0.553079   \n",
       "..                                     ...   \n",
       "406                               0.000000   \n",
       "407                               0.000000   \n",
       "408                               0.000000   \n",
       "409                              -0.000000   \n",
       "410                              -0.000000   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_1_Lambro_Olona  \\\n",
       "0                                             -0.0   \n",
       "1                                              0.0   \n",
       "2                                             -0.0   \n",
       "3                                              0.0   \n",
       "4                                             -0.0   \n",
       "..                                             ...   \n",
       "406                                            0.0   \n",
       "407                                            0.0   \n",
       "408                                            0.0   \n",
       "409                                           -0.0   \n",
       "410                                           -0.0   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_1_Oglio_Iseo  \\\n",
       "0                                           -0.0   \n",
       "1                                            0.0   \n",
       "2                                           -0.0   \n",
       "3                                            0.0   \n",
       "4                                           -0.0   \n",
       "..                                           ...   \n",
       "406                                          0.0   \n",
       "407                                          0.0   \n",
       "408                                          0.0   \n",
       "409                                         -0.0   \n",
       "410                                         -0.0   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_1_Ticino  \n",
       "0                                  -0.000000  \n",
       "1                                   0.000000  \n",
       "2                                  -0.000000  \n",
       "3                                   0.000000  \n",
       "4                                  -0.000000  \n",
       "..                                       ...  \n",
       "406                                 1.527659  \n",
       "407                                 0.019115  \n",
       "408                                 1.039841  \n",
       "409                                -2.580108  \n",
       "410                                -0.183864  \n",
       "\n",
       "[1644 rows x 94 columns]"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(clusterdf_train_withClass.shape[1]-len(clust_basins)):\n",
    "    for j in clust_basins:\n",
    "        clusterdf_train_withClass[clusterdf_train_withClass.columns[i]+'_'+j] = clusterdf_train_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "        clusterdf_val_withClass[clusterdf_val_withClass.columns[i]+'_'+j] = clusterdf_val_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "        clusterdf_test_withClass[clusterdf_test_withClass.columns[i]+'_'+j] = clusterdf_test_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "\n",
    "clusterdf_train_withClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "cc4acb1e",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2934203975293319\n",
      "0.26426191622064354\n",
      "0.15121968885589177\n",
      "0.2495948097547407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_ALOT_ohe = LinearRegression()\n",
    "model_ALOT_ohe.fit(pd.concat((clusterdf_train_withClass,clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Adda==1].values)\n",
    "print(r2_score(targets_df_test['Adda'].values, res))\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Lambro_Olona==1].values)\n",
    "print(r2_score(targets_df_test['Lambro_Olona'].values, res))\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Oglio_Iseo==1].values)\n",
    "print(r2_score(targets_df_test['Oglio_Iseo'].values, res))\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Ticino==1].values)\n",
    "print(r2_score(targets_df_test['Ticino'].values, res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51745de2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dd737e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ae2177",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e81f6696",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Others"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6940b5",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9c245c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### Riassunto wrapper - CMI - CMI best5\n",
    "\n",
    "Emiliani1: 0.30       0.19       0.40\n",
    "Emiliani2: 0.17       0.15       0.26\n",
    "Together:  0.14/0.04  0.07/0.04  0.12/0.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f3b764",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1641f1aa",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd55d2d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924c0e64",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb4e280",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb97ef65",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d36f10b2",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Load targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6b5d365",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.039373    0.00  2001     1 -2.546951\n",
      "1    2001-01-13  0.380618    0.43  2001     2 -0.277191\n",
      "2    2001-01-21  0.341985    0.38  2001     3 -0.534156\n",
      "3    2001-01-29  0.322044    0.35  2001     5 -0.666789\n",
      "4    2001-02-06  0.354954    0.40  2001     6 -0.447894\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.382706    0.40  2009    48 -0.263306\n",
      "407  2009-12-05  0.409921    0.46  2009    49 -0.082282\n",
      "408  2009-12-13  0.472087    0.53  2009    50  0.331204\n",
      "409  2009-12-21  0.324728    0.00  2009    52 -0.648940\n",
      "410  2009-12-29  0.086512    0.00  2009    53 -2.233412\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.010645    0.00  2001     1 -2.129508\n",
      "1    2001-01-13  0.206769    0.00  2001     2 -0.927136\n",
      "2    2001-01-21  0.267313    0.00  2001     3 -0.555958\n",
      "3    2001-01-29  0.240836    0.20  2001     5 -0.718282\n",
      "4    2001-02-06  0.193417    0.15  2001     6 -1.008995\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.230073    0.25  2009    48 -0.784269\n",
      "407  2009-12-05  0.243632    0.24  2009    49 -0.701139\n",
      "408  2009-12-13  0.251111    0.00  2009    50 -0.655289\n",
      "409  2009-12-21  0.099246    0.00  2009    52 -1.586325\n",
      "410  2009-12-29  0.064990    0.00  2009    53 -1.796340\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.379890    0.50  2001     1 -0.382765\n",
      "1    2001-01-13  0.482679    0.58  2001     2  0.319215\n",
      "2    2001-01-21  0.516259    0.59  2001     3  0.548542\n",
      "3    2001-01-29  0.434421    0.50  2001     5 -0.010351\n",
      "4    2001-02-06  0.494805    0.54  2001     6  0.402030\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.427085    0.43  2009    48 -0.060454\n",
      "407  2009-12-05  0.547380    0.57  2009    49  0.761079\n",
      "408  2009-12-13  0.531070    0.58  2009    50  0.649694\n",
      "409  2009-12-21  0.295704    0.00  2009    52 -0.957702\n",
      "410  2009-12-29  0.027861    0.00  2009    53 -2.786888\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.214281    0.00  2001     1 -1.339879\n",
      "1    2001-01-13  0.484737    0.52  2001     2  0.402993\n",
      "2    2001-01-21  0.466071    0.47  2001     3  0.282703\n",
      "3    2001-01-29  0.417470    0.44  2001     5 -0.030490\n",
      "4    2001-02-06  0.492202    0.53  2001     6  0.451097\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.436464    0.46  2009    48  0.091910\n",
      "407  2009-12-05  0.466152    0.49  2009    49  0.283224\n",
      "408  2009-12-13  0.553659    0.59  2009    50  0.847138\n",
      "409  2009-12-21  0.507978    0.65  2009    52  0.552758\n",
      "410  2009-12-29  0.083046    0.00  2009    53 -2.185583\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.102270    0.00  2001     1 -1.996014\n",
      "1    2001-01-13  0.454431    0.53  2001     2  0.498869\n",
      "2    2001-01-21  0.323514    0.32  2001     3 -0.428613\n",
      "3    2001-01-29  0.301661    0.31  2001     5 -0.583432\n",
      "4    2001-02-06  0.394733    0.44  2001     6  0.075938\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.388573    0.44  2009    48  0.032299\n",
      "407  2009-12-05  0.402760    0.47  2009    49  0.132804\n",
      "408  2009-12-13  0.353782    0.44  2009    50 -0.214182\n",
      "409  2009-12-21  0.043947    0.00  2009    52 -2.409204\n",
      "410  2009-12-29  0.006670    0.00  2009    53 -2.673294\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.369625    0.45  2001     1 -0.439541\n",
      "1    2001-01-13  0.429563    0.43  2001     2 -0.019547\n",
      "2    2001-01-21  0.470784    0.48  2001     3  0.269293\n",
      "3    2001-01-29  0.370358    0.37  2001     5 -0.434406\n",
      "4    2001-02-06  0.372263    0.37  2001     6 -0.421060\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.402059    0.40  2009    48 -0.212272\n",
      "407  2009-12-05  0.389658    0.39  2009    49 -0.299172\n",
      "408  2009-12-13  0.545184    0.56  2009    50  0.790614\n",
      "409  2009-12-21  0.447916    0.55  2009    52  0.109054\n",
      "410  2009-12-29  0.277300    0.32  2009    53 -1.086474\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.243674    0.26  2001     1 -1.223671\n",
      "1    2001-01-13  0.424116    0.44  2001     2 -0.087252\n",
      "2    2001-01-21  0.393786    0.39  2001     3 -0.278268\n",
      "3    2001-01-29  0.314939    0.31  2001     5 -0.774846\n",
      "4    2001-02-06  0.464902    0.48  2001     6  0.169616\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.465734    0.48  2009    48  0.174854\n",
      "407  2009-12-05  0.447390    0.47  2009    49  0.059327\n",
      "408  2009-12-13  0.556760    0.59  2009    50  0.748131\n",
      "409  2009-12-21  0.307880    0.00  2009    52 -0.819305\n",
      "410  2009-12-29  0.034211    0.00  2009    53 -2.542862\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.278983    0.00  2001     1 -1.146332\n",
      "1    2001-01-13  0.494910    0.51  2001     2  0.371173\n",
      "2    2001-01-21  0.496092    0.51  2001     3  0.379474\n",
      "3    2001-01-29  0.427992    0.43  2001     5 -0.099118\n",
      "4    2001-02-06  0.400512    0.41  2001     6 -0.292244\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.363952    0.37  2009    48 -0.549184\n",
      "407  2009-12-05  0.400487    0.40  2009    49 -0.292423\n",
      "408  2009-12-13  0.506771    0.52  2009    50  0.454529\n",
      "409  2009-12-21  0.387530    0.53  2009    52 -0.383480\n",
      "410  2009-12-29  0.279894    0.27  2009    53 -1.139931\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.278060    0.09  2001     1 -0.967137\n",
      "1    2001-01-13  0.445159    0.48  2001     2  0.070382\n",
      "2    2001-01-21  0.488982    0.52  2001     3  0.342478\n",
      "3    2001-01-29  0.362487    0.37  2001     5 -0.442927\n",
      "4    2001-02-06  0.430732    0.45  2001     6 -0.019192\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.430379    0.44  2009    48 -0.021388\n",
      "407  2009-12-05  0.419919    0.43  2009    49 -0.086330\n",
      "408  2009-12-13  0.526648    0.55  2009    50  0.576347\n",
      "409  2009-12-21  0.457440    0.61  2009    52  0.146632\n",
      "410  2009-12-29  0.301938    0.38  2009    53 -0.818877\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.264043    0.00  2001     1 -1.060146\n",
      "1    2001-01-13  0.354618    0.39  2001     2 -0.405065\n",
      "2    2001-01-21  0.427990    0.47  2001     3  0.125603\n",
      "3    2001-01-29  0.339495    0.35  2001     5 -0.514438\n",
      "4    2001-02-06  0.324134    0.34  2001     6 -0.625540\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.332713    0.35  2009    48 -0.563495\n",
      "407  2009-12-05  0.370253    0.40  2009    49 -0.291984\n",
      "408  2009-12-13  0.517201    0.57  2009    50  0.770822\n",
      "409  2009-12-21  0.353636    0.45  2009    52 -0.412164\n",
      "410  2009-12-29  0.261079    0.00  2009    53 -1.081585\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n"
     ]
    }
   ],
   "source": [
    "basins = ['Adda','Dora','Emiliani1','Emiliani2','Garda_Mincio','Lambro_Olona','Oglio_Iseo','Piemonte_Nord','Piemonte_Sud','Ticino']\n",
    "path_target = '/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/csv_VHI/'\n",
    "\n",
    "targets_train = {}\n",
    "targets_val = {}\n",
    "targets_test = {}\n",
    "targets_trainVal = {}\n",
    "for basin in basins:\n",
    "    target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target('',max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01', path=path_target+basin+'.csv')\n",
    "    targets_train[basin] = target_df_train\n",
    "    targets_val[basin] = target_df_val\n",
    "    targets_test[basin] = target_df_test\n",
    "    targets_trainVal[basin] = target_df_trainVal\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49fa2ec",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Best 5 wrapper clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e03cfd07",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### Load the selected features: best 5 Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8ab30ba",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "basins = ['Adda','Dora','Emiliani1','Emiliani2','Garda_Mincio','Lambro_Olona','Oglio_Iseo','Piemonte_Nord','Piemonte_Sud','Ticino']\n",
    "folder = '/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/reduced_features/'\n",
    "filelist = [file for file in os.listdir(folder) if file.endswith('_nonLinCFA_wrapper_best5_train.csv')]\n",
    "\n",
    "train_best5_wrapper = {}\n",
    "for file in filelist:\n",
    "    train_best5_wrapper[file] = pd.read_csv((folder+file))\n",
    "    \n",
    "filelist = [file for file in os.listdir(folder) if file.endswith('_nonLinCFA_wrapper_best5_val.csv')]\n",
    "\n",
    "val_best5_wrapper = {}\n",
    "for file in filelist:\n",
    "    val_best5_wrapper[file] = pd.read_csv((folder+file))\n",
    "    \n",
    "filelist = [file for file in os.listdir(folder) if file.endswith('_nonLinCFA_wrapper_best5_test.csv')]\n",
    "\n",
    "test_best5_wrapper = {}\n",
    "for file in filelist:\n",
    "    test_best5_wrapper[file] = pd.read_csv((folder+file))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "708812f6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "hierarchical_clustering = AgglomerativeClustering(linkage=\"average\", \n",
    "                                distance_threshold = None, \n",
    "                                n_clusters=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "50054c36",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>401</th>\n",
       "      <th>402</th>\n",
       "      <th>403</th>\n",
       "      <th>404</th>\n",
       "      <th>405</th>\n",
       "      <th>406</th>\n",
       "      <th>407</th>\n",
       "      <th>408</th>\n",
       "      <th>409</th>\n",
       "      <th>410</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Adda</th>\n",
       "      <td>-2.546951</td>\n",
       "      <td>-0.277191</td>\n",
       "      <td>-0.534156</td>\n",
       "      <td>-0.666789</td>\n",
       "      <td>-0.447894</td>\n",
       "      <td>-1.060644</td>\n",
       "      <td>-0.930783</td>\n",
       "      <td>0.130445</td>\n",
       "      <td>-0.182764</td>\n",
       "      <td>0.285961</td>\n",
       "      <td>...</td>\n",
       "      <td>1.245203</td>\n",
       "      <td>0.071188</td>\n",
       "      <td>1.085285</td>\n",
       "      <td>0.531438</td>\n",
       "      <td>-0.638894</td>\n",
       "      <td>-0.263306</td>\n",
       "      <td>-0.082282</td>\n",
       "      <td>0.331204</td>\n",
       "      <td>-0.648940</td>\n",
       "      <td>-2.233412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dora</th>\n",
       "      <td>-2.129508</td>\n",
       "      <td>-0.927136</td>\n",
       "      <td>-0.555958</td>\n",
       "      <td>-0.718282</td>\n",
       "      <td>-1.008995</td>\n",
       "      <td>-1.279207</td>\n",
       "      <td>-1.444875</td>\n",
       "      <td>-0.224922</td>\n",
       "      <td>-0.513422</td>\n",
       "      <td>-0.331122</td>\n",
       "      <td>...</td>\n",
       "      <td>1.521211</td>\n",
       "      <td>-0.076805</td>\n",
       "      <td>0.663966</td>\n",
       "      <td>0.023314</td>\n",
       "      <td>-1.370886</td>\n",
       "      <td>-0.784269</td>\n",
       "      <td>-0.701139</td>\n",
       "      <td>-0.655289</td>\n",
       "      <td>-1.586325</td>\n",
       "      <td>-1.796340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emiliani1</th>\n",
       "      <td>-0.382765</td>\n",
       "      <td>0.319215</td>\n",
       "      <td>0.548542</td>\n",
       "      <td>-0.010351</td>\n",
       "      <td>0.402030</td>\n",
       "      <td>-0.272581</td>\n",
       "      <td>-0.163632</td>\n",
       "      <td>0.537451</td>\n",
       "      <td>0.523582</td>\n",
       "      <td>0.764119</td>\n",
       "      <td>...</td>\n",
       "      <td>1.027290</td>\n",
       "      <td>0.055590</td>\n",
       "      <td>0.692477</td>\n",
       "      <td>0.361799</td>\n",
       "      <td>-0.418498</td>\n",
       "      <td>-0.060454</td>\n",
       "      <td>0.761079</td>\n",
       "      <td>0.649694</td>\n",
       "      <td>-0.957702</td>\n",
       "      <td>-2.786888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emiliani2</th>\n",
       "      <td>-1.339879</td>\n",
       "      <td>0.402993</td>\n",
       "      <td>0.282703</td>\n",
       "      <td>-0.030490</td>\n",
       "      <td>0.451097</td>\n",
       "      <td>-0.461545</td>\n",
       "      <td>-0.616218</td>\n",
       "      <td>0.586097</td>\n",
       "      <td>0.324908</td>\n",
       "      <td>0.490785</td>\n",
       "      <td>...</td>\n",
       "      <td>1.475893</td>\n",
       "      <td>0.723830</td>\n",
       "      <td>1.270697</td>\n",
       "      <td>1.013738</td>\n",
       "      <td>0.032229</td>\n",
       "      <td>0.091910</td>\n",
       "      <td>0.283224</td>\n",
       "      <td>0.847138</td>\n",
       "      <td>0.552758</td>\n",
       "      <td>-2.185583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Garda_Mincio</th>\n",
       "      <td>-1.996014</td>\n",
       "      <td>0.498869</td>\n",
       "      <td>-0.428613</td>\n",
       "      <td>-0.583432</td>\n",
       "      <td>0.075938</td>\n",
       "      <td>-1.170667</td>\n",
       "      <td>-0.994278</td>\n",
       "      <td>0.347932</td>\n",
       "      <td>0.270386</td>\n",
       "      <td>0.282736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.590168</td>\n",
       "      <td>-0.213240</td>\n",
       "      <td>0.570796</td>\n",
       "      <td>0.032382</td>\n",
       "      <td>-0.449253</td>\n",
       "      <td>0.032299</td>\n",
       "      <td>0.132804</td>\n",
       "      <td>-0.214182</td>\n",
       "      <td>-2.409204</td>\n",
       "      <td>-2.673294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lambro_Olona</th>\n",
       "      <td>-0.439541</td>\n",
       "      <td>-0.019547</td>\n",
       "      <td>0.269293</td>\n",
       "      <td>-0.434406</td>\n",
       "      <td>-0.421060</td>\n",
       "      <td>-1.360391</td>\n",
       "      <td>-1.488261</td>\n",
       "      <td>0.143476</td>\n",
       "      <td>-0.131799</td>\n",
       "      <td>0.022348</td>\n",
       "      <td>...</td>\n",
       "      <td>1.343884</td>\n",
       "      <td>-0.011918</td>\n",
       "      <td>1.203688</td>\n",
       "      <td>0.840946</td>\n",
       "      <td>-0.353547</td>\n",
       "      <td>-0.212272</td>\n",
       "      <td>-0.299172</td>\n",
       "      <td>0.790614</td>\n",
       "      <td>0.109054</td>\n",
       "      <td>-1.086474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oglio_Iseo</th>\n",
       "      <td>-1.223671</td>\n",
       "      <td>-0.087252</td>\n",
       "      <td>-0.278268</td>\n",
       "      <td>-0.774846</td>\n",
       "      <td>0.169616</td>\n",
       "      <td>-1.193040</td>\n",
       "      <td>-1.058212</td>\n",
       "      <td>0.153692</td>\n",
       "      <td>-0.057888</td>\n",
       "      <td>0.467061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.956288</td>\n",
       "      <td>0.122784</td>\n",
       "      <td>1.199917</td>\n",
       "      <td>0.568570</td>\n",
       "      <td>-0.268606</td>\n",
       "      <td>0.174854</td>\n",
       "      <td>0.059327</td>\n",
       "      <td>0.748131</td>\n",
       "      <td>-0.819305</td>\n",
       "      <td>-2.542862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Piemonte_Nord</th>\n",
       "      <td>-1.146332</td>\n",
       "      <td>0.371173</td>\n",
       "      <td>0.379474</td>\n",
       "      <td>-0.099118</td>\n",
       "      <td>-0.292244</td>\n",
       "      <td>-0.980959</td>\n",
       "      <td>-1.406861</td>\n",
       "      <td>0.562514</td>\n",
       "      <td>0.185923</td>\n",
       "      <td>0.419812</td>\n",
       "      <td>...</td>\n",
       "      <td>1.482606</td>\n",
       "      <td>-0.405493</td>\n",
       "      <td>1.139576</td>\n",
       "      <td>0.674711</td>\n",
       "      <td>-1.020396</td>\n",
       "      <td>-0.549184</td>\n",
       "      <td>-0.292423</td>\n",
       "      <td>0.454529</td>\n",
       "      <td>-0.383480</td>\n",
       "      <td>-1.139931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Piemonte_Sud</th>\n",
       "      <td>-0.967137</td>\n",
       "      <td>0.070382</td>\n",
       "      <td>0.342478</td>\n",
       "      <td>-0.442927</td>\n",
       "      <td>-0.019192</td>\n",
       "      <td>-0.759762</td>\n",
       "      <td>-0.853231</td>\n",
       "      <td>1.163451</td>\n",
       "      <td>0.341598</td>\n",
       "      <td>-0.003145</td>\n",
       "      <td>...</td>\n",
       "      <td>1.875714</td>\n",
       "      <td>0.694293</td>\n",
       "      <td>1.392717</td>\n",
       "      <td>1.349087</td>\n",
       "      <td>-0.551938</td>\n",
       "      <td>-0.021388</td>\n",
       "      <td>-0.086330</td>\n",
       "      <td>0.576347</td>\n",
       "      <td>0.146632</td>\n",
       "      <td>-0.818877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticino</th>\n",
       "      <td>-1.060146</td>\n",
       "      <td>-0.405065</td>\n",
       "      <td>0.125603</td>\n",
       "      <td>-0.514438</td>\n",
       "      <td>-0.625540</td>\n",
       "      <td>-1.434559</td>\n",
       "      <td>-1.530712</td>\n",
       "      <td>0.090771</td>\n",
       "      <td>-0.235814</td>\n",
       "      <td>0.024990</td>\n",
       "      <td>...</td>\n",
       "      <td>1.467046</td>\n",
       "      <td>-0.063035</td>\n",
       "      <td>1.071194</td>\n",
       "      <td>0.899153</td>\n",
       "      <td>-0.606295</td>\n",
       "      <td>-0.563495</td>\n",
       "      <td>-0.291984</td>\n",
       "      <td>0.770822</td>\n",
       "      <td>-0.412164</td>\n",
       "      <td>-1.081585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 411 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0         1         2         3         4         5    \\\n",
       "Adda          -2.546951 -0.277191 -0.534156 -0.666789 -0.447894 -1.060644   \n",
       "Dora          -2.129508 -0.927136 -0.555958 -0.718282 -1.008995 -1.279207   \n",
       "Emiliani1     -0.382765  0.319215  0.548542 -0.010351  0.402030 -0.272581   \n",
       "Emiliani2     -1.339879  0.402993  0.282703 -0.030490  0.451097 -0.461545   \n",
       "Garda_Mincio  -1.996014  0.498869 -0.428613 -0.583432  0.075938 -1.170667   \n",
       "Lambro_Olona  -0.439541 -0.019547  0.269293 -0.434406 -0.421060 -1.360391   \n",
       "Oglio_Iseo    -1.223671 -0.087252 -0.278268 -0.774846  0.169616 -1.193040   \n",
       "Piemonte_Nord -1.146332  0.371173  0.379474 -0.099118 -0.292244 -0.980959   \n",
       "Piemonte_Sud  -0.967137  0.070382  0.342478 -0.442927 -0.019192 -0.759762   \n",
       "Ticino        -1.060146 -0.405065  0.125603 -0.514438 -0.625540 -1.434559   \n",
       "\n",
       "                    6         7         8         9    ...       401  \\\n",
       "Adda          -0.930783  0.130445 -0.182764  0.285961  ...  1.245203   \n",
       "Dora          -1.444875 -0.224922 -0.513422 -0.331122  ...  1.521211   \n",
       "Emiliani1     -0.163632  0.537451  0.523582  0.764119  ...  1.027290   \n",
       "Emiliani2     -0.616218  0.586097  0.324908  0.490785  ...  1.475893   \n",
       "Garda_Mincio  -0.994278  0.347932  0.270386  0.282736  ...  0.590168   \n",
       "Lambro_Olona  -1.488261  0.143476 -0.131799  0.022348  ...  1.343884   \n",
       "Oglio_Iseo    -1.058212  0.153692 -0.057888  0.467061  ...  0.956288   \n",
       "Piemonte_Nord -1.406861  0.562514  0.185923  0.419812  ...  1.482606   \n",
       "Piemonte_Sud  -0.853231  1.163451  0.341598 -0.003145  ...  1.875714   \n",
       "Ticino        -1.530712  0.090771 -0.235814  0.024990  ...  1.467046   \n",
       "\n",
       "                    402       403       404       405       406       407  \\\n",
       "Adda           0.071188  1.085285  0.531438 -0.638894 -0.263306 -0.082282   \n",
       "Dora          -0.076805  0.663966  0.023314 -1.370886 -0.784269 -0.701139   \n",
       "Emiliani1      0.055590  0.692477  0.361799 -0.418498 -0.060454  0.761079   \n",
       "Emiliani2      0.723830  1.270697  1.013738  0.032229  0.091910  0.283224   \n",
       "Garda_Mincio  -0.213240  0.570796  0.032382 -0.449253  0.032299  0.132804   \n",
       "Lambro_Olona  -0.011918  1.203688  0.840946 -0.353547 -0.212272 -0.299172   \n",
       "Oglio_Iseo     0.122784  1.199917  0.568570 -0.268606  0.174854  0.059327   \n",
       "Piemonte_Nord -0.405493  1.139576  0.674711 -1.020396 -0.549184 -0.292423   \n",
       "Piemonte_Sud   0.694293  1.392717  1.349087 -0.551938 -0.021388 -0.086330   \n",
       "Ticino        -0.063035  1.071194  0.899153 -0.606295 -0.563495 -0.291984   \n",
       "\n",
       "                    408       409       410  \n",
       "Adda           0.331204 -0.648940 -2.233412  \n",
       "Dora          -0.655289 -1.586325 -1.796340  \n",
       "Emiliani1      0.649694 -0.957702 -2.786888  \n",
       "Emiliani2      0.847138  0.552758 -2.185583  \n",
       "Garda_Mincio  -0.214182 -2.409204 -2.673294  \n",
       "Lambro_Olona   0.790614  0.109054 -1.086474  \n",
       "Oglio_Iseo     0.748131 -0.819305 -2.542862  \n",
       "Piemonte_Nord  0.454529 -0.383480 -1.139931  \n",
       "Piemonte_Sud   0.576347  0.146632 -0.818877  \n",
       "Ticino         0.770822 -0.412164 -1.081585  \n",
       "\n",
       "[10 rows x 411 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_all_df = pd.DataFrame()\n",
    "for basin in basins:\n",
    "    row = targets_train[basin].mean_std.rename(basin)\n",
    "    target_all_df = pd.concat((target_all_df,row),axis=1)\n",
    "target_all_df = target_all_df.transpose()\n",
    "target_all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d08e51af",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAGhCAYAAAA9YP2DAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAimUlEQVR4nO3deXCU9eHH8c8mIZtESOSURJZDuWoQRDkaREFFBBW8QFQcA6IVBZFGrab9IYqE4LRVrChHq0BHQA6LIg5Q4xhQIRguK1oFVGjkVDkWSNgkm+/vjw5bI0TyhO/yZJP3a2Znsg+72U9U5M3uk6zHGGMEAABgQZTbAwAAQM1BWAAAAGsICwAAYA1hAQAArCEsAACANYQFAACwhrAAAADWEBYAAMCamLP9gGVlZdq9e7fq1asnj8dzth8eAABUgTFGR44cUUpKiqKiKn5e4qyHxe7du+Xz+c72wwIAAAsKCgrUrFmzCn/9rIdFvXr1JP13WGJi4tl+eAAAUAV+v18+ny/053hFznpYnHj5IzExkbAAACDCnO40Bk7eBAAA1hAWAADAGsICAABYQ1gAAABrCAsAAGANYQEAAKwhLAAAgDWEBQAAsIawAAAA1hAWAADAGkdhEQwGNW7cOLVq1Urx8fG68MIL9eyzz8oYE659AAAggjh6r5DnnntO06ZN05w5c5Samqr169dr+PDhSkpK0pgxY8K1EQAARAhHYbFmzRrddNNNuuGGGyRJLVu21Pz58/XJJ5+EZVxtY4xRUUnQ7RkAcMbi60Sf9s2qUDM5CosePXpo5syZ2rp1q9q2batPP/1UH330kZ5//vkK7xMIBBQIBELX/X5/1dfWYMYYDZq+Vht2HnR7CgCcsS4t6mvRyDTiohZyFBZPPvmk/H6/2rdvr+joaAWDQWVlZWno0KEV3ic7O1vPPPPMGQ+t6YpKgkQFgBpj/c6DKioJKiHW0R8zqAEc/RtfuHCh5s6dq3nz5ik1NVWbN2/W2LFjlZKSovT09FPeJzMzUxkZGaHrfr9fPp/vzFbXcOv/r48SYqPdngEAjhUWB9VlYo7bM+AiR2Hx+OOP68knn9Qdd9whSbr44ou1c+dOZWdnVxgWXq9XXq/3zJfWIgmx0VQ+ACAiOfp208LCQkVFlb9LdHS0ysrKrI4CAACRydFfiwcMGKCsrCw1b95cqamp2rRpk55//nnde++94doHAAAiiKOweOmllzRu3Dg99NBD2r9/v1JSUvTAAw/oqaeeCtc+AAAQQRyFRb169TRlyhRNmTIlTHMAAEAk471CAACANYQFAACwhrAAAADWEBYAAMAawgIAAFhDWAAAAGsICwAAYA1hAQAArCEsAACANYQFAACwhrAAAADWEBYAAMAawgIAAFhDWAAAAGsICwAAYA1hAQAArCEsAACANYQFAACwhrAAAADWEBYAAMAawgIAAFhDWAAAAGsICwAAYA1hAQAArCEsAACANYQFAACwhrAAAADWEBYAAMAawgIAAFhDWAAAAGsICwAAYA1hAQAArCEsAACANY7ComXLlvJ4PCddRo0aFa59AAAggsQ4uXF+fr6CwWDo+pYtW3Tttddq8ODB1ocBAIDI4ygsGjduXO765MmTdeGFF6pXr15WRwFAJDHGqKgkePob1gKFxaWn/Li2i68TLY/H4/aMs8JRWPxUcXGxXn/9dWVkZPziP6xAIKBAIBC67vf7q/qQAFDtGGM0aPpabdh50O0p1U6Xie+7PaHa6NKivhaNTKsVcVHlkzffeustHTp0SMOGDfvF22VnZyspKSl08fl8VX1IAKh2ikqCRAVOa/3Og7XmWa0qP2Px6quvqn///kpJSfnF22VmZiojIyN03e/3ExcAaqT1/9dHCbHRbs9ANVJYHFSXiTluzzirqhQWO3fuVE5Ojv7xj3+c9rZer1der7cqDwMAESUhNloJsVX++xpQI1TppZBZs2apSZMmuuGGG2zvAQAAEcxxWJSVlWnWrFlKT09XTAxlDgAA/sdxWOTk5Og///mP7r333nDsAQAAEczxUw59+/aVMSYcWwAAQITjvUIAAIA1hAUAALCGsAAAANYQFgAAwBrCAgAAWENYAAAAawgLAABgDWEBAACsISwAAIA1hAUAALCGsAAAANYQFgAAwBrCAgAAWENYAAAAawgLAABgDWEBAACsISwAAIA1hAUAALCGsAAAANYQFgAAwBrCAgAAWENYAAAAawgLAABgDWEBAACsISwAAIA1hAUAALCGsAAAANYQFgAAwBrCAgAAWENYAAAAawgLAABgDWEBAACsISwAAIA1jsNi165duvvuu9WwYUPFx8fr4osv1vr168OxDQAARJgYJzc+ePCgLr/8cl111VVavny5GjdurG3btql+/frh2gcAACKIo7B47rnn5PP5NGvWrNCxVq1aWR91JowxKioJuj3DscLi0lN+HCni60TL4/G4PQMA4DJHYbF06VJdd911Gjx4sFatWqXzzz9fDz30kO6///4K7xMIBBQIBELX/X5/1deehjFGg6av1YadB8P2GGdDl4nvuz3BsS4t6mvRyDTiAgBqOUfnWHzzzTeaNm2a2rRpo5UrV+rBBx/UmDFjNGfOnArvk52draSkpNDF5/Od8eiKFJUEIz4qItX6nQcj8pkiAIBdjp6xKCsrU5cuXTRp0iRJUufOnbVlyxZNnz5d6enpp7xPZmamMjIyQtf9fn9Y4+KE9f/XRwmx0WF/nNqusDioLhNz3J4BAKgmHIVFcnKyLrroonLHfvWrX+nNN9+s8D5er1der7dq685AQmy0EmIdfXkAAOAMOXop5PLLL9dXX31V7tjWrVvVokULq6MAAEBkchQWv/3tb5WXl6dJkyZp+/btmjdvnmbOnKlRo0aFax8AAIggjsKia9euWrJkiebPn68OHTro2Wef1ZQpUzR06NBw7QMAABHE8UkIN954o2688cZwbAEAABGO9woBAADWEBYAAMAawgIAAFhDWAAAAGsICwAAYA1hAQAArCEsAACANYQFAACwhrAAAADWEBYAAMAawgIAAFhDWAAAAGsICwAAYA1hAQAArCEsAACANYQFAACwhrAAAADWEBYAAMAawgIAAFhDWAAAAGsICwAAYA1hAQAArCEsAACANYQFAACwhrAAAADWEBYAAMAawgIAAFhDWAAAAGsICwAAYA1hAQAArCEsAACANYQFAACwhrAAAADWOAqLp59+Wh6Pp9ylffv24doGAAAiTIzTO6SmpionJ+d/nyDG8acAAAA1lOMqiImJUdOmTcOxBT9ljFRS6PaK0ysO/uTjQknRrk1xpE6C5PG4vQIAahzHYbFt2zalpKQoLi5OaWlpys7OVvPmzSu8fSAQUCAQCF33+/1VW1qbGCO9dp1UsM7tJadnvJJm/ffjP7aWPIFfvHm14fu1dO8K4gIALHN0jkX37t01e/ZsrVixQtOmTdO3336rK664QkeOHKnwPtnZ2UpKSgpdfD7fGY+u8UoKIyMqJCV4AtoRd5d2xN2lhEiJCkkqyIuMZ4QAIMI4esaif//+oY87duyo7t27q0WLFlq4cKFGjBhxyvtkZmYqIyMjdN3v9xMXTjy2XYpNcHtFzVFcKP2ptdsrAKDGOqMzL88991y1bdtW27dvr/A2Xq9XXq/3TB6mdotNkGLPcXsFAACVckY/x+Lo0aP6+uuvlZycbGsPAACIYI7C4rHHHtOqVau0Y8cOrVmzRrfccouio6N15513hmsfAACIII5eCvnuu+9055136scff1Tjxo3Vs2dP5eXlqXHjxuHaBwAAIoijsHjjjTfCtQMAANQAvFcIAACwhrAAAADWEBYAAMAawgIAAFhDWAAAAGsICwAAYA1hAQAArCEsAACANYQFAACwhrAAAADWEBYAAMAawgIAAFhDWAAAAGsICwAAYA1hAQAArCEsAACANYQFAACwhrAAAADWEBYAAMAawgIAAFhDWAAAAGsICwAAYA1hAQAArCEsAACANYQFAACwhrAAAADWEBYAAMAawgIAAFhDWAAAAGsICwAAYA1hAQAArCEsAACANYQFAACw5ozCYvLkyfJ4PBo7dqylOQAAIJJVOSzy8/M1Y8YMdezY0eYeAAAQwWKqcqejR49q6NCh+utf/6qJEyfa3gQAwFlhjJEpKgrb5y8rDv7v48IilZVGh+2xPPHx8ng8Yfv8lVWlsBg1apRuuOEG9enT57RhEQgEFAgEQtf9fn9VHhIAAKuMMdp511AVbdoUtsc4Hh0rDZgkSdp2eU/FBYvD9ljxl16qFnNfdz0uHIfFG2+8oY0bNyo/P79St8/OztYzzzzjeBgAAOFkiorCGhWSFBcs1vK3HgvrY5xQtHGjTFGRPAkJZ+XxKuIoLAoKCvTII4/ovffeU1xcXKXuk5mZqYyMjNB1v98vn8/nbCUAAGHU5uOPFBUf7/aMKikrKtK2y3u6PSPEUVhs2LBB+/fv16WXXho6FgwGtXr1ak2dOlWBQEDR0eVfP/J6vfJ6vXbWAgAQBlHx8Ypy+W/6NYWjsLjmmmv02WeflTs2fPhwtW/fXk888cRJUQEAAGoXR2FRr149dejQodyxc845Rw0bNjzpOAAAqH34yZsAAMCaKn276U/l5uZamAEAAGoCnrEAAADWEBYAAMAawgIAAFhDWAAAAGsICwAAYA1hAQAArCEsAACANYQFAACwhrAAAADWEBYAAMAawgIAAFhDWAAAAGsICwAAYA1hAQAArCEsAACANYQFAACwhrAAAADWEBYAAMAawgIAAFhDWAAAAGsICwAAYA1hAQAArCEsAACANYQFAACwhrAAAADWEBYAAMAawgIAAFhDWAAAAGsICwAAYA1hAQAArCEsAACANYQFAACwhrAAAADWOAqLadOmqWPHjkpMTFRiYqLS0tK0fPnycG0DAAARxlFYNGvWTJMnT9aGDRu0fv16XX311brpppv0+eefh2sfAACIIDFObjxgwIBy17OysjRt2jTl5eUpNTXV6jAA+DljjIpKi9yeUU5hSfAnHxdJnmgX15QXHxMvj8fj9gzUMo7C4qeCwaAWLVqkY8eOKS0trcLbBQIBBQKB0HW/31/VhwRQixljdM/ye7T5+81uTynHlNWR9KwkqffCXvJElbg76Cc6N+msOf3mEBc4qxyHxWeffaa0tDQdP35cdevW1ZIlS3TRRRdVePvs7Gw988wzZzQSAIpKi6pdVEiSJ6pE9X71pNszTmnT/k0qKi1SQp0Et6egFnEcFu3atdPmzZt1+PBhLV68WOnp6Vq1alWFcZGZmamMjIzQdb/fL5/PV/XFAGq93NtzFR8T7/aMaquotEi9F/Z2ewZqKcdhERsbq9atW0uSLrvsMuXn5+vFF1/UjBkzTnl7r9crr9d7ZisB4CfiY+L5WzhQTZ3xz7EoKysrdw4FAACovRw9Y5GZman+/furefPmOnLkiObNm6fc3FytXLkyXPsAAEAEcRQW+/fv1z333KM9e/YoKSlJHTt21MqVK3XttdeGax8AAIggjsLi1VdfDdcOAABQA/BeIQAAwBrCAgAAWENYAAAAawgLAABgDWEBAACsISwAAIA1hAUAALCGsAAAANYQFgAAwBrCAgAAWENYAAAAawgLAABgDWEBAACsISwAAIA1hAUAALCGsAAAANYQFgAAwBrCAgAAWENYAAAAawgLAABgDWEBAACsISwAAIA1hAUAALCGsAAAANYQFgAAwBrCAgAAWENYAAAAawgLAABgDWEBAACsISwAAIA1hAUAALCGsAAAANYQFgAAwBpHYZGdna2uXbuqXr16atKkiW6++WZ99dVX4doGAAAijKOwWLVqlUaNGqW8vDy99957KikpUd++fXXs2LFw7QMAABEkxsmNV6xYUe767Nmz1aRJE23YsEFXXnml1WGoIYyRSgrdXvE/xYWn/rg6qJMgeTxurwCAM+IoLH7u8OHDkqQGDRpUeJtAIKBAIBC67vf7z+QhEUmMkV67TipY5/aSU/tTa7cXlOf7tXTvCuICQESr8smbZWVlGjt2rC6//HJ16NChwttlZ2crKSkpdPH5fFV9SESaksLqGxXVUUFe9Xp2BwCqoMrPWIwaNUpbtmzRRx999Iu3y8zMVEZGRui63+8nLmqjx7ZLsQlur6ieigur37MnAFBFVQqL0aNHa9myZVq9erWaNWv2i7f1er3yer1VGocaJDZBij3H7RUAgDBzFBbGGD388MNasmSJcnNz1apVq3DtAgAAEchRWIwaNUrz5s3T22+/rXr16mnv3r2SpKSkJMXHx4dlIAAAiByOTt6cNm2aDh8+rN69eys5OTl0WbBgQbj2AQCACOL4pRAAAICK8F4hAADAGsICAABYQ1gAAABrCAsAAGANYQEAAKwhLAAAgDWEBQAAsIawAAAA1hAWAADAGsICAABYQ1gAAABrCAsAAGANYQEAAKwhLAAAgDWEBQAAsIawAAAA1hAWAADAGsICAABYQ1gAAABrCAsAAGANYQEAAKwhLAAAgDWEBQAAsIawAAAA1hAWAADAGsICAABYQ1gAAABrCAsAAGANYQEAAKwhLAAAgDWEBQAAsIawAAAA1hAWAADAGsdhsXr1ag0YMEApKSnyeDx66623wjALAABEIsdhcezYMXXq1Ekvv/xyOPYAAIAIFuP0Dv3791f//v3DsQUAagVjjIpKi8L2+X/6ucP5OJIUHxMvj8cT1sdAZHEcFk4FAgEFAoHQdb/fH+6HBIBqyxije5bfo83fbz4rj9d7Ye+wfv7OTTprTr85xAVCwn7yZnZ2tpKSkkIXn88X7ocEgGqrqLTorEXF2bBp/6awPyuCyBL2ZywyMzOVkZERuu73+4kLAJCUe3uu4mPi3Z5RJUWlRWF/NgSRKexh4fV65fV6w/0wABBx4mPilVAnwe0ZgFX8HAsAAGCN42csjh49qu3bt4euf/vtt9q8ebMaNGig5s2bWx0HAAAii+OwWL9+va666qrQ9RPnT6Snp2v27NnWhgEAgMjjOCx69+4tY0w4tgAAgAjHORYAAMAawgIAAFhDWAAAAGsICwAAYA1hAQAArCEsAACANYQFAACwhrAAAADWEBYAAMAawgIAAFhDWAAAAGsICwAAYA1hAQAArCEsAACANYQFAACwhrAAAADWEBYAAMAawgIAAFhDWAAAAGsICwAAYA1hAQAArCEsAACANYQFAACwhrAAAADWEBYAAMAawgIAAFhDWAAAAGsICwAAYA1hAQAArCEsAACANYQFAACwhrAAAADWEBYAAMCaKoXFyy+/rJYtWyouLk7du3fXJ598YnsXAACIQI7DYsGCBcrIyND48eO1ceNGderUSdddd532798fjn0AACCCxDi9w/PPP6/7779fw4cPlyRNnz5d7777rl577TU9+eST1gcC1ULxsTB+7sJTfxwOseeE9/MDqPUchUVxcbE2bNigzMzM0LGoqCj16dNHa9euPeV9AoGAAoFA6Prhw4clSX6/vyp7f1FhcanKAoWhz18a67ibqofiY1LA/Pdjv1+KDbq7p6pqytchSdnNzs7jZF0Y3s+f+V14P38YFZYUKlj03/+G/H6/SuuUuryoavg6qo+ywkIdDf7va4gqjbyvQTp7X8eJP7eNMb98Q+PArl27jCSzZs2acscff/xx061bt1PeZ/z48UYSFy5cuHDhwqUGXAoKCn6xFcL+V/rMzExlZGSErpeVlenAgQNq2LChPB5PuB8eAABYYIzRkSNHlJKS8ou3cxQWjRo1UnR0tPbt21fu+L59+9S0adNT3sfr9crr9ZY7du655zp5WAAAUA0kJSWd9jaOviskNjZWl112md5///3QsbKyMr3//vtKS0tzvhAAANQojl8KycjIUHp6urp06aJu3bppypQpOnbsWOi7RAAAQO3lOCyGDBmi77//Xk899ZT27t2rSy65RCtWrNB5550Xjn0AACCCeMxpv28EAACgcnivEAAAYA1hAQAArCEsAACANYQFAACwpsaExbBhw+TxeCq87Nq1y+2JlXL06FGNHz9e/fr1U4MGDeTxeDR79my3Zzny+eefa/DgwbrggguUkJCgRo0a6corr9Q777zj9jRHNmzYoH79+ikxMVH16tVT3759tXnzZrdnORYIBPTEE08oJSVF8fHx6t69u9577z23Z1Vafn6+Ro8erdTUVJ1zzjlq3ry5br/9dm3dutXtaY5t27ZNd9xxh5o1a6aEhAS1b99eEyZMUGFhmN98LoyysrLk8XjUoUMHt6dUWm5uboV/VuTl5bk9z7GNGzdq4MCBatCggRISEtShQwf95S9/cW1PhL5L18keeOAB9enTp9wxY4xGjhypli1b6vzzz3dpmTM//PCDJkyYoObNm6tTp07Kzc11e5JjO3fu1JEjR5Senq6UlBQVFhbqzTff1MCBAzVjxgz95je/cXviaW3cuFE9e/aUz+fT+PHjVVZWpldeeUW9evXSJ598onbt2rk9sdKGDRumxYsXa+zYsWrTpo1mz56t66+/Xh988IF69uzp9rzTeu655/Txxx9r8ODB6tixo/bu3aupU6fq0ksvVV5eXsT8gVZQUKBu3bopKSlJo0ePVoMGDbR27VqNHz9eGzZs0Ntvv+32RMe+++47TZo0SeecE5nvmjtmzBh17dq13LHWrVu7tKZq/vnPf2rAgAHq3Lmzxo0bp7p16+rrr7/Wd9+5+IaDTt6ELNJ8+OGHRpLJyspye0qlHT9+3OzZs8cYY0x+fr6RZGbNmuXuKAtKS0tNp06dTLt27dyeUinXX3+9qV+/vvnhhx9Cx3bv3m3q1q1rbr31VheXObNu3Tojyfzxj38MHSsqKjIXXnihSUtLc3FZ5X388ccmEAiUO7Z161bj9XrN0KFDXVrlXFZWlpFktmzZUu74PffcYySZAwcOuLSs6oYMGWKuvvpq06tXL5Oamur2nEr74IMPjCSzaNEit6eckcOHD5vzzjvP3HLLLSYYDLo9J6TGvBRyKvPmzZPH49Fdd93l9pRK83q9Fb7vSiSLjo6Wz+fToUOH3J5SKR9++KH69Omjhg0bho4lJyerV69eWrZsmY4ePeriuspbvHixoqOjyz1LFBcXpxEjRmjt2rUqKChwcV3l9OjRQ7GxseWOtWnTRqmpqfr3v//t0irnTrzl9M9/mGBycrKioqJO+hqru9WrV2vx4sWaMmWK21POyJEjR1QaoW+XPm/ePO3bt09ZWVmKiorSsWPHVFZW5vasmnOOxc+VlJRo4cKF6tGjh1q2bOn2nFrp2LFj+uGHH/T111/rhRde0PLly3XNNde4PatSAoGA4uPjTzqekJCg4uJibdmyxYVVzm3atElt27ZVYmJiuePdunWTpIg8Z0T678uc+/btU6NGjdyeUmm9e/eWJI0YMUKbN29WQUGBFixYoGnTpmnMmDER9XJCMBjUww8/rPvuu08XX3yx23OqbPjw4UpMTFRcXJyuuuoqrV+/3u1JjuTk5CgxMVG7du1Su3btVLduXSUmJurBBx/U8ePHXdtVY86x+LmVK1fqxx9/1NChQ92eUms9+uijmjFjhiQpKipKt956q6ZOneryqspp166d8vLyFAwGFR0dLUkqLi7WunXrJCliTgbes2ePkpOTTzp+4tju3bvP9iQr5s6dq127dmnChAluT6m0fv366dlnn9WkSZO0dOnS0PE//OEPmjhxoovLnJs+fbp27typnJwct6dUSWxsrG677TZdf/31atSokb744gv96U9/0hVXXKE1a9aoc+fObk+slG3btqm0tFQ33XSTRowYoezsbOXm5uqll17SoUOHNH/+fFd21diwmDdvnurUqaPbb7/d7Sm11tixYzVo0CDt3r1bCxcuVDAYVHFxsduzKuWhhx7Sgw8+qBEjRuh3v/udysrKNHHiRO3Zs0eSVFRU5PLCyikqKpLX6z3peFxcXOjXI82XX36pUaNGKS0tTenp6W7PcaRly5a68sorddttt6lhw4Z69913NWnSJDVt2lSjR492e16l/Pjjj3rqqac0btw4NW7c2O05VdKjRw/16NEjdH3gwIEaNGiQOnbsqMzMTK1YscLFdZV39OhRFRYWauTIkaHvArn11ltVXFysGTNmaMKECWrTps3ZH+b2SR7hcOTIEZOQkGBuvPFGt6eckZp08qYxxlx77bWma9eupqyszO0plfL73//e1KlTx0gykkyXLl3MH/7wByPJLFmyxO15lZKammquvvrqk45//vnnRpKZPn26C6uqbs+ePeaCCy4wPp/P7Nq1y+05jsyfP9/Ex8ebgoKCcseHDRtmEhISyp0oXJ2NHDnStG7dutwJtZF28mZF7rjjDhMbG2tKS0vdnlIpqampRpJZtWpVueOrVq0yksycOXNc2VUjz7F46623VFhYyMsg1cygQYOUn58fMT9/ICsrS/v27dOHH36of/3rX8rPzw+dGNW2bVuX11VOcnJy6FmWnzpxLCUl5WxPqrLDhw+rf//+OnTokFasWBFR2yXplVdeUefOndWsWbNyxwcOHKjCwkJt2rTJpWWVt23bNs2cOVNjxozR7t27tWPHDu3YsUPHjx9XSUmJduzYoQMHDrg9s8p8Pp+Ki4t17Ngxt6dUyonfAz8/IbhJkyaSpIMHD571TVINPXlz7ty5qlu3rgYOHOj2FPzEiafdDx8+7PKSyqtfv7569uwZOkEtJydHzZo1U/v27V1eVjmXXHKJtm7dGvqOhBNOnCtyySWXuLDKuePHj2vAgAHaunWrli1bposuusjtSY7t27dPwWDwpOMlJSWSFBHfmbBr1y6VlZVpzJgxatWqVeiybt06bd26Va1atYqo815+7ptvvlFcXJzq1q3r9pRKueyyyySdfM7XiXOn3HqpqsaFxffff6+cnBzdcsstSkhIcHtOrbR///6TjpWUlOjvf/+74uPjI/IPBUlasGCB8vPzNXbsWEVFRcZvnUGDBikYDGrmzJmhY4FAQLNmzVL37t3l8/lcXFc5wWBQQ4YM0dq1a7Vo0SKlpaW5PalK2rZtq02bNp30jN38+fMVFRWljh07urSs8jp06KAlS5acdElNTVXz5s21ZMkSjRgxwu2Zp/X999+fdOzTTz/V0qVL1bdv34j5/X3iHMJXX3213PG//e1viomJCX0n0tlW407eXLBggUpLSyP6ZZCpU6fq0KFDoep85513Qj9F7eGHH1ZSUpKb807rgQcekN/v15VXXqnzzz9fe/fu1dy5c/Xll1/qz3/+c0T8bWD16tWaMGGC+vbtq4YNGyovL0+zZs1Sv3799Mgjj7g9r9K6d++uwYMHKzMzU/v371fr1q01Z84c7dix46T/GVVXjz76qJYuXaoBAwbowIEDev3118v9+t133+3SMmcef/xxLV++XFdccYVGjx6thg0batmyZVq+fLnuu+++iHhpp1GjRrr55ptPOn7iZ1mc6teqoyFDhig+Pl49evRQkyZN9MUXX2jmzJlKSEjQ5MmT3Z5XaZ07d9a9996r1157TaWlperVq5dyc3O1aNEiZWZmuvfflCtndoTRr3/9a9OkSZOIOfnmVFq0aBE6YfDnl2+//dbteac1f/5806dPH3PeeeeZmJgYU79+fdOnTx/z9ttvuz2t0rZv32769u1rGjVqZLxer2nfvr3Jzs4+6SdARoKioiLz2GOPmaZNmxqv12u6du1qVqxY4fasSuvVq1eFvx8i7X9h69atM/379zdNmzY1derUMW3btjVZWVmmpKTE7WlnJNJO3nzxxRdNt27dTIMGDUxMTIxJTk42d999t9m2bZvb0xwrLi42Tz/9tGnRooWpU6eOad26tXnhhRdc3eQxxhhXigYAANQ4kfFCEgAAiAiEBQAAsIawAAAA1hAWAADAGsICAABYQ1gAAABrCAsAAGANYQEAAKwhLAAAgDWEBQAAsIawAAAA1hAWAADAGsICAABY8//+jSXVH0m83AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hierarchical_clustering_result = hierarchical_clustering.fit(target_all_df)\n",
    "plot_dendrogram(hierarchical_clustering_result, labels=hierarchical_clustering_result.labels_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f706dd8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 7-1: Piemonte nord da solo o con Dora\n",
    "# 0-9: Ticino e Adda simili, vicino anche 3, emiliani2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "76742011",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Adda', 'Dora', 'Emiliani1', 'Emiliani2', 'Garda_Mincio',\n",
       "       'Lambro_Olona', 'Oglio_Iseo', 'Piemonte_Nord', 'Piemonte_Sud',\n",
       "       'Ticino'], dtype=object)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_all_df.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "0f2c8aa6",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "linkage_data = linkage(np.transpose(targets_df_trainVal), method='ward', metric='euclidean')\n",
    "dendrogram(linkage_data)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "ff39286d",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "linkage_data = linkage(np.transpose(targets_df_trainVal), method='average', metric='euclidean')\n",
    "dendrogram(linkage_data)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "de295dc4",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Adda', 'Dora', 'Emiliani1', 'Emiliani2', 'Garda_Mincio',\n",
       "       'Lambro_Olona', 'Oglio_Iseo', 'Piemonte_Nord', 'Piemonte_Sud',\n",
       "       'Ticino'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_df_trainVal.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
