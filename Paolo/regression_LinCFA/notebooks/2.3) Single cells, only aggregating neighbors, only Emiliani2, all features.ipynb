{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "288de91a",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4f3825c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "sys.path.append(\"/Users/paolo/Documents/methods/CMI_FS\")\n",
    "from feature_selection import forwardFeatureSelection\n",
    "\n",
    "sys.path.append(\"/Users/paolo/Documents/methods/LinCFA\")\n",
    "from LinCFA import LinCFA\n",
    "\n",
    "sys.path.append(\"/Users/paolo/Documents/Droughts/Paolo/regression_LinCFA\")\n",
    "from aux import standardize,unfold_dataset,compute_r2,prepare_target,prepare_features,aggregate_unfolded_data,FS_with_linearWrapper,compare_methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b525256e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cells(output,selected_colnames, xmin=9, xmax=11, ymin=44, ymax=45.5):\n",
    "    x = []\n",
    "    y = []\n",
    "    colors = cm.rainbow(np.linspace(0,1,len(output)))\n",
    "    fig, ax = plt.subplots(2)\n",
    "    ax[0].set_xlim(xmin,xmax)\n",
    "    ax[1].set_xlim(xmin,xmax)\n",
    "    ax[0].set_ylim(ymin,ymax)\n",
    "    ax[1].set_ylim(ymin,ymax)\n",
    "    for i in range(len(output)): \n",
    "        #print(len(output[i]))\n",
    "        x = []\n",
    "        y = []\n",
    "        \n",
    "        for datum in output[i]:\n",
    "            x.append(float(datum.split('_')[1]))\n",
    "            y.append(float(datum.split('_')[2]))\n",
    "        ax[0].scatter(x,y,color=colors[i])\n",
    "    \n",
    "    x = []\n",
    "    y = []\n",
    "    col = cm.rainbow(np.linspace(0,1,len(selected_colnames)))\n",
    "    for i in range(len(selected_colnames)): \n",
    "        idx = int(selected_colnames[i].split('_')[-1])\n",
    "        for datum in output[idx]:\n",
    "            x.append(float(datum.split('_')[1]))\n",
    "            y.append(float(datum.split('_')[2]))\n",
    "        ax[1].scatter(x,y,color=col[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7236826f",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2d989b0",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.214281    0.00  2001     1 -1.402730\n",
      "1    2001-01-13  0.484737    0.52  2001     2  0.347916\n",
      "2    2001-01-21  0.466071    0.47  2001     3  0.227090\n",
      "3    2001-01-29  0.417470    0.44  2001     5 -0.087501\n",
      "4    2001-02-06  0.492202    0.53  2001     6  0.396235\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "584  2013-10-21  0.739946    0.79  2013    43  1.999865\n",
      "585  2013-10-29  0.447691    0.46  2013    44  0.108118\n",
      "586  2013-11-06  0.541628    0.56  2013    45  0.716163\n",
      "587  2013-11-14  0.493719    0.53  2013    46  0.406051\n",
      "588  2013-11-22  0.527436    0.57  2013    47  0.624301\n",
      "\n",
      "[589 rows x 6 columns]\n",
      " target shapes: ((589, 6), (200, 6), (789, 6), (192, 6))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x144536cd0>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target('')\n",
    "plt.plot(target_df_trainVal.loc[:,'mean'], color='blue')\n",
    "plt.plot(target_df_trainVal.loc[:,'mean_std'], color='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3846f4b",
   "metadata": {},
   "source": [
    "# 1) Aggregations: temperature, precipitation, both "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5f3113",
   "metadata": {},
   "source": [
    "## temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a28c89",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e58f6fa5",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'y', 'x', 'year', 'week', 'cyclostationary_mean_tg',\n",
       "       'cyclostationary_mean_rr', 'cyclostationary_mean_tg_1w',\n",
       "       'cyclostationary_mean_tg_4w', 'cyclostationary_mean_tg_8w',\n",
       "       'cyclostationary_mean_tg_12w', 'cyclostationary_mean_tg_16w',\n",
       "       'cyclostationary_mean_tg_24w', 'cyclostationary_mean_rr_1w',\n",
       "       'cyclostationary_mean_rr_4w', 'cyclostationary_mean_rr_8w',\n",
       "       'cyclostationary_mean_rr_12w', 'cyclostationary_mean_rr_16w',\n",
       "       'cyclostationary_mean_rr_24w'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path='/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/features/csv_allvalues/temporal_aggreg/Emiliani2_aggreg.csv'\n",
    "pd.read_csv(path).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e691ea0b",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.214281    0.00  2001     1 -1.402730\n",
      "1    2001-01-13  0.484737    0.52  2001     2  0.347916\n",
      "2    2001-01-21  0.466071    0.47  2001     3  0.227090\n",
      "3    2001-01-29  0.417470    0.44  2001     5 -0.087501\n",
      "4    2001-02-06  0.492202    0.53  2001     6  0.396235\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "584  2013-10-21  0.739946    0.79  2013    43  1.999865\n",
      "585  2013-10-29  0.447691    0.46  2013    44  0.108118\n",
      "586  2013-11-06  0.541628    0.56  2013    45  0.716163\n",
      "587  2013-11-14  0.493719    0.53  2013    46  0.406051\n",
      "588  2013-11-22  0.527436    0.57  2013    47  0.624301\n",
      "\n",
      "[589 rows x 6 columns]\n",
      " target shapes: ((589, 6), (200, 6), (789, 6), (192, 6))\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 42\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 49\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 36\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 47\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 40\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 33\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 22\n",
      "\n",
      "actual training score: 0.15298257575890595\n",
      "actual validation score: 0.3309031910287913, number of remaining columns: 267\n",
      "\n",
      "actual training score: 0.16310848774374098\n",
      "actual validation score: 0.34064028629260534, number of remaining columns: 266\n",
      "\n",
      "actual training score: 0.1674135500864824\n",
      "actual validation score: 0.36043327102620126, number of remaining columns: 265\n",
      "\n",
      "actual training score: 0.16830009689961278\n",
      "actual validation score: 0.368985537724409, number of remaining columns: 264\n",
      "\n",
      "actual training score: 0.17090367072170387\n",
      "actual validation score: 0.3876233279432788, number of remaining columns: 263\n",
      "\n",
      "actual training score: 0.17213642481830793\n",
      "actual validation score: 0.41351041211954376, number of remaining columns: 262\n",
      "\n",
      "actual training score: 0.18066787467286194\n",
      "actual validation score: 0.42631357341643195, number of remaining columns: 261\n",
      "\n",
      "actual training score: 0.18169333333519655\n",
      "actual validation score: 0.43452576286995725, number of remaining columns: 260\n",
      "\n",
      "actual training score: 0.19437694838031871\n",
      "actual validation score: 0.448377841135461, number of remaining columns: 259\n",
      "\n",
      "actual training score: 0.20589222730822343\n",
      "actual validation score: 0.4710303167520682, number of remaining columns: 258\n",
      "\n",
      "actual training score: 0.2113682672056959\n",
      "actual validation score: 0.49051655498199753, number of remaining columns: 257\n",
      "\n",
      "actual training score: 0.2163721933486703\n",
      "actual validation score: 0.4967738734986, number of remaining columns: 256\n",
      "\n",
      "actual training score: 0.2168495682925916\n",
      "actual validation score: 0.5005092987040454, number of remaining columns: 255\n",
      "\n",
      "actual training score: 0.21873624917323886\n",
      "actual validation score: 0.5066559953976535, number of remaining columns: 254\n",
      "\n",
      "actual training score: 0.22426580898099358\n",
      "actual validation score: 0.5136123129389363, number of remaining columns: 253\n",
      "\n",
      "actual training score: 0.22881354538013865\n",
      "actual validation score: 0.5224422422873525, number of remaining columns: 252\n",
      "\n",
      "actual training score: 0.23538201682184468\n",
      "actual validation score: 0.5354401587496993, number of remaining columns: 251\n",
      "\n",
      "actual training score: 0.23645557209993662\n",
      "actual validation score: 0.5417278870421582, number of remaining columns: 250\n",
      "\n",
      "actual training score: 0.2386455667301125\n",
      "actual validation score: 0.5468531075311984, number of remaining columns: 249\n",
      "\n",
      "actual training score: 0.2402592741244065\n",
      "actual validation score: 0.5526764561312443, number of remaining columns: 248\n",
      "\n",
      "actual training score: 0.24584829894853877\n",
      "actual validation score: 0.5589909511922315, number of remaining columns: 247\n",
      "\n",
      "actual training score: 0.24782986515361027\n",
      "actual validation score: 0.5631132388781871, number of remaining columns: 246\n",
      "\n",
      "actual training score: 0.24816516995304105\n",
      "actual validation score: 0.5662062630230252, number of remaining columns: 245\n",
      "\n",
      "actual training score: 0.24870929273043363\n",
      "actual validation score: 0.5685381215095802, number of remaining columns: 244\n",
      "\n",
      "actual training score: 0.2494437868868875\n",
      "actual validation score: 0.5709786143821687, number of remaining columns: 243\n",
      "\n",
      "actual training score: 0.24947878092924047\n",
      "actual validation score: 0.5721814009253119, number of remaining columns: 242\n",
      "\n",
      "actual training score: 0.2609704210141579\n",
      "actual validation score: 0.5792867272161389, number of remaining columns: 241\n",
      "\n",
      "actual training score: 0.26548510606275655\n",
      "actual validation score: 0.584084744722822, number of remaining columns: 240\n",
      "\n",
      "actual training score: 0.2699959037896953\n",
      "actual validation score: 0.5887787474624118, number of remaining columns: 239\n",
      "\n",
      "actual training score: 0.2803835904757591\n",
      "actual validation score: 0.5998073380771303, number of remaining columns: 238\n",
      "\n",
      "actual training score: 0.2815112203542366\n",
      "actual validation score: 0.605408943782387, number of remaining columns: 237\n",
      "\n",
      "actual training score: 0.2816349840504322\n",
      "actual validation score: 0.6065484446023366, number of remaining columns: 236\n",
      "\n",
      "actual training score: 0.2819187406826994\n",
      "actual validation score: 0.6067280438385761, number of remaining columns: 235\n",
      "\n",
      "actual training score: 0.2819239953529964\n",
      "actual validation score: 0.6068828695934735, number of remaining columns: 234\n",
      "\n",
      "actual training score: 0.28193730336768663\n",
      "actual validation score: 0.6068969476932492, number of remaining columns: 233\n",
      "\n",
      "actual training score: 0.28193986121957415\n",
      "actual validation score: 0.6069327746638848, number of remaining columns: 232\n",
      "\n",
      "actual training score: 0.28194602724469964\n",
      "actual validation score: 0.606875799795038, number of remaining columns: 231\n",
      "\n",
      "actual training score: 0.2822017431829368\n",
      "actual validation score: 0.6069577291727184, number of remaining columns: 230\n",
      "\n",
      "actual training score: 0.2822018915253147\n",
      "actual validation score: 0.6069808113948783, number of remaining columns: 229\n",
      "\n",
      "actual training score: 0.28224741125576425\n",
      "actual validation score: 0.606551363579519, number of remaining columns: 228\n",
      "\n",
      "actual training score: 0.28231968062084023\n",
      "actual validation score: 0.6063236648672305, number of remaining columns: 227\n",
      "\n",
      "actual training score: 0.28232352206235756\n",
      "actual validation score: 0.606229161245977, number of remaining columns: 226\n",
      "\n",
      "actual training score: 0.2823302122671557\n",
      "actual validation score: 0.605600930581224, number of remaining columns: 225\n",
      "\n",
      "actual training score: 0.28246909065927617\n",
      "actual validation score: 0.6047621965734591, number of remaining columns: 224\n",
      "\n",
      "actual training score: 0.28387067575623204\n",
      "actual validation score: 0.6037291297508417, number of remaining columns: 223\n",
      "\n",
      "actual training score: 0.2840144960039692\n",
      "actual validation score: 0.6038950696862431, number of remaining columns: 222\n",
      "\n",
      "actual training score: 0.2840181255072203\n",
      "actual validation score: 0.6042823887499247, number of remaining columns: 221\n",
      "\n",
      "actual training score: 0.2840366003950451\n",
      "actual validation score: 0.6037734977714545, number of remaining columns: 220\n",
      "\n",
      "actual training score: 0.2843683673964671\n",
      "actual validation score: 0.6015674556481303, number of remaining columns: 219\n",
      "\n",
      "actual training score: 0.2872667381336458\n",
      "actual validation score: 0.6001358634874252, number of remaining columns: 218\n",
      "\n",
      "actual training score: 0.2872672470955756\n",
      "actual validation score: 0.5999937918193372, number of remaining columns: 217\n",
      "\n",
      "actual training score: 0.2894134918499225\n",
      "actual validation score: 0.6089693163315097, number of remaining columns: 216\n",
      "\n",
      "actual training score: 0.3015379136460907\n",
      "actual validation score: 0.6123812542962448, number of remaining columns: 215\n",
      "\n",
      "actual training score: 0.30164850385075725\n",
      "actual validation score: 0.6141016724125122, number of remaining columns: 214\n",
      "\n",
      "actual training score: 0.30170098089104214\n",
      "actual validation score: 0.6158761160787127, number of remaining columns: 213\n",
      "\n",
      "actual training score: 0.3018479461794087\n",
      "actual validation score: 0.6153384526265958, number of remaining columns: 212\n",
      "\n",
      "actual training score: 0.30189249772900617\n",
      "actual validation score: 0.6139049850742593, number of remaining columns: 211\n",
      "\n",
      "actual training score: 0.30358468652802273\n",
      "actual validation score: 0.6127872396519292, number of remaining columns: 210\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual training score: 0.3036338227567562\n",
      "actual validation score: 0.6111138991214513, number of remaining columns: 209\n",
      "\n",
      "actual training score: 0.314397476579345\n",
      "actual validation score: 0.6083662191163877, number of remaining columns: 208\n",
      "\n",
      "actual training score: 0.31511880469656894\n",
      "actual validation score: 0.6162527761309031, number of remaining columns: 207\n",
      "\n",
      "actual training score: 0.31519760013363163\n",
      "actual validation score: 0.6198057192392796, number of remaining columns: 206\n",
      "\n",
      "actual training score: 0.3152005544342489\n",
      "actual validation score: 0.6201898372429093, number of remaining columns: 205\n",
      "\n",
      "actual training score: 0.31710363464355207\n",
      "actual validation score: 0.6195175545249989, number of remaining columns: 204\n",
      "\n",
      "actual training score: 0.3179017855567724\n",
      "actual validation score: 0.6218746955095565, number of remaining columns: 203\n",
      "\n",
      "actual training score: 0.31793310191550084\n",
      "actual validation score: 0.6204044729825773, number of remaining columns: 202\n",
      "\n",
      "actual training score: 0.3184461563118762\n",
      "actual validation score: 0.6186723369551164, number of remaining columns: 201\n",
      "\n",
      "actual training score: 0.3185131972320876\n",
      "actual validation score: 0.6162978409430442, number of remaining columns: 200\n",
      "\n",
      "actual training score: 0.3187930194332329\n",
      "actual validation score: 0.6120371125977426, number of remaining columns: 199\n",
      "\n",
      "actual training score: 0.3188888760784333\n",
      "actual validation score: 0.6093831706518051, number of remaining columns: 198\n",
      "\n",
      "actual training score: 0.31894757814752084\n",
      "actual validation score: 0.6056334764162812, number of remaining columns: 197\n",
      "\n",
      "actual training score: 0.32054777008907775\n",
      "actual validation score: 0.6002432612558262, number of remaining columns: 196\n",
      "\n",
      "actual training score: 0.32059053107002844\n",
      "actual validation score: 0.5973708037196145, number of remaining columns: 195\n",
      "\n",
      "actual training score: 0.3223326949843869\n",
      "actual validation score: 0.592170632641988, number of remaining columns: 194\n",
      "\n",
      "actual training score: 0.32280108796738916\n",
      "actual validation score: 0.5840666805733379, number of remaining columns: 193\n",
      "\n",
      "actual training score: 0.3242434623654069\n",
      "actual validation score: 0.5809674344622818, number of remaining columns: 192\n",
      "\n",
      "actual training score: 0.32583493782357986\n",
      "actual validation score: 0.5760968959704965, number of remaining columns: 191\n",
      "\n",
      "actual training score: 0.3340791949151617\n",
      "actual validation score: 0.5703913291406584, number of remaining columns: 190\n",
      "\n",
      "actual training score: 0.33631470964425647\n",
      "actual validation score: 0.5690557549991659, number of remaining columns: 189\n",
      "\n",
      "actual training score: 0.3365572345516171\n",
      "actual validation score: 0.567252851562726, number of remaining columns: 188\n",
      "\n",
      "actual training score: 0.3368972392380599\n",
      "actual validation score: 0.5634438105595441, number of remaining columns: 187\n",
      "\n",
      "actual training score: 0.34258768440153575\n",
      "actual validation score: 0.5599730344368428, number of remaining columns: 186\n",
      "\n",
      "actual training score: 0.3437442900797968\n",
      "actual validation score: 0.5531140639804488, number of remaining columns: 185\n",
      "\n",
      "actual training score: 0.3601607893505604\n",
      "actual validation score: 0.5508053311121106, number of remaining columns: 184\n",
      "\n",
      "actual training score: 0.361375230586483\n",
      "actual validation score: 0.5514645195152654, number of remaining columns: 183\n",
      "\n",
      "actual training score: 0.3613989452859634\n",
      "actual validation score: 0.549983982796177, number of remaining columns: 182\n",
      "\n",
      "actual training score: 0.3614839821388093\n",
      "actual validation score: 0.5485180566805904, number of remaining columns: 181\n",
      "\n",
      "actual training score: 0.363514178918826\n",
      "actual validation score: 0.5469492080635028, number of remaining columns: 180\n",
      "\n",
      "actual training score: 0.36534815674653565\n",
      "actual validation score: 0.538817082737026, number of remaining columns: 179\n",
      "\n",
      "actual training score: 0.36899346233423036\n",
      "actual validation score: 0.5373521794930254, number of remaining columns: 178\n",
      "\n",
      "actual training score: 0.37223466114261294\n",
      "actual validation score: 0.5357247242841476, number of remaining columns: 177\n",
      "\n",
      "actual training score: 0.37428802753429335\n",
      "actual validation score: 0.5305758634268534, number of remaining columns: 176\n",
      "\n",
      "actual training score: 0.3748782258482378\n",
      "actual validation score: 0.5301503212740892, number of remaining columns: 175\n",
      "\n",
      "actual training score: 0.38160414571021684\n",
      "actual validation score: 0.52165791436494, number of remaining columns: 174\n",
      "\n",
      "actual training score: 0.381830676439322\n",
      "actual validation score: 0.512949885063949, number of remaining columns: 173\n",
      "\n",
      "actual training score: 0.3818535121141834\n",
      "actual validation score: 0.5124877472335241, number of remaining columns: 172\n",
      "\n",
      "actual training score: 0.3900976971076635\n",
      "actual validation score: 0.5022420453826688, number of remaining columns: 171\n",
      "\n",
      "actual training score: 0.3910521417822367\n",
      "actual validation score: 0.5113773061336633, number of remaining columns: 170\n",
      "\n",
      "actual training score: 0.3910961896967219\n",
      "actual validation score: 0.5157128357383769, number of remaining columns: 169\n",
      "\n",
      "actual training score: 0.3950937309839674\n",
      "actual validation score: 0.5123234077037919, number of remaining columns: 168\n",
      "\n",
      "\n",
      "\n",
      "selected columns: ['cyclostationary_mean_tg_1w_41', 'cyclostationary_mean_tg_16w_14', 'cyclostationary_mean_tg_1w_26', 'cyclostationary_mean_tg_1w_3', 'cyclostationary_mean_tg_12w_37', 'cyclostationary_mean_tg_8w_13', 'cyclostationary_mean_tg_8w_14', 'cyclostationary_mean_tg_18', 'cyclostationary_mean_tg_12w_8', 'cyclostationary_mean_tg_12w_25', 'cyclostationary_mean_tg_1w_21', 'cyclostationary_mean_tg_1w_32', 'cyclostationary_mean_tg_24w_10', 'cyclostationary_mean_tg_16w_11', 'cyclostationary_mean_tg_8w_43', 'cyclostationary_mean_tg_8w_25', 'cyclostationary_mean_tg_16w_12', 'cyclostationary_mean_tg_16w_5', 'cyclostationary_mean_tg_12w_13', 'cyclostationary_mean_tg_12w_10', 'cyclostationary_mean_tg_24w_9', 'cyclostationary_mean_tg_39', 'cyclostationary_mean_tg_21', 'cyclostationary_mean_tg_1w_39', 'cyclostationary_mean_tg_4w_15', 'cyclostationary_mean_tg_9', 'cyclostationary_mean_tg_16w_18', 'cyclostationary_mean_tg_8w_26', 'cyclostationary_mean_tg_24w_17', 'cyclostationary_mean_tg_40', 'cyclostationary_mean_tg_25', 'cyclostationary_mean_tg_37', 'cyclostationary_mean_tg_11', 'cyclostationary_mean_tg_1w_43', 'cyclostationary_mean_tg_4', 'cyclostationary_mean_tg_1w_2', 'cyclostationary_mean_tg_16w_8', 'cyclostationary_mean_tg_12w_14', 'cyclostationary_mean_tg_1w_35', 'cyclostationary_mean_tg_27', 'cyclostationary_mean_tg_1w_37', 'cyclostationary_mean_tg_24w_8', 'cyclostationary_mean_tg_24w_18', 'cyclostationary_mean_tg_8w_10', 'cyclostationary_mean_tg_0', 'cyclostationary_mean_tg_1w_30', 'cyclostationary_mean_tg_8w_2', 'cyclostationary_mean_tg_12w_2', 'cyclostationary_mean_tg_24w_19', 'cyclostationary_mean_tg_1w_27', 'cyclostationary_mean_tg_19', 'cyclostationary_mean_tg_1w_18', 'cyclostationary_mean_tg_1w_19', 'cyclostationary_mean_tg_4w_18', 'cyclostationary_mean_tg_12w_12', 'cyclostationary_mean_tg_1w_9', 'cyclostationary_mean_tg_1w_29', 'cyclostationary_mean_tg_24w_13', 'cyclostationary_mean_tg_16w_21', 'cyclostationary_mean_tg_16w_0', 'cyclostationary_mean_tg_1w_10', 'cyclostationary_mean_tg_4w_13', 'cyclostationary_mean_tg_4w_23', 'cyclostationary_mean_tg_1w_11', 'cyclostationary_mean_tg_4w_9', 'cyclostationary_mean_tg_16w_31'], \n",
      "\n",
      "validation score: 0.6218746955095565, \n",
      "\n",
      "number of selected features: 66\n",
      "Full aggregate regression train score: 0.7264905690284812, test score: -31.106170157819534\n",
      "Aggregate regression train score with FS: 0.3963189876765306, test score: -0.1964484477039825\n"
     ]
    }
   ],
   "source": [
    "target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target('')\n",
    "\n",
    "path='/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/features/csv_allvalues/temporal_aggreg/Emiliani2_aggreg.csv'\n",
    "\n",
    "output,aggregate_trainVal,aggregate_test = aggregate_unfolded_data(path,['cyclostationary_mean_tg', \n",
    "                                                                         'cyclostationary_mean_tg_1w',\n",
    "                                                                         'cyclostationary_mean_tg_4w', \n",
    "                                                                         'cyclostationary_mean_tg_8w',\n",
    "                                                                         'cyclostationary_mean_tg_12w', \n",
    "                                                                         'cyclostationary_mean_tg_16w',\n",
    "                                                                         'cyclostationary_mean_tg_24w'\n",
    "                                                                        ],\n",
    "                                                                   target_df_trainVal)\n",
    "\n",
    "selected_colnames = FS_with_linearWrapper(aggregate_trainVal, target_df_train, target_df_val, 100)\n",
    "\n",
    "compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9126d08c",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "6\n",
      "9\n",
      "10\n",
      "13\n",
      "14\n",
      "19\n",
      "actual training score: 0.13542406146801456\n",
      "actual validation score: 0.22395861847823129, number of remaining columns: 7\n",
      "\n",
      "actual training score: 0.14025048804168394\n",
      "actual validation score: 0.23556054981546648, number of remaining columns: 6\n",
      "\n",
      "actual training score: 0.15550653016752947\n",
      "actual validation score: 0.24926128026595873, number of remaining columns: 5\n",
      "\n",
      "actual training score: 0.1558701632300581\n",
      "actual validation score: 0.24970647684736436, number of remaining columns: 4\n",
      "\n",
      "actual training score: 0.1559350020067305\n",
      "actual validation score: 0.25029283299054106, number of remaining columns: 3\n",
      "\n",
      "actual training score: 0.1559417385217038\n",
      "actual validation score: 0.24979899742830747, number of remaining columns: 2\n",
      "\n",
      "actual training score: 0.15712979159309548\n",
      "actual validation score: 0.24679153212418126, number of remaining columns: 1\n",
      "\n",
      "actual training score: 0.16352081049049938\n",
      "actual validation score: 0.21522313536192583, number of remaining columns: 0\n",
      "\n",
      "actual training score: 0.16352081049049938\n",
      "actual validation score: -10000, number of remaining columns: 0\n",
      "\n",
      "actual training score: 0.16352081049049938\n",
      "actual validation score: -10000, number of remaining columns: 0\n",
      "\n",
      "\n",
      "\n",
      "selected columns: ['cyclostationary_mean_tg_1', 'cyclostationary_mean_tg_19', 'cyclostationary_mean_tg_14', 'cyclostationary_mean_tg_10', 'cyclostationary_mean_tg_2', 'cyclostationary_mean_tg_13'], \n",
      "\n",
      "validation score: 0.25029283299054106, \n",
      "\n",
      "number of selected features: 6\n",
      "Full aggregate regression train score: 0.18349273615659478, test score: 0.04199319936071355\n",
      "Aggregate regression train score with FS: 0.18030392068243095, test score: 0.06319073151953836\n"
     ]
    }
   ],
   "source": [
    "### repeat keeping features with at least three cells\n",
    "ii = []\n",
    "for i in range(len(output)):\n",
    "    if (len(output[i]))>=3: \n",
    "        print(i)\n",
    "        ii.append(i)\n",
    "\n",
    "selected_colnames = FS_with_linearWrapper(aggregate_trainVal.iloc[:,ii], target_df_train, target_df_val, 10)\n",
    "\n",
    "compare_methods(aggregate_trainVal.iloc[:,ii], aggregate_test.iloc[:,ii], target_df_trainVal, target_df_test, selected_colnames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a5fd411",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.214281    0.00  2001     1 -1.402730\n",
      "1    2001-01-13  0.484737    0.52  2001     2  0.347916\n",
      "2    2001-01-21  0.466071    0.47  2001     3  0.227090\n",
      "3    2001-01-29  0.417470    0.44  2001     5 -0.087501\n",
      "4    2001-02-06  0.492202    0.53  2001     6  0.396235\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "584  2013-10-21  0.739946    0.79  2013    43  1.999865\n",
      "585  2013-10-29  0.447691    0.46  2013    44  0.108118\n",
      "586  2013-11-06  0.541628    0.56  2013    45  0.716163\n",
      "587  2013-11-14  0.493719    0.53  2013    46  0.406051\n",
      "588  2013-11-22  0.527436    0.57  2013    47  0.624301\n",
      "\n",
      "[589 rows x 6 columns]\n",
      " target shapes: ((589, 6), (200, 6), (789, 6), (192, 6))\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 42\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 49\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 36\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 47\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 40\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 33\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 22\n",
      "\n",
      "actual training score: 0.15298257575890595\n",
      "actual validation score: 0.3309031910287913, number of remaining columns: 267\n",
      "\n",
      "actual training score: 0.16310848774374098\n",
      "actual validation score: 0.34064028629260534, number of remaining columns: 266\n",
      "\n",
      "actual training score: 0.1674135500864824\n",
      "actual validation score: 0.36043327102620126, number of remaining columns: 265\n",
      "\n",
      "actual training score: 0.16830009689961278\n",
      "actual validation score: 0.368985537724409, number of remaining columns: 264\n",
      "\n",
      "\n",
      "\n",
      "selected columns: ['cyclostationary_mean_tg_1w_41', 'cyclostationary_mean_tg_16w_14', 'cyclostationary_mean_tg_1w_26', 'cyclostationary_mean_tg_1w_3', 'cyclostationary_mean_tg_12w_37'], \n",
      "\n",
      "validation score: 0.368985537724409, \n",
      "\n",
      "number of selected features: 5\n",
      "Full aggregate regression train score: 0.7264905690284812, test score: -31.106170157819534\n",
      "Aggregate regression train score with FS: 0.2173955883682882, test score: 0.10380394172497132\n"
     ]
    }
   ],
   "source": [
    "### full, forcing a low number of features\n",
    "target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target('')\n",
    "\n",
    "path='/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/features/csv_allvalues/temporal_aggreg/Emiliani2_aggreg.csv'\n",
    "\n",
    "output,aggregate_trainVal,aggregate_test = aggregate_unfolded_data(path,['cyclostationary_mean_tg', \n",
    "                                                                         'cyclostationary_mean_tg_1w',\n",
    "                                                                         'cyclostationary_mean_tg_4w', \n",
    "                                                                         'cyclostationary_mean_tg_8w',\n",
    "                                                                         'cyclostationary_mean_tg_12w', \n",
    "                                                                         'cyclostationary_mean_tg_16w',\n",
    "                                                                         'cyclostationary_mean_tg_24w'\n",
    "                                                                        ],\n",
    "                                                                   target_df_trainVal)\n",
    "\n",
    "selected_colnames = FS_with_linearWrapper(aggregate_trainVal, target_df_train, target_df_val, 4)\n",
    "\n",
    "compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b86bc9e",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### not considering last years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e850c800",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.214281    0.00  2001     1 -1.339879\n",
      "1    2001-01-13  0.484737    0.52  2001     2  0.402993\n",
      "2    2001-01-21  0.466071    0.47  2001     3  0.282703\n",
      "3    2001-01-29  0.417470    0.44  2001     5 -0.030490\n",
      "4    2001-02-06  0.492202    0.53  2001     6  0.451097\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.436464    0.46  2009    48  0.091910\n",
      "407  2009-12-05  0.466152    0.49  2009    49  0.283224\n",
      "408  2009-12-13  0.553659    0.59  2009    50  0.847138\n",
      "409  2009-12-21  0.507978    0.65  2009    52  0.552758\n",
      "410  2009-12-29  0.083046    0.00  2009    53 -2.185583\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 41\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 49\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 48\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 40\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 32\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 30\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 25\n",
      "\n",
      "actual training score: 0.08302904490443674\n",
      "actual validation score: 0.2598379156870856, number of remaining columns: 263\n",
      "\n",
      "actual training score: 0.10000770992396768\n",
      "actual validation score: 0.28580892425476767, number of remaining columns: 262\n",
      "\n",
      "actual training score: 0.10247447983266456\n",
      "actual validation score: 0.3177364611064829, number of remaining columns: 261\n",
      "\n",
      "actual training score: 0.10326738121724\n",
      "actual validation score: 0.33904250467797326, number of remaining columns: 260\n",
      "\n",
      "actual training score: 0.11136806793261167\n",
      "actual validation score: 0.3586517651368235, number of remaining columns: 259\n",
      "\n",
      "actual training score: 0.13299048115926315\n",
      "actual validation score: 0.37485808611480265, number of remaining columns: 258\n",
      "\n",
      "actual training score: 0.1356024113333163\n",
      "actual validation score: 0.37894628549857, number of remaining columns: 257\n",
      "\n",
      "actual training score: 0.1448078377757911\n",
      "actual validation score: 0.39499331384275094, number of remaining columns: 256\n",
      "\n",
      "actual training score: 0.14758526393986238\n",
      "actual validation score: 0.4037805602945509, number of remaining columns: 255\n",
      "\n",
      "actual training score: 0.14850064566261334\n",
      "actual validation score: 0.4098992098306281, number of remaining columns: 254\n",
      "\n",
      "actual training score: 0.1496971631879389\n",
      "actual validation score: 0.41621929498819976, number of remaining columns: 253\n",
      "\n",
      "actual training score: 0.15049786218545846\n",
      "actual validation score: 0.42053467212398843, number of remaining columns: 252\n",
      "\n",
      "actual training score: 0.154734789915698\n",
      "actual validation score: 0.42588620572072555, number of remaining columns: 251\n",
      "\n",
      "actual training score: 0.15555005365021735\n",
      "actual validation score: 0.42705348428434353, number of remaining columns: 250\n",
      "\n",
      "actual training score: 0.1557058080371908\n",
      "actual validation score: 0.428404362460023, number of remaining columns: 249\n",
      "\n",
      "actual training score: 0.15585027247474836\n",
      "actual validation score: 0.42904809730931537, number of remaining columns: 248\n",
      "\n",
      "actual training score: 0.15590668007079644\n",
      "actual validation score: 0.4295673383487554, number of remaining columns: 247\n",
      "\n",
      "actual training score: 0.15601521880169178\n",
      "actual validation score: 0.4293408382605455, number of remaining columns: 246\n",
      "\n",
      "actual training score: 0.15951580498721507\n",
      "actual validation score: 0.42922897363242296, number of remaining columns: 245\n",
      "\n",
      "actual training score: 0.16118802766362217\n",
      "actual validation score: 0.4289718349189341, number of remaining columns: 244\n",
      "\n",
      "actual training score: 0.16123809810127354\n",
      "actual validation score: 0.42891313100001227, number of remaining columns: 243\n",
      "\n",
      "actual training score: 0.162985948502253\n",
      "actual validation score: 0.4277708644380215, number of remaining columns: 242\n",
      "\n",
      "actual training score: 0.16322262849593028\n",
      "actual validation score: 0.4289977209970375, number of remaining columns: 241\n",
      "\n",
      "actual training score: 0.16911862967477698\n",
      "actual validation score: 0.43005398197022393, number of remaining columns: 240\n",
      "\n",
      "actual training score: 0.16913343303816064\n",
      "actual validation score: 0.43005259722613576, number of remaining columns: 239\n",
      "\n",
      "actual training score: 0.1696618203295892\n",
      "actual validation score: 0.42885037199379805, number of remaining columns: 238\n",
      "\n",
      "actual training score: 0.17082210472208104\n",
      "actual validation score: 0.42856798122716, number of remaining columns: 237\n",
      "\n",
      "actual training score: 0.17115697480015601\n",
      "actual validation score: 0.426509323994842, number of remaining columns: 236\n",
      "\n",
      "actual training score: 0.18807747308167466\n",
      "actual validation score: 0.42368056918350205, number of remaining columns: 235\n",
      "\n",
      "actual training score: 0.19470940795413227\n",
      "actual validation score: 0.4260996285462778, number of remaining columns: 234\n",
      "\n",
      "actual training score: 0.19791343019722407\n",
      "actual validation score: 0.41987417012010775, number of remaining columns: 233\n",
      "\n",
      "actual training score: 0.2212189438830554\n",
      "actual validation score: 0.4326727082478232, number of remaining columns: 232\n",
      "\n",
      "actual training score: 0.22675091178791928\n",
      "actual validation score: 0.4411007346620792, number of remaining columns: 231\n",
      "\n",
      "actual training score: 0.2272412512836769\n",
      "actual validation score: 0.4421210724854634, number of remaining columns: 230\n",
      "\n",
      "actual training score: 0.22724191098764135\n",
      "actual validation score: 0.4424250035405468, number of remaining columns: 229\n",
      "\n",
      "actual training score: 0.22727657889650255\n",
      "actual validation score: 0.44265032069353694, number of remaining columns: 228\n",
      "\n",
      "actual training score: 0.2273405686053528\n",
      "actual validation score: 0.44190970011362773, number of remaining columns: 227\n",
      "\n",
      "actual training score: 0.227483515746852\n",
      "actual validation score: 0.4404771316568762, number of remaining columns: 226\n",
      "\n",
      "actual training score: 0.22916237131028472\n",
      "actual validation score: 0.43877980960169316, number of remaining columns: 225\n",
      "\n",
      "actual training score: 0.22917499079069537\n",
      "actual validation score: 0.43847182575844046, number of remaining columns: 224\n",
      "\n",
      "actual training score: 0.22925224145375422\n",
      "actual validation score: 0.43608909232892623, number of remaining columns: 223\n",
      "\n",
      "actual training score: 0.22925413868524858\n",
      "actual validation score: 0.4367342556645951, number of remaining columns: 222\n",
      "\n",
      "actual training score: 0.2295046149825848\n",
      "actual validation score: 0.43326249869162103, number of remaining columns: 221\n",
      "\n",
      "actual training score: 0.23283554690937291\n",
      "actual validation score: 0.4290216564821452, number of remaining columns: 220\n",
      "\n",
      "actual training score: 0.23293895631629935\n",
      "actual validation score: 0.42201601633728214, number of remaining columns: 219\n",
      "\n",
      "actual training score: 0.2372022908015341\n",
      "actual validation score: 0.41931519868976497, number of remaining columns: 218\n",
      "\n",
      "actual training score: 0.23813537512993221\n",
      "actual validation score: 0.432072872515355, number of remaining columns: 217\n",
      "\n",
      "actual training score: 0.23819892857328684\n",
      "actual validation score: 0.42921071297211266, number of remaining columns: 216\n",
      "\n",
      "actual training score: 0.23884526260999528\n",
      "actual validation score: 0.4229089870254097, number of remaining columns: 215\n",
      "\n",
      "actual training score: 0.24250040192984745\n",
      "actual validation score: 0.40891378300228376, number of remaining columns: 214\n",
      "\n",
      "actual training score: 0.24347557428757527\n",
      "actual validation score: 0.43052633043951805, number of remaining columns: 213\n",
      "\n",
      "actual training score: 0.24736630063155396\n",
      "actual validation score: 0.4252996709307306, number of remaining columns: 212\n",
      "\n",
      "actual training score: 0.24739941034226964\n",
      "actual validation score: 0.4253336256163164, number of remaining columns: 211\n",
      "\n",
      "actual training score: 0.2482236872483894\n",
      "actual validation score: 0.4185521152618876, number of remaining columns: 210\n",
      "\n",
      "actual training score: 0.24902678285723878\n",
      "actual validation score: 0.410379535538705, number of remaining columns: 209\n",
      "\n",
      "actual training score: 0.251373194872206\n",
      "actual validation score: 0.4012095303369686, number of remaining columns: 208\n",
      "\n",
      "actual training score: 0.2581549076742643\n",
      "actual validation score: 0.3837671228760383, number of remaining columns: 207\n",
      "\n",
      "actual training score: 0.2593596521667757\n",
      "actual validation score: 0.4030983998967115, number of remaining columns: 206\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual training score: 0.26416158976662296\n",
      "actual validation score: 0.38301872686173033, number of remaining columns: 205\n",
      "\n",
      "actual training score: 0.2648269585586305\n",
      "actual validation score: 0.38633433360015834, number of remaining columns: 204\n",
      "\n",
      "actual training score: 0.27158283407803485\n",
      "actual validation score: 0.3544588798075563, number of remaining columns: 203\n",
      "\n",
      "actual training score: 0.2742714049520476\n",
      "actual validation score: 0.36782204415801456, number of remaining columns: 202\n",
      "\n",
      "actual training score: 0.2838775158771909\n",
      "actual validation score: 0.3653650032766561, number of remaining columns: 201\n",
      "\n",
      "actual training score: 0.2886520289333374\n",
      "actual validation score: 0.34741061692901076, number of remaining columns: 200\n",
      "\n",
      "actual training score: 0.28903159183990057\n",
      "actual validation score: 0.346527591978365, number of remaining columns: 199\n",
      "\n",
      "actual training score: 0.2948582835197805\n",
      "actual validation score: 0.3537712789771418, number of remaining columns: 198\n",
      "\n",
      "actual training score: 0.2957282156899229\n",
      "actual validation score: 0.35303029636929906, number of remaining columns: 197\n",
      "\n",
      "actual training score: 0.31211387676839597\n",
      "actual validation score: 0.34887100716402075, number of remaining columns: 196\n",
      "\n",
      "actual training score: 0.3121143227519675\n",
      "actual validation score: 0.3487818038513405, number of remaining columns: 195\n",
      "\n",
      "actual training score: 0.31212249907132605\n",
      "actual validation score: 0.3469320062412584, number of remaining columns: 194\n",
      "\n",
      "actual training score: 0.3145155223799557\n",
      "actual validation score: 0.3300180917998211, number of remaining columns: 193\n",
      "\n",
      "actual training score: 0.31529291630770895\n",
      "actual validation score: 0.32800350085183794, number of remaining columns: 192\n",
      "\n",
      "actual training score: 0.3173012908427908\n",
      "actual validation score: 0.3084664027823847, number of remaining columns: 191\n",
      "\n",
      "actual training score: 0.31797789833479206\n",
      "actual validation score: 0.2750015260575909, number of remaining columns: 190\n",
      "\n",
      "actual training score: 0.32516503736955604\n",
      "actual validation score: 0.27070981200014077, number of remaining columns: 189\n",
      "\n",
      "actual training score: 0.32752596830353564\n",
      "actual validation score: 0.2878605017248991, number of remaining columns: 188\n",
      "\n",
      "actual training score: 0.3294871347280003\n",
      "actual validation score: 0.25215139402368925, number of remaining columns: 187\n",
      "\n",
      "actual training score: 0.3305193899410306\n",
      "actual validation score: 0.2903489018316171, number of remaining columns: 186\n",
      "\n",
      "actual training score: 0.33154681261068075\n",
      "actual validation score: 0.28370888231820734, number of remaining columns: 185\n",
      "\n",
      "actual training score: 0.3316386165036648\n",
      "actual validation score: 0.27844433070651853, number of remaining columns: 184\n",
      "\n",
      "actual training score: 0.3426241951820187\n",
      "actual validation score: 0.2547653874901853, number of remaining columns: 183\n",
      "\n",
      "actual training score: 0.342819356494964\n",
      "actual validation score: 0.25814801886478955, number of remaining columns: 182\n",
      "\n",
      "actual training score: 0.3591764365726423\n",
      "actual validation score: 0.23215513685537315, number of remaining columns: 181\n",
      "\n",
      "actual training score: 0.37785326742013114\n",
      "actual validation score: 0.2923804743245214, number of remaining columns: 180\n",
      "\n",
      "actual training score: 0.3810736349457087\n",
      "actual validation score: 0.27805742416198165, number of remaining columns: 179\n",
      "\n",
      "actual training score: 0.3824758320042788\n",
      "actual validation score: 0.259360012713183, number of remaining columns: 178\n",
      "\n",
      "actual training score: 0.39867319159738357\n",
      "actual validation score: 0.23376817231038638, number of remaining columns: 177\n",
      "\n",
      "actual training score: 0.40134654343571907\n",
      "actual validation score: 0.20247604880729464, number of remaining columns: 176\n",
      "\n",
      "actual training score: 0.41825774619600564\n",
      "actual validation score: 0.18465212302215428, number of remaining columns: 175\n",
      "\n",
      "actual training score: 0.4207108115578533\n",
      "actual validation score: 0.17173747560801744, number of remaining columns: 174\n",
      "\n",
      "actual training score: 0.42584799428116427\n",
      "actual validation score: 0.16140860044649818, number of remaining columns: 173\n",
      "\n",
      "actual training score: 0.4282617644285034\n",
      "actual validation score: 0.15025408265391005, number of remaining columns: 172\n",
      "\n",
      "actual training score: 0.44314607087508706\n",
      "actual validation score: 0.16413543257231, number of remaining columns: 171\n",
      "\n",
      "actual training score: 0.4431954985554515\n",
      "actual validation score: 0.1676500034398224, number of remaining columns: 170\n",
      "\n",
      "actual training score: 0.44352035830650194\n",
      "actual validation score: 0.16896076880881972, number of remaining columns: 169\n",
      "\n",
      "actual training score: 0.4435218629147085\n",
      "actual validation score: 0.16901426850167733, number of remaining columns: 168\n",
      "\n",
      "actual training score: 0.4438386243956376\n",
      "actual validation score: 0.16627277153171827, number of remaining columns: 167\n",
      "\n",
      "actual training score: 0.4522432362272589\n",
      "actual validation score: 0.1471142125899254, number of remaining columns: 166\n",
      "\n",
      "actual training score: 0.4539723848382593\n",
      "actual validation score: 0.13823713506657875, number of remaining columns: 165\n",
      "\n",
      "actual training score: 0.45669653087499384\n",
      "actual validation score: 0.12424642924931306, number of remaining columns: 164\n",
      "\n",
      "\n",
      "\n",
      "selected columns: ['cyclostationary_mean_tg_1w_42', 'cyclostationary_mean_tg_1w_44', 'cyclostationary_mean_tg_1w_16', 'cyclostationary_mean_tg_24w_8', 'cyclostationary_mean_tg_24w_17', 'cyclostationary_mean_tg_24w_4', 'cyclostationary_mean_tg_1w_40', 'cyclostationary_mean_tg_12w_3', 'cyclostationary_mean_tg_12w_14', 'cyclostationary_mean_tg_1w_2', 'cyclostationary_mean_tg_1w_31', 'cyclostationary_mean_tg_1w_32', 'cyclostationary_mean_tg_1w_34', 'cyclostationary_mean_tg_1w_39', 'cyclostationary_mean_tg_16w_10', 'cyclostationary_mean_tg_16w_13', 'cyclostationary_mean_tg_1w_46', 'cyclostationary_mean_tg_1w_19', 'cyclostationary_mean_tg_12w_13', 'cyclostationary_mean_tg_4w_10', 'cyclostationary_mean_tg_1w_37', 'cyclostationary_mean_tg_1w_24', 'cyclostationary_mean_tg_1w_23', 'cyclostationary_mean_tg_12w_11', 'cyclostationary_mean_tg_16w_1', 'cyclostationary_mean_tg_4w_9', 'cyclostationary_mean_tg_4w_3', 'cyclostationary_mean_tg_24w_2', 'cyclostationary_mean_tg_8w_8', 'cyclostationary_mean_tg_1w_8', 'cyclostationary_mean_tg_12w_10', 'cyclostationary_mean_tg_24w_22', 'cyclostationary_mean_tg_24w_15', 'cyclostationary_mean_tg_1w_26', 'cyclostationary_mean_tg_24w_0', 'cyclostationary_mean_tg_1w_22', 'cyclostationary_mean_tg_24w_18'], \n",
      "\n",
      "validation score: 0.44265032069353694, \n",
      "\n",
      "number of selected features: 37\n",
      "Full aggregate regression train score: 0.7800775933217615, test score: -22.751755145654034\n",
      "Aggregate regression train score with FS: 0.3325614502303791, test score: -0.5911759301796364\n"
     ]
    }
   ],
   "source": [
    "target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target('',max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01')\n",
    "\n",
    "path='/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/features/csv_allvalues/temporal_aggreg/Emiliani2_aggreg.csv'\n",
    "\n",
    "output,aggregate_trainVal,aggregate_test = aggregate_unfolded_data(path,['cyclostationary_mean_tg', \n",
    "                                                                         'cyclostationary_mean_tg_1w',\n",
    "                                                                         'cyclostationary_mean_tg_4w', \n",
    "                                                                         'cyclostationary_mean_tg_8w',\n",
    "                                                                         'cyclostationary_mean_tg_12w', \n",
    "                                                                         'cyclostationary_mean_tg_16w',\n",
    "                                                                         'cyclostationary_mean_tg_24w'\n",
    "                                                                        ],\n",
    "                                                                   target_df_trainVal, \n",
    "                                                                   max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01')\n",
    "\n",
    "selected_colnames = FS_with_linearWrapper(aggregate_trainVal, target_df_train, target_df_val, 100, 228)\n",
    "\n",
    "compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d43fd47",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.214281    0.00  2001     1 -1.339879\n",
      "1    2001-01-13  0.484737    0.52  2001     2  0.402993\n",
      "2    2001-01-21  0.466071    0.47  2001     3  0.282703\n",
      "3    2001-01-29  0.417470    0.44  2001     5 -0.030490\n",
      "4    2001-02-06  0.492202    0.53  2001     6  0.451097\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.436464    0.46  2009    48  0.091910\n",
      "407  2009-12-05  0.466152    0.49  2009    49  0.283224\n",
      "408  2009-12-13  0.553659    0.59  2009    50  0.847138\n",
      "409  2009-12-21  0.507978    0.65  2009    52  0.552758\n",
      "410  2009-12-29  0.083046    0.00  2009    53 -2.185583\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 41\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 49\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 48\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 40\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 32\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 30\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 25\n",
      "\n",
      "actual training score: 0.08302904490443674\n",
      "actual validation score: 0.2598379156870856, number of remaining columns: 263\n",
      "\n",
      "actual training score: 0.10000770992396768\n",
      "actual validation score: 0.28580892425476767, number of remaining columns: 262\n",
      "\n",
      "actual training score: 0.10247447983266456\n",
      "actual validation score: 0.3177364611064829, number of remaining columns: 261\n",
      "\n",
      "actual training score: 0.10326738121724\n",
      "actual validation score: 0.33904250467797326, number of remaining columns: 260\n",
      "\n",
      "\n",
      "\n",
      "selected columns: ['cyclostationary_mean_tg_1w_42', 'cyclostationary_mean_tg_1w_44', 'cyclostationary_mean_tg_1w_16', 'cyclostationary_mean_tg_24w_8', 'cyclostationary_mean_tg_24w_17'], \n",
      "\n",
      "validation score: 0.33904250467797326, \n",
      "\n",
      "number of selected features: 5\n",
      "Full aggregate regression train score: 0.7800775933217615, test score: -22.751755145654034\n",
      "Aggregate regression train score with FS: 0.21300564882902318, test score: 0.16180863007554003\n"
     ]
    }
   ],
   "source": [
    "### full, forcing a low number of features\n",
    "\n",
    "target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target('',max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01')\n",
    "\n",
    "path='/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/features/csv_allvalues/temporal_aggreg/Emiliani2_aggreg.csv'\n",
    "\n",
    "output,aggregate_trainVal,aggregate_test = aggregate_unfolded_data(path,['cyclostationary_mean_tg', \n",
    "                                                                         'cyclostationary_mean_tg_1w',\n",
    "                                                                         'cyclostationary_mean_tg_4w', \n",
    "                                                                         'cyclostationary_mean_tg_8w',\n",
    "                                                                         'cyclostationary_mean_tg_12w', \n",
    "                                                                         'cyclostationary_mean_tg_16w',\n",
    "                                                                         'cyclostationary_mean_tg_24w'\n",
    "                                                                        ],\n",
    "                                                                   target_df_trainVal, \n",
    "                                                                   max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01')\n",
    "\n",
    "selected_colnames = FS_with_linearWrapper(aggregate_trainVal, target_df_train, target_df_val, 4, 228)\n",
    "\n",
    "compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899b096c",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### repeat both with CMI FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79b4364c",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.214281    0.00  2001     1 -1.402730\n",
      "1    2001-01-13  0.484737    0.52  2001     2  0.347916\n",
      "2    2001-01-21  0.466071    0.47  2001     3  0.227090\n",
      "3    2001-01-29  0.417470    0.44  2001     5 -0.087501\n",
      "4    2001-02-06  0.492202    0.53  2001     6  0.396235\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "584  2013-10-21  0.739946    0.79  2013    43  1.999865\n",
      "585  2013-10-29  0.447691    0.46  2013    44  0.108118\n",
      "586  2013-11-06  0.541628    0.56  2013    45  0.716163\n",
      "587  2013-11-14  0.493719    0.53  2013    46  0.406051\n",
      "588  2013-11-22  0.527436    0.57  2013    47  0.624301\n",
      "\n",
      "[589 rows x 6 columns]\n",
      " target shapes: ((589, 6), (200, 6), (789, 6), (192, 6))\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 42\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 49\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 36\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 47\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 40\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 33\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 22\n",
      "\n",
      "----- MI Scores -----\n",
      "[(67, 0.13025442260444184), (80, 0.12954411968198004), (83, 0.12930060842544505), (34, 0.12735661415154403), (71, 0.12508311372015474), (22, 0.12457640787502305), (16, 0.12389096732880998), (84, 0.12380272997239342), (76, 0.12205087767772023), (44, 0.1207248778856905), (3, 0.11717876450201495), (36, 0.11662081584231676), (51, 0.11659370122277775), (52, 0.11571880710373471), (85, 0.11512088194382984), (58, 0.11498935133647654), (33, 0.11461501944102642), (1, 0.11381349685640879), (35, 0.11367672213664079), (86, 0.11246643122590466), (55, 0.11215952820204433), (79, 0.11210848461828989), (19, 0.11202341103410843), (2, 0.11021574132223567), (43, 0.10988399519842987), (81, 0.10830927595935283), (13, 0.10813258824327396), (50, 0.10800280889883254), (31, 0.1077407353862741), (62, 0.10730500525647724), (49, 0.10687566484810244), (5, 0.10646284004877848), (65, 0.10626337264726811), (32, 0.10467297363692264), (38, 0.10442798710017918), (37, 0.10440178681056665), (89, 0.1038556377888575), (63, 0.1030394556654863), (25, 0.10301637582004189), (28, 0.10031770930194732), (75, 0.10010591688614032), (27, 0.09818236304075863), (87, 0.09702486740904166), (23, 0.0970176972501358), (72, 0.09589408567678753), (10, 0.09482446585174789), (68, 0.09436130286755978), (74, 0.09430617494280931), (29, 0.09357829044870386), (48, 0.09301462253181536), (78, 0.09216544733511955), (57, 0.0920484923168466), (40, 0.09196500062112871), (6, 0.09139963476899109), (73, 0.09135572842674507), (0, 0.09066988565786388), (82, 0.09013193361125932), (70, 0.08931548000078562), (9, 0.08904657414825463), (69, 0.08858051878538803), (7, 0.08803355154419298), (45, 0.0872530044994133), (24, 0.08566828367842573), (17, 0.08530148077231299), (54, 0.08522730870034446), (26, 0.08428869096211221), (61, 0.08389189662900472), (20, 0.08313833515488933), (90, 0.08103471001565718), (14, 0.08085287501748403), (30, 0.08084265632820575), (66, 0.07970235872207178), (60, 0.0792674851365368), (118, 0.07799093760117416), (11, 0.07774321698817134), (42, 0.07747127188891181), (64, 0.07720104742258135), (39, 0.07709168535961188), (41, 0.07700523767122837), (88, 0.07684244562100334), (8, 0.07659200501300852), (47, 0.07620790221244185), (46, 0.07576153231402616), (12, 0.07576092008133625), (21, 0.07566411324069547), (4, 0.07477456943299458), (59, 0.0743852861958423), (53, 0.07405399987276753), (97, 0.07326370132509415), (77, 0.07159759943217255), (15, 0.07091808078107092), (18, 0.06942168583008025), (123, 0.06786864872074427), (119, 0.06686681866103952), (111, 0.0648837110178035), (126, 0.06438028551366008), (125, 0.06437496976916464), (110, 0.06253751791911788), (93, 0.06241939197451509), (92, 0.062162646436021624), (108, 0.06100571665828217), (56, 0.06091698304782747), (101, 0.057594119329608486), (98, 0.057419505666589966), (116, 0.05617048704580777), (124, 0.05606695198997146), (99, 0.054737919203710524), (104, 0.05363686498926121), (129, 0.05298958103074472), (117, 0.0523457639125481), (113, 0.050417040050765624), (135, 0.05040859736989355), (122, 0.049564543474768075), (120, 0.04894048410106778), (128, 0.04788387508301101), (138, 0.047492601180904356), (121, 0.04715710750339053), (103, 0.046720024829078576), (132, 0.044339376541719426), (267, 0.04419317991061853), (91, 0.043713364216210665), (95, 0.04360968894262518), (96, 0.04265270161238712), (139, 0.04249639677173583), (142, 0.0417643808106586), (176, 0.041435799045224785), (133, 0.04130047797077573), (168, 0.04089675702726532), (112, 0.04088508993288274), (114, 0.0400553096352811), (223, 0.03861921784628823), (151, 0.038548417272784775), (115, 0.03813099053675553), (162, 0.03792271367551363), (172, 0.03763100063385019), (150, 0.03725611386217424), (94, 0.03675243988980057), (148, 0.03576347592886639), (171, 0.035643087697462016), (105, 0.03545304593920217), (134, 0.03492790199973914), (130, 0.03448580892488006), (187, 0.03428213747592298), (157, 0.03383294797184218), (106, 0.033783814810643964), (221, 0.03273393358782666), (258, 0.03209927286414418), (206, 0.03180698481044183), (160, 0.031700006868997814), (167, 0.03153311702862022), (127, 0.03152260202857779), (195, 0.031244914976392306), (102, 0.031128681031658247), (259, 0.030702668643277), (169, 0.03022664585423499), (137, 0.03011232904537449), (173, 0.02990082305854266), (262, 0.029618817777110847), (183, 0.029340284104877937), (191, 0.028759118230983087), (158, 0.028350318562135473), (146, 0.027857492935774743), (208, 0.02779693056946867), (175, 0.027401279383387083), (149, 0.027372266353139045), (170, 0.027317709745803203), (164, 0.027200987610898786), (211, 0.027010998939436787), (140, 0.026597237647858377), (216, 0.02631889065177388), (247, 0.026067172910068583), (193, 0.025839823306761718), (197, 0.025771340361103224), (263, 0.025693476943449412), (194, 0.025446823487808582), (100, 0.02539670224567038), (163, 0.02536089702275713), (161, 0.025180564608506928), (181, 0.025155365613882957), (165, 0.025008028365214815), (261, 0.024679791651855076), (188, 0.024574321722609847), (186, 0.02453078699103753), (182, 0.023925767300887562), (177, 0.023884609126100187), (203, 0.023414359185650997), (239, 0.02312987738315811), (250, 0.02303444322934234), (232, 0.022795123096339902), (212, 0.022684200945806667), (266, 0.022275454626092078), (242, 0.02226048207405751), (178, 0.022022222218595143), (249, 0.021963051683284527), (245, 0.021899250011712057), (205, 0.02180622011291434), (107, 0.02142480681001662), (147, 0.021424156429743987), (143, 0.021204594988544632), (264, 0.021026471969028217), (136, 0.020538162615222583), (237, 0.02043650976333814), (226, 0.020317475673181196), (255, 0.020215275895327817), (209, 0.020204704941760004), (156, 0.019900357883562692), (185, 0.01952506822289559), (152, 0.019481907603943378), (154, 0.01924279279113596), (184, 0.01921779473393781), (144, 0.019068250455973695), (215, 0.01903818026411488), (248, 0.018983229699347123), (131, 0.018979214910059442), (240, 0.018872156895506385), (166, 0.018630774325397326), (109, 0.01857679083907311), (202, 0.018415151084376215), (180, 0.018350136350923165), (246, 0.018308242233447215), (192, 0.018101999497703736), (179, 0.018036131552242207), (159, 0.017742005914072437), (217, 0.017664394235574813), (204, 0.017365717657324), (222, 0.01723573060133278), (218, 0.01685561379631922), (260, 0.01583422971255864), (251, 0.01516024638892173), (241, 0.015111100679481664), (153, 0.014893771820348496), (230, 0.014503121483816741), (252, 0.014437140008724012), (265, 0.013805704567524509), (220, 0.013776009963480024), (155, 0.013577189496805954), (214, 0.013534377939707765), (200, 0.01350465175354514), (268, 0.013437051330669806), (257, 0.013381477711659717), (207, 0.013340925551215249), (213, 0.013271951152160818), (254, 0.01304847666021384), (210, 0.012871010367098184), (236, 0.012717601965583279), (256, 0.012707250045467338), (235, 0.012034810345520112), (227, 0.012018803594267179), (201, 0.01195937117618997), (190, 0.011919366838561856), (145, 0.011909743773501656), (198, 0.011135148196626254), (243, 0.011131047888878769), (225, 0.0111070012825185), (238, 0.01074361733009867), (219, 0.010706948651514678), (231, 0.010425386383011619), (141, 0.010134675822294954), (189, 0.00994146452745684), (233, 0.00846150190805076), (229, 0.0080901447387597), (196, 0.007611609713706008), (228, 0.007136100785231359), (199, 0.00646203714182556), (234, 0.006029531936669709), (244, 0.005252651000387722), (174, 0.0025917451972767487), (224, 0.0021778130901373475), (253, -0.0020737173126804723)]\n",
      "Best MI score: 0.13025442260444184\n",
      "Adding first best original feature: 67\n",
      "CMI: 0.00919903508074893\n",
      "CMI: 0.009791762656778835\n",
      "CMI: 0.007324652109007235\n",
      "CMI: 0.003942968458301027\n",
      "CMI: 0.005361682663735018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMI: 0.014764521306124295\n",
      "CMI: 0.01155985057837175\n",
      "CMI: 0.013915753712383822\n",
      "CMI: 0.0015900503930955934\n",
      "CMI: 0.0033788603349111657\n",
      "CMI: 0.010837879788728494\n",
      "CMI: 0.009848383244844106\n",
      "CMI: 0.010566960652369645\n",
      "CMI: 0.005629622419597885\n",
      "CMI: 0.002466816606560951\n",
      "CMI: 0.018733348006862938\n",
      "CMI: 0.014036405095082416\n",
      "CMI: 0.005906463494198322\n",
      "CMI: 0.0036245700942887094\n",
      "CMI: 0.0020261908111633975\n",
      "CMI: 0.013920634866697229\n",
      "CMI: 0.015869351770697843\n",
      "CMI: 0.0032992228748159047\n",
      "CMI: 0.004215557903297057\n",
      "CMI: 0.014676186958463538\n",
      "CMI: 0.018497861975337537\n",
      "CMI: 0.00811858273667293\n",
      "CMI: 0.0022491125396239264\n",
      "CMI: 0.015611954314990989\n",
      "CMI: 0.002219494493934465\n",
      "CMI: 0.006398086210423065\n",
      "CMI: 0.0022446565166482357\n",
      "CMI: 0.003635640468446888\n",
      "CMI: 0.006751047739064792\n",
      "CMI: 0.005223471372461513\n",
      "CMI: 0.007998564400395952\n",
      "CMI: 0.0016111749857340985\n",
      "CMI: 0.00748811353185827\n",
      "CMI: 0.0015237951276024786\n",
      "CMI: 0.008415180918650483\n",
      "CMI: 0.009288443058397294\n",
      "CMI: 0.005916385059237278\n",
      "CMI: 0.008813323201654122\n",
      "CMI: 0.008893838843833934\n",
      "CMI: 0.008343197465503105\n",
      "CMI: 0.006975563217262698\n",
      "CMI: 0.008998303908473837\n",
      "CMI: 0.011414834504419269\n",
      "CMI: 0.0016249403939819496\n",
      "CMI: 0.00738697940977695\n",
      "CMI: 0.01193305170943526\n",
      "CMI: 0.008325853298482483\n",
      "CMI: 0.00199536392858482\n",
      "CMI: 0.0015188091932049896\n",
      "CMI: 0.006922027443991757\n",
      "CMI: 0.0027658952039885942\n",
      "CMI: 0.0022159949637570175\n",
      "CMI: 0.0035911677034480005\n",
      "CMI: 0.014020375475994246\n",
      "CMI: 0.006592063085264471\n",
      "CMI: 0.004087446081609658\n",
      "CMI: 0.0008590630193347493\n",
      "CMI: 0.005664648768281405\n",
      "CMI: 0.005178687752405403\n",
      "CMI: 0.015280381650857988\n",
      "CMI: 0.005764954244856985\n",
      "CMI: 0.012358373351538832\n",
      "CMI: 0.0018592412590510143\n",
      "CMI: 0.0023753442535270064\n",
      "CMI: 0.018211915226829245\n",
      "CMI: 0.01728170764869741\n",
      "CMI: 0.013359447216865245\n",
      "CMI: 0.007916402864092204\n",
      "CMI: 0.006710434633688256\n",
      "CMI: 0.004386347155711012\n",
      "CMI: 0.004042546319460383\n",
      "CMI: 0.0028476766359463723\n",
      "CMI: 0.00355305261440117\n",
      "CMI: 0.002216809409966436\n",
      "CMI: 0.010345280946116475\n",
      "CMI: 0.012447806392138466\n",
      "CMI: 0.007494152342802596\n",
      "CMI: 0.014902114567669128\n",
      "CMI: 0.0047509732870957555\n",
      "CMI: 0.005545456050538716\n",
      "CMI: 0.02087772732383497\n",
      "CMI: 0.028139531684154923\n",
      "CMI: 0.022428389683167377\n",
      "CMI: 0.014679128623898363\n",
      "CMI: 0.01211022005154433\n",
      "CMI: 0.014451288800380768\n",
      "CMI: 0.016481481518878544\n",
      "CMI: 0.024678218367465143\n",
      "CMI: 0.010918607265229696\n",
      "CMI: 0.01036739644982343\n",
      "CMI: 0.014785205395432266\n",
      "CMI: 0.03337235969650909\n",
      "CMI: 0.018606325732772655\n",
      "CMI: 0.01067184216761613\n",
      "CMI: 0.017673275050185067\n",
      "CMI: 0.009518514018923258\n",
      "CMI: 0.01478366840479542\n",
      "CMI: 0.010361972390277085\n",
      "CMI: 0.014170283355223717\n",
      "CMI: 0.017857157825344583\n",
      "CMI: 0.013621222928025478\n",
      "CMI: 0.006743882213743668\n",
      "CMI: 0.0065198055375877695\n",
      "CMI: 0.01108519845271111\n",
      "CMI: 0.003772551061692553\n",
      "CMI: 0.007147557404796223\n",
      "CMI: 0.011370131402817285\n",
      "CMI: 0.00596481914098268\n",
      "CMI: 0.014871604899550306\n",
      "CMI: 0.020688696051821248\n",
      "CMI: 0.017719954246447484\n",
      "CMI: 0.008008077327273766\n",
      "CMI: 0.010646474859145383\n",
      "CMI: 0.0077477627717866815\n",
      "CMI: 0.0033622259158062606\n",
      "CMI: 0.007532917809341927\n",
      "CMI: 0.008867810177309005\n",
      "CMI: 0.0047569634217565215\n",
      "CMI: 0.0155293794059434\n",
      "CMI: 0.024620987902574304\n",
      "CMI: 0.016806820760669527\n",
      "CMI: 0.019439382867695087\n",
      "CMI: 0.015831577767268484\n",
      "CMI: 0.019850352158367862\n",
      "CMI: 0.02333557107641357\n",
      "CMI: 0.0227283904733227\n",
      "CMI: 0.009573596286732156\n",
      "CMI: 0.0032710454737219785\n",
      "CMI: 0.006273914098179428\n",
      "CMI: 0.013105874843495513\n",
      "CMI: 0.019939694285586534\n",
      "CMI: 0.014780203066537212\n",
      "CMI: 0.009935656685725686\n",
      "CMI: 0.017868393814091804\n",
      "CMI: 0.0305822166304551\n",
      "CMI: 0.018133296471580296\n",
      "CMI: 0.011894341897590255\n",
      "CMI: 0.0070363834693626115\n",
      "CMI: 0.018653231719931773\n",
      "CMI: 0.013401211394315049\n",
      "CMI: 0.0024181999915521557\n",
      "CMI: 0.0012458765863734012\n",
      "CMI: 0.012612614379257259\n",
      "CMI: 0.017758944074852484\n",
      "CMI: 0.00894831394644896\n",
      "CMI: 0.014797323246262345\n",
      "CMI: 0.009456979897965512\n",
      "CMI: 0.02191532366848664\n",
      "CMI: 0.02446885235543078\n",
      "CMI: 0.0077235168794106135\n",
      "CMI: 0.014642499036330414\n",
      "CMI: 0.0045977527545842944\n",
      "CMI: 0.005637747840287283\n",
      "CMI: 0.00040236147196962\n",
      "CMI: 0.003792221497797482\n",
      "CMI: 0.009405206814743633\n",
      "CMI: 0.0013595729257078193\n",
      "CMI: 0.009250382944750446\n",
      "CMI: 0.024382007545994844\n",
      "CMI: 0.004245794514251278\n",
      "CMI: 0.016215646435973396\n",
      "CMI: 0.0005802757098632982\n",
      "CMI: 0.008563876522188762\n",
      "CMI: 0.008353492852441996\n",
      "CMI: 0.018439091292938192\n",
      "CMI: 0.01119338095638639\n",
      "CMI: 0.03759581519012822\n",
      "CMI: 0.011556384269373055\n",
      "CMI: 0.019409031712079666\n",
      "CMI: 0.0010812881632906723\n",
      "CMI: 0.00766721583051741\n",
      "CMI: 0.00831127133745413\n",
      "CMI: 0.008194793007636397\n",
      "CMI: 0.007050427543859067\n",
      "CMI: 0.011086842218412024\n",
      "CMI: 0.008920253986449439\n",
      "CMI: 0.01200784503864985\n",
      "CMI: 0.016396249195777507\n",
      "CMI: 0.019424901359583996\n",
      "CMI: 0.00787245654226737\n",
      "CMI: 0.010521685447229479\n",
      "CMI: 0.011996120405563193\n",
      "CMI: 0.007577503766643762\n",
      "CMI: 0.006150450176053285\n",
      "CMI: 0.003733218556722706\n",
      "CMI: 0.005096380398999706\n",
      "CMI: 0.01773941247760047\n",
      "CMI: 0.00802643205907741\n",
      "CMI: 0.012410380087019557\n",
      "CMI: 0.015950783030571625\n",
      "CMI: 0.026720259405540736\n",
      "CMI: 0.003313615515844248\n",
      "CMI: 0.008673876551503673\n",
      "CMI: 0.011022575105668841\n",
      "CMI: 0.003941759793465893\n",
      "CMI: 0.012937348398932541\n",
      "CMI: 0.001612205781910514\n",
      "CMI: 0.003425332512168394\n",
      "CMI: 0.00687733462147988\n",
      "CMI: 0.006917539569563674\n",
      "CMI: 0.022209761087171986\n",
      "CMI: 0.02214713214130845\n",
      "CMI: 0.00786877639173833\n",
      "CMI: 0.006088072813409839\n",
      "CMI: 0.0011517309040957047\n",
      "CMI: 0.006859387253393245\n",
      "CMI: 0.009158861270036678\n",
      "CMI: 0.00818731943600634\n",
      "Highest CMI score: 0.03759581519012822\n",
      "Adding original feature: 221\n",
      "CMI: 0.00231980574418178\n",
      "CMI: 0.005026533598329663\n",
      "CMI: 0.005697333203570021\n",
      "CMI: 0.010008978212949576\n",
      "CMI: 0.0031758470350601864\n",
      "CMI: 0.001026985080241738\n",
      "CMI: 0.001235292363553936\n",
      "CMI: 0.006890892638002966\n",
      "CMI: 0.0041929646203917315\n",
      "CMI: 0.003745290324321471\n",
      "CMI: 0.0005415951355041415\n",
      "CMI: 0.0006014487802771806\n",
      "CMI: 0.00771850895315998\n",
      "CMI: 0.007017394633902274\n",
      "CMI: 0.00893037622725562\n",
      "CMI: 0.0070996122864065425\n",
      "CMI: 0.0006896578884900695\n",
      "CMI: 0.005365847073092567\n",
      "CMI: 0.006112289429420575\n",
      "CMI: 0.006143219878256695\n",
      "CMI: 0.00017096656685178235\n",
      "CMI: 0.002596469385554079\n",
      "CMI: 0.004839047898028692\n",
      "CMI: 0.003896210375122028\n",
      "CMI: 0.0012671532533044816\n",
      "CMI: 0.0027689211689808924\n",
      "CMI: 2.8869244160262264e-05\n",
      "CMI: 0.013898166855853378\n",
      "CMI: 0.0008063032865063546\n",
      "CMI: 0.002506313655664061\n",
      "CMI: 0.0011015675607780606\n",
      "CMI: 0.005084634629207413\n",
      "CMI: 0.006404297134514986\n",
      "CMI: 0.022956226178976497\n",
      "CMI: 0.005287988968093071\n",
      "CMI: 0.013546315843880385\n",
      "CMI: 0.013740933826662666\n",
      "CMI: 0.005368056692160811\n",
      "CMI: 0.013420912382856004\n",
      "CMI: 0.009196731243517886\n",
      "CMI: 0.013078433916422966\n",
      "CMI: 0.008694476493719794\n",
      "CMI: 0.012126426890803371\n",
      "CMI: 0.006623365289349009\n",
      "CMI: 0.01206021581172742\n",
      "CMI: 0.01100996529980336\n",
      "CMI: 0.003266625680890589\n",
      "CMI: 0.0013170930151031601\n",
      "CMI: 0.0007456016275740329\n",
      "CMI: 0.018469883655745256\n",
      "CMI: 0.000668288216913171\n",
      "CMI: 0.006721888836776685\n",
      "CMI: 0.0016754341571237341\n",
      "CMI: 0.012120380774337525\n",
      "CMI: 0.004310823163429012\n",
      "CMI: 0.0013629174009057443\n",
      "CMI: 0.0103859583241033\n",
      "CMI: 0.013471545915522659\n",
      "CMI: 0.015697732733219893\n",
      "CMI: 0.007825849633903287\n",
      "CMI: 0.01612501630143265\n",
      "CMI: 0.011937949331668862\n",
      "CMI: 0.003997573864232412\n",
      "CMI: 0.008694243576543748\n",
      "CMI: 0.02019901015141029\n",
      "CMI: 0.01042557259648022\n",
      "CMI: 0.008694516629319249\n",
      "CMI: 0.013424869391649719\n",
      "CMI: 0.00652254672171082\n",
      "CMI: 0.00623977824415628\n",
      "CMI: 0.004117722059756385\n",
      "CMI: 0.011286277961739533\n",
      "CMI: 0.004437799150860705\n",
      "CMI: 0.0012137917258331077\n",
      "CMI: 0.011630014727722848\n",
      "CMI: 0.00853739329349626\n",
      "CMI: 0.0028741086484941614\n",
      "CMI: 0.012603642343029742\n",
      "CMI: 0.0003295168500014045\n",
      "CMI: 0.007156415338075095\n",
      "CMI: 0.0037949778707490056\n",
      "CMI: 0.004383046773275195\n",
      "CMI: 0.001115270481298558\n",
      "CMI: 7.365437584047618e-05\n",
      "CMI: 0.005922505902875297\n",
      "CMI: 0.00012089316286051366\n",
      "CMI: 0.011226164620555645\n",
      "CMI: 0.013260763278238802\n",
      "CMI: 0.0196916538958693\n",
      "CMI: 0.024187603485001707\n",
      "CMI: 0.016480584044851115\n",
      "CMI: 0.025796798328827975\n",
      "CMI: 0.0005036014755905871\n",
      "CMI: 0.020981229821441322\n",
      "CMI: 0.007221984775399565\n",
      "CMI: 0.0005184526110511289\n",
      "CMI: 0.0029219965344841337\n",
      "CMI: 0.0025739304751082603\n",
      "Highest CMI score: 0.025796798328827975\n",
      "Adding original feature: 255\n",
      "CMI: 0.0077311389997749835\n",
      "CMI: 0.0012531522756610847\n",
      "CMI: 0.003928935751529278\n",
      "CMI: 0.009618436093543709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMI: 0.013787907280004369\n",
      "CMI: 0.0003770298644076575\n",
      "CMI: 0.010685191592650689\n",
      "CMI: 0.004217601401418913\n",
      "CMI: 0.00321359923715836\n",
      "CMI: 0.007765776684105108\n",
      "CMI: 0.002882021360667314\n",
      "CMI: 0.0037287055862388896\n",
      "CMI: 0.0007371059361907517\n",
      "CMI: 0.0011816681918609406\n",
      "CMI: 0.016273003536251135\n",
      "CMI: 8.754832531349122e-06\n",
      "CMI: 0.0004716847086129461\n",
      "CMI: 0.0015371373494556528\n",
      "CMI: 0.003775469274715365\n",
      "CMI: 0.0035878616479693426\n",
      "Highest CMI score: 0.016273003536251135\n",
      "Adding original feature: 254\n",
      "CMI: 0.0007296634373672173\n",
      "CMI: 0.001192000847918595\n",
      "CMI: 0.0005060898659814961\n",
      "CMI: 0.0014103968737413375\n",
      "CMI: 0.0005253188657307617\n",
      "CMI: 0.0006486951036909494\n",
      "CMI: 0.002108219157619634\n",
      "CMI: 0.006680915580015906\n",
      "CMI: 0.00035376109937418354\n",
      "CMI: 0.00024093817624065705\n",
      "CMI: 0.005140498795170451\n",
      "CMI: 0.005262814234329505\n",
      "Highest CMI score: 0.006680915580015906\n",
      "Adding original feature: 250\n",
      "CMI: 1.813748272044835e-05\n",
      "Highest CMI score: 1.813748272044835e-05\n",
      "Adding original feature: 76\n",
      "Highest CMI score: -0.0007186974583571482\n",
      "\n",
      "[67, 221, 255, 254, 250, 76]\n",
      "\n",
      "Full aggregate regression train score: 0.7264905690284812, test score: -31.106170157819534\n",
      "Aggregate regression train score with FS: 0.18455493126026534, test score: 0.04024294852454202\n"
     ]
    }
   ],
   "source": [
    "target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target('')\n",
    "\n",
    "output,aggregate_trainVal,aggregate_test = aggregate_unfolded_data(path,['cyclostationary_mean_tg',\n",
    "       'cyclostationary_mean_tg_1w',\n",
    "       'cyclostationary_mean_tg_4w', 'cyclostationary_mean_tg_8w',\n",
    "       'cyclostationary_mean_tg_12w', 'cyclostationary_mean_tg_16w',\n",
    "       'cyclostationary_mean_tg_24w'],target_df_trainVal)\n",
    "\n",
    "res = {\n",
    "    \"delta\" : [], # list with all deltas\n",
    "    \"numSelected\" : [], #\n",
    "    \"selectedFeatures\" : [] \n",
    "}\n",
    "\n",
    "res['selectedFeatures'] = forwardFeatureSelection(10,np.array(aggregate_trainVal),np.array(target_df_trainVal.mean_std),res,20,1)\n",
    "selectedFeatures='selectedFeatures'\n",
    "print(f'\\n{res[selectedFeatures]}\\n')\n",
    "selected_colnames = aggregate_trainVal.columns[res['selectedFeatures']]\n",
    "compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc49280e",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "6\n",
      "9\n",
      "10\n",
      "13\n",
      "14\n",
      "19\n",
      "----- MI Scores -----\n",
      "[(6, 0.13369491633190958), (5, 0.12411805727993833), (1, 0.12381066696070472), (2, 0.11154320219722483), (8, 0.10868386912841668), (3, 0.09170749801802068), (0, 0.08492510702855696), (4, 0.08299222046345438), (7, 0.07277371050492143)]\n",
      "Best MI score: 0.13369491633190958\n",
      "Adding first best original feature: 6\n",
      "CMI: 0.002469468895136967\n",
      "Highest CMI score: 0.002469468895136967\n",
      "Adding original feature: 1\n",
      "CMI: 0.0026907838147205154\n",
      "CMI: 0.010168579198811784\n",
      "Highest CMI score: 0.010168579198811784\n",
      "Adding original feature: 8\n",
      "CMI: 0.003467166102302882\n",
      "CMI: 0.003924959878174289\n",
      "Highest CMI score: 0.003924959878174289\n",
      "Adding original feature: 5\n",
      "CMI: 0.0012418828636597545\n",
      "Highest CMI score: 0.0012418828636597545\n",
      "Adding original feature: 2\n",
      "Highest CMI score: -0.0029457807247840195\n",
      "\n",
      "[6, 1, 8, 5, 2]\n",
      "\n",
      "Full aggregate regression train score: 0.18349273615659478, test score: 0.04199319936071355\n",
      "Aggregate regression train score with FS: 0.17132334814933103, test score: 0.041984258108946126\n"
     ]
    }
   ],
   "source": [
    "### repeat keeping features with at least three cells\n",
    "ii = []\n",
    "for i in range(len(output)):\n",
    "    if (len(output[i]))>=3: \n",
    "        print(i)\n",
    "        ii.append(i)\n",
    "\n",
    "res = {\n",
    "    \"delta\" : [], # list with all deltas\n",
    "    \"numSelected\" : [], #\n",
    "    \"selectedFeatures\" : [] \n",
    "#    \"accuracy\" : [] # list of scores associated with the reduced problem\n",
    "}\n",
    "\n",
    "res['selectedFeatures'] = forwardFeatureSelection(10,np.array(aggregate_trainVal.iloc[:,ii]),np.array(target_df_trainVal.mean_std),res,10,1)\n",
    "selectedFeatures='selectedFeatures'\n",
    "print(f'\\n{res[selectedFeatures]}\\n')\n",
    "selected_colnames = aggregate_trainVal.iloc[:,ii].columns[res['selectedFeatures']]\n",
    "compare_methods(aggregate_trainVal.iloc[:,ii], aggregate_test.iloc[:,ii], target_df_trainVal, target_df_test, selected_colnames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "057ee656",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.214281    0.00  2001     1 -1.339879\n",
      "1    2001-01-13  0.484737    0.52  2001     2  0.402993\n",
      "2    2001-01-21  0.466071    0.47  2001     3  0.282703\n",
      "3    2001-01-29  0.417470    0.44  2001     5 -0.030490\n",
      "4    2001-02-06  0.492202    0.53  2001     6  0.451097\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.436464    0.46  2009    48  0.091910\n",
      "407  2009-12-05  0.466152    0.49  2009    49  0.283224\n",
      "408  2009-12-13  0.553659    0.59  2009    50  0.847138\n",
      "409  2009-12-21  0.507978    0.65  2009    52  0.552758\n",
      "410  2009-12-29  0.083046    0.00  2009    53 -2.185583\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 41\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 49\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 48\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 40\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 32\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 30\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 25\n",
      "\n",
      "----- MI Scores -----\n",
      "[(65, 0.13581585309537378), (1, 0.13505461083647102), (17, 0.1336253951612861), (22, 0.13292394575475824), (35, 0.1314947303492075), (81, 0.13069123294496232), (13, 0.13043798808455945), (74, 0.12875304464935164), (50, 0.12671700820733212), (75, 0.1248562685125378), (60, 0.12479126466694364), (78, 0.12463846662517435), (2, 0.12455630733277606), (10, 0.12445953011926814), (33, 0.12383644035918981), (34, 0.12351615803964139), (66, 0.12341128944924201), (77, 0.12256467225678017), (42, 0.12011406211181495), (6, 0.1191326366947945), (83, 0.1173352308158649), (37, 0.11677572043276202), (57, 0.11643049112680165), (43, 0.11620479481131091), (53, 0.11542326787804412), (82, 0.11503497437329975), (19, 0.11134774938980065), (64, 0.11092699794197866), (5, 0.11013559411702513), (15, 0.10933694055031372), (73, 0.10762764009133689), (26, 0.10639343474232596), (62, 0.1062471319683625), (49, 0.10603735253034889), (27, 0.10413574714800101), (32, 0.1031824211131886), (31, 0.10303043561142895), (84, 0.1011749499746129), (24, 0.10117477263442257), (30, 0.10115891091565443), (36, 0.10089751960238888), (0, 0.10061050366701373), (69, 0.09967451194068722), (85, 0.09952082319809791), (11, 0.09928800055862086), (25, 0.09837955367460148), (124, 0.09831081574927145), (7, 0.09716249084528307), (76, 0.09715486754501293), (38, 0.09674503527089101), (29, 0.09628861105514297), (28, 0.09548894517094199), (87, 0.09512734091593773), (3, 0.09501019884305828), (8, 0.0946340510559481), (40, 0.09396003052002877), (79, 0.09379158058855251), (136, 0.09139628132408192), (72, 0.09077826136273147), (97, 0.09076136385371739), (105, 0.09047532970765305), (100, 0.09040488088179521), (16, 0.0892798383541589), (4, 0.08785533209619939), (80, 0.08454515140876795), (70, 0.08401358168175745), (56, 0.08341497772267857), (20, 0.08246163579244427), (23, 0.08109352622457383), (48, 0.08066084321572295), (111, 0.0796526979350869), (45, 0.07936131917629609), (68, 0.07928735414262464), (39, 0.07921842318994085), (47, 0.07873902596188526), (139, 0.07854710525011586), (188, 0.07773411277758398), (55, 0.07748313038987), (41, 0.07710592805882054), (18, 0.07671004309464893), (115, 0.07573973721434103), (89, 0.07529382125049738), (58, 0.07521919956605369), (46, 0.07521787057510441), (91, 0.07516164261468143), (21, 0.07509211772700959), (123, 0.07506630311402361), (135, 0.07503761576346638), (71, 0.07466805230632648), (67, 0.07392047929150586), (259, 0.07352278304638972), (98, 0.07262585317719782), (61, 0.07128216030915008), (185, 0.07115344249988176), (63, 0.07069319444494178), (52, 0.0701211291001197), (132, 0.06974810067015934), (150, 0.06847564569702963), (44, 0.06844754374548231), (128, 0.0681128062203191), (88, 0.06788241276823238), (93, 0.06787184036295321), (263, 0.06653777766551189), (187, 0.06627165555179411), (204, 0.06573008402412606), (129, 0.06554679770153546), (141, 0.06451571707504446), (127, 0.06427469138682587), (108, 0.06321376970369103), (140, 0.06318841145009689), (113, 0.06293043539063084), (175, 0.062416923645066034), (122, 0.06173854401454857), (12, 0.06154465928566862), (126, 0.060739526347093606), (99, 0.060685142982779966), (54, 0.06008429478640214), (120, 0.059820196213249195), (59, 0.05970092288175496), (219, 0.059274597165965726), (51, 0.05921769544787926), (212, 0.058974523487543944), (107, 0.0584638483747493), (119, 0.058338256554613076), (191, 0.05815778989392451), (104, 0.05789777609914177), (144, 0.05740025368787109), (125, 0.05685759281983422), (92, 0.05670929562606272), (86, 0.05660301114055047), (148, 0.056115968859696726), (158, 0.05605514964964765), (9, 0.05583991557037529), (106, 0.055700664089196314), (222, 0.05546348664615895), (14, 0.05502074429926837), (149, 0.0546422361056572), (153, 0.05441015991617992), (215, 0.05342753753566159), (169, 0.052671985222242194), (118, 0.05251133668895218), (181, 0.052200116565193015), (116, 0.052029365748566404), (143, 0.05129915613586238), (110, 0.05096806992257548), (176, 0.05078096057462939), (131, 0.050569098788132594), (172, 0.05010637686748453), (255, 0.050035005962793554), (164, 0.049494608824159805), (121, 0.049399680317400205), (221, 0.04848227167378126), (109, 0.04826434593343344), (152, 0.04798453195178872), (112, 0.04758562455990436), (174, 0.047449465763849945), (173, 0.04723947724479487), (133, 0.046798016015657), (134, 0.04667272286054657), (117, 0.0458146716420928), (177, 0.04507816558290335), (114, 0.04495471176561488), (159, 0.044911000097635594), (207, 0.04473315235133114), (170, 0.04428458759911999), (146, 0.04425016105459942), (196, 0.04366092478248454), (198, 0.04347901508207789), (142, 0.04273637905074994), (195, 0.04265014231493115), (101, 0.04256511539732068), (253, 0.042352228433498), (235, 0.04230813507926108), (137, 0.04224825405200672), (171, 0.041405440230631814), (168, 0.04128070325096379), (201, 0.04118126425109107), (154, 0.04111100674579964), (95, 0.04108058646147479), (165, 0.040952307481581594), (155, 0.04070691211815687), (262, 0.04012515178074353), (211, 0.039961101583028485), (203, 0.03993409010610112), (194, 0.03942222202252838), (167, 0.03925852926987327), (156, 0.03918391689491662), (193, 0.03871311561845832), (246, 0.038334686405436635), (102, 0.038278282849072996), (130, 0.037965229428794565), (184, 0.03728009221089104), (254, 0.03705095840340245), (145, 0.03649611374773058), (160, 0.036366135621816724), (239, 0.036235309805572574), (94, 0.03614786591020495), (96, 0.03611158524325686), (220, 0.03595389747874752), (90, 0.03591405045030584), (163, 0.03371647912475754), (244, 0.03357586282894819), (261, 0.0331852397217703), (166, 0.0329478792103667), (237, 0.032051054957153796), (224, 0.03118486163746837), (200, 0.030838179880089526), (218, 0.030695244244151428), (157, 0.030420240841519466), (182, 0.03021236525454539), (206, 0.03015983320258106), (151, 0.030078002625090472), (103, 0.02977691092966068), (264, 0.029022406318602437), (180, 0.028779374026798168), (162, 0.028700791968406886), (192, 0.028542006664438742), (240, 0.028503741212356788), (217, 0.028290550205452306), (197, 0.027873449918658446), (251, 0.027444026267247117), (199, 0.02738937448548795), (179, 0.027090419026053247), (147, 0.026950512116596367), (241, 0.026937237561742926), (183, 0.02602967735661519), (161, 0.025891165908466462), (243, 0.025782313136380856), (138, 0.025251578349896116), (258, 0.02513536324912335), (190, 0.02298769455574419), (232, 0.022267434728199375), (225, 0.02150538272365045), (227, 0.02112640574339395), (228, 0.020546353317391908), (236, 0.01952775675672057), (250, 0.01943030436535108), (257, 0.01912460323110608), (209, 0.017832660253566092), (214, 0.01763959492317453), (202, 0.017421776960547693), (216, 0.017180243228774317), (208, 0.016823352717530066), (189, 0.013174546438387915), (234, 0.012849396131073972), (230, 0.012328571516793051), (238, 0.011883833617188757), (186, 0.010994180773513676), (249, 0.010171756293178565), (256, 0.00928774328635512), (226, 0.008623335404627583), (247, 0.008253082315159718), (223, 0.00782425860580327), (252, 0.007560128725401261), (210, 0.007425604484230421), (260, 0.00722030862401297), (245, 0.005940511515330449), (205, 0.004936802424541452), (242, 0.004212347837369171), (233, 0.0035345946350680097), (248, 0.0017725932448176462), (229, 0.001199283744453612), (231, -0.0020961023020281324), (213, -0.005605609229336752), (178, -0.008931202232416138)]\n",
      "Best MI score: 0.13581585309537378\n",
      "Adding first best original feature: 65\n",
      "CMI: 0.006182510803362906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMI: 0.0007187043416190808\n",
      "CMI: 0.007230283006921828\n",
      "CMI: 0.010960782557124626\n",
      "CMI: 0.004037662917051987\n",
      "CMI: 0.0030121090469339695\n",
      "CMI: 0.00901303930319236\n",
      "CMI: 0.010679830312408128\n",
      "CMI: 0.007991863917649472\n",
      "CMI: 0.007852564860627437\n",
      "CMI: 0.00366519897243045\n",
      "CMI: 0.0008717181977179189\n",
      "CMI: 0.004855860583884625\n",
      "CMI: 0.0016694691580188548\n",
      "CMI: 0.003150176167287966\n",
      "CMI: 7.280346436999707e-05\n",
      "CMI: 0.0066669900567441764\n",
      "CMI: 0.0010740375930284873\n",
      "CMI: 0.004229936382990518\n",
      "CMI: 0.002345428708940056\n",
      "CMI: 0.006505443413236778\n",
      "CMI: 0.0009718254515048985\n",
      "CMI: 0.002922072263154857\n",
      "CMI: 0.006159317752981092\n",
      "CMI: 0.0043559963566974225\n",
      "CMI: 0.007870045701975747\n",
      "CMI: 0.014874696806860849\n",
      "CMI: 0.00787474513291836\n",
      "CMI: 0.010899360473428488\n",
      "CMI: 0.0064345123206901444\n",
      "CMI: 0.007962800583828727\n",
      "CMI: 0.017237516765143318\n",
      "CMI: 0.009234658383358157\n",
      "CMI: 0.011970045240902227\n",
      "CMI: 0.010548893948092136\n",
      "CMI: 0.005194665917216845\n",
      "CMI: 0.010026292679333582\n",
      "CMI: 0.002526984514724967\n",
      "CMI: 0.01697275327165859\n",
      "CMI: 0.01836988809182416\n",
      "CMI: 0.007425143877033025\n",
      "CMI: 0.0031580980284626747\n",
      "CMI: 0.005536252858972579\n",
      "CMI: 0.0026179499752951585\n",
      "CMI: 0.005684770995632027\n",
      "CMI: 0.02215588052292683\n",
      "CMI: 0.0011465824312679729\n",
      "CMI: 0.004881929671033569\n",
      "CMI: 0.013066293316048\n",
      "CMI: 0.0049441207295972955\n",
      "Highest CMI score: 0.02215588052292683\n",
      "Adding original feature: 255\n",
      "CMI: 0.0006490568310758837\n",
      "CMI: 0.0035942001212576624\n",
      "CMI: 0.014257225846146943\n",
      "CMI: 0.0007458181488424476\n",
      "CMI: 0.026214965639937027\n",
      "CMI: 0.0005921940684370519\n",
      "CMI: 0.0064425715050220045\n",
      "CMI: 0.018437227932989242\n",
      "CMI: 0.012716202975197904\n",
      "CMI: 0.006713051850573165\n",
      "CMI: 0.010992886647127192\n",
      "CMI: 0.02452826826030552\n",
      "CMI: 4.7432281284676137e-05\n",
      "CMI: 0.018785521659218624\n",
      "CMI: 0.004970372544036483\n",
      "CMI: 0.004014035524139342\n",
      "CMI: 0.00556191115871757\n",
      "CMI: 0.005226353342964035\n",
      "CMI: 0.009238642986992257\n",
      "CMI: 0.01711136664011212\n",
      "CMI: 0.007426922531525826\n",
      "CMI: 0.013467887511430299\n",
      "CMI: 0.010430196261851932\n",
      "CMI: 0.0010328055352081533\n",
      "CMI: 6.950210727266204e-05\n",
      "Highest CMI score: 0.026214965639937027\n",
      "Adding original feature: 142\n",
      "CMI: 0.0001191171484190845\n",
      "CMI: 0.007768934743966505\n",
      "CMI: 0.007023940570842074\n",
      "CMI: 0.006627771674284494\n",
      "CMI: 0.004402212859957261\n",
      "CMI: 0.001949315440266608\n",
      "CMI: 0.002217373186101157\n",
      "CMI: 0.004964587021756617\n",
      "CMI: 0.0028882499839241182\n",
      "CMI: 0.006719638812836021\n",
      "CMI: 0.0018185242020220538\n",
      "CMI: 0.00686856507212949\n",
      "CMI: 0.002080356971074393\n",
      "CMI: 0.0006867468701742541\n",
      "CMI: 0.0008256492109844915\n",
      "CMI: 0.001762420570622425\n",
      "CMI: 0.001131273557684137\n",
      "CMI: 0.011013680596988373\n",
      "CMI: 0.014625467303367862\n",
      "CMI: 0.0005196961979161141\n",
      "CMI: 0.0015703216322815738\n",
      "CMI: 0.00044053712216532426\n",
      "CMI: 0.012989314193981666\n",
      "CMI: 0.026318612764565763\n",
      "CMI: 0.013652002612021596\n",
      "CMI: 0.0015746117967017637\n",
      "CMI: 0.009402634174124042\n",
      "CMI: 0.00797175779275422\n",
      "CMI: 0.0026857966819896495\n",
      "CMI: 0.0022334519148502763\n",
      "Highest CMI score: 0.026318612764565763\n",
      "Adding original feature: 248\n",
      "CMI: 0.006035521799116816\n",
      "CMI: 0.0002945282482463285\n",
      "CMI: 2.137867018284223e-05\n",
      "CMI: 0.005533003768365491\n",
      "CMI: 0.00040928273478099686\n",
      "CMI: 0.00029593651901177465\n",
      "CMI: 0.006773808477967519\n",
      "CMI: 0.0020816431511092304\n",
      "CMI: 0.003947816512131969\n",
      "CMI: 0.002225923448777589\n",
      "CMI: 0.011425267900644964\n",
      "CMI: 0.00023419601903018616\n",
      "CMI: 0.0012349268401763425\n",
      "CMI: 0.004192631483328602\n",
      "CMI: 0.004896403891863299\n",
      "CMI: 0.0016397367968822019\n",
      "CMI: 0.00411790769573428\n",
      "CMI: 0.0013407320613743334\n",
      "CMI: 0.0021699973653533378\n",
      "CMI: 0.0007048948117838183\n",
      "CMI: 0.0019084288598852917\n",
      "CMI: 0.0016323466857871283\n",
      "CMI: 0.006715554168959997\n",
      "CMI: 0.011700171573771956\n",
      "CMI: 0.00034422123369545754\n",
      "CMI: 0.013694939690520186\n",
      "CMI: 0.0033657936331068228\n",
      "CMI: 0.00939702780513027\n",
      "CMI: 0.005789960676255396\n",
      "CMI: 0.002266600536931701\n",
      "CMI: 0.012279993779847731\n",
      "CMI: 0.0034515725682476572\n",
      "CMI: 0.004761887273912996\n",
      "CMI: 0.0046470466391462795\n",
      "CMI: 0.002103491101117544\n",
      "Highest CMI score: 0.013694939690520186\n",
      "Adding original feature: 249\n",
      "CMI: 0.003800582318665424\n",
      "CMI: 0.002081440105067417\n",
      "CMI: 0.006111308970262214\n",
      "CMI: 0.005066613631970529\n",
      "CMI: 0.010690869260426422\n",
      "CMI: 0.014435771843862188\n",
      "CMI: 0.004800863943127037\n",
      "CMI: 0.0032027348720037874\n",
      "CMI: 0.0004260151948622948\n",
      "CMI: 0.010500074681016075\n",
      "CMI: 0.0027292219985762534\n",
      "CMI: 0.008970500038745888\n",
      "CMI: 0.0024820855813630083\n",
      "CMI: 0.012017450414399056\n",
      "Highest CMI score: 0.014435771843862188\n",
      "Adding original feature: 219\n",
      "CMI: 0.0007323677640141413\n",
      "CMI: 0.0017954048218996876\n",
      "CMI: 0.008366007553276822\n",
      "CMI: 0.0019887919755470496\n",
      "CMI: 0.0036271402677132414\n",
      "CMI: 0.005090626771776768\n",
      "CMI: 0.002326129498077062\n",
      "CMI: 0.0010244119985545475\n",
      "CMI: 0.0051216701363862305\n",
      "CMI: 0.003653841958151577\n",
      "CMI: 0.008147405242589445\n",
      "CMI: 0.008305238423605754\n",
      "CMI: 0.002537635472156241\n",
      "CMI: 0.0057253634315648505\n",
      "Highest CMI score: 0.008366007553276822\n",
      "Adding original feature: 60\n",
      "CMI: 0.0008930523818361791\n",
      "CMI: 0.0017697961036769183\n",
      "CMI: 0.000957498666608575\n",
      "CMI: 0.002499936808754072\n",
      "Highest CMI score: 0.002499936808754072\n",
      "Adding original feature: 264\n",
      "CMI: 0.00369820084075953\n",
      "CMI: 0.0001269866349955795\n",
      "Highest CMI score: 0.00369820084075953\n",
      "Adding original feature: 138\n",
      "CMI: 0.0015607625035512496\n",
      "CMI: 0.0031338395583136447\n",
      "CMI: 0.0022600207573421627\n",
      "CMI: 0.0037080971577735378\n",
      "CMI: 0.0003653956527291391\n",
      "Highest CMI score: 0.0037080971577735378\n",
      "Adding original feature: 72\n",
      "CMI: 0.0002508771367872864\n",
      "Highest CMI score: 0.0002508771367872864\n",
      "Adding original feature: 50\n",
      "CMI: 0.0008532347089041381\n",
      "Highest CMI score: 0.0008532347089041381\n",
      "Adding original feature: 57\n",
      "Highest CMI score: -0.0002755319085721575\n",
      "\n",
      "[65, 255, 142, 248, 249, 219, 60, 264, 138, 72, 50, 57]\n",
      "\n",
      "Full aggregate regression train score: 0.7800775933217615, test score: -22.751755145654034\n",
      "Aggregate regression train score with FS: 0.19338647049070357, test score: 0.32916968028105165\n"
     ]
    }
   ],
   "source": [
    "### what happens without considering the last years?\n",
    "target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target('',max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01')\n",
    "\n",
    "path='/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/features/csv_allvalues/temporal_aggreg/Emiliani2_aggreg.csv'\n",
    "\n",
    "output,aggregate_trainVal,aggregate_test = aggregate_unfolded_data(path,['cyclostationary_mean_tg',\n",
    "       'cyclostationary_mean_tg_1w',\n",
    "       'cyclostationary_mean_tg_4w', 'cyclostationary_mean_tg_8w',\n",
    "       'cyclostationary_mean_tg_12w', 'cyclostationary_mean_tg_16w',\n",
    "       'cyclostationary_mean_tg_24w'],target_df_trainVal, max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01')\n",
    "\n",
    "res = {\n",
    "    \"delta\" : [], # list with all deltas\n",
    "    \"numSelected\" : [], #\n",
    "    \"selectedFeatures\" : [] \n",
    "#    \"accuracy\" : [] # list of scores associated with the reduced problem\n",
    "}\n",
    "\n",
    "res['selectedFeatures'] = forwardFeatureSelection(10,np.array(aggregate_trainVal),np.array(target_df_trainVal.mean_std),res,10,1)\n",
    "selectedFeatures='selectedFeatures'\n",
    "print(f'\\n{res[selectedFeatures]}\\n')\n",
    "selected_colnames = aggregate_trainVal.columns[res['selectedFeatures']]\n",
    "compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d54d0e06",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "7\n",
      "10\n",
      "14\n",
      "16\n",
      "17\n",
      "19\n",
      "----- MI Scores -----\n",
      "[(1, 0.13505461083647102), (6, 0.1336253951612861), (3, 0.12445953011926814), (7, 0.11134774938980065), (0, 0.10061050366701373), (2, 0.09716249084528307), (5, 0.0892798383541589), (4, 0.05502074429926837)]\n",
      "Best MI score: 0.13505461083647102\n",
      "Adding first best original feature: 1\n",
      "CMI: 0.007238248531410224\n",
      "CMI: 0.005259645329403068\n",
      "Highest CMI score: 0.007238248531410224\n",
      "Adding original feature: 6\n",
      "Highest CMI score: -0.000606310469806054\n",
      "\n",
      "[1, 6]\n",
      "\n",
      "Full aggregate regression train score: 0.1843265913751193, test score: 0.13080411634512878\n",
      "Aggregate regression train score with FS: 0.12515433663485154, test score: 0.11948168829116379\n"
     ]
    }
   ],
   "source": [
    "### repeat keeping features with at least three cells and excluding last years\n",
    "ii = []\n",
    "for i in range(len(output)):\n",
    "    if (len(output[i]))>=3: \n",
    "        print(i)\n",
    "        ii.append(i)\n",
    "\n",
    "res = {\n",
    "    \"delta\" : [], # list with all deltas\n",
    "    \"numSelected\" : [], #\n",
    "    \"selectedFeatures\" : [] \n",
    "}\n",
    "\n",
    "res['selectedFeatures'] = forwardFeatureSelection(10,np.array(aggregate_trainVal.iloc[:,ii]),np.array(target_df_trainVal.mean_std),res,10,1)\n",
    "selectedFeatures='selectedFeatures'\n",
    "print(f'\\n{res[selectedFeatures]}\\n')\n",
    "selected_colnames = aggregate_trainVal.iloc[:,ii].columns[res['selectedFeatures']]\n",
    "compare_methods(aggregate_trainVal.iloc[:,ii], aggregate_test.iloc[:,ii], target_df_trainVal, target_df_test, selected_colnames)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba64e53",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## precipitation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4708f9",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "154d762c",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.214281    0.00  2001     1 -1.402730\n",
      "1    2001-01-13  0.484737    0.52  2001     2  0.347916\n",
      "2    2001-01-21  0.466071    0.47  2001     3  0.227090\n",
      "3    2001-01-29  0.417470    0.44  2001     5 -0.087501\n",
      "4    2001-02-06  0.492202    0.53  2001     6  0.396235\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "584  2013-10-21  0.739946    0.79  2013    43  1.999865\n",
      "585  2013-10-29  0.447691    0.46  2013    44  0.108118\n",
      "586  2013-11-06  0.541628    0.56  2013    45  0.716163\n",
      "587  2013-11-14  0.493719    0.53  2013    46  0.406051\n",
      "588  2013-11-22  0.527436    0.57  2013    47  0.624301\n",
      "\n",
      "[589 rows x 6 columns]\n",
      " target shapes: ((589, 6), (200, 6), (789, 6), (192, 6))\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 24\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 30\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 32\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 33\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 28\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 26\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 34\n",
      "\n",
      "actual training score: 0.1496147780387076\n",
      "actual validation score: 0.22227939632068527, number of remaining columns: 205\n",
      "\n",
      "actual training score: 0.15113068604005675\n",
      "actual validation score: 0.24227602972967377, number of remaining columns: 204\n",
      "\n",
      "actual training score: 0.15189422521708407\n",
      "actual validation score: 0.2550629056446563, number of remaining columns: 203\n",
      "\n",
      "actual training score: 0.156770030647312\n",
      "actual validation score: 0.2805121673812945, number of remaining columns: 202\n",
      "\n",
      "actual training score: 0.160659645003998\n",
      "actual validation score: 0.28969172204334337, number of remaining columns: 201\n",
      "\n",
      "actual training score: 0.16289387636465358\n",
      "actual validation score: 0.2993272963745761, number of remaining columns: 200\n",
      "\n",
      "actual training score: 0.163566066907881\n",
      "actual validation score: 0.30523176720688916, number of remaining columns: 199\n",
      "\n",
      "actual training score: 0.16766596658318889\n",
      "actual validation score: 0.320891578159765, number of remaining columns: 198\n",
      "\n",
      "actual training score: 0.16829208972476795\n",
      "actual validation score: 0.3277033532855579, number of remaining columns: 197\n",
      "\n",
      "actual training score: 0.17049780911365064\n",
      "actual validation score: 0.33525042231708735, number of remaining columns: 196\n",
      "\n",
      "actual training score: 0.21975580581405663\n",
      "actual validation score: 0.35613115290595965, number of remaining columns: 195\n",
      "\n",
      "actual training score: 0.23082854942899522\n",
      "actual validation score: 0.3662470599011547, number of remaining columns: 194\n",
      "\n",
      "actual training score: 0.23601614748280686\n",
      "actual validation score: 0.37610335072237566, number of remaining columns: 193\n",
      "\n",
      "actual training score: 0.2370716719718633\n",
      "actual validation score: 0.3833924506056332, number of remaining columns: 192\n",
      "\n",
      "actual training score: 0.23875720978857284\n",
      "actual validation score: 0.38890204683845564, number of remaining columns: 191\n",
      "\n",
      "actual training score: 0.2391984660116503\n",
      "actual validation score: 0.3938755517075542, number of remaining columns: 190\n",
      "\n",
      "actual training score: 0.24047203102318682\n",
      "actual validation score: 0.4005756743633948, number of remaining columns: 189\n",
      "\n",
      "actual training score: 0.2406377025086156\n",
      "actual validation score: 0.4030833467953414, number of remaining columns: 188\n",
      "\n",
      "actual training score: 0.24117162750871546\n",
      "actual validation score: 0.40754887769274617, number of remaining columns: 187\n",
      "\n",
      "actual training score: 0.24474946655295804\n",
      "actual validation score: 0.41218933821999215, number of remaining columns: 186\n",
      "\n",
      "actual training score: 0.24615875533796427\n",
      "actual validation score: 0.4151059919618243, number of remaining columns: 185\n",
      "\n",
      "actual training score: 0.2480896223197655\n",
      "actual validation score: 0.4195028876614426, number of remaining columns: 184\n",
      "\n",
      "actual training score: 0.2482713106305845\n",
      "actual validation score: 0.4218898634121182, number of remaining columns: 183\n",
      "\n",
      "actual training score: 0.2489912726097493\n",
      "actual validation score: 0.4239998284095208, number of remaining columns: 182\n",
      "\n",
      "actual training score: 0.24918553077442795\n",
      "actual validation score: 0.42593574702667825, number of remaining columns: 181\n",
      "\n",
      "actual training score: 0.24925317119477397\n",
      "actual validation score: 0.42781630272637183, number of remaining columns: 180\n",
      "\n",
      "actual training score: 0.24940795909878577\n",
      "actual validation score: 0.43037627322986205, number of remaining columns: 179\n",
      "\n",
      "actual training score: 0.25003027975879244\n",
      "actual validation score: 0.43240941752563733, number of remaining columns: 178\n",
      "\n",
      "actual training score: 0.251914194332165\n",
      "actual validation score: 0.4460033155984301, number of remaining columns: 177\n",
      "\n",
      "actual training score: 0.2519789764740116\n",
      "actual validation score: 0.447138096052326, number of remaining columns: 176\n",
      "\n",
      "actual training score: 0.2533465200481899\n",
      "actual validation score: 0.4514612693155079, number of remaining columns: 175\n",
      "\n",
      "actual training score: 0.26284997189553994\n",
      "actual validation score: 0.45297525870109023, number of remaining columns: 174\n",
      "\n",
      "actual training score: 0.2630266847544285\n",
      "actual validation score: 0.4551352324224307, number of remaining columns: 173\n",
      "\n",
      "actual training score: 0.26392880584952916\n",
      "actual validation score: 0.4563712575516361, number of remaining columns: 172\n",
      "\n",
      "actual training score: 0.26401770894419097\n",
      "actual validation score: 0.45883230087719684, number of remaining columns: 171\n",
      "\n",
      "actual training score: 0.26581242441672415\n",
      "actual validation score: 0.462839326360183, number of remaining columns: 170\n",
      "\n",
      "actual training score: 0.2674380174041219\n",
      "actual validation score: 0.46779985286515213, number of remaining columns: 169\n",
      "\n",
      "actual training score: 0.26792718516049385\n",
      "actual validation score: 0.4700734160581348, number of remaining columns: 168\n",
      "\n",
      "actual training score: 0.2681333813097341\n",
      "actual validation score: 0.47131158471411927, number of remaining columns: 167\n",
      "\n",
      "actual training score: 0.26869715548511697\n",
      "actual validation score: 0.4727157099895246, number of remaining columns: 166\n",
      "\n",
      "actual training score: 0.27083289504811625\n",
      "actual validation score: 0.47302137932389576, number of remaining columns: 165\n",
      "\n",
      "actual training score: 0.2711072486385824\n",
      "actual validation score: 0.47720719139968915, number of remaining columns: 164\n",
      "\n",
      "actual training score: 0.274196603370656\n",
      "actual validation score: 0.48260671167028846, number of remaining columns: 163\n",
      "\n",
      "actual training score: 0.27420386304644007\n",
      "actual validation score: 0.48329541560659106, number of remaining columns: 162\n",
      "\n",
      "actual training score: 0.27500924342977484\n",
      "actual validation score: 0.4844109654187082, number of remaining columns: 161\n",
      "\n",
      "actual training score: 0.2750437583347527\n",
      "actual validation score: 0.48492499520816057, number of remaining columns: 160\n",
      "\n",
      "actual training score: 0.27505467140305406\n",
      "actual validation score: 0.48524025641615964, number of remaining columns: 159\n",
      "\n",
      "actual training score: 0.27507574762539533\n",
      "actual validation score: 0.4850522636952337, number of remaining columns: 158\n",
      "\n",
      "actual training score: 0.27513106776114604\n",
      "actual validation score: 0.4847915755185571, number of remaining columns: 157\n",
      "\n",
      "actual training score: 0.2755467873205303\n",
      "actual validation score: 0.4841106640830526, number of remaining columns: 156\n",
      "\n",
      "actual training score: 0.27565340877950184\n",
      "actual validation score: 0.4832816713596195, number of remaining columns: 155\n",
      "\n",
      "actual training score: 0.27588466684999735\n",
      "actual validation score: 0.4830860292426181, number of remaining columns: 154\n",
      "\n",
      "actual training score: 0.2760106302707013\n",
      "actual validation score: 0.48196690503206563, number of remaining columns: 153\n",
      "\n",
      "actual training score: 0.27637132222046235\n",
      "actual validation score: 0.48104133915977487, number of remaining columns: 152\n",
      "\n",
      "actual training score: 0.27680097555638794\n",
      "actual validation score: 0.47986679961961054, number of remaining columns: 151\n",
      "\n",
      "actual training score: 0.2782893123979089\n",
      "actual validation score: 0.47934054185883146, number of remaining columns: 150\n",
      "\n",
      "actual training score: 0.2782910837862297\n",
      "actual validation score: 0.47961915112144105, number of remaining columns: 149\n",
      "\n",
      "actual training score: 0.27918553969388893\n",
      "actual validation score: 0.4816883628462375, number of remaining columns: 148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual training score: 0.2791855541494336\n",
      "actual validation score: 0.4817110574215502, number of remaining columns: 147\n",
      "\n",
      "actual training score: 0.27918861596059175\n",
      "actual validation score: 0.48108055036597874, number of remaining columns: 146\n",
      "\n",
      "actual training score: 0.27919615751790283\n",
      "actual validation score: 0.4800303393668949, number of remaining columns: 145\n",
      "\n",
      "actual training score: 0.2805835500833197\n",
      "actual validation score: 0.48015756223779393, number of remaining columns: 144\n",
      "\n",
      "actual training score: 0.2866763644885969\n",
      "actual validation score: 0.4784645212408771, number of remaining columns: 143\n",
      "\n",
      "actual training score: 0.2881567729011375\n",
      "actual validation score: 0.4778985639211736, number of remaining columns: 142\n",
      "\n",
      "actual training score: 0.2885711226509742\n",
      "actual validation score: 0.4758897945419178, number of remaining columns: 141\n",
      "\n",
      "actual training score: 0.28921385140331013\n",
      "actual validation score: 0.47325505619025665, number of remaining columns: 140\n",
      "\n",
      "actual training score: 0.2901737666588623\n",
      "actual validation score: 0.4709984894393904, number of remaining columns: 139\n",
      "\n",
      "actual training score: 0.29090249759987896\n",
      "actual validation score: 0.4689592888439942, number of remaining columns: 138\n",
      "\n",
      "actual training score: 0.29234731551850623\n",
      "actual validation score: 0.46544065565071524, number of remaining columns: 137\n",
      "\n",
      "actual training score: 0.29248439554314476\n",
      "actual validation score: 0.4613550704133489, number of remaining columns: 136\n",
      "\n",
      "actual training score: 0.29502239160855326\n",
      "actual validation score: 0.4587440543725445, number of remaining columns: 135\n",
      "\n",
      "actual training score: 0.3008773231257499\n",
      "actual validation score: 0.45484501873651717, number of remaining columns: 134\n",
      "\n",
      "actual training score: 0.3008895556564938\n",
      "actual validation score: 0.45304114342235824, number of remaining columns: 133\n",
      "\n",
      "actual training score: 0.301288926146578\n",
      "actual validation score: 0.4500776156374231, number of remaining columns: 132\n",
      "\n",
      "actual training score: 0.30146942220923667\n",
      "actual validation score: 0.44862089486654133, number of remaining columns: 131\n",
      "\n",
      "actual training score: 0.3015376514334219\n",
      "actual validation score: 0.44695162033496005, number of remaining columns: 130\n",
      "\n",
      "actual training score: 0.3029181025681791\n",
      "actual validation score: 0.4496207079616993, number of remaining columns: 129\n",
      "\n",
      "actual training score: 0.31644123506804867\n",
      "actual validation score: 0.44833229700543664, number of remaining columns: 128\n",
      "\n",
      "actual training score: 0.3164708733390196\n",
      "actual validation score: 0.4487880025688865, number of remaining columns: 127\n",
      "\n",
      "actual training score: 0.3176318225249184\n",
      "actual validation score: 0.4481724537173043, number of remaining columns: 126\n",
      "\n",
      "actual training score: 0.317645350423978\n",
      "actual validation score: 0.4479244777610526, number of remaining columns: 125\n",
      "\n",
      "actual training score: 0.31895035074531297\n",
      "actual validation score: 0.4470965447885984, number of remaining columns: 124\n",
      "\n",
      "actual training score: 0.3197550214014574\n",
      "actual validation score: 0.4471125426987821, number of remaining columns: 123\n",
      "\n",
      "actual training score: 0.3197999660402814\n",
      "actual validation score: 0.4464216992464014, number of remaining columns: 122\n",
      "\n",
      "actual training score: 0.32043721148737025\n",
      "actual validation score: 0.4451966535338715, number of remaining columns: 121\n",
      "\n",
      "actual training score: 0.32463770780926027\n",
      "actual validation score: 0.44426055093656236, number of remaining columns: 120\n",
      "\n",
      "actual training score: 0.3327865028468382\n",
      "actual validation score: 0.44213268389400806, number of remaining columns: 119\n",
      "\n",
      "actual training score: 0.33404688148245953\n",
      "actual validation score: 0.44881353951432545, number of remaining columns: 118\n",
      "\n",
      "actual training score: 0.3342468472472271\n",
      "actual validation score: 0.45104297031078, number of remaining columns: 117\n",
      "\n",
      "actual training score: 0.33770164725292007\n",
      "actual validation score: 0.4523657271873962, number of remaining columns: 116\n",
      "\n",
      "actual training score: 0.3377018895776124\n",
      "actual validation score: 0.45227164898714567, number of remaining columns: 115\n",
      "\n",
      "actual training score: 0.33796913514613114\n",
      "actual validation score: 0.4504228457335433, number of remaining columns: 114\n",
      "\n",
      "actual training score: 0.33811374436474284\n",
      "actual validation score: 0.4486480961756213, number of remaining columns: 113\n",
      "\n",
      "actual training score: 0.3476242718277536\n",
      "actual validation score: 0.4485171455418916, number of remaining columns: 112\n",
      "\n",
      "actual training score: 0.3476248706247851\n",
      "actual validation score: 0.4487121539527338, number of remaining columns: 111\n",
      "\n",
      "actual training score: 0.34924396891018417\n",
      "actual validation score: 0.4481008469921086, number of remaining columns: 110\n",
      "\n",
      "actual training score: 0.34942878792456944\n",
      "actual validation score: 0.4469771941406765, number of remaining columns: 109\n",
      "\n",
      "actual training score: 0.35040155730372224\n",
      "actual validation score: 0.44526046219491555, number of remaining columns: 108\n",
      "\n",
      "actual training score: 0.3504572610038216\n",
      "actual validation score: 0.44474334583790587, number of remaining columns: 107\n",
      "\n",
      "actual training score: 0.35156127771662715\n",
      "actual validation score: 0.4452342636379748, number of remaining columns: 106\n",
      "\n",
      "\n",
      "\n",
      "selected columns: ['cyclostationary_mean_rr_8w_16', 'cyclostationary_mean_rr_1w_13', 'cyclostationary_mean_rr_8w_22', 'cyclostationary_mean_rr_8w_27', 'cyclostationary_mean_rr_8w_26', 'cyclostationary_mean_rr_12w_21', 'cyclostationary_mean_rr_8w_18', 'cyclostationary_mean_rr_12w_5', 'cyclostationary_mean_rr_12w_19', 'cyclostationary_mean_rr_8w_9', 'cyclostationary_mean_rr_8w_7', 'cyclostationary_mean_rr_8w_14', 'cyclostationary_mean_rr_24w_26', 'cyclostationary_mean_rr_4w_31', 'cyclostationary_mean_rr_1w_15', 'cyclostationary_mean_rr_1w_3', 'cyclostationary_mean_rr_4w_28', 'cyclostationary_mean_rr_4w_25', 'cyclostationary_mean_rr_12w_27', 'cyclostationary_mean_rr_16w_11', 'cyclostationary_mean_rr_4w_6', 'cyclostationary_mean_rr_24w_6', 'cyclostationary_mean_rr_24w_28', 'cyclostationary_mean_rr_8w_4', 'cyclostationary_mean_rr_16w_22', 'cyclostationary_mean_rr_8w_3', 'cyclostationary_mean_rr_16w_2', 'cyclostationary_mean_rr_8w_32', 'cyclostationary_mean_rr_16w_17', 'cyclostationary_mean_rr_16w_25', 'cyclostationary_mean_rr_0', 'cyclostationary_mean_rr_18', 'cyclostationary_mean_rr_24w_20', 'cyclostationary_mean_rr_24w_32', 'cyclostationary_mean_rr_4w_30', 'cyclostationary_mean_rr_4w_19', 'cyclostationary_mean_rr_1w_21', 'cyclostationary_mean_rr_4w_21', 'cyclostationary_mean_rr_1w_24', 'cyclostationary_mean_rr_10', 'cyclostationary_mean_rr_24w_8', 'cyclostationary_mean_rr_4w_0', 'cyclostationary_mean_rr_4w_8', 'cyclostationary_mean_rr_16w_0', 'cyclostationary_mean_rr_8w_29', 'cyclostationary_mean_rr_12w_14', 'cyclostationary_mean_rr_1w_10', 'cyclostationary_mean_rr_16w_6'], \n",
      "\n",
      "validation score: 0.48524025641615964, \n",
      "\n",
      "number of selected features: 48\n",
      "Full aggregate regression train score: 0.5709453283924056, test score: -0.5612643215121798\n",
      "Aggregate regression train score with FS: 0.32809291322626344, test score: -0.1786761134637489\n"
     ]
    }
   ],
   "source": [
    "target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target('')\n",
    "\n",
    "path='/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/features/csv_allvalues/temporal_aggreg/Emiliani2_aggreg.csv'\n",
    "\n",
    "output,aggregate_trainVal,aggregate_test = aggregate_unfolded_data(path,['cyclostationary_mean_rr', \n",
    "                                                                         'cyclostationary_mean_rr_1w',\n",
    "                                                                         'cyclostationary_mean_rr_4w', \n",
    "                                                                         'cyclostationary_mean_rr_8w',\n",
    "                                                                         'cyclostationary_mean_rr_12w', \n",
    "                                                                         'cyclostationary_mean_rr_16w',\n",
    "                                                                         'cyclostationary_mean_rr_24w'\n",
    "                                                                        ],\n",
    "                                                                   target_df_trainVal)\n",
    "\n",
    "selected_colnames = FS_with_linearWrapper(aggregate_trainVal, target_df_train, target_df_val, 100)\n",
    "\n",
    "compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c912cf3",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "3\n",
      "4\n",
      "7\n",
      "8\n",
      "13\n",
      "14\n",
      "16\n",
      "21\n",
      "25\n",
      "27\n",
      "actual training score: 0.07809898152286088\n",
      "actual validation score: 0.02600661076829569, number of remaining columns: 10\n",
      "\n",
      "actual training score: 0.0847925822730422\n",
      "actual validation score: 0.025831589442307568, number of remaining columns: 9\n",
      "\n",
      "actual training score: 0.0849060783065525\n",
      "actual validation score: 0.024954891347490293, number of remaining columns: 8\n",
      "\n",
      "actual training score: 0.08871988149605836\n",
      "actual validation score: 0.026616459282883698, number of remaining columns: 7\n",
      "\n",
      "actual training score: 0.09229262416247574\n",
      "actual validation score: 0.02495711809593959, number of remaining columns: 6\n",
      "\n",
      "actual training score: 0.09323092685687895\n",
      "actual validation score: 0.03096787741693796, number of remaining columns: 5\n",
      "\n",
      "actual training score: 0.09572110250269728\n",
      "actual validation score: 0.032654867268776755, number of remaining columns: 4\n",
      "\n",
      "actual training score: 0.10917857372956796\n",
      "actual validation score: 0.024287059555100132, number of remaining columns: 3\n",
      "\n",
      "actual training score: 0.10942219515734564\n",
      "actual validation score: 0.027046631801117438, number of remaining columns: 2\n",
      "\n",
      "actual training score: 0.11084501559027282\n",
      "actual validation score: 0.013068824229049536, number of remaining columns: 1\n",
      "\n",
      "\n",
      "\n",
      "selected columns: ['cyclostationary_mean_rr_1w_1', 'cyclostationary_mean_rr_0', 'cyclostationary_mean_rr_1w_3', 'cyclostationary_mean_rr_8', 'cyclostationary_mean_rr_3', 'cyclostationary_mean_rr_21', 'cyclostationary_mean_rr_13', 'cyclostationary_mean_rr_16'], \n",
      "\n",
      "validation score: 0.032654867268776755, \n",
      "\n",
      "number of selected features: 8\n",
      "Full aggregate regression train score: 0.09829192314737889, test score: 0.04958536663510049\n",
      "Aggregate regression train score with FS: 0.08762967280819056, test score: 0.02928604510826316\n"
     ]
    }
   ],
   "source": [
    "### repeat keeping features with at least three cells\n",
    "ii = []\n",
    "for i in range(len(output)):\n",
    "    if (len(output[i]))>=3: \n",
    "        print(i)\n",
    "        ii.append(i)\n",
    "\n",
    "selected_colnames = FS_with_linearWrapper(aggregate_trainVal.iloc[:,ii], target_df_train, target_df_val, 10)\n",
    "\n",
    "compare_methods(aggregate_trainVal.iloc[:,ii], aggregate_test.iloc[:,ii], target_df_trainVal, target_df_test, selected_colnames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7a6ff54",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.214281    0.00  2001     1 -1.402730\n",
      "1    2001-01-13  0.484737    0.52  2001     2  0.347916\n",
      "2    2001-01-21  0.466071    0.47  2001     3  0.227090\n",
      "3    2001-01-29  0.417470    0.44  2001     5 -0.087501\n",
      "4    2001-02-06  0.492202    0.53  2001     6  0.396235\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "584  2013-10-21  0.739946    0.79  2013    43  1.999865\n",
      "585  2013-10-29  0.447691    0.46  2013    44  0.108118\n",
      "586  2013-11-06  0.541628    0.56  2013    45  0.716163\n",
      "587  2013-11-14  0.493719    0.53  2013    46  0.406051\n",
      "588  2013-11-22  0.527436    0.57  2013    47  0.624301\n",
      "\n",
      "[589 rows x 6 columns]\n",
      " target shapes: ((589, 6), (200, 6), (789, 6), (192, 6))\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 24\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 30\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 32\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 33\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 28\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 26\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 34\n",
      "\n",
      "actual training score: 0.1496147780387076\n",
      "actual validation score: 0.22227939632068527, number of remaining columns: 205\n",
      "\n",
      "actual training score: 0.15113068604005675\n",
      "actual validation score: 0.24227602972967377, number of remaining columns: 204\n",
      "\n",
      "actual training score: 0.15189422521708407\n",
      "actual validation score: 0.2550629056446563, number of remaining columns: 203\n",
      "\n",
      "actual training score: 0.156770030647312\n",
      "actual validation score: 0.2805121673812945, number of remaining columns: 202\n",
      "\n",
      "\n",
      "\n",
      "selected columns: ['cyclostationary_mean_rr_8w_16', 'cyclostationary_mean_rr_1w_13', 'cyclostationary_mean_rr_8w_22', 'cyclostationary_mean_rr_8w_27', 'cyclostationary_mean_rr_8w_26'], \n",
      "\n",
      "validation score: 0.2805121673812945, \n",
      "\n",
      "number of selected features: 5\n",
      "Full aggregate regression train score: 0.5709453283924056, test score: -0.5612643215121798\n",
      "Aggregate regression train score with FS: 0.1886270391536694, test score: 0.051228907205394414\n"
     ]
    }
   ],
   "source": [
    "### full, forcing a low number of features\n",
    "target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target('')\n",
    "\n",
    "path='/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/features/csv_allvalues/temporal_aggreg/Emiliani2_aggreg.csv'\n",
    "\n",
    "output,aggregate_trainVal,aggregate_test = aggregate_unfolded_data(path,['cyclostationary_mean_rr', \n",
    "                                                                         'cyclostationary_mean_rr_1w',\n",
    "                                                                         'cyclostationary_mean_rr_4w', \n",
    "                                                                         'cyclostationary_mean_rr_8w',\n",
    "                                                                         'cyclostationary_mean_rr_12w', \n",
    "                                                                         'cyclostationary_mean_rr_16w',\n",
    "                                                                         'cyclostationary_mean_rr_24w'\n",
    "                                                                        ],\n",
    "                                                                   target_df_trainVal)\n",
    "\n",
    "selected_colnames = FS_with_linearWrapper(aggregate_trainVal, target_df_train, target_df_val, 4)\n",
    "\n",
    "compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c015c6af",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### not considering last years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07434e78",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.214281    0.00  2001     1 -1.339879\n",
      "1    2001-01-13  0.484737    0.52  2001     2  0.402993\n",
      "2    2001-01-21  0.466071    0.47  2001     3  0.282703\n",
      "3    2001-01-29  0.417470    0.44  2001     5 -0.030490\n",
      "4    2001-02-06  0.492202    0.53  2001     6  0.451097\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.436464    0.46  2009    48  0.091910\n",
      "407  2009-12-05  0.466152    0.49  2009    49  0.283224\n",
      "408  2009-12-13  0.553659    0.59  2009    50  0.847138\n",
      "409  2009-12-21  0.507978    0.65  2009    52  0.552758\n",
      "410  2009-12-29  0.083046    0.00  2009    53 -2.185583\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 28\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 29\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 36\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 39\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 33\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 27\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 36\n",
      "\n",
      "actual training score: 0.07324125553704952\n",
      "actual validation score: 0.2274397338796913, number of remaining columns: 226\n",
      "\n",
      "actual training score: 0.0859284926278111\n",
      "actual validation score: 0.2722892769082381, number of remaining columns: 225\n",
      "\n",
      "actual training score: 0.10803026739854826\n",
      "actual validation score: 0.2887846532374908, number of remaining columns: 224\n",
      "\n",
      "actual training score: 0.1112732434896817\n",
      "actual validation score: 0.30677514792446947, number of remaining columns: 223\n",
      "\n",
      "actual training score: 0.11356001552226658\n",
      "actual validation score: 0.32330492633173236, number of remaining columns: 222\n",
      "\n",
      "actual training score: 0.11963845235248005\n",
      "actual validation score: 0.34454791615001357, number of remaining columns: 221\n",
      "\n",
      "actual training score: 0.1218909350153019\n",
      "actual validation score: 0.35695930437215007, number of remaining columns: 220\n",
      "\n",
      "actual training score: 0.12432073483688211\n",
      "actual validation score: 0.3661850516506514, number of remaining columns: 219\n",
      "\n",
      "actual training score: 0.12991546344118898\n",
      "actual validation score: 0.3756204163236281, number of remaining columns: 218\n",
      "\n",
      "actual training score: 0.13195293441058842\n",
      "actual validation score: 0.37959803588491625, number of remaining columns: 217\n",
      "\n",
      "actual training score: 0.13402798370080904\n",
      "actual validation score: 0.38363058561739494, number of remaining columns: 216\n",
      "\n",
      "actual training score: 0.13432015567653766\n",
      "actual validation score: 0.38784446604011247, number of remaining columns: 215\n",
      "\n",
      "actual training score: 0.13454249697971576\n",
      "actual validation score: 0.39127981403615564, number of remaining columns: 214\n",
      "\n",
      "actual training score: 0.13485948317227625\n",
      "actual validation score: 0.3948989321957205, number of remaining columns: 213\n",
      "\n",
      "actual training score: 0.14091360831603383\n",
      "actual validation score: 0.39662904194672144, number of remaining columns: 212\n",
      "\n",
      "actual training score: 0.14374829380295007\n",
      "actual validation score: 0.40241128954565053, number of remaining columns: 211\n",
      "\n",
      "actual training score: 0.14589780845677114\n",
      "actual validation score: 0.4141629130691714, number of remaining columns: 210\n",
      "\n",
      "actual training score: 0.1488921140939662\n",
      "actual validation score: 0.4186499892452923, number of remaining columns: 209\n",
      "\n",
      "actual training score: 0.14933445028824155\n",
      "actual validation score: 0.42327286178434376, number of remaining columns: 208\n",
      "\n",
      "actual training score: 0.15086932208160286\n",
      "actual validation score: 0.42638537868916626, number of remaining columns: 207\n",
      "\n",
      "actual training score: 0.1520308539573828\n",
      "actual validation score: 0.4299519832013108, number of remaining columns: 206\n",
      "\n",
      "actual training score: 0.15404858708047686\n",
      "actual validation score: 0.43279329915448317, number of remaining columns: 205\n",
      "\n",
      "actual training score: 0.154252583363915\n",
      "actual validation score: 0.43372952118848895, number of remaining columns: 204\n",
      "\n",
      "actual training score: 0.15435152886771475\n",
      "actual validation score: 0.43397923533632254, number of remaining columns: 203\n",
      "\n",
      "actual training score: 0.1543753420502243\n",
      "actual validation score: 0.434068774656272, number of remaining columns: 202\n",
      "\n",
      "actual training score: 0.15438825632301156\n",
      "actual validation score: 0.4341628364352377, number of remaining columns: 201\n",
      "\n",
      "actual training score: 0.15438938270179536\n",
      "actual validation score: 0.43415801182443636, number of remaining columns: 200\n",
      "\n",
      "actual training score: 0.1544567901328322\n",
      "actual validation score: 0.43414756567715607, number of remaining columns: 199\n",
      "\n",
      "actual training score: 0.16481406378508767\n",
      "actual validation score: 0.43401876184934374, number of remaining columns: 198\n",
      "\n",
      "actual training score: 0.16789933131322632\n",
      "actual validation score: 0.4344747467694322, number of remaining columns: 197\n",
      "\n",
      "actual training score: 0.16790801189593618\n",
      "actual validation score: 0.43460640426365116, number of remaining columns: 196\n",
      "\n",
      "actual training score: 0.1679105755643746\n",
      "actual validation score: 0.43476264736965864, number of remaining columns: 195\n",
      "\n",
      "actual training score: 0.16792538837724824\n",
      "actual validation score: 0.4343091302096642, number of remaining columns: 194\n",
      "\n",
      "actual training score: 0.1679535378706729\n",
      "actual validation score: 0.4337210630781617, number of remaining columns: 193\n",
      "\n",
      "actual training score: 0.1680753282806785\n",
      "actual validation score: 0.4325704027216213, number of remaining columns: 192\n",
      "\n",
      "actual training score: 0.16835618942488806\n",
      "actual validation score: 0.43188625909711365, number of remaining columns: 191\n",
      "\n",
      "actual training score: 0.16970841256436497\n",
      "actual validation score: 0.4305775304446191, number of remaining columns: 190\n",
      "\n",
      "actual training score: 0.1697115584993225\n",
      "actual validation score: 0.4302032779549859, number of remaining columns: 189\n",
      "\n",
      "actual training score: 0.17387867432757376\n",
      "actual validation score: 0.4300381358940675, number of remaining columns: 188\n",
      "\n",
      "actual training score: 0.17542815583575955\n",
      "actual validation score: 0.43233242769372393, number of remaining columns: 187\n",
      "\n",
      "actual training score: 0.17677809494598906\n",
      "actual validation score: 0.4305754835412048, number of remaining columns: 186\n",
      "\n",
      "actual training score: 0.17942225664131672\n",
      "actual validation score: 0.4282738569059966, number of remaining columns: 185\n",
      "\n",
      "actual training score: 0.1796519036446912\n",
      "actual validation score: 0.4295580874607602, number of remaining columns: 184\n",
      "\n",
      "actual training score: 0.17979236237526686\n",
      "actual validation score: 0.4289543183790526, number of remaining columns: 183\n",
      "\n",
      "actual training score: 0.18148403061210927\n",
      "actual validation score: 0.4254540968850288, number of remaining columns: 182\n",
      "\n",
      "actual training score: 0.18280203090252178\n",
      "actual validation score: 0.42102658149711936, number of remaining columns: 181\n",
      "\n",
      "actual training score: 0.18385843015712777\n",
      "actual validation score: 0.41570183643473824, number of remaining columns: 180\n",
      "\n",
      "actual training score: 0.18427694620990065\n",
      "actual validation score: 0.41235912516069173, number of remaining columns: 179\n",
      "\n",
      "actual training score: 0.1863733230447414\n",
      "actual validation score: 0.41264358142304647, number of remaining columns: 178\n",
      "\n",
      "actual training score: 0.19940557405613768\n",
      "actual validation score: 0.408980842380147, number of remaining columns: 177\n",
      "\n",
      "actual training score: 0.20262340836605386\n",
      "actual validation score: 0.404394625500733, number of remaining columns: 176\n",
      "\n",
      "actual training score: 0.20436835901618144\n",
      "actual validation score: 0.40109476664840593, number of remaining columns: 175\n",
      "\n",
      "actual training score: 0.21278707240559824\n",
      "actual validation score: 0.3938276835713327, number of remaining columns: 174\n",
      "\n",
      "actual training score: 0.21323121987673388\n",
      "actual validation score: 0.38589054991095606, number of remaining columns: 173\n",
      "\n",
      "actual training score: 0.21464501780991285\n",
      "actual validation score: 0.3785030466965993, number of remaining columns: 172\n",
      "\n",
      "actual training score: 0.2204136727055711\n",
      "actual validation score: 0.3740843279479802, number of remaining columns: 171\n",
      "\n",
      "actual training score: 0.22120116910854448\n",
      "actual validation score: 0.3757390729879835, number of remaining columns: 170\n",
      "\n",
      "actual training score: 0.22304088061901417\n",
      "actual validation score: 0.3739375374713487, number of remaining columns: 169\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual training score: 0.22706922705112365\n",
      "actual validation score: 0.3689662931668568, number of remaining columns: 168\n",
      "\n",
      "actual training score: 0.23717976046837785\n",
      "actual validation score: 0.36186736939755515, number of remaining columns: 167\n",
      "\n",
      "actual training score: 0.24079572205252597\n",
      "actual validation score: 0.35868874659541505, number of remaining columns: 166\n",
      "\n",
      "actual training score: 0.2596297816039357\n",
      "actual validation score: 0.3494046139940571, number of remaining columns: 165\n",
      "\n",
      "actual training score: 0.2615633934148547\n",
      "actual validation score: 0.34840863051217374, number of remaining columns: 164\n",
      "\n",
      "actual training score: 0.2615812445222434\n",
      "actual validation score: 0.3474000227256224, number of remaining columns: 163\n",
      "\n",
      "actual training score: 0.27943874135773017\n",
      "actual validation score: 0.34372778330297604, number of remaining columns: 162\n",
      "\n",
      "actual training score: 0.2826151399727145\n",
      "actual validation score: 0.34432910879893575, number of remaining columns: 161\n",
      "\n",
      "actual training score: 0.28271721409716033\n",
      "actual validation score: 0.34212774976549176, number of remaining columns: 160\n",
      "\n",
      "actual training score: 0.2832386464002892\n",
      "actual validation score: 0.33960315234869254, number of remaining columns: 159\n",
      "\n",
      "actual training score: 0.28671756180689445\n",
      "actual validation score: 0.3302294517158171, number of remaining columns: 158\n",
      "\n",
      "actual training score: 0.2868425971199253\n",
      "actual validation score: 0.327482167377547, number of remaining columns: 157\n",
      "\n",
      "actual training score: 0.2882188263754841\n",
      "actual validation score: 0.3214566020537145, number of remaining columns: 156\n",
      "\n",
      "actual training score: 0.29144754665352846\n",
      "actual validation score: 0.3174800755688484, number of remaining columns: 155\n",
      "\n",
      "actual training score: 0.2929481180046355\n",
      "actual validation score: 0.31613206170128794, number of remaining columns: 154\n",
      "\n",
      "actual training score: 0.2955527300702129\n",
      "actual validation score: 0.3124877870354116, number of remaining columns: 153\n",
      "\n",
      "actual training score: 0.29579030137034523\n",
      "actual validation score: 0.3078907275563805, number of remaining columns: 152\n",
      "\n",
      "actual training score: 0.324797867585646\n",
      "actual validation score: 0.3283308085065584, number of remaining columns: 151\n",
      "\n",
      "actual training score: 0.3248476462498344\n",
      "actual validation score: 0.32995749899727445, number of remaining columns: 150\n",
      "\n",
      "actual training score: 0.3267493713384244\n",
      "actual validation score: 0.3302185539520701, number of remaining columns: 149\n",
      "\n",
      "actual training score: 0.3267493914906554\n",
      "actual validation score: 0.33029479504081394, number of remaining columns: 148\n",
      "\n",
      "actual training score: 0.3268813461972141\n",
      "actual validation score: 0.3327218889957114, number of remaining columns: 147\n",
      "\n",
      "actual training score: 0.3274945871445549\n",
      "actual validation score: 0.3329620314452173, number of remaining columns: 146\n",
      "\n",
      "actual training score: 0.3275769927267047\n",
      "actual validation score: 0.3324947696065974, number of remaining columns: 145\n",
      "\n",
      "actual training score: 0.32777465415616436\n",
      "actual validation score: 0.3305205671687874, number of remaining columns: 144\n",
      "\n",
      "actual training score: 0.32832494458524863\n",
      "actual validation score: 0.3277696979002016, number of remaining columns: 143\n",
      "\n",
      "actual training score: 0.3335773164833601\n",
      "actual validation score: 0.32570679648517, number of remaining columns: 142\n",
      "\n",
      "actual training score: 0.333860598442808\n",
      "actual validation score: 0.3272499595455237, number of remaining columns: 141\n",
      "\n",
      "actual training score: 0.33629350904194366\n",
      "actual validation score: 0.3240600820445536, number of remaining columns: 140\n",
      "\n",
      "actual training score: 0.3393047807211266\n",
      "actual validation score: 0.31882598381932625, number of remaining columns: 139\n",
      "\n",
      "actual training score: 0.34028241022492267\n",
      "actual validation score: 0.314056720727691, number of remaining columns: 138\n",
      "\n",
      "actual training score: 0.3415143690015344\n",
      "actual validation score: 0.3057273362425038, number of remaining columns: 137\n",
      "\n",
      "actual training score: 0.3426773225865829\n",
      "actual validation score: 0.2980172391118091, number of remaining columns: 136\n",
      "\n",
      "actual training score: 0.34313061125736877\n",
      "actual validation score: 0.2917716964922362, number of remaining columns: 135\n",
      "\n",
      "actual training score: 0.34389919921804657\n",
      "actual validation score: 0.28771596751578243, number of remaining columns: 134\n",
      "\n",
      "actual training score: 0.34420120645952623\n",
      "actual validation score: 0.27485094755559136, number of remaining columns: 133\n",
      "\n",
      "actual training score: 0.34548436972990393\n",
      "actual validation score: 0.2603871458914063, number of remaining columns: 132\n",
      "\n",
      "actual training score: 0.35131553696484374\n",
      "actual validation score: 0.2421071400126199, number of remaining columns: 131\n",
      "\n",
      "actual training score: 0.3563462471814325\n",
      "actual validation score: 0.2583088104229968, number of remaining columns: 130\n",
      "\n",
      "actual training score: 0.3643443317769455\n",
      "actual validation score: 0.25602481412204514, number of remaining columns: 129\n",
      "\n",
      "actual training score: 0.3650208977357994\n",
      "actual validation score: 0.2492727416117554, number of remaining columns: 128\n",
      "\n",
      "actual training score: 0.3651522802057272\n",
      "actual validation score: 0.24394404753217658, number of remaining columns: 127\n",
      "\n",
      "\n",
      "\n",
      "selected columns: ['cyclostationary_mean_rr_8w_19', 'cyclostationary_mean_rr_1w_25', 'cyclostationary_mean_rr_8w_25', 'cyclostationary_mean_rr_4w_12', 'cyclostationary_mean_rr_12w_13', 'cyclostationary_mean_rr_16w_23', 'cyclostationary_mean_rr_4w_22', 'cyclostationary_mean_rr_16w_8', 'cyclostationary_mean_rr_12w_19', 'cyclostationary_mean_rr_1w_14', 'cyclostationary_mean_rr_8w_12', 'cyclostationary_mean_rr_24w_1', 'cyclostationary_mean_rr_24w_21', 'cyclostationary_mean_rr_8w_21', 'cyclostationary_mean_rr_8w_30', 'cyclostationary_mean_rr_24w_23', 'cyclostationary_mean_rr_24w_0', 'cyclostationary_mean_rr_24w_30', 'cyclostationary_mean_rr_8w_31', 'cyclostationary_mean_rr_12w_32', 'cyclostationary_mean_rr_12w_18', 'cyclostationary_mean_rr_8w_10', 'cyclostationary_mean_rr_4w_29', 'cyclostationary_mean_rr_12w_12', 'cyclostationary_mean_rr_8w_11', 'cyclostationary_mean_rr_8w_20', 'cyclostationary_mean_rr_12w_30', 'cyclostationary_mean_rr_4w_18', 'cyclostationary_mean_rr_8w_13', 'cyclostationary_mean_rr_1w_19', 'cyclostationary_mean_rr_8w_16', 'cyclostationary_mean_rr_4w_35', 'cyclostationary_mean_rr_1w_28'], \n",
      "\n",
      "validation score: 0.43476264736965864, \n",
      "\n",
      "number of selected features: 33\n",
      "Full aggregate regression train score: 0.6387042337942732, test score: -3.0819047521251655\n",
      "Aggregate regression train score with FS: 0.2899164838189523, test score: -0.07760719754893008\n"
     ]
    }
   ],
   "source": [
    "target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target('',max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01')\n",
    "\n",
    "path='/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/features/csv_allvalues/temporal_aggreg/Emiliani2_aggreg.csv'\n",
    "\n",
    "output,aggregate_trainVal,aggregate_test = aggregate_unfolded_data(path,['cyclostationary_mean_rr', \n",
    "                                                                         'cyclostationary_mean_rr_1w',\n",
    "                                                                         'cyclostationary_mean_rr_4w', \n",
    "                                                                         'cyclostationary_mean_rr_8w',\n",
    "                                                                         'cyclostationary_mean_rr_12w', \n",
    "                                                                         'cyclostationary_mean_rr_16w',\n",
    "                                                                         'cyclostationary_mean_rr_24w'\n",
    "                                                                        ],\n",
    "                                                                   target_df_trainVal, \n",
    "                                                                   max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01')\n",
    "\n",
    "selected_colnames = FS_with_linearWrapper(aggregate_trainVal, target_df_train, target_df_val, 100, 228)\n",
    "\n",
    "compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92d6c7b3",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.214281    0.00  2001     1 -1.339879\n",
      "1    2001-01-13  0.484737    0.52  2001     2  0.402993\n",
      "2    2001-01-21  0.466071    0.47  2001     3  0.282703\n",
      "3    2001-01-29  0.417470    0.44  2001     5 -0.030490\n",
      "4    2001-02-06  0.492202    0.53  2001     6  0.451097\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.436464    0.46  2009    48  0.091910\n",
      "407  2009-12-05  0.466152    0.49  2009    49  0.283224\n",
      "408  2009-12-13  0.553659    0.59  2009    50  0.847138\n",
      "409  2009-12-21  0.507978    0.65  2009    52  0.552758\n",
      "410  2009-12-29  0.083046    0.00  2009    53 -2.185583\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 28\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 29\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 36\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 39\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 33\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 27\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 36\n",
      "\n",
      "actual training score: 0.07324125553704952\n",
      "actual validation score: 0.2274397338796913, number of remaining columns: 226\n",
      "\n",
      "actual training score: 0.0859284926278111\n",
      "actual validation score: 0.2722892769082381, number of remaining columns: 225\n",
      "\n",
      "actual training score: 0.10803026739854826\n",
      "actual validation score: 0.2887846532374908, number of remaining columns: 224\n",
      "\n",
      "actual training score: 0.1112732434896817\n",
      "actual validation score: 0.30677514792446947, number of remaining columns: 223\n",
      "\n",
      "\n",
      "\n",
      "selected columns: ['cyclostationary_mean_rr_8w_19', 'cyclostationary_mean_rr_1w_25', 'cyclostationary_mean_rr_8w_25', 'cyclostationary_mean_rr_4w_12', 'cyclostationary_mean_rr_12w_13'], \n",
      "\n",
      "validation score: 0.30677514792446947, \n",
      "\n",
      "number of selected features: 5\n",
      "Full aggregate regression train score: 0.6387042337942732, test score: -3.0819047521251655\n",
      "Aggregate regression train score with FS: 0.2068916647319915, test score: -0.0005387115843495938\n"
     ]
    }
   ],
   "source": [
    "### full, forcing a low number of features\n",
    "\n",
    "target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target('',max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01')\n",
    "\n",
    "path='/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/features/csv_allvalues/temporal_aggreg/Emiliani2_aggreg.csv'\n",
    "\n",
    "output,aggregate_trainVal,aggregate_test = aggregate_unfolded_data(path,['cyclostationary_mean_rr', \n",
    "                                                                         'cyclostationary_mean_rr_1w',\n",
    "                                                                         'cyclostationary_mean_rr_4w', \n",
    "                                                                         'cyclostationary_mean_rr_8w',\n",
    "                                                                         'cyclostationary_mean_rr_12w', \n",
    "                                                                         'cyclostationary_mean_rr_16w',\n",
    "                                                                         'cyclostationary_mean_rr_24w'                                                                        ],\n",
    "                                                                   target_df_trainVal, \n",
    "                                                                   max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01')\n",
    "\n",
    "selected_colnames = FS_with_linearWrapper(aggregate_trainVal, target_df_train, target_df_val, 4, 228)\n",
    "\n",
    "compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f793659a",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### repeating both with CMI FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "47907915",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.214281    0.00  2001     1 -1.402730\n",
      "1    2001-01-13  0.484737    0.52  2001     2  0.347916\n",
      "2    2001-01-21  0.466071    0.47  2001     3  0.227090\n",
      "3    2001-01-29  0.417470    0.44  2001     5 -0.087501\n",
      "4    2001-02-06  0.492202    0.53  2001     6  0.396235\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "584  2013-10-21  0.739946    0.79  2013    43  1.999865\n",
      "585  2013-10-29  0.447691    0.46  2013    44  0.108118\n",
      "586  2013-11-06  0.541628    0.56  2013    45  0.716163\n",
      "587  2013-11-14  0.493719    0.53  2013    46  0.406051\n",
      "588  2013-11-22  0.527436    0.57  2013    47  0.624301\n",
      "\n",
      "[589 rows x 6 columns]\n",
      " target shapes: ((589, 6), (200, 6), (789, 6), (192, 6))\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 24\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 30\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 32\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 33\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 28\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 26\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 34\n",
      "\n",
      "----- MI Scores -----\n",
      "[(57, 0.10743675877022264), (60, 0.10230666994181674), (92, 0.10090196891905488), (88, 0.09933945049355289), (55, 0.09905371648836954), (102, 0.09655946665385019), (58, 0.09648679371093713), (91, 0.09608521290801879), (118, 0.09343929069506912), (86, 0.09218830070135929), (97, 0.09088993554996724), (89, 0.09043243935521225), (61, 0.09029500201254008), (134, 0.09020105341984963), (90, 0.08987434338722335), (54, 0.08937458479963303), (124, 0.08892902015687933), (99, 0.08883873363175732), (35, 0.08851294294966568), (68, 0.0884892952161176), (145, 0.0877975562203877), (65, 0.08765048046750304), (101, 0.08615868336274765), (56, 0.08501614022929671), (95, 0.08399597839124993), (87, 0.08315802244190033), (93, 0.08314716315108961), (34, 0.08280555723956484), (133, 0.08226524540415046), (125, 0.08203297690546478), (27, 0.0817666256114414), (59, 0.08142468951839885), (26, 0.08015724712312372), (67, 0.07983956247770935), (100, 0.07926061805885781), (0, 0.07690513665580699), (130, 0.07667333265842931), (138, 0.07650402907606764), (117, 0.07635740754644744), (127, 0.07544532660204001), (96, 0.07482227155632692), (62, 0.07359939655534767), (98, 0.07233338505203844), (121, 0.071869358016938), (66, 0.07151547950889464), (123, 0.07132095432926847), (107, 0.0711322123226364), (122, 0.07112035786349008), (94, 0.07059788852256986), (168, 0.07044416523705761), (137, 0.0699198537127629), (63, 0.0694381891085606), (129, 0.06940567073518078), (24, 0.06892161897235165), (140, 0.0684840767364467), (64, 0.06803883222358922), (69, 0.06793813631066822), (116, 0.0678266395355323), (104, 0.06741954381207424), (166, 0.06712728626106933), (25, 0.06646109738599457), (120, 0.06607609827442844), (169, 0.06510266610866701), (126, 0.06474454866137838), (33, 0.06438944911315812), (136, 0.06399567296207001), (135, 0.06378280611368767), (3, 0.0636866034541994), (8, 0.06343157969986746), (85, 0.063231429692151), (128, 0.0632210852276573), (111, 0.06290548452655811), (147, 0.0628317685374955), (142, 0.06278413986465498), (31, 0.06262094569555787), (108, 0.06234173869658703), (144, 0.0622905613180909), (141, 0.06200298303013731), (4, 0.06187456041933343), (146, 0.06182360098517152), (1, 0.061348919071963305), (143, 0.061217881733230874), (167, 0.06071364493387012), (46, 0.06051848328806359), (47, 0.060175537910212365), (9, 0.06017288930313072), (172, 0.059821430766467586), (74, 0.0588720593689619), (153, 0.05832449572174921), (152, 0.05818769514997557), (170, 0.05783042455810244), (106, 0.05765881351296301), (119, 0.05764299612680549), (84, 0.05749134818854813), (29, 0.05733400714762252), (75, 0.057204361240723), (103, 0.056775608688713675), (32, 0.05663993151976903), (5, 0.056559837990785844), (77, 0.05645204959368939), (113, 0.055236118855475046), (28, 0.05480554956019784), (149, 0.05434372301691934), (131, 0.05431479815184616), (109, 0.05350312445271631), (154, 0.05339082218234025), (30, 0.053368456102079354), (115, 0.053337865363343485), (78, 0.05313308404472807), (148, 0.05300350423252587), (39, 0.05280832318346544), (45, 0.05221130957772064), (105, 0.0519810767127279), (203, 0.05181697021676126), (76, 0.05177671591799043), (70, 0.051541234478957504), (156, 0.051201220300623525), (37, 0.051200911352862366), (38, 0.05092701565052617), (114, 0.050364227108151374), (110, 0.05031279851375313), (36, 0.05023198716069569), (165, 0.050214378818576245), (139, 0.04948378196691886), (164, 0.049132677343688876), (159, 0.04908647022358636), (11, 0.04862741311706546), (155, 0.04859656711327822), (6, 0.04846756931084812), (48, 0.04790159520663222), (157, 0.04722803462661926), (162, 0.046903471836979856), (10, 0.04649157327962075), (192, 0.0458400130315082), (53, 0.044222829333499476), (42, 0.04401722301493805), (50, 0.04370435169705468), (18, 0.04340525150024588), (82, 0.043158120540682625), (41, 0.043056888721610516), (79, 0.043004859153799396), (49, 0.04280782469871037), (182, 0.042258723414844525), (190, 0.04224119970324023), (132, 0.04223273811419301), (201, 0.04182243765849715), (83, 0.04146747035141834), (161, 0.0412475303226552), (206, 0.04030179343528449), (40, 0.040164929234642675), (112, 0.040097508822967524), (188, 0.03929514536580497), (23, 0.039215457428315434), (2, 0.038057653745647915), (158, 0.03779824381077755), (160, 0.036909453778902555), (186, 0.03659419302974896), (180, 0.03609906321684377), (200, 0.03602631367372262), (21, 0.03602400623844905), (202, 0.0357403764178145), (12, 0.03453413976500961), (44, 0.03447934138987345), (177, 0.033984474325583255), (81, 0.03355525165677106), (72, 0.03332651213699296), (163, 0.033225783242638064), (193, 0.03283647826760953), (14, 0.03240454801659148), (181, 0.03215585640399445), (183, 0.032068740999349914), (51, 0.03203072402327586), (185, 0.03200094457249757), (187, 0.0319293092773562), (174, 0.031168210776618358), (196, 0.03107841799678587), (71, 0.030909068456568097), (150, 0.030874518677744545), (197, 0.030871781401734643), (7, 0.030273812310576895), (189, 0.030105499660583596), (73, 0.029769772627392242), (184, 0.029228476327447215), (43, 0.029008830198092826), (198, 0.02890891937192386), (15, 0.028816475589478793), (194, 0.028384452818881026), (195, 0.02818226498218654), (171, 0.02723717781855005), (52, 0.026656699554052168), (20, 0.026381393154285157), (17, 0.026138275786049797), (173, 0.026135289012200413), (204, 0.025248792259492645), (151, 0.024691919079652607), (175, 0.02446387323402466), (19, 0.024442084975139142), (179, 0.023141695492762543), (191, 0.02312922989631555), (80, 0.022345412951901938), (199, 0.0220987829753525), (178, 0.021902368124727196), (176, 0.021698647665469886), (22, 0.01713286929139715), (16, 0.015849364111258233), (205, 0.015641110108002787), (13, 0.011741265478189105)]\n",
      "Best MI score: 0.10743675877022264\n",
      "Adding first best original feature: 57\n",
      "CMI: 0.038888293108378144\n",
      "CMI: 0.027794936098805165\n",
      "CMI: 0.0010781829515828512\n",
      "CMI: 0.03116439916656842\n",
      "CMI: 0.0273823619152357\n",
      "CMI: 0.02224694442881177\n",
      "CMI: 0.006524837335744632\n",
      "CMI: 0.025523878529327623\n",
      "CMI: 0.030836323621364778\n",
      "CMI: 0.01608520185240553\n",
      "CMI: 0.009740465239657381\n",
      "CMI: 0.01228773500668981\n",
      "CMI: 0.00022415750349191743\n",
      "CMI: 0.0003405606688627605\n",
      "CMI: 0.0009154191881123735\n",
      "CMI: 0.01436742425031634\n",
      "CMI: 0.010137271705539533\n",
      "CMI: 0.01464840963918794\n",
      "CMI: 0.024802673261576383\n",
      "CMI: 0.012556531183993608\n",
      "CMI: 0.01052956838127328\n",
      "CMI: 0.024816614424148856\n",
      "CMI: 0.0019162878001851152\n",
      "CMI: 0.003877664954327051\n",
      "CMI: 0.00020423538206477965\n",
      "CMI: 0.004999612473986378\n",
      "CMI: 0.0009766869307888948\n",
      "CMI: 0.022485078652161386\n",
      "CMI: 0.027594056321872576\n",
      "CMI: 0.0023707505721074495\n",
      "CMI: 0.002867904792075812\n",
      "CMI: 0.007206207921665805\n",
      "CMI: 0.006880455659383014\n",
      "CMI: 0.01136848555049523\n",
      "CMI: 0.005992167008286281\n",
      "CMI: 0.00234657891822658\n",
      "CMI: 0.004906140875571591\n",
      "CMI: 0.008270562627549063\n",
      "CMI: 0.028427002110170754\n",
      "CMI: 0.005545008700523477\n",
      "CMI: 0.003714517802915221\n",
      "CMI: 0.005809241368682522\n",
      "CMI: 0.00616687530016595\n",
      "CMI: 0.010636274701586665\n",
      "CMI: 0.003998782674610485\n",
      "CMI: 0.009009500650855096\n",
      "CMI: 0.008388731440057168\n",
      "CMI: 0.012977014774812737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMI: 0.008174168001752385\n",
      "CMI: 0.013583281856804838\n",
      "CMI: 0.0002905518418058889\n",
      "CMI: 0.02657062670784592\n",
      "CMI: 0.0025155522760256788\n",
      "CMI: 0.00751988164811368\n",
      "CMI: 0.013714377824859902\n",
      "CMI: 0.02573622957941933\n",
      "CMI: 0.002800093951311547\n",
      "CMI: 0.011496611079607658\n",
      "CMI: 0.0019576032567653057\n",
      "CMI: 0.016644013179511877\n",
      "CMI: 0.007322233588488936\n",
      "CMI: 0.00044269839473531913\n",
      "CMI: 0.002141590331048146\n",
      "CMI: 0.021587894118536857\n",
      "CMI: 0.0011269945842802692\n",
      "CMI: 0.003086293186760708\n",
      "CMI: 0.004887727037155981\n",
      "CMI: 0.00047010750122124245\n",
      "CMI: 0.011511859745225311\n",
      "CMI: 0.023023095200744206\n",
      "CMI: 0.013683742564010365\n",
      "CMI: 0.009923133080089921\n",
      "CMI: 0.016907111443266565\n",
      "CMI: 0.012078999075935903\n",
      "CMI: 0.01248232878099964\n",
      "CMI: 0.008414833599802635\n",
      "CMI: 0.003262507916882554\n",
      "CMI: 0.007469379053058722\n",
      "CMI: 0.02064488726064566\n",
      "CMI: 0.022725415125717338\n",
      "CMI: 0.012614734875760064\n",
      "CMI: 0.014328985505332612\n",
      "CMI: 0.01699374143969848\n",
      "CMI: 0.015451426659047501\n",
      "CMI: 0.017060097643187486\n",
      "CMI: 0.029369726903671525\n",
      "CMI: 0.017509802544448574\n",
      "CMI: 0.01742151983263257\n",
      "CMI: 0.01122303146388362\n",
      "CMI: 0.01694354171548297\n",
      "CMI: 0.013751151480237075\n",
      "CMI: 0.007632825832126142\n",
      "CMI: 0.0024127503524911526\n",
      "CMI: 0.000656375886207719\n",
      "CMI: 0.006972259665191757\n",
      "CMI: 0.00747075627946471\n",
      "CMI: 0.00525661816033296\n",
      "CMI: 0.004001451466466396\n",
      "CMI: 0.007037704679244874\n",
      "CMI: 0.006662096425764583\n",
      "CMI: 0.012007480661461359\n",
      "CMI: 0.01092481477691458\n",
      "CMI: 0.016680454031211878\n",
      "CMI: 0.007850170297336326\n",
      "CMI: 0.0015538721074983969\n",
      "CMI: 0.00372204760438663\n",
      "CMI: 0.010496857688438624\n",
      "CMI: 8.565323691367421e-06\n",
      "CMI: 0.010672979659146611\n",
      "CMI: 0.005556148958662549\n",
      "CMI: 0.0010833086400400815\n",
      "CMI: 0.0032455699812021233\n",
      "CMI: 0.0177724753914386\n",
      "CMI: 0.011979602326453051\n",
      "CMI: 0.0039619055080928195\n",
      "CMI: 0.0024731241998945525\n",
      "CMI: 0.016074307466101667\n",
      "CMI: 0.007355737677777419\n",
      "CMI: 0.005410098347656239\n",
      "CMI: 0.012902200253418275\n",
      "CMI: 0.004996945056295693\n",
      "CMI: 0.003217815427271717\n",
      "CMI: 0.013175997877543408\n",
      "CMI: 0.004095224073528983\n",
      "CMI: 0.007712745361261805\n",
      "CMI: 0.005661563415816348\n",
      "CMI: 0.010442931625053678\n",
      "CMI: 0.0012558656890646752\n",
      "CMI: 0.008964057636297693\n",
      "CMI: 0.01610941867497412\n",
      "Highest CMI score: 0.038888293108378144\n",
      "Adding original feature: 0\n",
      "CMI: 0.0008764255064240556\n",
      "CMI: 0.0038452780783660434\n",
      "CMI: 0.0007964288386519136\n",
      "CMI: 0.0016709493842513579\n",
      "CMI: 0.006101252038569094\n",
      "CMI: 0.00702162546980814\n",
      "CMI: 0.0008463619769457087\n",
      "CMI: 0.00815125823492488\n",
      "CMI: 0.008052004482855812\n",
      "CMI: 0.0018681545316464043\n",
      "CMI: 0.0010712978710769594\n",
      "CMI: 0.0021581891984029378\n",
      "CMI: 0.001025276150939891\n",
      "CMI: 0.0037258903466560467\n",
      "CMI: 0.0008466232979278121\n",
      "Highest CMI score: 0.00815125823492488\n",
      "Adding original feature: 102\n",
      "CMI: 0.0022191289557905725\n",
      "CMI: 0.004372632881422228\n",
      "CMI: 0.009411034445304167\n",
      "CMI: 0.003010438867737858\n",
      "CMI: 0.0017026782558810238\n",
      "CMI: 0.004498571057374057\n",
      "CMI: 0.00046376050154114945\n",
      "CMI: 0.00607614512788382\n",
      "CMI: 0.0006668131868719229\n",
      "CMI: 0.0019963039212889666\n",
      "CMI: 0.0002736474580837811\n",
      "CMI: 0.00512152214014458\n",
      "CMI: 0.0005497346086633381\n",
      "CMI: 0.003453287343590322\n",
      "CMI: 8.882366475976289e-05\n",
      "Highest CMI score: 0.009411034445304167\n",
      "Adding original feature: 24\n",
      "CMI: 0.0007769170135190351\n",
      "CMI: 0.0006503460865139032\n",
      "CMI: 0.001078833570963167\n",
      "CMI: 0.0020554824014871187\n",
      "Highest CMI score: 0.0020554824014871187\n",
      "Adding original feature: 141\n",
      "CMI: 0.0018958747817950927\n",
      "CMI: 0.0031193501681335833\n",
      "CMI: 0.0016636414595661009\n",
      "CMI: 0.002719873202809364\n",
      "CMI: 0.0010737591993738305\n",
      "CMI: 0.002165706556321617\n",
      "Highest CMI score: 0.0031193501681335833\n",
      "Adding original feature: 8\n",
      "CMI: 0.00033033310293861806\n",
      "CMI: 0.0023160953264950435\n",
      "CMI: 0.00016387327751160585\n",
      "CMI: 0.0018891090795096488\n",
      "Highest CMI score: 0.0023160953264950435\n",
      "Adding original feature: 167\n",
      "CMI: 0.00015738306417573122\n",
      "CMI: 0.0005674785268790783\n",
      "CMI: 0.0018760221420676682\n",
      "Highest CMI score: 0.0018760221420676682\n",
      "Adding original feature: 95\n",
      "CMI: 0.001239799857423951\n",
      "CMI: 0.0014508400188727733\n",
      "Highest CMI score: 0.0014508400188727733\n",
      "Adding original feature: 119\n",
      "CMI: 0.0011938426994798634\n",
      "CMI: 0.0009303169385563859\n",
      "Highest CMI score: 0.0011938426994798634\n",
      "Adding original feature: 3\n",
      "Highest CMI score: -0.0008367738989389362\n",
      "\n",
      "[57, 0, 102, 24, 141, 8, 167, 95, 119, 3]\n",
      "\n",
      "Full aggregate regression train score: 0.5709453283924056, test score: -0.5612643215121798\n",
      "Aggregate regression train score with FS: 0.1734318739291013, test score: 0.0017632434076767511\n"
     ]
    }
   ],
   "source": [
    "target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target('')\n",
    "\n",
    "output,aggregate_trainVal,aggregate_test = aggregate_unfolded_data(path,[\n",
    "       'cyclostationary_mean_rr',\n",
    "       'cyclostationary_mean_rr_1w',\n",
    "       'cyclostationary_mean_rr_4w', 'cyclostationary_mean_rr_8w',\n",
    "       'cyclostationary_mean_rr_12w', 'cyclostationary_mean_rr_16w',\n",
    "       'cyclostationary_mean_rr_24w'],target_df_trainVal)\n",
    "\n",
    "res = {\n",
    "    \"delta\" : [], # list with all deltas\n",
    "    \"numSelected\" : [], #\n",
    "    \"selectedFeatures\" : [] \n",
    "}\n",
    "\n",
    "res['selectedFeatures'] = forwardFeatureSelection(10,np.array(aggregate_trainVal),np.array(target_df_trainVal.mean_std),res,20,1)\n",
    "selectedFeatures='selectedFeatures'\n",
    "print(f'\\n{res[selectedFeatures]}\\n')\n",
    "selected_colnames = aggregate_trainVal.columns[res['selectedFeatures']]\n",
    "compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "32c4f6ec",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "3\n",
      "4\n",
      "7\n",
      "8\n",
      "13\n",
      "14\n",
      "16\n",
      "21\n",
      "25\n",
      "27\n",
      "----- MI Scores -----\n",
      "[(11, 0.07608944151941698), (5, 0.0652097565049519), (0, 0.058759853248492255), (2, 0.057780978839124794), (10, 0.05491959557774612), (3, 0.05410973188860993), (7, 0.04926706180037885), (1, 0.04414197656784926), (9, 0.03436287523524891), (8, 0.017957545434423204), (4, 0.016576282459283394), (6, 0.013166607222872615)]\n",
      "Best MI score: 0.07608944151941698\n",
      "Adding first best original feature: 11\n",
      "CMI: 0.037009509882969166\n",
      "CMI: 0.0015307599270689837\n",
      "CMI: 0.02657918044149081\n",
      "CMI: 0.030791655539546325\n",
      "CMI: 0.009641726521456034\n",
      "CMI: 0.018426289183132827\n",
      "CMI: 0.015875157612758026\n",
      "CMI: 0.011070609468971912\n",
      "CMI: 0.017757010131936576\n",
      "CMI: 0.005888000162428769\n",
      "Highest CMI score: 0.037009509882969166\n",
      "Adding original feature: 0\n",
      "Highest CMI score: -0.0002895662057497833\n",
      "\n",
      "[11, 0]\n",
      "\n",
      "Full aggregate regression train score: 0.09829192314737889, test score: 0.04958536663510049\n",
      "Aggregate regression train score with FS: 0.042990462106621274, test score: 0.022607600892132984\n"
     ]
    }
   ],
   "source": [
    "### repeat keeping features with at least three cells\n",
    "ii = []\n",
    "for i in range(len(output)):\n",
    "    if (len(output[i]))>=3: \n",
    "        print(i)\n",
    "        ii.append(i)\n",
    "\n",
    "res = {\n",
    "    \"delta\" : [], # list with all deltas\n",
    "    \"numSelected\" : [], #\n",
    "    \"selectedFeatures\" : [] \n",
    "#    \"accuracy\" : [] # list of scores associated with the reduced problem\n",
    "}\n",
    "\n",
    "res['selectedFeatures'] = forwardFeatureSelection(10,np.array(aggregate_trainVal.iloc[:,ii]),np.array(target_df_trainVal.mean_std),res,10,1)\n",
    "selectedFeatures='selectedFeatures'\n",
    "print(f'\\n{res[selectedFeatures]}\\n')\n",
    "selected_colnames = aggregate_trainVal.iloc[:,ii].columns[res['selectedFeatures']]\n",
    "compare_methods(aggregate_trainVal.iloc[:,ii], aggregate_test.iloc[:,ii], target_df_trainVal, target_df_test, selected_colnames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3a9715eb",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.214281    0.00  2001     1 -1.339879\n",
      "1    2001-01-13  0.484737    0.52  2001     2  0.402993\n",
      "2    2001-01-21  0.466071    0.47  2001     3  0.282703\n",
      "3    2001-01-29  0.417470    0.44  2001     5 -0.030490\n",
      "4    2001-02-06  0.492202    0.53  2001     6  0.451097\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.436464    0.46  2009    48  0.091910\n",
      "407  2009-12-05  0.466152    0.49  2009    49  0.283224\n",
      "408  2009-12-13  0.553659    0.59  2009    50  0.847138\n",
      "409  2009-12-21  0.507978    0.65  2009    52  0.552758\n",
      "410  2009-12-29  0.083046    0.00  2009    53 -2.185583\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 28\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 29\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 36\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 39\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 33\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 27\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 36\n",
      "\n",
      "----- MI Scores -----\n",
      "[(74, 0.12874077211883111), (68, 0.1277889705384366), (104, 0.1268241207271313), (112, 0.12362241069655744), (69, 0.12310963255758561), (158, 0.12248755184188319), (97, 0.12202512000507912), (94, 0.12118812921120199), (98, 0.1188979599205249), (64, 0.11617043840737115), (60, 0.11608304177197297), (182, 0.11563245157183769), (95, 0.11535152539357396), (58, 0.11387243468032031), (96, 0.11083440787028744), (138, 0.11066282094179933), (61, 0.10933154474462303), (57, 0.10895572714111289), (163, 0.10778898841213953), (108, 0.10652517919708691), (67, 0.10500599147787323), (105, 0.10487806559522687), (160, 0.10485553478916006), (131, 0.10432868907585176), (124, 0.10085653577289384), (93, 0.1006520701634717), (110, 0.1005772369283381), (63, 0.10044235462154422), (183, 0.09891257290571968), (129, 0.09797853978313026), (119, 0.09722552222469123), (106, 0.09630490915814505), (77, 0.09622233508029267), (99, 0.09609351774361964), (137, 0.0950859084301944), (107, 0.0945751918604273), (152, 0.09446552102853588), (66, 0.09443722098287688), (117, 0.09332681843211767), (154, 0.09284258145229847), (153, 0.09192287588956692), (103, 0.09136991446297459), (73, 0.09024307694145309), (162, 0.09016260988289293), (70, 0.08885480089615277), (113, 0.08849146956311622), (2, 0.08830413469347519), (155, 0.08791443245455235), (151, 0.08740145995786931), (122, 0.086599576938982), (62, 0.08657320807606614), (149, 0.0858237787122887), (184, 0.08559078513212498), (11, 0.08551713286237457), (139, 0.08535650944709175), (130, 0.08520857772652254), (185, 0.08496959222216273), (7, 0.08318729936411873), (9, 0.08252158915719636), (128, 0.08235748536806167), (134, 0.0823423212624834), (71, 0.08223960459558932), (30, 0.08184596859537661), (147, 0.0818142502356242), (84, 0.08179196380125643), (132, 0.08124394636714695), (156, 0.08114991093023914), (143, 0.08083809853790286), (31, 0.08079358266104533), (92, 0.08019292388332039), (102, 0.0800375887670078), (120, 0.07983519728140855), (65, 0.07973933216048419), (0, 0.07919816591699666), (118, 0.07809976178076884), (166, 0.07709774947080195), (40, 0.07676022634465368), (101, 0.07618512931297902), (159, 0.0756550605045837), (165, 0.07565090790676078), (72, 0.075240657163634), (123, 0.07450464987300101), (115, 0.07427040916603465), (32, 0.07418369891142562), (37, 0.07340150656469692), (4, 0.07326593931401697), (133, 0.07317261999019893), (89, 0.07278679064095768), (59, 0.07272607982751346), (135, 0.07239218139976458), (188, 0.07218770062233695), (146, 0.07145653509598722), (170, 0.07136613079324114), (157, 0.07127050440804596), (76, 0.07126718443605692), (56, 0.07113102186050821), (121, 0.07092826702581531), (12, 0.07085772998788138), (13, 0.07057853400969465), (145, 0.06984234967381661), (174, 0.0696491492648051), (219, 0.06945520476092312), (53, 0.06923981802712093), (41, 0.06908696625454265), (167, 0.06905131126122972), (140, 0.06896951017938323), (82, 0.06824207512210084), (10, 0.0682046530932125), (111, 0.06791295008218223), (148, 0.06645457694719367), (80, 0.066237965365808), (114, 0.06461887403130785), (187, 0.06423005385422949), (85, 0.06415326246319811), (17, 0.06400231812433886), (43, 0.06388662866197796), (164, 0.0635229078736756), (177, 0.06300822397877645), (175, 0.06273504854509265), (42, 0.062347961431916156), (141, 0.06176069355862116), (35, 0.06167119769831247), (51, 0.061513195655229405), (136, 0.06144869329526968), (142, 0.0610668510904228), (49, 0.06063881352425037), (29, 0.06056925911008613), (169, 0.05994415060594731), (116, 0.059530129315578516), (191, 0.05943450624353), (33, 0.05940627859028981), (23, 0.05935953452744363), (55, 0.05854085083283541), (109, 0.05846669560674659), (75, 0.05825889791770142), (190, 0.0576787254935376), (34, 0.0573051794509041), (5, 0.05682607547322715), (217, 0.05665872951676962), (45, 0.0565976017127121), (150, 0.055748324720710146), (161, 0.05569700204644676), (18, 0.05498995269556534), (125, 0.05466236523950021), (172, 0.054577332300283096), (88, 0.054417100059385985), (126, 0.05338055505948762), (212, 0.052943818652145584), (28, 0.05285327081871651), (38, 0.052640118968373825), (47, 0.05244792035275058), (178, 0.051993034239991055), (44, 0.050753384023954476), (127, 0.05049155692907435), (193, 0.05009227589148163), (181, 0.050019965677935534), (26, 0.04997633280479427), (50, 0.049619919545624114), (207, 0.04882932188752801), (189, 0.04831588823978645), (25, 0.04773844477463132), (20, 0.04759884972003266), (15, 0.0474663158170742), (83, 0.047176768959211725), (216, 0.04703969067022719), (176, 0.046641150272925515), (224, 0.04583676988609705), (48, 0.04565621447539726), (173, 0.045494238912744636), (100, 0.045023337579436315), (198, 0.04475520599929371), (1, 0.044752993361387654), (91, 0.04459705897203215), (79, 0.04387223838373965), (36, 0.043627418370983315), (201, 0.043310626913065475), (52, 0.04324260142994271), (39, 0.04261732449308597), (179, 0.042581830338925264), (22, 0.0415464445205626), (186, 0.04149362056654041), (203, 0.04130895458881408), (6, 0.040944276481551675), (171, 0.04085939840082336), (213, 0.04042138306923973), (54, 0.039947572777478464), (215, 0.039739251151737445), (3, 0.039325001748386344), (200, 0.03914163485626611), (196, 0.03792317287234666), (46, 0.03784625837006983), (210, 0.03751242601093573), (78, 0.0367485481019914), (195, 0.036268658694145015), (223, 0.036252697003541466), (19, 0.035603593846909636), (204, 0.03535681775830326), (86, 0.035356313554615555), (225, 0.03419747276223315), (220, 0.03409229490933682), (21, 0.03376859736550506), (180, 0.03362065807193324), (192, 0.033313482306141166), (202, 0.032546081763445214), (90, 0.032402979014381855), (144, 0.03236145553973946), (168, 0.03229672488191466), (16, 0.032090482723311387), (199, 0.03142403062424197), (14, 0.030984200792682163), (208, 0.030861239449329406), (209, 0.030501122934564653), (205, 0.030136868881341438), (226, 0.0295242611495781), (218, 0.02906974529271412), (206, 0.02722174271521766), (24, 0.02597428589007736), (8, 0.025932763785423512), (194, 0.0249132201667681), (87, 0.024302630500174813), (211, 0.0232450840140995), (81, 0.02160810599533096), (197, 0.016765187598471752), (214, 0.010645057008100518), (227, 0.010395778453371052), (222, 0.010232595074441415), (221, 0.009209210807615742), (27, 0.009157183617009994)]\n",
      "Best MI score: 0.12874077211883111\n",
      "Adding first best original feature: 74\n",
      "CMI: 0.01661933635087251\n",
      "CMI: 0.01227772945858649\n",
      "CMI: 0.020799453406687984\n",
      "CMI: 0.0026083497110192533\n",
      "CMI: 0.0003841562619857075\n",
      "CMI: 0.0033422705467644476\n",
      "CMI: 0.004722060359048208\n",
      "CMI: 0.004932132292987362\n",
      "CMI: 0.005671882703214309\n",
      "CMI: 0.00791513225917198\n",
      "CMI: 0.0024467900929878716\n",
      "CMI: 0.015964200311494647\n",
      "CMI: 0.0011924881873097426\n",
      "CMI: 0.007962407659006354\n",
      "CMI: 0.004865999130695936\n",
      "CMI: 0.010476986950048034\n",
      "CMI: 0.011837616368252563\n",
      "CMI: 0.003510266444233523\n",
      "CMI: 0.009578074409875958\n",
      "CMI: 0.013606023203430379\n",
      "CMI: 0.005310890509960586\n",
      "CMI: 0.02472433687222053\n",
      "CMI: 0.006320723117707205\n",
      "CMI: 0.001406039333232828\n",
      "CMI: 0.001986580194346166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMI: 0.015063135308159059\n",
      "CMI: 0.02905237710074196\n",
      "CMI: 0.004428796289332265\n",
      "CMI: 0.007773824846529165\n",
      "CMI: 0.0007834333965270335\n",
      "CMI: 0.011654034814973152\n",
      "CMI: 0.005399800130514193\n",
      "CMI: 0.0012532518133766823\n",
      "CMI: 0.01920470747085576\n",
      "CMI: 0.005976273408241944\n",
      "CMI: 0.0020401712826000618\n",
      "CMI: 0.03777239357342976\n",
      "CMI: 0.00041775956365711076\n",
      "CMI: 0.013425072842590396\n",
      "CMI: 0.00812563151747811\n",
      "CMI: 0.014490038660878723\n",
      "CMI: 0.0193614144787628\n",
      "CMI: 0.0009331097419012224\n",
      "CMI: 0.0032371553502874573\n",
      "CMI: 0.011011535006766021\n",
      "CMI: 0.012147457289356983\n",
      "Highest CMI score: 0.03777239357342976\n",
      "Adding original feature: 149\n",
      "CMI: 0.01959991301249356\n",
      "CMI: 0.0036496763089926276\n",
      "CMI: 0.0019366511346290138\n",
      "CMI: 0.02171848851958924\n",
      "CMI: 0.022013653138457795\n",
      "CMI: 0.01337505331228464\n",
      "CMI: 0.0058981513102388805\n",
      "CMI: 0.012952106584557033\n",
      "CMI: 0.0033634519214124636\n",
      "CMI: 0.01618012246969258\n",
      "CMI: 0.020295872105337398\n",
      "CMI: 0.0017404025815465907\n",
      "CMI: 0.0060118502844832\n",
      "CMI: 0.013171227072159286\n",
      "CMI: 0.0062872120934342746\n",
      "CMI: 0.0018627634974787977\n",
      "CMI: 0.003803478483517503\n",
      "CMI: 0.004069214283498185\n",
      "CMI: 0.0038716317371295106\n",
      "CMI: 0.00045013398972956753\n",
      "CMI: 0.0010051719406808102\n",
      "CMI: 0.004148271967837597\n",
      "CMI: 0.001549402207039502\n",
      "CMI: 0.0014316312911965279\n",
      "CMI: 0.004742071731809072\n",
      "CMI: 0.0026827640448252588\n",
      "CMI: 0.0002772595871790573\n",
      "CMI: 0.005358784028566044\n",
      "CMI: 0.00240235474161804\n",
      "CMI: 0.005453196053550158\n",
      "CMI: 0.016351230062007727\n",
      "CMI: 0.004939783150960303\n",
      "CMI: 0.02333036928230281\n",
      "CMI: 0.007540977496652862\n",
      "CMI: 0.0011334325460739259\n",
      "CMI: 0.0009045282099623408\n",
      "CMI: 0.002968884548807116\n",
      "CMI: 0.0025708973871943486\n",
      "CMI: 0.002226400441307508\n",
      "CMI: 0.01713739026858177\n",
      "CMI: 0.014867044548887404\n",
      "Highest CMI score: 0.02333036928230281\n",
      "Adding original feature: 206\n",
      "CMI: 0.007791882399336397\n",
      "CMI: 0.002014293028340136\n",
      "CMI: 0.017553333983833852\n",
      "CMI: 0.005871041186560871\n",
      "CMI: 0.011275819697263267\n",
      "CMI: 0.00782582903304127\n",
      "CMI: 0.009149349602603496\n",
      "CMI: 0.005545024878345489\n",
      "CMI: 0.008435072986486852\n",
      "CMI: 0.0018477692591638284\n",
      "CMI: 0.0036219248091171052\n",
      "CMI: 0.007331507422958294\n",
      "CMI: 0.00035137852703626127\n",
      "CMI: 0.006795834849832982\n",
      "CMI: 0.005396252270129409\n",
      "CMI: 0.004417315155925805\n",
      "CMI: 0.0027812560763192384\n",
      "CMI: 0.0064611686573856075\n",
      "CMI: 0.0017765758735683868\n",
      "CMI: 0.008554829008008996\n",
      "CMI: 0.013628080178690827\n",
      "Highest CMI score: 0.017553333983833852\n",
      "Adding original feature: 4\n",
      "CMI: 2.358205161812066e-06\n",
      "CMI: 0.003966795661145606\n",
      "CMI: 0.0024833940413691302\n",
      "CMI: 0.0021421779183125877\n",
      "CMI: 0.004228815075990128\n",
      "CMI: 0.0026728324634687217\n",
      "CMI: 0.007972880049359504\n",
      "CMI: 0.0018773723034813394\n",
      "CMI: 0.003934427443797406\n",
      "Highest CMI score: 0.007972880049359504\n",
      "Adding original feature: 162\n",
      "Highest CMI score: -0.0026559440669901846\n",
      "\n",
      "[74, 149, 206, 4, 162]\n",
      "\n",
      "Full aggregate regression train score: 0.6387042337942732, test score: -3.0819047521251655\n",
      "Aggregate regression train score with FS: 0.1329337940428753, test score: 0.11271539012346887\n"
     ]
    }
   ],
   "source": [
    "### what happens without considering the last years?\n",
    "target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target('',max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01')\n",
    "\n",
    "path='/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/features/csv_allvalues/temporal_aggreg/Emiliani2_aggreg.csv'\n",
    "\n",
    "output,aggregate_trainVal,aggregate_test = aggregate_unfolded_data(path,[\n",
    "       'cyclostationary_mean_rr',\n",
    "       'cyclostationary_mean_rr_1w',\n",
    "       'cyclostationary_mean_rr_4w', 'cyclostationary_mean_rr_8w',\n",
    "       'cyclostationary_mean_rr_12w', 'cyclostationary_mean_rr_16w',\n",
    "       'cyclostationary_mean_rr_24w'],target_df_trainVal, max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01')\n",
    "\n",
    "res = {\n",
    "    \"delta\" : [], # list with all deltas\n",
    "    \"numSelected\" : [], #\n",
    "    \"selectedFeatures\" : [] \n",
    "#    \"accuracy\" : [] # list of scores associated with the reduced problem\n",
    "}\n",
    "\n",
    "res['selectedFeatures'] = forwardFeatureSelection(10,np.array(aggregate_trainVal),np.array(target_df_trainVal.mean_std),res,10,1)\n",
    "selectedFeatures='selectedFeatures'\n",
    "print(f'\\n{res[selectedFeatures]}\\n')\n",
    "selected_colnames = aggregate_trainVal.columns[res['selectedFeatures']]\n",
    "compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ce6c64db",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "6\n",
      "8\n",
      "9\n",
      "18\n",
      "20\n",
      "25\n",
      "26\n",
      "----- MI Scores -----\n",
      "[(0, 0.08830413469347519), (5, 0.08252158915719636), (2, 0.07326593931401697), (6, 0.05498995269556534), (9, 0.04997633280479427), (8, 0.04773844477463132), (7, 0.04759884972003266), (3, 0.040944276481551675), (1, 0.039325001748386344), (4, 0.025932763785423512)]\n",
      "Best MI score: 0.08830413469347519\n",
      "Adding first best original feature: 0\n",
      "CMI: 0.012328119466631898\n",
      "CMI: 0.0050900896692183395\n",
      "Highest CMI score: 0.012328119466631898\n",
      "Adding original feature: 2\n",
      "CMI: 6.452304735245218e-05\n",
      "CMI: 0.0026330032232820683\n",
      "CMI: 0.0017456510833474548\n",
      "Highest CMI score: 0.0026330032232820683\n",
      "Adding original feature: 7\n",
      "CMI: 0.004327243070018805\n",
      "CMI: 0.0006240357286703274\n",
      "Highest CMI score: 0.004327243070018805\n",
      "Adding original feature: 1\n",
      "Highest CMI score: -0.0013945249022170453\n",
      "\n",
      "[0, 2, 7, 1]\n",
      "\n",
      "Full aggregate regression train score: 0.08531091252267498, test score: 0.07160702654865714\n",
      "Aggregate regression train score with FS: 0.08233209582986023, test score: 0.08101743740229261\n"
     ]
    }
   ],
   "source": [
    "### repeat keeping features with at least three cells and excluding last years\n",
    "ii = []\n",
    "for i in range(len(output)):\n",
    "    if (len(output[i]))>=3: \n",
    "        print(i)\n",
    "        ii.append(i)\n",
    "\n",
    "res = {\n",
    "    \"delta\" : [], # list with all deltas\n",
    "    \"numSelected\" : [], #\n",
    "    \"selectedFeatures\" : [] \n",
    "}\n",
    "\n",
    "res['selectedFeatures'] = forwardFeatureSelection(10,np.array(aggregate_trainVal.iloc[:,ii]),np.array(target_df_trainVal.mean_std),res,10,1)\n",
    "selectedFeatures='selectedFeatures'\n",
    "print(f'\\n{res[selectedFeatures]}\\n')\n",
    "selected_colnames = aggregate_trainVal.iloc[:,ii].columns[res['selectedFeatures']]\n",
    "compare_methods(aggregate_trainVal.iloc[:,ii], aggregate_test.iloc[:,ii], target_df_trainVal, target_df_test, selected_colnames)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac92b9fa",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## both"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139c8980",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3cd88841",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.214281    0.00  2001     1 -1.402730\n",
      "1    2001-01-13  0.484737    0.52  2001     2  0.347916\n",
      "2    2001-01-21  0.466071    0.47  2001     3  0.227090\n",
      "3    2001-01-29  0.417470    0.44  2001     5 -0.087501\n",
      "4    2001-02-06  0.492202    0.53  2001     6  0.396235\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "584  2013-10-21  0.739946    0.79  2013    43  1.999865\n",
      "585  2013-10-29  0.447691    0.46  2013    44  0.108118\n",
      "586  2013-11-06  0.541628    0.56  2013    45  0.716163\n",
      "587  2013-11-14  0.493719    0.53  2013    46  0.406051\n",
      "588  2013-11-22  0.527436    0.57  2013    47  0.624301\n",
      "\n",
      "[589 rows x 6 columns]\n",
      " target shapes: ((589, 6), (200, 6), (789, 6), (192, 6))\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 24\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 30\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 32\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 33\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 28\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 26\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 34\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 24\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 30\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 32\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 33\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 28\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 26\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 34\n",
      "\n",
      "actual training score: 0.1496147780387076\n",
      "actual validation score: 0.22227939632068527, number of remaining columns: 205\n",
      "\n",
      "actual training score: 0.15113068604005675\n",
      "actual validation score: 0.24227602972967377, number of remaining columns: 204\n",
      "\n",
      "actual training score: 0.15189422521708407\n",
      "actual validation score: 0.2550629056446563, number of remaining columns: 203\n",
      "\n",
      "actual training score: 0.156770030647312\n",
      "actual validation score: 0.2805121673812945, number of remaining columns: 202\n",
      "\n",
      "actual training score: 0.160659645003998\n",
      "actual validation score: 0.28969172204334337, number of remaining columns: 201\n",
      "\n",
      "actual training score: 0.16289387636465358\n",
      "actual validation score: 0.2993272963745761, number of remaining columns: 200\n",
      "\n",
      "actual training score: 0.163566066907881\n",
      "actual validation score: 0.30523176720688916, number of remaining columns: 199\n",
      "\n",
      "actual training score: 0.16766596658318889\n",
      "actual validation score: 0.320891578159765, number of remaining columns: 198\n",
      "\n",
      "actual training score: 0.16829208972476795\n",
      "actual validation score: 0.3277033532855579, number of remaining columns: 197\n",
      "\n",
      "actual training score: 0.17049780911365064\n",
      "actual validation score: 0.33525042231708735, number of remaining columns: 196\n",
      "\n",
      "actual training score: 0.21975580581405663\n",
      "actual validation score: 0.35613115290595965, number of remaining columns: 195\n",
      "\n",
      "actual training score: 0.23082854942899522\n",
      "actual validation score: 0.3662470599011547, number of remaining columns: 194\n",
      "\n",
      "actual training score: 0.23601614748280686\n",
      "actual validation score: 0.37610335072237566, number of remaining columns: 193\n",
      "\n",
      "actual training score: 0.2370716719718633\n",
      "actual validation score: 0.3833924506056332, number of remaining columns: 192\n",
      "\n",
      "actual training score: 0.23875720978857284\n",
      "actual validation score: 0.38890204683845564, number of remaining columns: 191\n",
      "\n",
      "actual training score: 0.2391984660116503\n",
      "actual validation score: 0.3938755517075542, number of remaining columns: 190\n",
      "\n",
      "actual training score: 0.24047203102318682\n",
      "actual validation score: 0.4005756743633948, number of remaining columns: 189\n",
      "\n",
      "actual training score: 0.2406377025086156\n",
      "actual validation score: 0.4030833467953414, number of remaining columns: 188\n",
      "\n",
      "actual training score: 0.24117162750871546\n",
      "actual validation score: 0.40754887769274617, number of remaining columns: 187\n",
      "\n",
      "actual training score: 0.24474946655295804\n",
      "actual validation score: 0.41218933821999215, number of remaining columns: 186\n",
      "\n",
      "actual training score: 0.24615875533796427\n",
      "actual validation score: 0.4151059919618243, number of remaining columns: 185\n",
      "\n",
      "actual training score: 0.2480896223197655\n",
      "actual validation score: 0.4195028876614426, number of remaining columns: 184\n",
      "\n",
      "actual training score: 0.2482713106305845\n",
      "actual validation score: 0.4218898634121182, number of remaining columns: 183\n",
      "\n",
      "actual training score: 0.2489912726097493\n",
      "actual validation score: 0.4239998284095208, number of remaining columns: 182\n",
      "\n",
      "actual training score: 0.24918553077442795\n",
      "actual validation score: 0.42593574702667825, number of remaining columns: 181\n",
      "\n",
      "actual training score: 0.24925317119477397\n",
      "actual validation score: 0.42781630272637183, number of remaining columns: 180\n",
      "\n",
      "actual training score: 0.24940795909878577\n",
      "actual validation score: 0.43037627322986205, number of remaining columns: 179\n",
      "\n",
      "actual training score: 0.25003027975879244\n",
      "actual validation score: 0.43240941752563733, number of remaining columns: 178\n",
      "\n",
      "actual training score: 0.251914194332165\n",
      "actual validation score: 0.4460033155984301, number of remaining columns: 177\n",
      "\n",
      "actual training score: 0.2519789764740116\n",
      "actual validation score: 0.447138096052326, number of remaining columns: 176\n",
      "\n",
      "actual training score: 0.2533465200481899\n",
      "actual validation score: 0.4514612693155079, number of remaining columns: 175\n",
      "\n",
      "actual training score: 0.26284997189553994\n",
      "actual validation score: 0.45297525870109023, number of remaining columns: 174\n",
      "\n",
      "actual training score: 0.2630266847544285\n",
      "actual validation score: 0.4551352324224307, number of remaining columns: 173\n",
      "\n",
      "actual training score: 0.26392880584952916\n",
      "actual validation score: 0.4563712575516361, number of remaining columns: 172\n",
      "\n",
      "actual training score: 0.26401770894419097\n",
      "actual validation score: 0.45883230087719684, number of remaining columns: 171\n",
      "\n",
      "actual training score: 0.26581242441672415\n",
      "actual validation score: 0.462839326360183, number of remaining columns: 170\n",
      "\n",
      "actual training score: 0.2674380174041219\n",
      "actual validation score: 0.46779985286515213, number of remaining columns: 169\n",
      "\n",
      "actual training score: 0.26792718516049385\n",
      "actual validation score: 0.4700734160581348, number of remaining columns: 168\n",
      "\n",
      "actual training score: 0.2681333813097341\n",
      "actual validation score: 0.47131158471411927, number of remaining columns: 167\n",
      "\n",
      "actual training score: 0.26869715548511697\n",
      "actual validation score: 0.4727157099895246, number of remaining columns: 166\n",
      "\n",
      "actual training score: 0.27083289504811625\n",
      "actual validation score: 0.47302137932389576, number of remaining columns: 165\n",
      "\n",
      "actual training score: 0.2711072486385824\n",
      "actual validation score: 0.47720719139968915, number of remaining columns: 164\n",
      "\n",
      "actual training score: 0.274196603370656\n",
      "actual validation score: 0.48260671167028846, number of remaining columns: 163\n",
      "\n",
      "actual training score: 0.27420386304644007\n",
      "actual validation score: 0.48329541560659106, number of remaining columns: 162\n",
      "\n",
      "actual training score: 0.27500924342977484\n",
      "actual validation score: 0.4844109654187082, number of remaining columns: 161\n",
      "\n",
      "actual training score: 0.2750437583347527\n",
      "actual validation score: 0.48492499520816057, number of remaining columns: 160\n",
      "\n",
      "actual training score: 0.27505467140305406\n",
      "actual validation score: 0.48524025641615964, number of remaining columns: 159\n",
      "\n",
      "actual training score: 0.27507574762539533\n",
      "actual validation score: 0.4850522636952337, number of remaining columns: 158\n",
      "\n",
      "actual training score: 0.27513106776114604\n",
      "actual validation score: 0.4847915755185571, number of remaining columns: 157\n",
      "\n",
      "actual training score: 0.2755467873205303\n",
      "actual validation score: 0.4841106640830526, number of remaining columns: 156\n",
      "\n",
      "actual training score: 0.27565340877950184\n",
      "actual validation score: 0.4832816713596195, number of remaining columns: 155\n",
      "\n",
      "actual training score: 0.27588466684999735\n",
      "actual validation score: 0.4830860292426181, number of remaining columns: 154\n",
      "\n",
      "actual training score: 0.2760106302707013\n",
      "actual validation score: 0.48196690503206563, number of remaining columns: 153\n",
      "\n",
      "actual training score: 0.27637132222046235\n",
      "actual validation score: 0.48104133915977487, number of remaining columns: 152\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual training score: 0.27680097555638794\n",
      "actual validation score: 0.47986679961961054, number of remaining columns: 151\n",
      "\n",
      "actual training score: 0.2782893123979089\n",
      "actual validation score: 0.47934054185883146, number of remaining columns: 150\n",
      "\n",
      "actual training score: 0.2782910837862297\n",
      "actual validation score: 0.47961915112144105, number of remaining columns: 149\n",
      "\n",
      "actual training score: 0.27918553969388893\n",
      "actual validation score: 0.4816883628462375, number of remaining columns: 148\n",
      "\n",
      "actual training score: 0.2791855541494336\n",
      "actual validation score: 0.4817110574215502, number of remaining columns: 147\n",
      "\n",
      "actual training score: 0.27918861596059175\n",
      "actual validation score: 0.48108055036597874, number of remaining columns: 146\n",
      "\n",
      "actual training score: 0.27919615751790283\n",
      "actual validation score: 0.4800303393668949, number of remaining columns: 145\n",
      "\n",
      "actual training score: 0.2805835500833197\n",
      "actual validation score: 0.48015756223779393, number of remaining columns: 144\n",
      "\n",
      "actual training score: 0.2866763644885969\n",
      "actual validation score: 0.4784645212408771, number of remaining columns: 143\n",
      "\n",
      "actual training score: 0.2881567729011375\n",
      "actual validation score: 0.4778985639211736, number of remaining columns: 142\n",
      "\n",
      "actual training score: 0.2885711226509742\n",
      "actual validation score: 0.4758897945419178, number of remaining columns: 141\n",
      "\n",
      "actual training score: 0.28921385140331013\n",
      "actual validation score: 0.47325505619025665, number of remaining columns: 140\n",
      "\n",
      "actual training score: 0.2901737666588623\n",
      "actual validation score: 0.4709984894393904, number of remaining columns: 139\n",
      "\n",
      "actual training score: 0.29090249759987896\n",
      "actual validation score: 0.4689592888439942, number of remaining columns: 138\n",
      "\n",
      "actual training score: 0.29234731551850623\n",
      "actual validation score: 0.46544065565071524, number of remaining columns: 137\n",
      "\n",
      "actual training score: 0.29248439554314476\n",
      "actual validation score: 0.4613550704133489, number of remaining columns: 136\n",
      "\n",
      "actual training score: 0.29502239160855326\n",
      "actual validation score: 0.4587440543725445, number of remaining columns: 135\n",
      "\n",
      "actual training score: 0.3008773231257499\n",
      "actual validation score: 0.45484501873651717, number of remaining columns: 134\n",
      "\n",
      "actual training score: 0.3008895556564938\n",
      "actual validation score: 0.45304114342235824, number of remaining columns: 133\n",
      "\n",
      "actual training score: 0.301288926146578\n",
      "actual validation score: 0.4500776156374231, number of remaining columns: 132\n",
      "\n",
      "actual training score: 0.30146942220923667\n",
      "actual validation score: 0.44862089486654133, number of remaining columns: 131\n",
      "\n",
      "actual training score: 0.3015376514334219\n",
      "actual validation score: 0.44695162033496005, number of remaining columns: 130\n",
      "\n",
      "actual training score: 0.3029181025681791\n",
      "actual validation score: 0.4496207079616993, number of remaining columns: 129\n",
      "\n",
      "actual training score: 0.31644123506804867\n",
      "actual validation score: 0.44833229700543664, number of remaining columns: 128\n",
      "\n",
      "actual training score: 0.3164708733390196\n",
      "actual validation score: 0.4487880025688865, number of remaining columns: 127\n",
      "\n",
      "actual training score: 0.3176318225249184\n",
      "actual validation score: 0.4481724537173043, number of remaining columns: 126\n",
      "\n",
      "actual training score: 0.317645350423978\n",
      "actual validation score: 0.4479244777610526, number of remaining columns: 125\n",
      "\n",
      "actual training score: 0.31895035074531297\n",
      "actual validation score: 0.4470965447885984, number of remaining columns: 124\n",
      "\n",
      "actual training score: 0.3197550214014574\n",
      "actual validation score: 0.4471125426987821, number of remaining columns: 123\n",
      "\n",
      "actual training score: 0.3197999660402814\n",
      "actual validation score: 0.4464216992464014, number of remaining columns: 122\n",
      "\n",
      "actual training score: 0.32043721148737025\n",
      "actual validation score: 0.4451966535338715, number of remaining columns: 121\n",
      "\n",
      "actual training score: 0.32463770780926027\n",
      "actual validation score: 0.44426055093656236, number of remaining columns: 120\n",
      "\n",
      "actual training score: 0.3327865028468382\n",
      "actual validation score: 0.44213268389400806, number of remaining columns: 119\n",
      "\n",
      "actual training score: 0.33404688148245953\n",
      "actual validation score: 0.44881353951432545, number of remaining columns: 118\n",
      "\n",
      "actual training score: 0.3342468472472271\n",
      "actual validation score: 0.45104297031078, number of remaining columns: 117\n",
      "\n",
      "actual training score: 0.33770164725292007\n",
      "actual validation score: 0.4523657271873962, number of remaining columns: 116\n",
      "\n",
      "actual training score: 0.3377018895776124\n",
      "actual validation score: 0.45227164898714567, number of remaining columns: 115\n",
      "\n",
      "actual training score: 0.33796913514613114\n",
      "actual validation score: 0.4504228457335433, number of remaining columns: 114\n",
      "\n",
      "actual training score: 0.33811374436474284\n",
      "actual validation score: 0.4486480961756213, number of remaining columns: 113\n",
      "\n",
      "actual training score: 0.3476242718277536\n",
      "actual validation score: 0.4485171455418916, number of remaining columns: 112\n",
      "\n",
      "actual training score: 0.3476248706247851\n",
      "actual validation score: 0.4487121539527338, number of remaining columns: 111\n",
      "\n",
      "actual training score: 0.34924396891018417\n",
      "actual validation score: 0.4481008469921086, number of remaining columns: 110\n",
      "\n",
      "actual training score: 0.34942878792456944\n",
      "actual validation score: 0.4469771941406765, number of remaining columns: 109\n",
      "\n",
      "actual training score: 0.35040155730372224\n",
      "actual validation score: 0.44526046219491555, number of remaining columns: 108\n",
      "\n",
      "actual training score: 0.3504572610038216\n",
      "actual validation score: 0.44474334583790587, number of remaining columns: 107\n",
      "\n",
      "actual training score: 0.35156127771662715\n",
      "actual validation score: 0.4452342636379748, number of remaining columns: 106\n",
      "\n",
      "\n",
      "\n",
      "selected columns: ['cyclostationary_mean_rr_8w_16', 'cyclostationary_mean_rr_1w_13', 'cyclostationary_mean_rr_8w_22', 'cyclostationary_mean_rr_8w_27', 'cyclostationary_mean_rr_8w_26', 'cyclostationary_mean_rr_12w_21', 'cyclostationary_mean_rr_8w_18', 'cyclostationary_mean_rr_12w_5', 'cyclostationary_mean_rr_12w_19', 'cyclostationary_mean_rr_8w_9', 'cyclostationary_mean_rr_8w_7', 'cyclostationary_mean_rr_8w_14', 'cyclostationary_mean_rr_24w_26', 'cyclostationary_mean_rr_4w_31', 'cyclostationary_mean_rr_1w_15', 'cyclostationary_mean_rr_1w_3', 'cyclostationary_mean_rr_4w_28', 'cyclostationary_mean_rr_4w_25', 'cyclostationary_mean_rr_12w_27', 'cyclostationary_mean_rr_16w_11', 'cyclostationary_mean_rr_4w_6', 'cyclostationary_mean_rr_24w_6', 'cyclostationary_mean_rr_24w_28', 'cyclostationary_mean_rr_8w_4', 'cyclostationary_mean_rr_16w_22', 'cyclostationary_mean_rr_8w_3', 'cyclostationary_mean_rr_16w_2', 'cyclostationary_mean_rr_8w_32', 'cyclostationary_mean_rr_16w_17', 'cyclostationary_mean_rr_16w_25', 'cyclostationary_mean_rr_0', 'cyclostationary_mean_rr_18', 'cyclostationary_mean_rr_24w_20', 'cyclostationary_mean_rr_24w_32', 'cyclostationary_mean_rr_4w_30', 'cyclostationary_mean_rr_4w_19', 'cyclostationary_mean_rr_1w_21', 'cyclostationary_mean_rr_4w_21', 'cyclostationary_mean_rr_1w_24', 'cyclostationary_mean_rr_10', 'cyclostationary_mean_rr_24w_8', 'cyclostationary_mean_rr_4w_0', 'cyclostationary_mean_rr_4w_8', 'cyclostationary_mean_rr_16w_0', 'cyclostationary_mean_rr_8w_29', 'cyclostationary_mean_rr_12w_14', 'cyclostationary_mean_rr_1w_10', 'cyclostationary_mean_rr_16w_6'], \n",
      "\n",
      "validation score: 0.48524025641615964, \n",
      "\n",
      "number of selected features: 48\n",
      "Full aggregate regression train score: 0.5709453283924056, test score: -0.5612643215121798\n",
      "Aggregate regression train score with FS: 0.32809291322626344, test score: -0.1786761134637489\n"
     ]
    }
   ],
   "source": [
    "target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target('')\n",
    "\n",
    "path='/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/features/csv_allvalues/temporal_aggreg/Emiliani2_aggreg.csv'\n",
    "\n",
    "output,aggregate_trainVal,aggregate_test = aggregate_unfolded_data(path,['cyclostationary_mean_rr', \n",
    "                                                                         'cyclostationary_mean_rr_1w',\n",
    "                                                                         'cyclostationary_mean_rr_4w', \n",
    "                                                                         'cyclostationary_mean_rr_8w',\n",
    "                                                                         'cyclostationary_mean_rr_12w', \n",
    "                                                                         'cyclostationary_mean_rr_16w',\n",
    "                                                                         'cyclostationary_mean_rr_24w',\n",
    "                                                                         'cyclostationary_mean_rr', \n",
    "                                                                         'cyclostationary_mean_rr_1w',\n",
    "                                                                         'cyclostationary_mean_rr_4w', \n",
    "                                                                         'cyclostationary_mean_rr_8w',\n",
    "                                                                         'cyclostationary_mean_rr_12w', \n",
    "                                                                         'cyclostationary_mean_rr_16w',\n",
    "                                                                         'cyclostationary_mean_rr_24w'\n",
    "                                                                        ],\n",
    "                                                                   target_df_trainVal)\n",
    "\n",
    "selected_colnames = FS_with_linearWrapper(aggregate_trainVal, target_df_train, target_df_val, 100)\n",
    "\n",
    "compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d73ae8d9",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "3\n",
      "4\n",
      "7\n",
      "8\n",
      "13\n",
      "14\n",
      "16\n",
      "21\n",
      "25\n",
      "27\n",
      "actual training score: 0.07809898152286088\n",
      "actual validation score: 0.02600661076829569, number of remaining columns: 10\n",
      "\n",
      "actual training score: 0.0847925822730422\n",
      "actual validation score: 0.025831589442307568, number of remaining columns: 9\n",
      "\n",
      "actual training score: 0.0849060783065525\n",
      "actual validation score: 0.024954891347490293, number of remaining columns: 8\n",
      "\n",
      "actual training score: 0.08871988149605836\n",
      "actual validation score: 0.026616459282883698, number of remaining columns: 7\n",
      "\n",
      "actual training score: 0.09229262416247574\n",
      "actual validation score: 0.02495711809593959, number of remaining columns: 6\n",
      "\n",
      "actual training score: 0.09323092685687895\n",
      "actual validation score: 0.03096787741693796, number of remaining columns: 5\n",
      "\n",
      "actual training score: 0.09572110250269728\n",
      "actual validation score: 0.032654867268776755, number of remaining columns: 4\n",
      "\n",
      "actual training score: 0.10917857372956796\n",
      "actual validation score: 0.024287059555100132, number of remaining columns: 3\n",
      "\n",
      "actual training score: 0.10942219515734564\n",
      "actual validation score: 0.027046631801117438, number of remaining columns: 2\n",
      "\n",
      "actual training score: 0.11084501559027282\n",
      "actual validation score: 0.013068824229049536, number of remaining columns: 1\n",
      "\n",
      "\n",
      "\n",
      "selected columns: ['cyclostationary_mean_rr_1w_1', 'cyclostationary_mean_rr_0', 'cyclostationary_mean_rr_1w_3', 'cyclostationary_mean_rr_8', 'cyclostationary_mean_rr_3', 'cyclostationary_mean_rr_21', 'cyclostationary_mean_rr_13', 'cyclostationary_mean_rr_16'], \n",
      "\n",
      "validation score: 0.032654867268776755, \n",
      "\n",
      "number of selected features: 8\n",
      "Full aggregate regression train score: 0.09829192314737889, test score: 0.04958536663510049\n",
      "Aggregate regression train score with FS: 0.08762967280819056, test score: 0.02928604510826316\n"
     ]
    }
   ],
   "source": [
    "### repeat keeping features with at least three cells\n",
    "ii = []\n",
    "for i in range(len(output)):\n",
    "    if (len(output[i]))>=3: \n",
    "        print(i)\n",
    "        ii.append(i)\n",
    "\n",
    "selected_colnames = FS_with_linearWrapper(aggregate_trainVal.iloc[:,ii], target_df_train, target_df_val, 10)\n",
    "\n",
    "compare_methods(aggregate_trainVal.iloc[:,ii], aggregate_test.iloc[:,ii], target_df_trainVal, target_df_test, selected_colnames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13375eaf",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.214281    0.00  2001     1 -1.402730\n",
      "1    2001-01-13  0.484737    0.52  2001     2  0.347916\n",
      "2    2001-01-21  0.466071    0.47  2001     3  0.227090\n",
      "3    2001-01-29  0.417470    0.44  2001     5 -0.087501\n",
      "4    2001-02-06  0.492202    0.53  2001     6  0.396235\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "584  2013-10-21  0.739946    0.79  2013    43  1.999865\n",
      "585  2013-10-29  0.447691    0.46  2013    44  0.108118\n",
      "586  2013-11-06  0.541628    0.56  2013    45  0.716163\n",
      "587  2013-11-14  0.493719    0.53  2013    46  0.406051\n",
      "588  2013-11-22  0.527436    0.57  2013    47  0.624301\n",
      "\n",
      "[589 rows x 6 columns]\n",
      " target shapes: ((589, 6), (200, 6), (789, 6), (192, 6))\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 24\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 30\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 32\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 33\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 28\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 26\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 34\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 42\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 49\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 36\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 47\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 40\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 33\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 22\n",
      "\n",
      "actual training score: 0.18950874660641226\n",
      "actual validation score: 0.3811537402581725, number of remaining columns: 474\n",
      "\n",
      "actual training score: 0.196802693463613\n",
      "actual validation score: 0.4190370321913347, number of remaining columns: 473\n",
      "\n",
      "actual training score: 0.20280339265109326\n",
      "actual validation score: 0.43306612184816873, number of remaining columns: 472\n",
      "\n",
      "actual training score: 0.20722837758675106\n",
      "actual validation score: 0.44812206680952815, number of remaining columns: 471\n",
      "\n",
      "\n",
      "\n",
      "selected columns: ['cyclostationary_mean_tg_1w_41', 'cyclostationary_mean_rr_8w_16', 'cyclostationary_mean_tg_16w_14', 'cyclostationary_mean_rr_16w_11', 'cyclostationary_mean_tg_4'], \n",
      "\n",
      "validation score: 0.44812206680952815, \n",
      "\n",
      "number of selected features: 5\n",
      "Full aggregate regression train score: 0.8501602784300545, test score: -19.266049022334943\n",
      "Aggregate regression train score with FS: 0.264835580805295, test score: 0.08553975399490954\n"
     ]
    }
   ],
   "source": [
    "### full, forcing a low number of features\n",
    "target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target('')\n",
    "\n",
    "path='/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/features/csv_allvalues/temporal_aggreg/Emiliani2_aggreg.csv'\n",
    "\n",
    "output,aggregate_trainVal,aggregate_test = aggregate_unfolded_data(path,['cyclostationary_mean_rr', \n",
    "                                                                         'cyclostationary_mean_rr_1w',\n",
    "                                                                         'cyclostationary_mean_rr_4w', \n",
    "                                                                         'cyclostationary_mean_rr_8w',\n",
    "                                                                         'cyclostationary_mean_rr_12w', \n",
    "                                                                         'cyclostationary_mean_rr_16w',\n",
    "                                                                         'cyclostationary_mean_rr_24w',\n",
    "                                                                         'cyclostationary_mean_tg', \n",
    "                                                                         'cyclostationary_mean_tg_1w',\n",
    "                                                                         'cyclostationary_mean_tg_4w', \n",
    "                                                                         'cyclostationary_mean_tg_8w',\n",
    "                                                                         'cyclostationary_mean_tg_12w', \n",
    "                                                                         'cyclostationary_mean_tg_16w',\n",
    "                                                                         'cyclostationary_mean_tg_24w'\n",
    "                                                                        ],\n",
    "                                                                   target_df_trainVal)\n",
    "\n",
    "selected_colnames = FS_with_linearWrapper(aggregate_trainVal, target_df_train, target_df_val, 4)\n",
    "\n",
    "compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4332dd2",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual training score: 0.18950874660641226\n",
      "actual validation score: 0.3811537402581725, number of remaining columns: 474\n",
      "\n",
      "actual training score: 0.196802693463613\n",
      "actual validation score: 0.4190370321913347, number of remaining columns: 473\n",
      "\n",
      "actual training score: 0.20280339265109326\n",
      "actual validation score: 0.43306612184816873, number of remaining columns: 472\n",
      "\n",
      "actual training score: 0.20722837758675106\n",
      "actual validation score: 0.44812206680952815, number of remaining columns: 471\n",
      "\n",
      "actual training score: 0.2083907448085499\n",
      "actual validation score: 0.46032001586278626, number of remaining columns: 470\n",
      "\n",
      "actual training score: 0.21799977370528212\n",
      "actual validation score: 0.48290635863524434, number of remaining columns: 469\n",
      "\n",
      "actual training score: 0.21963731453375956\n",
      "actual validation score: 0.49083184787784717, number of remaining columns: 468\n",
      "\n",
      "actual training score: 0.2238118025125888\n",
      "actual validation score: 0.510773919739361, number of remaining columns: 467\n",
      "\n",
      "actual training score: 0.22522228663986865\n",
      "actual validation score: 0.519179976932661, number of remaining columns: 466\n",
      "\n",
      "\n",
      "\n",
      "selected columns: ['cyclostationary_mean_tg_1w_41', 'cyclostationary_mean_rr_8w_16', 'cyclostationary_mean_tg_16w_14', 'cyclostationary_mean_rr_16w_11', 'cyclostationary_mean_tg_4', 'cyclostationary_mean_rr_12w_2', 'cyclostationary_mean_rr_8w_12', 'cyclostationary_mean_rr_8w_27', 'cyclostationary_mean_rr_8w_18', 'cyclostationary_mean_rr_8w_32'], \n",
      "\n",
      "validation score: 0.519179976932661, \n",
      "\n",
      "number of selected features: 10\n",
      "Full aggregate regression train score: 0.8501602784300545, test score: -19.266049022334943\n",
      "Aggregate regression train score with FS: 0.2936265002427807, test score: 0.026449122575808226\n"
     ]
    }
   ],
   "source": [
    "selected_colnames = FS_with_linearWrapper(aggregate_trainVal, target_df_train, target_df_val, 9)\n",
    "\n",
    "compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69121f7d",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### not considering last years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a27e0692",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.214281    0.00  2001     1 -1.339879\n",
      "1    2001-01-13  0.484737    0.52  2001     2  0.402993\n",
      "2    2001-01-21  0.466071    0.47  2001     3  0.282703\n",
      "3    2001-01-29  0.417470    0.44  2001     5 -0.030490\n",
      "4    2001-02-06  0.492202    0.53  2001     6  0.451097\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.436464    0.46  2009    48  0.091910\n",
      "407  2009-12-05  0.466152    0.49  2009    49  0.283224\n",
      "408  2009-12-13  0.553659    0.59  2009    50  0.847138\n",
      "409  2009-12-21  0.507978    0.65  2009    52  0.552758\n",
      "410  2009-12-29  0.083046    0.00  2009    53 -2.185583\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 28\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 29\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 36\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 39\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 33\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 27\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 36\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 41\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 49\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 48\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 40\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 32\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 30\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 25\n",
      "\n",
      "actual training score: 0.09538756789900393\n",
      "actual validation score: 0.3413585882489344, number of remaining columns: 491\n",
      "\n",
      "actual training score: 0.12413622082567954\n",
      "actual validation score: 0.3823725064915444, number of remaining columns: 490\n",
      "\n",
      "actual training score: 0.1577063121645781\n",
      "actual validation score: 0.4305798035991807, number of remaining columns: 489\n",
      "\n",
      "actual training score: 0.16089888118688345\n",
      "actual validation score: 0.454951000706186, number of remaining columns: 488\n",
      "\n",
      "actual training score: 0.1619751970360489\n",
      "actual validation score: 0.47202801012718687, number of remaining columns: 487\n",
      "\n",
      "actual training score: 0.16666741734387758\n",
      "actual validation score: 0.4893838983380814, number of remaining columns: 486\n",
      "\n",
      "actual training score: 0.16832225554192992\n",
      "actual validation score: 0.5037449327525447, number of remaining columns: 485\n",
      "\n",
      "actual training score: 0.19029902644129337\n",
      "actual validation score: 0.5133960361340805, number of remaining columns: 484\n",
      "\n",
      "actual training score: 0.19302748803548098\n",
      "actual validation score: 0.5225166365915893, number of remaining columns: 483\n",
      "\n",
      "actual training score: 0.1985775458741934\n",
      "actual validation score: 0.5288963693593327, number of remaining columns: 482\n",
      "\n",
      "actual training score: 0.1993155559850871\n",
      "actual validation score: 0.5334753763489068, number of remaining columns: 481\n",
      "\n",
      "actual training score: 0.20052205808645962\n",
      "actual validation score: 0.5429267466514602, number of remaining columns: 480\n",
      "\n",
      "actual training score: 0.20138873630758636\n",
      "actual validation score: 0.5490981011889036, number of remaining columns: 479\n",
      "\n",
      "actual training score: 0.2050286907360338\n",
      "actual validation score: 0.5555888419483909, number of remaining columns: 478\n",
      "\n",
      "actual training score: 0.2065720736512805\n",
      "actual validation score: 0.5595226083080982, number of remaining columns: 477\n",
      "\n",
      "actual training score: 0.208284279063234\n",
      "actual validation score: 0.5630218904650643, number of remaining columns: 476\n",
      "\n",
      "actual training score: 0.20887252201320405\n",
      "actual validation score: 0.566200544078187, number of remaining columns: 475\n",
      "\n",
      "actual training score: 0.2105666635508222\n",
      "actual validation score: 0.5692416894110386, number of remaining columns: 474\n",
      "\n",
      "actual training score: 0.2114765195972691\n",
      "actual validation score: 0.5725188382715054, number of remaining columns: 473\n",
      "\n",
      "actual training score: 0.21324949915967428\n",
      "actual validation score: 0.5756962870270983, number of remaining columns: 472\n",
      "\n",
      "actual training score: 0.21472697354911208\n",
      "actual validation score: 0.5828760514116891, number of remaining columns: 471\n",
      "\n",
      "actual training score: 0.216292722753734\n",
      "actual validation score: 0.5860044707275271, number of remaining columns: 470\n",
      "\n",
      "actual training score: 0.21734741669018176\n",
      "actual validation score: 0.5912007400697269, number of remaining columns: 469\n",
      "\n",
      "actual training score: 0.217811810933059\n",
      "actual validation score: 0.5949769619751674, number of remaining columns: 468\n",
      "\n",
      "actual training score: 0.22033750434872157\n",
      "actual validation score: 0.6000794087262646, number of remaining columns: 467\n",
      "\n",
      "actual training score: 0.22053297578583952\n",
      "actual validation score: 0.6031082101029314, number of remaining columns: 466\n",
      "\n",
      "actual training score: 0.22084374138680818\n",
      "actual validation score: 0.6055638047531173, number of remaining columns: 465\n",
      "\n",
      "actual training score: 0.22166058249611342\n",
      "actual validation score: 0.6073958253520642, number of remaining columns: 464\n",
      "\n",
      "actual training score: 0.2236060072935807\n",
      "actual validation score: 0.6141905261654368, number of remaining columns: 463\n",
      "\n",
      "actual training score: 0.23032372845965066\n",
      "actual validation score: 0.6172031428921845, number of remaining columns: 462\n",
      "\n",
      "actual training score: 0.23265125270678122\n",
      "actual validation score: 0.6185905352770863, number of remaining columns: 461\n",
      "\n",
      "actual training score: 0.2327413265824978\n",
      "actual validation score: 0.6200729274377472, number of remaining columns: 460\n",
      "\n",
      "actual training score: 0.23282723357516\n",
      "actual validation score: 0.6206966244207766, number of remaining columns: 459\n",
      "\n",
      "actual training score: 0.2390027608606956\n",
      "actual validation score: 0.6264134968033108, number of remaining columns: 458\n",
      "\n",
      "actual training score: 0.24315829118051246\n",
      "actual validation score: 0.6312221426130742, number of remaining columns: 457\n",
      "\n",
      "actual training score: 0.24447290334734084\n",
      "actual validation score: 0.6330199869846987, number of remaining columns: 456\n",
      "\n",
      "actual training score: 0.2446267458542828\n",
      "actual validation score: 0.6345860489145569, number of remaining columns: 455\n",
      "\n",
      "actual training score: 0.2450826022814755\n",
      "actual validation score: 0.6355489619281757, number of remaining columns: 454\n",
      "\n",
      "actual training score: 0.24512549264106864\n",
      "actual validation score: 0.6362337036131935, number of remaining columns: 453\n",
      "\n",
      "actual training score: 0.2451357624406738\n",
      "actual validation score: 0.6365221355533293, number of remaining columns: 452\n",
      "\n",
      "actual training score: 0.245136544173302\n",
      "actual validation score: 0.6367162636001611, number of remaining columns: 451\n",
      "\n",
      "actual training score: 0.2453716652080452\n",
      "actual validation score: 0.6370121452211364, number of remaining columns: 450\n",
      "\n",
      "actual training score: 0.24563134672822196\n",
      "actual validation score: 0.6374885247652473, number of remaining columns: 449\n",
      "\n",
      "actual training score: 0.24563994140871803\n",
      "actual validation score: 0.638139403698173, number of remaining columns: 448\n",
      "\n",
      "actual training score: 0.2456446629024237\n",
      "actual validation score: 0.6383906188477318, number of remaining columns: 447\n",
      "\n",
      "actual training score: 0.24571820278915513\n",
      "actual validation score: 0.638825052444359, number of remaining columns: 446\n",
      "\n",
      "actual training score: 0.2457254177106749\n",
      "actual validation score: 0.6393360103131037, number of remaining columns: 445\n",
      "\n",
      "actual training score: 0.24572709524602931\n",
      "actual validation score: 0.6393191615107982, number of remaining columns: 444\n",
      "\n",
      "actual training score: 0.24579716421882913\n",
      "actual validation score: 0.6391466348259949, number of remaining columns: 443\n",
      "\n",
      "actual training score: 0.24606931663781662\n",
      "actual validation score: 0.6389836632410275, number of remaining columns: 442\n",
      "\n",
      "actual training score: 0.2464659930237113\n",
      "actual validation score: 0.6387695346531013, number of remaining columns: 441\n",
      "\n",
      "actual training score: 0.24648183709174176\n",
      "actual validation score: 0.6388237801697614, number of remaining columns: 440\n",
      "\n",
      "actual training score: 0.24649423236060652\n",
      "actual validation score: 0.638216016995101, number of remaining columns: 439\n",
      "\n",
      "actual training score: 0.2518557146186957\n",
      "actual validation score: 0.6384294435233511, number of remaining columns: 438\n",
      "\n",
      "actual training score: 0.25299000477170885\n",
      "actual validation score: 0.6383114394807269, number of remaining columns: 437\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual training score: 0.2529901611990091\n",
      "actual validation score: 0.6382057054513106, number of remaining columns: 436\n",
      "\n",
      "actual training score: 0.25366348996460153\n",
      "actual validation score: 0.6371671184532017, number of remaining columns: 435\n",
      "\n",
      "actual training score: 0.2544352384339936\n",
      "actual validation score: 0.6342019408112375, number of remaining columns: 434\n",
      "\n",
      "actual training score: 0.25493344649861316\n",
      "actual validation score: 0.6304720275844115, number of remaining columns: 433\n",
      "\n",
      "actual training score: 0.25654430545364426\n",
      "actual validation score: 0.6283533547485562, number of remaining columns: 432\n",
      "\n",
      "actual training score: 0.2606728333460666\n",
      "actual validation score: 0.6331988993210558, number of remaining columns: 431\n",
      "\n",
      "actual training score: 0.263387448745556\n",
      "actual validation score: 0.6313217359020802, number of remaining columns: 430\n",
      "\n",
      "actual training score: 0.263403674846012\n",
      "actual validation score: 0.6305035631339988, number of remaining columns: 429\n",
      "\n",
      "actual training score: 0.2661343448158284\n",
      "actual validation score: 0.6327687460020517, number of remaining columns: 428\n",
      "\n",
      "actual training score: 0.267694472199859\n",
      "actual validation score: 0.6335753138298714, number of remaining columns: 427\n",
      "\n",
      "actual training score: 0.26780755293585035\n",
      "actual validation score: 0.6382138694056119, number of remaining columns: 426\n",
      "\n",
      "actual training score: 0.26786719667141634\n",
      "actual validation score: 0.6361120395848591, number of remaining columns: 425\n",
      "\n",
      "actual training score: 0.27065549909160114\n",
      "actual validation score: 0.6311392596123574, number of remaining columns: 424\n",
      "\n",
      "actual training score: 0.2715184880436763\n",
      "actual validation score: 0.6293495172025394, number of remaining columns: 423\n",
      "\n",
      "actual training score: 0.2724211010571992\n",
      "actual validation score: 0.6251086071209359, number of remaining columns: 422\n",
      "\n",
      "actual training score: 0.27288760454323313\n",
      "actual validation score: 0.620438864446288, number of remaining columns: 421\n",
      "\n",
      "actual training score: 0.27297069468646007\n",
      "actual validation score: 0.612489417889182, number of remaining columns: 420\n",
      "\n",
      "actual training score: 0.2741327519313955\n",
      "actual validation score: 0.6092997843690671, number of remaining columns: 419\n",
      "\n",
      "actual training score: 0.28071286733150647\n",
      "actual validation score: 0.6030482447934928, number of remaining columns: 418\n",
      "\n",
      "actual training score: 0.28120119968254453\n",
      "actual validation score: 0.5988756999711271, number of remaining columns: 417\n",
      "\n",
      "actual training score: 0.2843728314824615\n",
      "actual validation score: 0.5936870698129729, number of remaining columns: 416\n",
      "\n",
      "actual training score: 0.28564574379511265\n",
      "actual validation score: 0.5875179688441858, number of remaining columns: 415\n",
      "\n",
      "actual training score: 0.2857448703647735\n",
      "actual validation score: 0.582431791768477, number of remaining columns: 414\n",
      "\n",
      "actual training score: 0.2875806458537906\n",
      "actual validation score: 0.5747121742602967, number of remaining columns: 413\n",
      "\n",
      "actual training score: 0.28774583276916565\n",
      "actual validation score: 0.5748166244882333, number of remaining columns: 412\n",
      "\n",
      "actual training score: 0.2915847888652209\n",
      "actual validation score: 0.5648968051093285, number of remaining columns: 411\n",
      "\n",
      "actual training score: 0.29531096184635575\n",
      "actual validation score: 0.5535886589123877, number of remaining columns: 410\n",
      "\n",
      "actual training score: 0.29974961283120993\n",
      "actual validation score: 0.5442833403826666, number of remaining columns: 409\n",
      "\n",
      "actual training score: 0.3030065561262796\n",
      "actual validation score: 0.5345951456535625, number of remaining columns: 408\n",
      "\n",
      "actual training score: 0.30392088998783784\n",
      "actual validation score: 0.5270285927868835, number of remaining columns: 407\n",
      "\n",
      "actual training score: 0.3061274078777344\n",
      "actual validation score: 0.5223705709383872, number of remaining columns: 406\n",
      "\n",
      "actual training score: 0.3063350603975461\n",
      "actual validation score: 0.5174592425413828, number of remaining columns: 405\n",
      "\n",
      "actual training score: 0.3137576117867843\n",
      "actual validation score: 0.5079869683602951, number of remaining columns: 404\n",
      "\n",
      "actual training score: 0.31651477390890603\n",
      "actual validation score: 0.4973138002344675, number of remaining columns: 403\n",
      "\n",
      "actual training score: 0.31698735273021805\n",
      "actual validation score: 0.49136670435839414, number of remaining columns: 402\n",
      "\n",
      "actual training score: 0.32104237036617567\n",
      "actual validation score: 0.4819307551749419, number of remaining columns: 401\n",
      "\n",
      "actual training score: 0.3243121074271865\n",
      "actual validation score: 0.4799835246501196, number of remaining columns: 400\n",
      "\n",
      "actual training score: 0.32691499028155824\n",
      "actual validation score: 0.4747711227832013, number of remaining columns: 399\n",
      "\n",
      "actual training score: 0.3281158582177395\n",
      "actual validation score: 0.47022370979699524, number of remaining columns: 398\n",
      "\n",
      "actual training score: 0.3327953270068936\n",
      "actual validation score: 0.46129470835307296, number of remaining columns: 397\n",
      "\n",
      "actual training score: 0.33354348601952966\n",
      "actual validation score: 0.4715841962469668, number of remaining columns: 396\n",
      "\n",
      "actual training score: 0.335096994319375\n",
      "actual validation score: 0.4624990550124496, number of remaining columns: 395\n",
      "\n",
      "actual training score: 0.3384890976792122\n",
      "actual validation score: 0.44747778705561836, number of remaining columns: 394\n",
      "\n",
      "actual training score: 0.3403790138516989\n",
      "actual validation score: 0.44176537339850297, number of remaining columns: 393\n",
      "\n",
      "actual training score: 0.34342683265509955\n",
      "actual validation score: 0.4267240335786021, number of remaining columns: 392\n",
      "\n",
      "\n",
      "\n",
      "selected columns: ['cyclostationary_mean_tg_1w_42', 'cyclostationary_mean_rr_8w_19', 'cyclostationary_mean_tg_4w_45', 'cyclostationary_mean_tg_4w_15', 'cyclostationary_mean_rr_16w_8', 'cyclostationary_mean_rr_16w_23', 'cyclostationary_mean_rr_8w_25', 'cyclostationary_mean_tg_24w_8', 'cyclostationary_mean_tg_4w_2', 'cyclostationary_mean_tg_24w_2', 'cyclostationary_mean_rr_1w_25', 'cyclostationary_mean_rr_1w_15', 'cyclostationary_mean_rr_1w_19', 'cyclostationary_mean_rr_8w_29', 'cyclostationary_mean_tg_4w_47', 'cyclostationary_mean_tg_1w_24', 'cyclostationary_mean_tg_14', 'cyclostationary_mean_tg_1w_44', 'cyclostationary_mean_rr_12w_29', 'cyclostationary_mean_rr_8w_16', 'cyclostationary_mean_rr_12w_21', 'cyclostationary_mean_rr_24w_30', 'cyclostationary_mean_rr_24w_21', 'cyclostationary_mean_rr_8w_38', 'cyclostationary_mean_rr_16w_11', 'cyclostationary_mean_rr_12w_15', 'cyclostationary_mean_rr_8w_10', 'cyclostationary_mean_tg_1w_31', 'cyclostationary_mean_tg_12w_23', 'cyclostationary_mean_tg_8w_34', 'cyclostationary_mean_rr_8w_12', 'cyclostationary_mean_rr_8w_13', 'cyclostationary_mean_rr_1w_28', 'cyclostationary_mean_tg_8w_38', 'cyclostationary_mean_tg_12w_22', 'cyclostationary_mean_rr_4w_25', 'cyclostationary_mean_rr_4w_29', 'cyclostationary_mean_tg_16w_8', 'cyclostationary_mean_tg_4w_43', 'cyclostationary_mean_tg_12w_11', 'cyclostationary_mean_rr_16w_7', 'cyclostationary_mean_tg_8w_17', 'cyclostationary_mean_rr_16w_16', 'cyclostationary_mean_tg_24w_14', 'cyclostationary_mean_rr_24w_26', 'cyclostationary_mean_tg_16w_14', 'cyclostationary_mean_tg_16w_4', 'cyclostationary_mean_tg_16w_11'], \n",
      "\n",
      "validation score: 0.6393360103131037, \n",
      "\n",
      "number of selected features: 48\n",
      "Full aggregate regression train score: 0.9180110159940698, test score: -107.58500924872342\n",
      "Aggregate regression train score with FS: 0.40653210801834616, test score: -0.43586022139148417\n"
     ]
    }
   ],
   "source": [
    "target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target('',max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01')\n",
    "\n",
    "path='/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/features/csv_allvalues/temporal_aggreg/Emiliani2_aggreg.csv'\n",
    "\n",
    "output,aggregate_trainVal,aggregate_test = aggregate_unfolded_data(path,['cyclostationary_mean_rr', \n",
    "                                                                         'cyclostationary_mean_rr_1w',\n",
    "                                                                         'cyclostationary_mean_rr_4w', \n",
    "                                                                         'cyclostationary_mean_rr_8w',\n",
    "                                                                         'cyclostationary_mean_rr_12w', \n",
    "                                                                         'cyclostationary_mean_rr_16w',\n",
    "                                                                         'cyclostationary_mean_rr_24w',\n",
    "                                                                         'cyclostationary_mean_tg', \n",
    "                                                                         'cyclostationary_mean_tg_1w',\n",
    "                                                                         'cyclostationary_mean_tg_4w', \n",
    "                                                                         'cyclostationary_mean_tg_8w',\n",
    "                                                                         'cyclostationary_mean_tg_12w', \n",
    "                                                                         'cyclostationary_mean_tg_16w',\n",
    "                                                                         'cyclostationary_mean_tg_24w'\n",
    "                                                                        ],\n",
    "                                                                   target_df_trainVal, \n",
    "                                                                   max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01')\n",
    "\n",
    "selected_colnames = FS_with_linearWrapper(aggregate_trainVal, target_df_train, target_df_val, 100, 228)\n",
    "\n",
    "compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bce13569",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.214281    0.00  2001     1 -1.339879\n",
      "1    2001-01-13  0.484737    0.52  2001     2  0.402993\n",
      "2    2001-01-21  0.466071    0.47  2001     3  0.282703\n",
      "3    2001-01-29  0.417470    0.44  2001     5 -0.030490\n",
      "4    2001-02-06  0.492202    0.53  2001     6  0.451097\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.436464    0.46  2009    48  0.091910\n",
      "407  2009-12-05  0.466152    0.49  2009    49  0.283224\n",
      "408  2009-12-13  0.553659    0.59  2009    50  0.847138\n",
      "409  2009-12-21  0.507978    0.65  2009    52  0.552758\n",
      "410  2009-12-29  0.083046    0.00  2009    53 -2.185583\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 28\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 29\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 36\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 39\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 33\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 27\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 36\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 41\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 49\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 48\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 40\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 32\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 30\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 25\n",
      "\n",
      "actual training score: 0.09538756789900393\n",
      "actual validation score: 0.3413585882489344, number of remaining columns: 491\n",
      "\n",
      "actual training score: 0.12413622082567954\n",
      "actual validation score: 0.3823725064915444, number of remaining columns: 490\n",
      "\n",
      "actual training score: 0.1577063121645781\n",
      "actual validation score: 0.4305798035991807, number of remaining columns: 489\n",
      "\n",
      "actual training score: 0.16089888118688345\n",
      "actual validation score: 0.454951000706186, number of remaining columns: 488\n",
      "\n",
      "\n",
      "\n",
      "selected columns: ['cyclostationary_mean_tg_1w_42', 'cyclostationary_mean_rr_8w_19', 'cyclostationary_mean_tg_4w_45', 'cyclostationary_mean_tg_4w_15', 'cyclostationary_mean_rr_16w_8'], \n",
      "\n",
      "validation score: 0.454951000706186, \n",
      "\n",
      "number of selected features: 5\n",
      "Full aggregate regression train score: 0.9180110159940698, test score: -107.58500924872342\n",
      "Aggregate regression train score with FS: 0.2872828657643317, test score: 0.2279324840887177\n"
     ]
    }
   ],
   "source": [
    "### full, forcing a low number of features\n",
    "\n",
    "target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target('',max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01')\n",
    "\n",
    "path='/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/features/csv_allvalues/temporal_aggreg/Emiliani2_aggreg.csv'\n",
    "\n",
    "output,aggregate_trainVal,aggregate_test = aggregate_unfolded_data(path,['cyclostationary_mean_rr', \n",
    "                                                                         'cyclostationary_mean_rr_1w',\n",
    "                                                                         'cyclostationary_mean_rr_4w', \n",
    "                                                                         'cyclostationary_mean_rr_8w',\n",
    "                                                                         'cyclostationary_mean_rr_12w', \n",
    "                                                                         'cyclostationary_mean_rr_16w',\n",
    "                                                                         'cyclostationary_mean_rr_24w',\n",
    "                                                                         'cyclostationary_mean_tg', \n",
    "                                                                         'cyclostationary_mean_tg_1w',\n",
    "                                                                         'cyclostationary_mean_tg_4w', \n",
    "                                                                         'cyclostationary_mean_tg_8w',\n",
    "                                                                         'cyclostationary_mean_tg_12w', \n",
    "                                                                         'cyclostationary_mean_tg_16w',\n",
    "                                                                         'cyclostationary_mean_tg_24w'\n",
    "                                                                        ],\n",
    "                                                                   target_df_trainVal, \n",
    "                                                                   max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01')\n",
    "\n",
    "selected_colnames = FS_with_linearWrapper(aggregate_trainVal, target_df_train, target_df_val, 4, 228)\n",
    "\n",
    "compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6902cb5d",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual training score: 0.09538756789900393\n",
      "actual validation score: 0.3413585882489344, number of remaining columns: 491\n",
      "\n",
      "actual training score: 0.12413622082567954\n",
      "actual validation score: 0.3823725064915444, number of remaining columns: 490\n",
      "\n",
      "actual training score: 0.1577063121645781\n",
      "actual validation score: 0.4305798035991807, number of remaining columns: 489\n",
      "\n",
      "actual training score: 0.16089888118688345\n",
      "actual validation score: 0.454951000706186, number of remaining columns: 488\n",
      "\n",
      "actual training score: 0.1619751970360489\n",
      "actual validation score: 0.47202801012718687, number of remaining columns: 487\n",
      "\n",
      "actual training score: 0.16666741734387758\n",
      "actual validation score: 0.4893838983380814, number of remaining columns: 486\n",
      "\n",
      "actual training score: 0.16832225554192992\n",
      "actual validation score: 0.5037449327525447, number of remaining columns: 485\n",
      "\n",
      "actual training score: 0.19029902644129337\n",
      "actual validation score: 0.5133960361340805, number of remaining columns: 484\n",
      "\n",
      "actual training score: 0.19302748803548098\n",
      "actual validation score: 0.5225166365915893, number of remaining columns: 483\n",
      "\n",
      "\n",
      "\n",
      "selected columns: ['cyclostationary_mean_tg_1w_42', 'cyclostationary_mean_rr_8w_19', 'cyclostationary_mean_tg_4w_45', 'cyclostationary_mean_tg_4w_15', 'cyclostationary_mean_rr_16w_8', 'cyclostationary_mean_rr_16w_23', 'cyclostationary_mean_rr_8w_25', 'cyclostationary_mean_tg_24w_8', 'cyclostationary_mean_tg_4w_2', 'cyclostationary_mean_tg_24w_2'], \n",
      "\n",
      "validation score: 0.5225166365915893, \n",
      "\n",
      "number of selected features: 10\n",
      "Full aggregate regression train score: 0.9180110159940698, test score: -107.58500924872342\n",
      "Aggregate regression train score with FS: 0.32838087301627905, test score: 0.15635715548929685\n"
     ]
    }
   ],
   "source": [
    "selected_colnames = FS_with_linearWrapper(aggregate_trainVal, target_df_train, target_df_val, 9, 228)\n",
    "\n",
    "compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3392a9",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### repeating both with CMI FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b910c33f",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.214281    0.00  2001     1 -1.402730\n",
      "1    2001-01-13  0.484737    0.52  2001     2  0.347916\n",
      "2    2001-01-21  0.466071    0.47  2001     3  0.227090\n",
      "3    2001-01-29  0.417470    0.44  2001     5 -0.087501\n",
      "4    2001-02-06  0.492202    0.53  2001     6  0.396235\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "584  2013-10-21  0.739946    0.79  2013    43  1.999865\n",
      "585  2013-10-29  0.447691    0.46  2013    44  0.108118\n",
      "586  2013-11-06  0.541628    0.56  2013    45  0.716163\n",
      "587  2013-11-14  0.493719    0.53  2013    46  0.406051\n",
      "588  2013-11-22  0.527436    0.57  2013    47  0.624301\n",
      "\n",
      "[589 rows x 6 columns]\n",
      " target shapes: ((589, 6), (200, 6), (789, 6), (192, 6))\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 42\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 24\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 49\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 36\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 47\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 40\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 33\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 22\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 30\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 32\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 33\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 28\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 26\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 34\n",
      "\n",
      "----- MI Scores -----\n",
      "[(91, 0.13025442260444184), (104, 0.12954411968198004), (107, 0.12930060842544505), (34, 0.12735661415154403), (95, 0.12508311372015474), (22, 0.12457640787502305), (16, 0.12389096732880998), (108, 0.12380272997239342), (100, 0.12205087767772023), (68, 0.1207248778856905), (3, 0.11717876450201495), (36, 0.11662081584231676), (75, 0.11659370122277775), (76, 0.11571880710373471), (109, 0.11512088194382984), (82, 0.11498935133647654), (33, 0.11461501944102642), (1, 0.11381349685640879), (35, 0.11367672213664079), (110, 0.11246643122590466), (79, 0.11215952820204433), (103, 0.11210848461828989), (19, 0.11202341103410843), (2, 0.11021574132223567), (67, 0.10988399519842987), (105, 0.10830927595935283), (13, 0.10813258824327396), (74, 0.10800280889883254), (31, 0.1077407353862741), (326, 0.10743675877022264), (86, 0.10730500525647724), (73, 0.10687566484810244), (5, 0.10646284004877848), (89, 0.10626337264726811), (32, 0.10467297363692264), (38, 0.10442798710017918), (37, 0.10440178681056665), (113, 0.1038556377888575), (87, 0.1030394556654863), (25, 0.10301637582004189), (329, 0.10230666994181674), (361, 0.10090196891905488), (28, 0.10031770930194732), (99, 0.10010591688614032), (357, 0.09933945049355289), (324, 0.09905371648836954), (27, 0.09818236304075863), (111, 0.09702486740904166), (23, 0.0970176972501358), (371, 0.09655946665385019), (327, 0.09648679371093713), (360, 0.09608521290801879), (96, 0.09589408567678753), (10, 0.09482446585174789), (92, 0.09436130286755978), (98, 0.09430617494280931), (29, 0.09357829044870386), (387, 0.09343929069506912), (72, 0.09301462253181536), (355, 0.09218830070135929), (102, 0.09216544733511955), (81, 0.0920484923168466), (40, 0.09196500062112871), (6, 0.09139963476899109), (97, 0.09135572842674507), (366, 0.09088993554996724), (0, 0.09066988565786388), (358, 0.09043243935521225), (330, 0.09029500201254008), (403, 0.09020105341984963), (106, 0.09013193361125932), (359, 0.08987434338722335), (323, 0.08937458479963303), (94, 0.08931548000078562), (9, 0.08904657414825463), (393, 0.08892902015687933), (368, 0.08883873363175732), (93, 0.08858051878538803), (304, 0.08851294294966568), (337, 0.0884892952161176), (7, 0.08803355154419298), (414, 0.0877975562203877), (334, 0.08765048046750304), (69, 0.0872530044994133), (370, 0.08615868336274765), (24, 0.08566828367842573), (17, 0.08530148077231299), (78, 0.08522730870034446), (325, 0.08501614022929671), (26, 0.08428869096211221), (364, 0.08399597839124993), (85, 0.08389189662900472), (356, 0.08315802244190033), (362, 0.08314716315108961), (20, 0.08313833515488933), (303, 0.08280555723956484), (402, 0.08226524540415046), (394, 0.08203297690546478), (296, 0.0817666256114414), (328, 0.08142468951839885), (114, 0.08103471001565718), (14, 0.08085287501748403), (30, 0.08084265632820575), (295, 0.08015724712312372), (336, 0.07983956247770935), (90, 0.07970235872207178), (84, 0.0792674851365368), (369, 0.07926061805885781), (142, 0.07799093760117416), (11, 0.07774321698817134), (66, 0.07747127188891181), (88, 0.07720104742258135), (39, 0.07709168535961188), (41, 0.07700523767122837), (42, 0.07690513665580699), (112, 0.07684244562100334), (399, 0.07667333265842931), (8, 0.07659200501300852), (407, 0.07650402907606764), (386, 0.07635740754644744), (71, 0.07620790221244185), (70, 0.07576153231402616), (12, 0.07576092008133625), (21, 0.07566411324069547), (396, 0.07544532660204001), (365, 0.07482227155632692), (4, 0.07477456943299458), (83, 0.0743852861958423), (77, 0.07405399987276753), (331, 0.07359939655534767), (121, 0.07326370132509415), (367, 0.07233338505203844), (390, 0.071869358016938), (101, 0.07159759943217255), (335, 0.07151547950889464), (392, 0.07132095432926847), (376, 0.0711322123226364), (391, 0.07112035786349008), (15, 0.07091808078107092), (363, 0.07059788852256986), (437, 0.07044416523705761), (406, 0.0699198537127629), (332, 0.0694381891085606), (18, 0.06942168583008025), (398, 0.06940567073518078), (293, 0.06892161897235165), (409, 0.0684840767364467), (333, 0.06803883222358922), (338, 0.06793813631066822), (147, 0.06786864872074427), (385, 0.0678266395355323), (373, 0.06741954381207424), (435, 0.06712728626106933), (143, 0.06686681866103952), (294, 0.06646109738599457), (389, 0.06607609827442844), (438, 0.06510266610866701), (135, 0.0648837110178035), (395, 0.06474454866137838), (302, 0.06438944911315812), (150, 0.06438028551366008), (149, 0.06437496976916464), (405, 0.06399567296207001), (404, 0.06378280611368767), (45, 0.0636866034541994), (50, 0.06343157969986746), (354, 0.063231429692151), (397, 0.0632210852276573), (380, 0.06290548452655811), (416, 0.0628317685374955), (411, 0.06278413986465498), (300, 0.06262094569555787), (134, 0.06253751791911788), (117, 0.06241939197451509), (377, 0.06234173869658703), (413, 0.0622905613180909), (116, 0.062162646436021624), (410, 0.06200298303013731), (46, 0.06187456041933343), (415, 0.06182360098517152), (43, 0.061348919071963305), (412, 0.061217881733230874), (132, 0.06100571665828217), (80, 0.06091698304782747), (436, 0.06071364493387012), (315, 0.06051848328806359), (316, 0.060175537910212365), (51, 0.06017288930313072), (441, 0.059821430766467586), (343, 0.0588720593689619), (422, 0.05832449572174921), (421, 0.05818769514997557), (439, 0.05783042455810244), (375, 0.05765881351296301), (388, 0.05764299612680549), (125, 0.057594119329608486), (353, 0.05749134818854813), (122, 0.057419505666589966), (298, 0.05733400714762252), (344, 0.057204361240723), (372, 0.056775608688713675), (301, 0.05663993151976903), (47, 0.056559837990785844), (346, 0.05645204959368939), (140, 0.05617048704580777), (148, 0.05606695198997146), (382, 0.055236118855475046), (297, 0.05480554956019784), (123, 0.054737919203710524), (418, 0.05434372301691934), (400, 0.05431479815184616), (128, 0.05363686498926121), (378, 0.05350312445271631), (423, 0.05339082218234025), (299, 0.053368456102079354), (384, 0.053337865363343485), (347, 0.05313308404472807), (417, 0.05300350423252587), (153, 0.05298958103074472), (308, 0.05280832318346544), (141, 0.0523457639125481), (314, 0.05221130957772064), (374, 0.0519810767127279), (472, 0.05181697021676126), (345, 0.05177671591799043), (339, 0.051541234478957504), (425, 0.051201220300623525), (306, 0.051200911352862366), (307, 0.05092701565052617), (137, 0.050417040050765624), (159, 0.05040859736989355), (383, 0.050364227108151374), (379, 0.05031279851375313), (305, 0.05023198716069569), (434, 0.050214378818576245), (146, 0.049564543474768075), (408, 0.04948378196691886), (433, 0.049132677343688876), (428, 0.04908647022358636), (144, 0.04894048410106778), (53, 0.04862741311706546), (424, 0.04859656711327822), (48, 0.04846756931084812), (317, 0.04790159520663222), (152, 0.04788387508301101), (162, 0.047492601180904356), (426, 0.04722803462661926), (145, 0.04715710750339053), (431, 0.046903471836979856), (127, 0.046720024829078576), (52, 0.04649157327962075), (461, 0.0458400130315082), (156, 0.044339376541719426), (322, 0.044222829333499476), (291, 0.04419317991061853), (311, 0.04401722301493805), (115, 0.043713364216210665), (319, 0.04370435169705468), (119, 0.04360968894262518), (60, 0.04340525150024588), (351, 0.043158120540682625), (310, 0.043056888721610516), (348, 0.043004859153799396), (318, 0.04280782469871037), (120, 0.04265270161238712), (163, 0.04249639677173583), (451, 0.042258723414844525), (459, 0.04224119970324023), (401, 0.04223273811419301), (470, 0.04182243765849715), (166, 0.0417643808106586), (352, 0.04146747035141834), (200, 0.041435799045224785), (157, 0.04130047797077573), (430, 0.0412475303226552), (192, 0.04089675702726532), (136, 0.04088508993288274), (475, 0.04030179343528449), (309, 0.040164929234642675), (381, 0.040097508822967524), (138, 0.0400553096352811), (457, 0.03929514536580497), (65, 0.039215457428315434), (247, 0.03861921784628823), (175, 0.038548417272784775), (139, 0.03813099053675553), (44, 0.038057653745647915), (186, 0.03792271367551363), (427, 0.03779824381077755), (196, 0.03763100063385019), (174, 0.03725611386217424), (429, 0.036909453778902555), (118, 0.03675243988980057), (455, 0.03659419302974896), (449, 0.03609906321684377), (469, 0.03602631367372262), (63, 0.03602400623844905), (172, 0.03576347592886639), (471, 0.0357403764178145), (195, 0.035643087697462016), (129, 0.03545304593920217), (158, 0.03492790199973914), (54, 0.03453413976500961), (154, 0.03448580892488006), (313, 0.03447934138987345), (211, 0.03428213747592298), (446, 0.033984474325583255), (181, 0.03383294797184218), (130, 0.033783814810643964), (350, 0.03355525165677106), (341, 0.03332651213699296), (432, 0.033225783242638064), (462, 0.03283647826760953), (245, 0.03273393358782666), (56, 0.03240454801659148), (450, 0.03215585640399445), (282, 0.03209927286414418), (452, 0.032068740999349914), (320, 0.03203072402327586), (454, 0.03200094457249757), (456, 0.0319293092773562), (230, 0.03180698481044183), (184, 0.031700006868997814), (191, 0.03153311702862022), (151, 0.03152260202857779), (219, 0.031244914976392306), (443, 0.031168210776618358), (126, 0.031128681031658247), (465, 0.03107841799678587), (340, 0.030909068456568097), (419, 0.030874518677744545), (466, 0.030871781401734643), (283, 0.030702668643277), (49, 0.030273812310576895), (193, 0.03022664585423499), (161, 0.03011232904537449), (458, 0.030105499660583596), (197, 0.02990082305854266), (342, 0.029769772627392242), (286, 0.029618817777110847), (207, 0.029340284104877937), (453, 0.029228476327447215), (312, 0.029008830198092826), (467, 0.02890891937192386), (57, 0.028816475589478793), (215, 0.028759118230983087), (463, 0.028384452818881026), (182, 0.028350318562135473), (464, 0.02818226498218654), (170, 0.027857492935774743), (232, 0.02779693056946867), (199, 0.027401279383387083), (173, 0.027372266353139045), (194, 0.027317709745803203), (440, 0.02723717781855005), (188, 0.027200987610898786), (235, 0.027010998939436787), (321, 0.026656699554052168), (164, 0.026597237647858377), (62, 0.026381393154285157), (240, 0.02631889065177388), (59, 0.026138275786049797), (442, 0.026135289012200413), (271, 0.026067172910068583), (217, 0.025839823306761718), (221, 0.025771340361103224), (287, 0.025693476943449412), (218, 0.025446823487808582), (124, 0.02539670224567038), (187, 0.02536089702275713), (473, 0.025248792259492645), (185, 0.025180564608506928), (205, 0.025155365613882957), (189, 0.025008028365214815), (420, 0.024691919079652607), (285, 0.024679791651855076), (212, 0.024574321722609847), (210, 0.02453078699103753), (444, 0.02446387323402466), (61, 0.024442084975139142), (206, 0.023925767300887562), (201, 0.023884609126100187), (227, 0.023414359185650997), (448, 0.023141695492762543), (263, 0.02312987738315811), (460, 0.02312922989631555), (274, 0.02303444322934234), (256, 0.022795123096339902), (236, 0.022684200945806667), (349, 0.022345412951901938), (290, 0.022275454626092078), (266, 0.02226048207405751), (468, 0.0220987829753525), (202, 0.022022222218595143), (273, 0.021963051683284527), (447, 0.021902368124727196), (269, 0.021899250011712057), (229, 0.02180622011291434), (445, 0.021698647665469886), (131, 0.02142480681001662), (171, 0.021424156429743987), (167, 0.021204594988544632), (288, 0.021026471969028217), (160, 0.020538162615222583), (261, 0.02043650976333814), (250, 0.020317475673181196), (279, 0.020215275895327817), (233, 0.020204704941760004), (180, 0.019900357883562692), (209, 0.01952506822289559), (176, 0.019481907603943378), (178, 0.01924279279113596), (208, 0.01921779473393781), (168, 0.019068250455973695), (239, 0.01903818026411488), (272, 0.018983229699347123), (155, 0.018979214910059442), (264, 0.018872156895506385), (190, 0.018630774325397326), (133, 0.01857679083907311), (226, 0.018415151084376215), (204, 0.018350136350923165), (270, 0.018308242233447215), (216, 0.018101999497703736), (203, 0.018036131552242207), (183, 0.017742005914072437), (241, 0.017664394235574813), (228, 0.017365717657324), (246, 0.01723573060133278), (64, 0.01713286929139715), (242, 0.01685561379631922), (58, 0.015849364111258233), (284, 0.01583422971255864), (474, 0.015641110108002787), (275, 0.01516024638892173), (265, 0.015111100679481664), (177, 0.014893771820348496), (254, 0.014503121483816741), (276, 0.014437140008724012), (289, 0.013805704567524509), (244, 0.013776009963480024), (179, 0.013577189496805954), (238, 0.013534377939707765), (224, 0.01350465175354514), (292, 0.013437051330669806), (281, 0.013381477711659717), (231, 0.013340925551215249), (237, 0.013271951152160818), (278, 0.01304847666021384), (234, 0.012871010367098184), (260, 0.012717601965583279), (280, 0.012707250045467338), (259, 0.012034810345520112), (251, 0.012018803594267179), (225, 0.01195937117618997), (214, 0.011919366838561856), (169, 0.011909743773501656), (55, 0.011741265478189105), (222, 0.011135148196626254), (267, 0.011131047888878769), (249, 0.0111070012825185), (262, 0.01074361733009867), (243, 0.010706948651514678), (255, 0.010425386383011619), (165, 0.010134675822294954), (213, 0.00994146452745684), (257, 0.00846150190805076), (253, 0.0080901447387597), (220, 0.007611609713706008), (252, 0.007136100785231359), (223, 0.00646203714182556), (258, 0.006029531936669709), (268, 0.005252651000387722), (198, 0.0025917451972767487), (248, 0.0021778130901373475), (277, -0.0020737173126804723)]\n",
      "Best MI score: 0.13025442260444184\n",
      "Adding first best original feature: 91\n",
      "CMI: 0.00919903508074893\n",
      "CMI: 0.009791762656778835\n",
      "CMI: 0.007324652109007235\n",
      "CMI: 0.003942968458301027\n",
      "CMI: 0.005361682663735018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMI: 0.014764521306124295\n",
      "CMI: 0.01155985057837175\n",
      "CMI: 0.013915753712383822\n",
      "CMI: 0.0015900503930955934\n",
      "CMI: 0.0033788603349111657\n",
      "CMI: 0.010837879788728494\n",
      "CMI: 0.009848383244844106\n",
      "CMI: 0.010566960652369645\n",
      "CMI: 0.005629622419597885\n",
      "CMI: 0.002466816606560951\n",
      "CMI: 0.018733348006862938\n",
      "CMI: 0.014036405095082416\n",
      "CMI: 0.005906463494198322\n",
      "CMI: 0.0036245700942887094\n",
      "CMI: 0.0020261908111633975\n",
      "CMI: 0.013920634866697229\n",
      "CMI: 0.015869351770697843\n",
      "CMI: 0.0032992228748159047\n",
      "CMI: 0.004215557903297057\n",
      "CMI: 0.014676186958463538\n",
      "CMI: 0.018497861975337537\n",
      "CMI: 0.00811858273667293\n",
      "CMI: 0.0022491125396239264\n",
      "CMI: 0.015611954314990989\n",
      "CMI: 0.03144144835917398\n",
      "CMI: 0.008669991059011145\n",
      "CMI: 0.002590870126613687\n",
      "CMI: 0.03354697140276408\n",
      "CMI: 0.027904526432477705\n",
      "CMI: 0.020346911757795294\n",
      "CMI: 0.011203874332928465\n",
      "CMI: 0.029390074617563627\n",
      "CMI: 0.01712230868955303\n",
      "CMI: 0.004705504071314287\n",
      "CMI: 0.0008132208334366842\n",
      "CMI: 0.008743967884803527\n",
      "CMI: 0.0035194146278234306\n",
      "CMI: 0.0015572276212338643\n",
      "CMI: 0.012967610845999428\n",
      "CMI: 0.0027448572957145256\n",
      "CMI: 0.014351334681190403\n",
      "CMI: 0.002219494493934465\n",
      "CMI: 0.006398086210423065\n",
      "CMI: 0.0022446565166482357\n",
      "CMI: 0.003635640468446888\n",
      "CMI: 0.006751047739064792\n",
      "CMI: 0.005223471372461513\n",
      "CMI: 0.007998564400395952\n",
      "CMI: 0.0016111749857340985\n",
      "CMI: 0.00748811353185827\n",
      "CMI: 0.0015237951276024786\n",
      "CMI: 0.008415180918650483\n",
      "CMI: 0.009288443058397294\n",
      "CMI: 0.005916385059237278\n",
      "CMI: 0.008813323201654122\n",
      "CMI: 0.008893838843833934\n",
      "CMI: 0.008343197465503105\n",
      "CMI: 0.006975563217262698\n",
      "CMI: 0.008998303908473837\n",
      "CMI: 0.011414834504419269\n",
      "CMI: 0.0016249403939819496\n",
      "CMI: 0.00738697940977695\n",
      "CMI: 0.01193305170943526\n",
      "CMI: 0.008325853298482483\n",
      "CMI: 0.00199536392858482\n",
      "CMI: 0.0015188091932049896\n",
      "CMI: 0.006922027443991757\n",
      "CMI: 0.0027658952039885942\n",
      "CMI: 0.0022159949637570175\n",
      "CMI: 0.0035911677034480005\n",
      "CMI: 0.014020375475994246\n",
      "CMI: 0.006592063085264471\n",
      "CMI: 0.004087446081609658\n",
      "CMI: 0.0008590630193347493\n",
      "CMI: 0.005664648768281405\n",
      "CMI: 0.005178687752405403\n",
      "CMI: 0.015280381650857988\n",
      "CMI: 0.005764954244856985\n",
      "CMI: 0.012358373351538832\n",
      "CMI: 0.0018592412590510143\n",
      "CMI: 0.0023753442535270064\n",
      "CMI: 0.018211915226829245\n",
      "CMI: 0.01728170764869741\n",
      "CMI: 0.013359447216865245\n",
      "CMI: 0.007916402864092204\n",
      "CMI: 0.006710434633688256\n",
      "CMI: 0.004386347155711012\n",
      "CMI: 0.004042546319460383\n",
      "CMI: 0.0028476766359463723\n",
      "CMI: 0.00355305261440117\n",
      "CMI: 0.002216809409966436\n",
      "CMI: 0.010345280946116475\n",
      "CMI: 0.012447806392138466\n",
      "CMI: 0.007494152342802596\n",
      "CMI: 0.014902114567669128\n",
      "CMI: 0.0047509732870957555\n",
      "CMI: 0.005545456050538716\n",
      "CMI: 0.02087772732383497\n",
      "CMI: 0.028139531684154923\n",
      "CMI: 0.022428389683167377\n",
      "CMI: 0.014679128623898363\n",
      "CMI: 0.01211022005154433\n",
      "CMI: 0.014451288800380768\n",
      "CMI: 0.016481481518878544\n",
      "CMI: 0.024678218367465143\n",
      "CMI: 0.010918607265229696\n",
      "CMI: 0.01036739644982343\n",
      "CMI: 0.014785205395432266\n",
      "CMI: 0.03337235969650909\n",
      "CMI: 0.018606325732772655\n",
      "CMI: 0.01067184216761613\n",
      "CMI: 0.017673275050185067\n",
      "CMI: 0.009518514018923258\n",
      "CMI: 0.01478366840479542\n",
      "CMI: 0.010361972390277085\n",
      "CMI: 0.014170283355223717\n",
      "CMI: 0.017857157825344583\n",
      "CMI: 0.013621222928025478\n",
      "CMI: 0.006743882213743668\n",
      "CMI: 0.0065198055375877695\n",
      "CMI: 0.01108519845271111\n",
      "CMI: 0.003772551061692553\n",
      "CMI: 0.007147557404796223\n",
      "CMI: 0.011370131402817285\n",
      "CMI: 0.00596481914098268\n",
      "CMI: 0.014871604899550306\n",
      "CMI: 0.020688696051821248\n",
      "CMI: 0.017719954246447484\n",
      "CMI: 0.008008077327273766\n",
      "CMI: 0.010646474859145383\n",
      "CMI: 0.0077477627717866815\n",
      "CMI: 0.0033622259158062606\n",
      "CMI: 0.007532917809341927\n",
      "CMI: 0.008867810177309005\n",
      "CMI: 0.0047569634217565215\n",
      "CMI: 0.0155293794059434\n",
      "CMI: 0.024620987902574304\n",
      "CMI: 0.016806820760669527\n",
      "CMI: 0.019439382867695087\n",
      "CMI: 0.015831577767268484\n",
      "CMI: 0.019850352158367862\n",
      "CMI: 0.02333557107641357\n",
      "CMI: 0.0227283904733227\n",
      "CMI: 0.009573596286732156\n",
      "CMI: 0.0032710454737219785\n",
      "CMI: 0.006273914098179428\n",
      "CMI: 0.013105874843495513\n",
      "CMI: 0.019939694285586534\n",
      "CMI: 0.014780203066537212\n",
      "CMI: 0.009935656685725686\n",
      "CMI: 0.017868393814091804\n",
      "CMI: 0.0305822166304551\n",
      "CMI: 0.018133296471580296\n",
      "CMI: 0.011894341897590255\n",
      "CMI: 0.0070363834693626115\n",
      "CMI: 0.018653231719931773\n",
      "CMI: 0.013401211394315049\n",
      "CMI: 0.0024181999915521557\n",
      "CMI: 0.0012458765863734012\n",
      "CMI: 0.012612614379257259\n",
      "CMI: 0.017758944074852484\n",
      "CMI: 0.00894831394644896\n",
      "CMI: 0.014797323246262345\n",
      "CMI: 0.009456979897965512\n",
      "CMI: 0.02191532366848664\n",
      "CMI: 0.02446885235543078\n",
      "CMI: 0.0077235168794106135\n",
      "CMI: 0.014642499036330414\n",
      "CMI: 0.0045977527545842944\n",
      "CMI: 0.005637747840287283\n",
      "CMI: 0.00040236147196962\n",
      "CMI: 0.003792221497797482\n",
      "CMI: 0.009405206814743633\n",
      "CMI: 0.0013595729257078193\n",
      "CMI: 0.009250382944750446\n",
      "CMI: 0.024382007545994844\n",
      "CMI: 0.004245794514251278\n",
      "CMI: 0.016215646435973396\n",
      "CMI: 0.0005802757098632982\n",
      "CMI: 0.008563876522188762\n",
      "CMI: 0.008353492852441996\n",
      "CMI: 0.018439091292938192\n",
      "CMI: 0.01119338095638639\n",
      "CMI: 0.03759581519012822\n",
      "CMI: 0.011556384269373055\n",
      "CMI: 0.019409031712079666\n",
      "CMI: 0.0010812881632906723\n",
      "CMI: 0.00766721583051741\n",
      "CMI: 0.00831127133745413\n",
      "CMI: 0.008194793007636397\n",
      "CMI: 0.007050427543859067\n",
      "CMI: 0.011086842218412024\n",
      "CMI: 0.008920253986449439\n",
      "CMI: 0.01200784503864985\n",
      "CMI: 0.016396249195777507\n",
      "CMI: 0.019424901359583996\n",
      "CMI: 0.00787245654226737\n",
      "CMI: 0.010521685447229479\n",
      "CMI: 0.011996120405563193\n",
      "CMI: 0.007577503766643762\n",
      "CMI: 0.006150450176053285\n",
      "CMI: 0.003733218556722706\n",
      "CMI: 0.005096380398999706\n",
      "CMI: 0.01773941247760047\n",
      "CMI: 0.00802643205907741\n",
      "CMI: 0.012410380087019557\n",
      "CMI: 0.015950783030571625\n",
      "CMI: 0.026720259405540736\n",
      "CMI: 0.003313615515844248\n",
      "CMI: 0.008673876551503673\n",
      "CMI: 0.011022575105668841\n",
      "CMI: 0.003941759793465893\n",
      "CMI: 0.012937348398932541\n",
      "CMI: 0.001612205781910514\n",
      "CMI: 0.003425332512168394\n",
      "CMI: 0.00687733462147988\n",
      "CMI: 0.006917539569563674\n",
      "CMI: 0.022209761087171986\n",
      "CMI: 0.02214713214130845\n",
      "CMI: 0.00786877639173833\n",
      "CMI: 0.006088072813409839\n",
      "CMI: 0.0011517309040957047\n",
      "CMI: 0.006859387253393245\n",
      "CMI: 0.009158861270036678\n",
      "CMI: 0.00818731943600634\n",
      "CMI: 0.02365538840615819\n",
      "CMI: 0.03658118452273326\n",
      "CMI: 0.021072141756526497\n",
      "CMI: 0.03568079410847394\n",
      "CMI: 0.021308573256578534\n",
      "CMI: 0.017235195473417564\n",
      "CMI: 0.026829207096832897\n",
      "CMI: 0.019608824617501935\n",
      "CMI: 0.013132023926352515\n",
      "CMI: 0.015414859154061739\n",
      "CMI: 0.03540820723565316\n",
      "CMI: 0.05067794112218971\n",
      "CMI: 0.016558522823144045\n",
      "CMI: 0.00841974014988342\n",
      "CMI: 0.007028049360755101\n",
      "CMI: 0.007723001782844241\n",
      "CMI: 0.002505219619123422\n",
      "CMI: 0.013124972762182163\n",
      "CMI: 0.004939921758158217\n",
      "CMI: 0.004943216601010519\n",
      "CMI: 0.004281959723034301\n",
      "CMI: 0.012382098639593664\n",
      "CMI: 0.024878204249452557\n",
      "CMI: 0.02004647861888781\n",
      "CMI: 0.008278112270577093\n",
      "CMI: 0.009122230910492357\n",
      "CMI: 0.014182359970974528\n",
      "CMI: 0.010297295937590378\n",
      "CMI: 0.01554444467933594\n",
      "CMI: 0.038193047909213934\n",
      "CMI: 0.0607619400751232\n",
      "CMI: 0.04406045546066331\n",
      "CMI: 0.07169738392913616\n",
      "CMI: 0.05862385437866677\n",
      "CMI: 0.04155935101125696\n",
      "CMI: 0.061210598772740626\n",
      "CMI: 0.05190932499174636\n",
      "CMI: 0.04894311136163074\n",
      "CMI: 0.04073332567894744\n",
      "CMI: 0.03890013878590165\n",
      "CMI: 0.05477363800588861\n",
      "CMI: 0.03426681273473042\n",
      "CMI: 0.04862723791287027\n",
      "CMI: 0.06401771629123654\n",
      "CMI: 0.03751201401711787\n",
      "CMI: 0.025921261621182884\n",
      "CMI: 0.021331752297551576\n",
      "CMI: 0.02338218565910588\n",
      "CMI: 0.008682409473312391\n",
      "CMI: 0.03330283081740512\n",
      "CMI: 0.02989971658582352\n",
      "CMI: 0.018214002816207053\n",
      "CMI: 0.032341476908445466\n",
      "CMI: 0.022836897502411663\n",
      "CMI: 0.014841661852730476\n",
      "CMI: 0.01328355291696276\n",
      "CMI: 0.011334595806136771\n",
      "CMI: 0.016463642692646968\n",
      "CMI: 0.012071095614919786\n",
      "CMI: 0.02375150529874054\n",
      "CMI: 0.020954576445947642\n",
      "CMI: 0.07464080105238216\n",
      "CMI: 0.06198036195444423\n",
      "CMI: 0.05830703595630593\n",
      "CMI: 0.05102062553515366\n",
      "CMI: 0.06000419121947842\n",
      "CMI: 0.052695446161898196\n",
      "CMI: 0.060764835560627145\n",
      "CMI: 0.06861642836449988\n",
      "CMI: 0.0514486562178848\n",
      "CMI: 0.0611511938468734\n",
      "CMI: 0.05471590345795038\n",
      "CMI: 0.06125413258011858\n",
      "CMI: 0.026718851693353196\n",
      "CMI: 0.04486327379753213\n",
      "CMI: 0.011504782562318738\n",
      "CMI: 0.04290122014232467\n",
      "CMI: 0.04996661826147375\n",
      "CMI: 0.048543653875113946\n",
      "CMI: 0.043840481094835654\n",
      "CMI: 0.046199595865619836\n",
      "CMI: 0.04741317070760925\n",
      "CMI: 0.055217167622520436\n",
      "CMI: 0.03353840855401069\n",
      "CMI: 0.048818876476768774\n",
      "CMI: 0.0261085061434215\n",
      "CMI: 0.04091303793467482\n",
      "CMI: 0.02747625394045447\n",
      "CMI: 0.02769438792995818\n",
      "CMI: 0.039001613925952305\n",
      "CMI: 0.03143776167709664\n",
      "CMI: 0.06198784938657323\n",
      "CMI: 0.030248388725137354\n",
      "CMI: 0.05575041820584567\n",
      "CMI: 0.04553263254500292\n",
      "CMI: 0.0470213854949548\n",
      "CMI: 0.028598157622074127\n",
      "CMI: 0.03380948322706456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMI: 0.0400821644955352\n",
      "CMI: 0.05556460239512129\n",
      "CMI: 0.05207644667063843\n",
      "CMI: 0.03859829554090935\n",
      "CMI: 0.03394671715156411\n",
      "CMI: 0.04553702406849666\n",
      "CMI: 0.04349166860322293\n",
      "CMI: 0.048603110988769266\n",
      "CMI: 0.02826594076423769\n",
      "CMI: 0.024825036135411788\n",
      "CMI: 0.04798883648998353\n",
      "CMI: 0.041116805608776674\n",
      "CMI: 0.04413246808773677\n",
      "CMI: 0.0324522997531585\n",
      "CMI: 0.04401018466232279\n",
      "CMI: 0.04834135457002317\n",
      "CMI: 0.02431762681912336\n",
      "CMI: 0.05380304086123236\n",
      "CMI: 0.039380931396822944\n",
      "CMI: 0.03368394192690888\n",
      "CMI: 0.037235234251472654\n",
      "CMI: 0.02595816128550163\n",
      "CMI: 0.04070367364864208\n",
      "CMI: 0.023326229117770936\n",
      "CMI: 0.02768894819870052\n",
      "CMI: 0.029591434206267697\n",
      "CMI: 0.016586243988400584\n",
      "CMI: 0.008052729730355479\n",
      "CMI: 0.03222084635367439\n",
      "CMI: 0.02781050015620834\n",
      "CMI: 0.02540393790925896\n",
      "CMI: 0.0232472314179209\n",
      "CMI: 0.02396490965643483\n",
      "CMI: 0.02409518071165309\n",
      "CMI: 0.0025882626326009517\n",
      "CMI: 0.03070132283631491\n",
      "CMI: 9.734900407623592e-05\n",
      "CMI: 0.010954080187346393\n",
      "CMI: 0.01202790299119047\n",
      "CMI: 0.006688440531925383\n",
      "CMI: 0.003641647988278679\n",
      "CMI: 0.030992749447784906\n",
      "CMI: 0.04385453868270281\n",
      "CMI: 0.04197693241926145\n",
      "CMI: 0.05385056065076052\n",
      "CMI: 0.035618863231304976\n",
      "CMI: 0.013549953587530139\n",
      "CMI: 0.015066182687127977\n",
      "CMI: 0.012173453091689601\n",
      "CMI: 0.007454846268370147\n",
      "CMI: 0.011750228761156889\n",
      "CMI: 0.01355979741498095\n",
      "CMI: 0.006824763138997936\n",
      "CMI: 0.010194619558075518\n",
      "CMI: 0.017726050574876667\n",
      "CMI: 0.016509090111554214\n",
      "CMI: 0.025779133919184044\n",
      "CMI: 0.01697434389051139\n",
      "CMI: 0.013704820191589945\n",
      "CMI: 0.006765811504522712\n",
      "CMI: 0.012509896552789501\n",
      "CMI: 0.01798000257601015\n",
      "CMI: 0.008225790413526002\n",
      "CMI: 0.0043777696060012805\n",
      "CMI: 0.0041546485507592545\n",
      "CMI: 0.016226732549391998\n",
      "CMI: 0.0019818011266360125\n",
      "CMI: 0.02560329105101261\n",
      "CMI: 0.01176302153393688\n",
      "CMI: 0.02227349583821961\n",
      "CMI: 0.018369179698229765\n",
      "CMI: 0.02830432786524975\n",
      "CMI: 0.016469942184699188\n",
      "CMI: 0.0026227496209146883\n",
      "CMI: 0.0273555549099585\n",
      "CMI: 0.014129791390380314\n",
      "CMI: 0.01938942183593495\n",
      "CMI: 0.009916685771125783\n",
      "CMI: 0.016381646358087865\n",
      "CMI: 0.01496030350348529\n",
      "CMI: 0.01500898033265427\n",
      "Highest CMI score: 0.07464080105238216\n",
      "Adding original feature: 355\n",
      "CMI: 0.001879357373532925\n",
      "CMI: 0.004429599686773228\n",
      "CMI: 0.010765716464889274\n",
      "CMI: 0.009488410337649411\n",
      "CMI: 0.0017611752126427127\n",
      "CMI: 0.005691320125400051\n",
      "CMI: 0.005901030157170112\n",
      "CMI: 0.0016081611260242712\n",
      "CMI: 0.01063815825528186\n",
      "CMI: 0.006219984501212278\n",
      "CMI: 0.00265165813856022\n",
      "CMI: 0.003926323935488446\n",
      "CMI: 0.005481272124427394\n",
      "CMI: 0.0018501628925177704\n",
      "CMI: 0.003664621121032857\n",
      "CMI: 0.0006962137503162547\n",
      "CMI: 0.0022578857119999185\n",
      "CMI: 0.0029910907900838335\n",
      "CMI: 0.0004255146181356695\n",
      "CMI: 0.00038925428154235053\n",
      "CMI: 0.00582446742192827\n",
      "CMI: 0.0009962027170945797\n",
      "CMI: 0.00034280297209501875\n",
      "CMI: 0.00011796346364031929\n",
      "CMI: 0.0057541754955587054\n",
      "CMI: 0.009846897764555773\n",
      "CMI: 0.0021028240577931068\n",
      "CMI: 0.010262686440436875\n",
      "CMI: 0.0006646740308302035\n",
      "CMI: 0.00034738268524442395\n",
      "CMI: 0.002334175634490121\n",
      "CMI: 0.00022104663683905623\n",
      "CMI: 0.006687866979195767\n",
      "CMI: 0.008693239847992612\n",
      "CMI: 0.012518117543999202\n",
      "CMI: 0.0016139711127410028\n",
      "CMI: 0.00560853652236476\n",
      "CMI: 0.008795382030737348\n",
      "CMI: 0.00680520714663943\n",
      "CMI: 0.010229505479899204\n",
      "CMI: 0.004124922669406533\n",
      "CMI: 0.00553706649570998\n",
      "CMI: 0.004957089899957384\n",
      "CMI: 0.004420385679011762\n",
      "CMI: 0.013572566108964346\n",
      "CMI: 0.0065775283244702\n",
      "CMI: 0.007630130197471635\n",
      "CMI: 0.016793206075781025\n",
      "CMI: 0.006048735761672364\n",
      "CMI: 0.007856759263779933\n",
      "CMI: 0.009580063862524774\n",
      "CMI: 0.0013627030252714167\n",
      "CMI: 0.00402932498695921\n",
      "CMI: 0.0003399910518773197\n",
      "CMI: 0.00815159118990344\n",
      "CMI: 0.001294657864547355\n",
      "CMI: 0.010037732086923323\n",
      "CMI: 0.010409459820768324\n",
      "CMI: 0.010982473014307076\n",
      "CMI: 0.0023290155303852533\n",
      "CMI: 0.0011716445668861208\n",
      "CMI: 0.0011194679182430778\n",
      "CMI: 0.013664187300921865\n",
      "CMI: 0.010413331917390467\n",
      "CMI: 0.008449712436465806\n",
      "CMI: 0.00013831596633578913\n",
      "CMI: 0.005099102358341101\n",
      "CMI: 0.005408692398764264\n",
      "CMI: 0.00030309286276736236\n",
      "CMI: 0.005229506266010375\n",
      "CMI: 0.006482521109207884\n",
      "CMI: 0.0043057776861769315\n",
      "CMI: 0.009502345009216567\n",
      "CMI: 0.003504895726924112\n",
      "CMI: 0.0031013324893816863\n",
      "CMI: 0.020798545568336074\n",
      "CMI: 0.005512624361825674\n",
      "CMI: 0.008464944701831456\n",
      "CMI: 0.0019867079414604694\n",
      "CMI: 0.0044110897445129305\n",
      "CMI: 0.004954399869462223\n",
      "CMI: 0.00497262857826658\n",
      "CMI: 0.011431825153262909\n",
      "CMI: 0.010231434539668599\n",
      "CMI: 0.00591656488806086\n",
      "CMI: 0.0009541391790015841\n",
      "CMI: 0.007045620477645453\n",
      "CMI: 0.004194860006958845\n",
      "CMI: 0.017759571366893684\n",
      "CMI: 0.00031022404793529246\n",
      "CMI: 0.0021982815337141526\n",
      "CMI: 0.004237346466091696\n",
      "CMI: 0.0007946375696022967\n",
      "CMI: 0.0029989628077521646\n",
      "CMI: 0.006866586719237927\n",
      "CMI: 0.005482042476588539\n",
      "CMI: 0.0006799130557894606\n",
      "CMI: 0.00582139171535026\n",
      "CMI: 0.00079072900652008\n",
      "CMI: 0.003714917177069732\n",
      "CMI: 0.001023932597427668\n",
      "CMI: 0.00342872485703416\n",
      "CMI: 0.012282266993017737\n",
      "CMI: 0.0014396960368336376\n",
      "CMI: 0.0050352590488225435\n",
      "CMI: 0.006763410003082698\n",
      "CMI: 0.006394409101167425\n",
      "CMI: 0.004251527868555094\n",
      "CMI: 0.006900537318413752\n",
      "CMI: 0.0006420040350990086\n",
      "CMI: 0.0015467993448371742\n",
      "CMI: 0.0043741054016521175\n",
      "CMI: 5.7084077790647836e-05\n",
      "CMI: 0.0016274398463467787\n",
      "CMI: 0.006041905060268887\n",
      "CMI: 0.009953326664643769\n",
      "CMI: 0.0012349245168473688\n",
      "CMI: 0.007137406535985408\n",
      "CMI: 0.004631496720788164\n",
      "CMI: 0.0029777690849246974\n",
      "CMI: 0.0024607273180008993\n",
      "CMI: 0.003971374869101318\n",
      "CMI: 0.008012716488844801\n",
      "CMI: 0.0011766575593402662\n",
      "CMI: 0.0015288644227537673\n",
      "CMI: 0.009406101001441763\n",
      "CMI: 0.006415033946305687\n",
      "CMI: 0.0020081398741191303\n",
      "CMI: 0.0009131132627329674\n",
      "CMI: 0.0023949605424108678\n",
      "CMI: 0.0041848355991154496\n",
      "CMI: 0.010630425662863818\n",
      "CMI: 0.0036831697742641945\n",
      "CMI: 0.00830221612673468\n",
      "CMI: 0.009187708135477174\n",
      "CMI: 0.00895362593089094\n",
      "CMI: 0.00012384560558842406\n",
      "CMI: 0.00037657690440329183\n",
      "CMI: 0.00306319232725219\n",
      "CMI: 9.694911603255751e-05\n",
      "CMI: 0.005062953259147185\n",
      "Highest CMI score: 0.020798545568336074\n",
      "Adding original feature: 211\n",
      "CMI: 0.001478868955750584\n",
      "CMI: 0.0015291815367456107\n",
      "CMI: 0.0016116088878660728\n",
      "CMI: 0.000316063130547356\n",
      "CMI: 0.0016543187039683993\n",
      "CMI: 0.0006012753960649708\n",
      "CMI: 0.00451191154955341\n",
      "CMI: 0.007144238972812245\n",
      "CMI: 0.001644635957654933\n",
      "CMI: 0.002083374472967886\n",
      "CMI: 0.004249974024481906\n",
      "CMI: 0.007819205243305455\n",
      "CMI: 0.0013519617354602886\n",
      "CMI: 0.003291447741185838\n",
      "CMI: 0.0056285924637007045\n",
      "CMI: 8.426528691332646e-05\n",
      "CMI: 0.0038155517588744914\n",
      "CMI: 0.004274341574139973\n",
      "CMI: 0.0003664023688279838\n",
      "CMI: 0.00234533961964814\n",
      "CMI: 0.0059712307121638775\n",
      "CMI: 7.433808200410508e-05\n",
      "CMI: 0.001755746088007215\n",
      "CMI: 6.927149426577683e-05\n",
      "CMI: 0.0015635913438554472\n",
      "CMI: 0.0044064702791070665\n",
      "Highest CMI score: 0.007819205243305455\n",
      "Adding original feature: 326\n",
      "CMI: 0.0008756316301752609\n",
      "CMI: 0.003348203133961447\n",
      "CMI: 0.0003789767052638504\n",
      "CMI: 0.003839176489456697\n",
      "CMI: 0.0030191472482778425\n",
      "CMI: 0.0012018612616261082\n",
      "CMI: 0.0013238009339088253\n",
      "CMI: 0.000634219461090435\n",
      "CMI: 0.002189522769942248\n",
      "CMI: 0.0019019484345904891\n",
      "CMI: 0.0028805032335849634\n",
      "CMI: 0.0002004117066461697\n",
      "CMI: 0.0029893651543519417\n",
      "CMI: 0.0016104613472488205\n",
      "CMI: 0.0013537306685553474\n",
      "CMI: 0.0003123555438543091\n",
      "CMI: 0.0002149129329190591\n",
      "Highest CMI score: 0.003839176489456697\n",
      "Adding original feature: 75\n",
      "CMI: 0.002574089134279145\n",
      "CMI: 0.0005198711259262467\n",
      "CMI: 0.0015840717398485082\n",
      "CMI: 0.0016137503719257928\n",
      "CMI: 0.0021164383354814187\n",
      "CMI: 0.0029416601838410106\n",
      "Highest CMI score: 0.0029416601838410106\n",
      "Adding original feature: 245\n",
      "Highest CMI score: -0.0010742561707872689\n",
      "\n",
      "[91, 355, 211, 326, 75, 245]\n",
      "\n",
      "Full aggregate regression train score: 0.8501602784300542, test score: -19.266049022340347\n",
      "Aggregate regression train score with FS: 0.2261007603140146, test score: 0.12625966224462537\n"
     ]
    }
   ],
   "source": [
    "target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target('')\n",
    "\n",
    "output,aggregate_trainVal,aggregate_test = aggregate_unfolded_data(path,['cyclostationary_mean_tg',\n",
    "       'cyclostationary_mean_rr', 'cyclostationary_mean_tg_1w',\n",
    "       'cyclostationary_mean_tg_4w', 'cyclostationary_mean_tg_8w',\n",
    "       'cyclostationary_mean_tg_12w', 'cyclostationary_mean_tg_16w',\n",
    "       'cyclostationary_mean_tg_24w', 'cyclostationary_mean_rr_1w',\n",
    "       'cyclostationary_mean_rr_4w', 'cyclostationary_mean_rr_8w',\n",
    "       'cyclostationary_mean_rr_12w', 'cyclostationary_mean_rr_16w',\n",
    "       'cyclostationary_mean_rr_24w'],target_df_trainVal)\n",
    "\n",
    "res = {\n",
    "    \"delta\" : [], # list with all deltas\n",
    "    \"numSelected\" : [], #\n",
    "    \"selectedFeatures\" : [] \n",
    "}\n",
    "\n",
    "res['selectedFeatures'] = forwardFeatureSelection(10,np.array(aggregate_trainVal),np.array(target_df_trainVal.mean_std),res,20,1)\n",
    "selectedFeatures='selectedFeatures'\n",
    "print(f'\\n{res[selectedFeatures]}\\n')\n",
    "selected_colnames = aggregate_trainVal.columns[res['selectedFeatures']]\n",
    "compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61efb7ec",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "3\n",
      "4\n",
      "7\n",
      "8\n",
      "13\n",
      "14\n",
      "16\n",
      "21\n",
      "25\n",
      "27\n",
      "----- MI Scores -----\n",
      "[(8, 0.1410706468750247), (2, 0.13732920520146047), (6, 0.13369491633190958), (1, 0.11154320219722483), (11, 0.10464260959049179), (10, 0.09943328430139721), (4, 0.09631917723714903), (5, 0.08833739742620962), (9, 0.08599091958130035), (0, 0.08492510702855696), (7, 0.07277371050492143), (3, 0.061168529124984654)]\n",
      "Best MI score: 0.1410706468750247\n",
      "Adding first best original feature: 8\n",
      "CMI: 0.008524838022175546\n",
      "CMI: 0.004859100468180888\n",
      "Highest CMI score: 0.008524838022175546\n",
      "Adding original feature: 1\n",
      "Highest CMI score: -0.009526272891657361\n",
      "\n",
      "[8, 1]\n",
      "\n",
      "Full aggregate regression train score: 0.18332002993362595, test score: 0.05227427489662784\n",
      "Aggregate regression train score with FS: 0.12608543730146393, test score: 0.04707773057354592\n"
     ]
    }
   ],
   "source": [
    "### repeat keeping features with at least three cells\n",
    "ii = []\n",
    "for i in range(len(output)):\n",
    "    if (len(output[i]))>=3: \n",
    "        print(i)\n",
    "        ii.append(i)\n",
    "\n",
    "res = {\n",
    "    \"delta\" : [], # list with all deltas\n",
    "    \"numSelected\" : [], #\n",
    "    \"selectedFeatures\" : [] \n",
    "#    \"accuracy\" : [] # list of scores associated with the reduced problem\n",
    "}\n",
    "\n",
    "res['selectedFeatures'] = forwardFeatureSelection(10,np.array(aggregate_trainVal.iloc[:,ii]),np.array(target_df_trainVal.mean_std),res,10,1)\n",
    "selectedFeatures='selectedFeatures'\n",
    "print(f'\\n{res[selectedFeatures]}\\n')\n",
    "selected_colnames = aggregate_trainVal.iloc[:,ii].columns[res['selectedFeatures']]\n",
    "compare_methods(aggregate_trainVal.iloc[:,ii], aggregate_test.iloc[:,ii], target_df_trainVal, target_df_test, selected_colnames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "60333e98",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.214281    0.00  2001     1 -1.339879\n",
      "1    2001-01-13  0.484737    0.52  2001     2  0.402993\n",
      "2    2001-01-21  0.466071    0.47  2001     3  0.282703\n",
      "3    2001-01-29  0.417470    0.44  2001     5 -0.030490\n",
      "4    2001-02-06  0.492202    0.53  2001     6  0.451097\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.436464    0.46  2009    48  0.091910\n",
      "407  2009-12-05  0.466152    0.49  2009    49  0.283224\n",
      "408  2009-12-13  0.553659    0.59  2009    50  0.847138\n",
      "409  2009-12-21  0.507978    0.65  2009    52  0.552758\n",
      "410  2009-12-29  0.083046    0.00  2009    53 -2.185583\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 41\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 28\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 49\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 48\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 40\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 32\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 30\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 25\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 29\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 36\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 39\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 33\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 27\n",
      "\n",
      "Number of features: 130\n",
      "\n",
      "Number of aggregated features: 36\n",
      "\n",
      "----- MI Scores -----\n",
      "[(93, 0.13581585309537378), (1, 0.13505461083647102), (17, 0.1336253951612861), (22, 0.13292394575475824), (35, 0.1314947303492075), (109, 0.13069123294496232), (13, 0.13043798808455945), (102, 0.12875304464935164), (339, 0.12874077211883111), (333, 0.1277889705384366), (369, 0.1268241207271313), (78, 0.12671700820733212), (103, 0.1248562685125378), (88, 0.12479126466694364), (106, 0.12463846662517435), (2, 0.12455630733277606), (10, 0.12445953011926814), (33, 0.12383644035918981), (377, 0.12362241069655744), (34, 0.12351615803964139), (94, 0.12341128944924201), (334, 0.12310963255758561), (105, 0.12256467225678017), (423, 0.12248755184188319), (362, 0.12202512000507912), (359, 0.12118812921120199), (70, 0.12011406211181495), (6, 0.1191326366947945), (363, 0.1188979599205249), (111, 0.1173352308158649), (37, 0.11677572043276202), (85, 0.11643049112680165), (71, 0.11620479481131091), (329, 0.11617043840737115), (325, 0.11608304177197297), (447, 0.11563245157183769), (81, 0.11542326787804412), (360, 0.11535152539357396), (110, 0.11503497437329975), (323, 0.11387243468032031), (19, 0.11134774938980065), (92, 0.11092699794197866), (361, 0.11083440787028744), (403, 0.11066282094179933), (5, 0.11013559411702513), (15, 0.10933694055031372), (326, 0.10933154474462303), (322, 0.10895572714111289), (428, 0.10778898841213953), (101, 0.10762764009133689), (373, 0.10652517919708691), (26, 0.10639343474232596), (90, 0.1062471319683625), (77, 0.10603735253034889), (332, 0.10500599147787323), (370, 0.10487806559522687), (425, 0.10485553478916006), (396, 0.10432868907585176), (27, 0.10413574714800101), (32, 0.1031824211131886), (31, 0.10303043561142895), (112, 0.1011749499746129), (24, 0.10117477263442257), (30, 0.10115891091565443), (36, 0.10089751960238888), (389, 0.10085653577289384), (358, 0.1006520701634717), (0, 0.10061050366701373), (375, 0.1005772369283381), (328, 0.10044235462154422), (97, 0.09967451194068722), (113, 0.09952082319809791), (11, 0.09928800055862086), (448, 0.09891257290571968), (25, 0.09837955367460148), (152, 0.09831081574927145), (394, 0.09797853978313026), (384, 0.09722552222469123), (7, 0.09716249084528307), (104, 0.09715486754501293), (38, 0.09674503527089101), (371, 0.09630490915814505), (29, 0.09628861105514297), (342, 0.09622233508029267), (364, 0.09609351774361964), (28, 0.09548894517094199), (115, 0.09512734091593773), (402, 0.0950859084301944), (3, 0.09501019884305828), (8, 0.0946340510559481), (372, 0.0945751918604273), (417, 0.09446552102853588), (331, 0.09443722098287688), (40, 0.09396003052002877), (107, 0.09379158058855251), (382, 0.09332681843211767), (419, 0.09284258145229847), (418, 0.09192287588956692), (164, 0.09139628132408192), (368, 0.09136991446297459), (100, 0.09077826136273147), (125, 0.09076136385371739), (133, 0.09047532970765305), (128, 0.09040488088179521), (338, 0.09024307694145309), (427, 0.09016260988289293), (16, 0.0892798383541589), (335, 0.08885480089615277), (378, 0.08849146956311622), (43, 0.08830413469347519), (420, 0.08791443245455235), (4, 0.08785533209619939), (416, 0.08740145995786931), (387, 0.086599576938982), (327, 0.08657320807606614), (414, 0.0858237787122887), (449, 0.08559078513212498), (52, 0.08551713286237457), (404, 0.08535650944709175), (395, 0.08520857772652254), (450, 0.08496959222216273), (108, 0.08454515140876795), (98, 0.08401358168175745), (84, 0.08341497772267857), (48, 0.08318729936411873), (50, 0.08252158915719636), (20, 0.08246163579244427), (393, 0.08235748536806167), (399, 0.0823423212624834), (336, 0.08223960459558932), (295, 0.08184596859537661), (412, 0.0818142502356242), (349, 0.08179196380125643), (397, 0.08124394636714695), (421, 0.08114991093023914), (23, 0.08109352622457383), (408, 0.08083809853790286), (296, 0.08079358266104533), (76, 0.08066084321572295), (357, 0.08019292388332039), (367, 0.0800375887670078), (385, 0.07983519728140855), (330, 0.07973933216048419), (139, 0.0796526979350869), (73, 0.07936131917629609), (96, 0.07928735414262464), (39, 0.07921842318994085), (41, 0.07919816591699666), (75, 0.07873902596188526), (167, 0.07854710525011586), (383, 0.07809976178076884), (216, 0.07773411277758398), (83, 0.07748313038987), (69, 0.07710592805882054), (431, 0.07709774947080195), (305, 0.07676022634465368), (18, 0.07671004309464893), (366, 0.07618512931297902), (143, 0.07573973721434103), (424, 0.0756550605045837), (430, 0.07565090790676078), (117, 0.07529382125049738), (337, 0.075240657163634), (86, 0.07521919956605369), (74, 0.07521787057510441), (119, 0.07516164261468143), (21, 0.07509211772700959), (151, 0.07506630311402361), (163, 0.07503761576346638), (99, 0.07466805230632648), (388, 0.07450464987300101), (380, 0.07427040916603465), (297, 0.07418369891142562), (95, 0.07392047929150586), (287, 0.07352278304638972), (302, 0.07340150656469692), (45, 0.07326593931401697), (398, 0.07317261999019893), (354, 0.07278679064095768), (324, 0.07272607982751346), (126, 0.07262585317719782), (400, 0.07239218139976458), (453, 0.07218770062233695), (411, 0.07145653509598722), (435, 0.07136613079324114), (89, 0.07128216030915008), (422, 0.07127050440804596), (341, 0.07126718443605692), (213, 0.07115344249988176), (321, 0.07113102186050821), (386, 0.07092826702581531), (53, 0.07085772998788138), (91, 0.07069319444494178), (54, 0.07057853400969465), (80, 0.0701211291001197), (410, 0.06984234967381661), (160, 0.06974810067015934), (439, 0.0696491492648051), (484, 0.06945520476092312), (318, 0.06923981802712093), (306, 0.06908696625454265), (432, 0.06905131126122972), (405, 0.06896951017938323), (178, 0.06847564569702963), (72, 0.06844754374548231), (347, 0.06824207512210084), (51, 0.0682046530932125), (156, 0.0681128062203191), (376, 0.06791295008218223), (116, 0.06788241276823238), (121, 0.06787184036295321), (291, 0.06653777766551189), (413, 0.06645457694719367), (215, 0.06627165555179411), (345, 0.066237965365808), (232, 0.06573008402412606), (157, 0.06554679770153546), (379, 0.06461887403130785), (169, 0.06451571707504446), (155, 0.06427469138682587), (452, 0.06423005385422949), (350, 0.06415326246319811), (58, 0.06400231812433886), (308, 0.06388662866197796), (429, 0.0635229078736756), (136, 0.06321376970369103), (168, 0.06318841145009689), (442, 0.06300822397877645), (141, 0.06293043539063084), (440, 0.06273504854509265), (203, 0.062416923645066034), (307, 0.062347961431916156), (406, 0.06176069355862116), (150, 0.06173854401454857), (300, 0.06167119769831247), (12, 0.06154465928566862), (316, 0.061513195655229405), (401, 0.06144869329526968), (407, 0.0610668510904228), (154, 0.060739526347093606), (127, 0.060685142982779966), (314, 0.06063881352425037), (294, 0.06056925911008613), (82, 0.06008429478640214), (434, 0.05994415060594731), (148, 0.059820196213249195), (87, 0.05970092288175496), (381, 0.059530129315578516), (456, 0.05943450624353), (298, 0.05940627859028981), (64, 0.05935953452744363), (247, 0.059274597165965726), (79, 0.05921769544787926), (240, 0.058974523487543944), (320, 0.05854085083283541), (374, 0.05846669560674659), (135, 0.0584638483747493), (147, 0.058338256554613076), (340, 0.05825889791770142), (219, 0.05815778989392451), (132, 0.05789777609914177), (455, 0.0576787254935376), (172, 0.05740025368787109), (299, 0.0573051794509041), (153, 0.05685759281983422), (46, 0.05682607547322715), (120, 0.05670929562606272), (482, 0.05665872951676962), (114, 0.05660301114055047), (310, 0.0565976017127121), (176, 0.056115968859696726), (186, 0.05605514964964765), (9, 0.05583991557037529), (415, 0.055748324720710146), (134, 0.055700664089196314), (426, 0.05569700204644676), (250, 0.05546348664615895), (14, 0.05502074429926837), (59, 0.05498995269556534), (390, 0.05466236523950021), (177, 0.0546422361056572), (437, 0.054577332300283096), (353, 0.054417100059385985), (181, 0.05441015991617992), (243, 0.05342753753566159), (391, 0.05338055505948762), (477, 0.052943818652145584), (293, 0.05285327081871651), (197, 0.052671985222242194), (303, 0.052640118968373825), (146, 0.05251133668895218), (312, 0.05244792035275058), (209, 0.052200116565193015), (144, 0.052029365748566404), (443, 0.051993034239991055), (171, 0.05129915613586238), (138, 0.05096806992257548), (204, 0.05078096057462939), (309, 0.050753384023954476), (159, 0.050569098788132594), (392, 0.05049155692907435), (200, 0.05010637686748453), (458, 0.05009227589148163), (283, 0.050035005962793554), (446, 0.050019965677935534), (67, 0.04997633280479427), (315, 0.049619919545624114), (192, 0.049494608824159805), (149, 0.049399680317400205), (472, 0.04882932188752801), (249, 0.04848227167378126), (454, 0.04831588823978645), (137, 0.04826434593343344), (180, 0.04798453195178872), (66, 0.04773844477463132), (61, 0.04759884972003266), (140, 0.04758562455990436), (56, 0.0474663158170742), (202, 0.047449465763849945), (201, 0.04723947724479487), (348, 0.047176768959211725), (481, 0.04703969067022719), (161, 0.046798016015657), (162, 0.04667272286054657), (441, 0.046641150272925515), (489, 0.04583676988609705), (145, 0.0458146716420928), (313, 0.04565621447539726), (438, 0.045494238912744636), (205, 0.04507816558290335), (365, 0.045023337579436315), (142, 0.04495471176561488), (187, 0.044911000097635594), (463, 0.04475520599929371), (42, 0.044752993361387654), (235, 0.04473315235133114), (356, 0.04459705897203215), (198, 0.04428458759911999), (174, 0.04425016105459942), (344, 0.04387223838373965), (224, 0.04366092478248454), (301, 0.043627418370983315), (226, 0.04347901508207789), (466, 0.043310626913065475), (317, 0.04324260142994271), (170, 0.04273637905074994), (223, 0.04265014231493115), (304, 0.04261732449308597), (444, 0.042581830338925264), (129, 0.04256511539732068), (281, 0.042352228433498), (263, 0.04230813507926108), (165, 0.04224825405200672), (63, 0.0415464445205626), (451, 0.04149362056654041), (199, 0.041405440230631814), (468, 0.04130895458881408), (196, 0.04128070325096379), (229, 0.04118126425109107), (182, 0.04111100674579964), (123, 0.04108058646147479), (193, 0.040952307481581594), (47, 0.040944276481551675), (436, 0.04085939840082336), (183, 0.04070691211815687), (478, 0.04042138306923973), (290, 0.04012515178074353), (239, 0.039961101583028485), (319, 0.039947572777478464), (231, 0.03993409010610112), (480, 0.039739251151737445), (222, 0.03942222202252838), (44, 0.039325001748386344), (195, 0.03925852926987327), (184, 0.03918391689491662), (465, 0.03914163485626611), (221, 0.03871311561845832), (274, 0.038334686405436635), (130, 0.038278282849072996), (158, 0.037965229428794565), (461, 0.03792317287234666), (311, 0.03784625837006983), (475, 0.03751242601093573), (212, 0.03728009221089104), (282, 0.03705095840340245), (343, 0.0367485481019914), (173, 0.03649611374773058), (188, 0.036366135621816724), (460, 0.036268658694145015), (488, 0.036252697003541466), (267, 0.036235309805572574), (122, 0.03614786591020495), (124, 0.03611158524325686), (248, 0.03595389747874752), (118, 0.03591405045030584), (60, 0.035603593846909636), (469, 0.03535681775830326), (351, 0.035356313554615555), (490, 0.03419747276223315), (485, 0.03409229490933682), (62, 0.03376859736550506), (191, 0.03371647912475754), (445, 0.03362065807193324), (272, 0.03357586282894819), (457, 0.033313482306141166), (289, 0.0331852397217703), (194, 0.0329478792103667), (467, 0.032546081763445214), (355, 0.032402979014381855), (409, 0.03236145553973946), (433, 0.03229672488191466), (57, 0.032090482723311387), (265, 0.032051054957153796), (464, 0.03142403062424197), (252, 0.03118486163746837), (55, 0.030984200792682163), (473, 0.030861239449329406), (228, 0.030838179880089526), (246, 0.030695244244151428), (474, 0.030501122934564653), (185, 0.030420240841519466), (210, 0.03021236525454539), (234, 0.03015983320258106), (470, 0.030136868881341438), (179, 0.030078002625090472), (131, 0.02977691092966068), (491, 0.0295242611495781), (483, 0.02906974529271412), (292, 0.029022406318602437), (208, 0.028779374026798168), (190, 0.028700791968406886), (220, 0.028542006664438742), (268, 0.028503741212356788), (245, 0.028290550205452306), (225, 0.027873449918658446), (279, 0.027444026267247117), (227, 0.02738937448548795), (471, 0.02722174271521766), (207, 0.027090419026053247), (175, 0.026950512116596367), (269, 0.026937237561742926), (211, 0.02602967735661519), (65, 0.02597428589007736), (49, 0.025932763785423512), (189, 0.025891165908466462), (271, 0.025782313136380856), (166, 0.025251578349896116), (286, 0.02513536324912335), (459, 0.0249132201667681), (352, 0.024302630500174813), (476, 0.0232450840140995), (218, 0.02298769455574419), (260, 0.022267434728199375), (346, 0.02160810599533096), (253, 0.02150538272365045), (255, 0.02112640574339395), (256, 0.020546353317391908), (264, 0.01952775675672057), (278, 0.01943030436535108), (285, 0.01912460323110608), (237, 0.017832660253566092), (242, 0.01763959492317453), (230, 0.017421776960547693), (244, 0.017180243228774317), (236, 0.016823352717530066), (462, 0.016765187598471752), (217, 0.013174546438387915), (262, 0.012849396131073972), (258, 0.012328571516793051), (266, 0.011883833617188757), (214, 0.010994180773513676), (479, 0.010645057008100518), (492, 0.010395778453371052), (487, 0.010232595074441415), (277, 0.010171756293178565), (284, 0.00928774328635512), (486, 0.009209210807615742), (68, 0.009157183617009994), (254, 0.008623335404627583), (275, 0.008253082315159718), (251, 0.00782425860580327), (280, 0.007560128725401261), (238, 0.007425604484230421), (288, 0.00722030862401297), (273, 0.005940511515330449), (233, 0.004936802424541452), (270, 0.004212347837369171), (261, 0.0035345946350680097), (276, 0.0017725932448176462), (257, 0.001199283744453612), (259, -0.0020961023020281324), (241, -0.005605609229336752), (206, -0.008931202232416138)]\n",
      "Best MI score: 0.13581585309537378\n",
      "Adding first best original feature: 93\n",
      "CMI: 0.006182510803362906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMI: 0.0007187043416190808\n",
      "CMI: 0.007230283006921828\n",
      "CMI: 0.010960782557124626\n",
      "CMI: 0.004037662917051987\n",
      "CMI: 0.0030121090469339695\n",
      "CMI: 0.034576722792044906\n",
      "CMI: 0.006383562233786\n",
      "CMI: 0.0008470043611637501\n",
      "CMI: 0.030296655718422633\n",
      "CMI: 0.016021396013591205\n",
      "CMI: 0.014997216123326107\n",
      "CMI: 0.015660988669430692\n",
      "CMI: 0.007094128475894329\n",
      "CMI: 0.015377512279242389\n",
      "CMI: 0.008212055728211987\n",
      "CMI: 0.0004273845750938088\n",
      "CMI: 0.00901303930319236\n",
      "CMI: 0.010679830312408128\n",
      "CMI: 0.007991863917649472\n",
      "CMI: 0.007852564860627437\n",
      "CMI: 0.00366519897243045\n",
      "CMI: 0.0008717181977179189\n",
      "CMI: 0.004855860583884625\n",
      "CMI: 0.0016694691580188548\n",
      "CMI: 0.003150176167287966\n",
      "CMI: 7.280346436999707e-05\n",
      "CMI: 0.0066669900567441764\n",
      "CMI: 0.0010740375930284873\n",
      "CMI: 0.004229936382990518\n",
      "CMI: 0.002345428708940056\n",
      "CMI: 0.006505443413236778\n",
      "CMI: 0.0009718254515048985\n",
      "CMI: 0.002922072263154857\n",
      "CMI: 0.006159317752981092\n",
      "CMI: 0.0043559963566974225\n",
      "CMI: 0.007870045701975747\n",
      "CMI: 0.014874696806860849\n",
      "CMI: 0.00787474513291836\n",
      "CMI: 0.010899360473428488\n",
      "CMI: 0.0064345123206901444\n",
      "CMI: 0.007962800583828727\n",
      "CMI: 0.017237516765143318\n",
      "CMI: 0.009234658383358157\n",
      "CMI: 0.011970045240902227\n",
      "CMI: 0.010548893948092136\n",
      "CMI: 0.005194665917216845\n",
      "CMI: 0.010026292679333582\n",
      "CMI: 0.002526984514724967\n",
      "CMI: 0.01697275327165859\n",
      "CMI: 0.01836988809182416\n",
      "CMI: 0.007425143877033025\n",
      "CMI: 0.0031580980284626747\n",
      "CMI: 0.005536252858972579\n",
      "CMI: 0.0026179499752951585\n",
      "CMI: 0.005684770995632027\n",
      "CMI: 0.02215588052292683\n",
      "CMI: 0.0011465824312679729\n",
      "CMI: 0.004881929671033569\n",
      "CMI: 0.013066293316048\n",
      "CMI: 0.0049441207295972955\n",
      "CMI: 0.014728606440256725\n",
      "CMI: 0.022050186087102686\n",
      "CMI: 0.0237732662576082\n",
      "CMI: 0.032811951602779776\n",
      "CMI: 0.02011373568429628\n",
      "CMI: 0.010510202267503654\n",
      "CMI: 0.005667601810104422\n",
      "CMI: 0.012627340197328335\n",
      "CMI: 0.005283175918643496\n",
      "CMI: 0.01600855688318903\n",
      "CMI: 0.0002019725270378525\n",
      "CMI: 0.0027415109620368694\n",
      "CMI: 0.026616659637496265\n",
      "CMI: 0.020092645277309473\n",
      "CMI: 0.007214168342635913\n",
      "CMI: 0.006071891145747715\n",
      "CMI: 0.0028236879298456363\n",
      "CMI: 0.005445784519538338\n",
      "CMI: 0.00479941815554244\n",
      "CMI: 0.004578084573430757\n",
      "CMI: 0.015408070543611069\n",
      "CMI: 0.006936186668610261\n",
      "CMI: 0.0024252397503559953\n",
      "CMI: 0.0015646905399087085\n",
      "CMI: 0.009107638922207978\n",
      "CMI: 0.04609857007863735\n",
      "CMI: 0.06852064434995936\n",
      "CMI: 0.04406702118632008\n",
      "CMI: 0.08084551987638844\n",
      "CMI: 0.051542267022252175\n",
      "CMI: 0.028574193157098915\n",
      "CMI: 0.049033181558685246\n",
      "CMI: 0.034191882117390104\n",
      "CMI: 0.05853931724648817\n",
      "CMI: 0.03361614866400586\n",
      "CMI: 0.04713533470253589\n",
      "CMI: 0.05870256994639533\n",
      "CMI: 0.058233674212608194\n",
      "CMI: 0.05749832147440262\n",
      "CMI: 0.0410938784478867\n",
      "CMI: 0.04627763061347798\n",
      "CMI: 0.04631454053101333\n",
      "CMI: 0.041355019765840495\n",
      "CMI: 0.005646642397805018\n",
      "CMI: 0.0543144791343019\n",
      "CMI: 0.019398814819448773\n",
      "CMI: 0.01727011064035988\n",
      "CMI: 0.010175733435776019\n",
      "CMI: 0.028760281161090057\n",
      "CMI: 0.003116370897850218\n",
      "CMI: 0.011251390289802737\n",
      "CMI: 0.04017759089299791\n",
      "CMI: 0.0231674019646691\n",
      "CMI: 0.0038455819019948823\n",
      "CMI: 0.00589124238636618\n",
      "CMI: 0.020766047542617322\n",
      "CMI: 0.01101577319633995\n",
      "CMI: 0.0029418214730982384\n",
      "CMI: 0.015598809799796026\n",
      "CMI: 0.05690764053972802\n",
      "CMI: 0.04202553574982809\n",
      "CMI: 0.04862579042842796\n",
      "CMI: 0.04972143390413708\n",
      "CMI: 0.02327216019215886\n",
      "CMI: 0.06642154842576484\n",
      "CMI: 0.07375327059454978\n",
      "CMI: 0.035681924899363004\n",
      "CMI: 0.06903138849800042\n",
      "CMI: 0.04890104756364849\n",
      "CMI: 0.048689982356904526\n",
      "CMI: 0.04511103549490797\n",
      "CMI: 0.028795256442884776\n",
      "CMI: 0.004058007283329557\n",
      "CMI: 0.018410841550452556\n",
      "CMI: 0.02563763533432392\n",
      "CMI: 0.0003745882823673885\n",
      "CMI: 0.028331110852393482\n",
      "CMI: 0.03826777535683171\n",
      "CMI: 0.023700635884088467\n",
      "CMI: 0.02406698558074663\n",
      "CMI: 0.046514068635409245\n",
      "CMI: 0.019916852356502535\n",
      "CMI: 0.05403681688585732\n",
      "CMI: 0.038573752760293706\n",
      "CMI: 0.0602122799783355\n",
      "CMI: 0.043637280937983414\n",
      "CMI: 0.0384591492083029\n",
      "CMI: 0.02651175179247245\n",
      "CMI: 0.019896069314133902\n",
      "CMI: 0.06005888139836241\n",
      "CMI: 0.001655543652204522\n",
      "CMI: 0.018191541973167746\n",
      "CMI: 0.02211174730689816\n",
      "CMI: 0.049902670150528655\n",
      "CMI: 0.056195760917677084\n",
      "CMI: 0.019362530782751936\n",
      "CMI: 0.03964342420428993\n",
      "CMI: 0.04135496317130674\n",
      "CMI: 0.025157286328764183\n",
      "CMI: 0.018214309164881815\n",
      "CMI: 0.012551564383168456\n",
      "CMI: 0.022911569931430786\n",
      "CMI: 0.06437732538109942\n",
      "CMI: 0.047393654518018385\n",
      "CMI: 0.027505280198541676\n",
      "CMI: 0.040496751554658844\n",
      "CMI: 0.05186256219535321\n",
      "CMI: 0.01592983884981844\n",
      "CMI: 0.019612203273132345\n",
      "CMI: 0.005386522335819238\n",
      "CMI: 0.02354025388134723\n",
      "CMI: 0.03478421545680241\n",
      "CMI: 0.03115065488663188\n",
      "CMI: 0.053893771825452685\n",
      "CMI: 0.009572306152067916\n",
      "CMI: 0.03566747696600045\n",
      "CMI: 0.032702788967042346\n",
      "CMI: 0.024372630849648247\n",
      "CMI: 0.043857742973846064\n",
      "CMI: 0.06676340533928088\n",
      "CMI: 0.007387807924479406\n",
      "CMI: 0.05021380723464952\n",
      "CMI: 0.01607241574704807\n",
      "CMI: 0.021591818130735768\n",
      "CMI: 0.045323736416185145\n",
      "CMI: 0.002032507777166459\n",
      "CMI: 0.04387520728935654\n",
      "CMI: 0.03508478387996558\n",
      "CMI: 0.014195624152327224\n",
      "CMI: 0.001693965917769602\n",
      "CMI: 0.023203265614990587\n",
      "CMI: 0.02236243720998138\n",
      "CMI: 0.02359128968437424\n",
      "CMI: 0.02277497362813033\n",
      "CMI: 0.0013171957721248018\n",
      "CMI: 0.00862481611901414\n",
      "CMI: 0.007383523372377521\n",
      "CMI: 0.01030109352263256\n",
      "CMI: 0.027594061429180056\n",
      "CMI: 0.03850245255421936\n",
      "CMI: 0.03564974793880571\n",
      "CMI: 0.056948133684202706\n",
      "CMI: 0.027933428655058185\n",
      "CMI: 0.021885068995919077\n",
      "CMI: 0.012690477173133652\n",
      "CMI: 0.011814177259585668\n",
      "CMI: 0.00521297433238857\n",
      "CMI: 0.01269450001313513\n",
      "CMI: 0.0009514229895492832\n",
      "CMI: 0.019874834910278277\n",
      "CMI: 0.0004047367940783475\n",
      "CMI: 0.027683321760093027\n",
      "CMI: 3.963692193961754e-05\n",
      "CMI: 0.004981675992108303\n",
      "CMI: 0.005797441047744684\n",
      "CMI: 0.0035128925273315015\n",
      "CMI: 0.0005954591340449067\n",
      "CMI: 0.007165425266336456\n",
      "CMI: 0.03549125245497295\n",
      "CMI: 0.0028868287650940516\n",
      "CMI: 0.0033704548811636093\n",
      "CMI: 0.005370032751453563\n",
      "CMI: 0.004144604269005037\n",
      "Highest CMI score: 0.08084551987638844\n",
      "Adding original feature: 325\n",
      "CMI: 0.0006252759297731281\n",
      "CMI: 0.003246984866474595\n",
      "CMI: 0.0010150268963570463\n",
      "CMI: 0.006632191558708478\n",
      "CMI: 0.007582776395055751\n",
      "CMI: 0.006962104145860348\n",
      "CMI: 0.013331828577423044\n",
      "CMI: 0.0009062548510962165\n",
      "CMI: 0.0005680092643721157\n",
      "CMI: 0.01658512275758936\n",
      "CMI: 0.01327641244637559\n",
      "CMI: 0.0029555352290833448\n",
      "CMI: 0.004636488276563155\n",
      "CMI: 0.003162737505210539\n",
      "CMI: 0.00036427978339576006\n",
      "CMI: 0.0011875829474835842\n",
      "CMI: 0.0036748588966994955\n",
      "CMI: 0.002820952943560384\n",
      "CMI: 0.0021761297046067607\n",
      "CMI: 0.008428973953639396\n",
      "CMI: 0.00424356329575773\n",
      "CMI: 0.003763225813305432\n",
      "CMI: 0.004738489046927502\n",
      "CMI: 0.002451532835400533\n",
      "CMI: 0.0014349726952306019\n",
      "CMI: 0.007617203097537106\n",
      "CMI: 0.004773166885057023\n",
      "CMI: 0.003558211089806973\n",
      "CMI: 0.0034206928141942983\n",
      "CMI: 0.0020231844284851475\n",
      "CMI: 0.006010780521851777\n",
      "CMI: 0.011929486666525518\n",
      "CMI: 0.011578830095936021\n",
      "CMI: 0.0037965161551153648\n",
      "CMI: 8.911141676534728e-05\n",
      "CMI: 0.0005595162202824688\n",
      "CMI: 0.00022123714496979918\n",
      "CMI: 0.00849097259717338\n",
      "CMI: 0.005225902937775251\n",
      "CMI: 0.008622883878571658\n",
      "CMI: 0.017837279408871726\n",
      "CMI: 0.012652239960014633\n",
      "CMI: 0.0011768970267193035\n",
      "CMI: 0.0051629172597244255\n",
      "CMI: 0.012053380747816866\n",
      "CMI: 0.01064374717317329\n",
      "CMI: 0.006106328846457593\n",
      "CMI: 0.000896836776109855\n",
      "CMI: 0.0053246841500627085\n",
      "CMI: 0.0037427562222792643\n",
      "CMI: 0.006925236468285828\n",
      "CMI: 0.00837692585560762\n",
      "CMI: 0.0008250497397021828\n",
      "CMI: 0.0030176123720063452\n",
      "Highest CMI score: 0.017837279408871726\n",
      "Adding original feature: 403\n",
      "CMI: 0.004296012579757619\n",
      "CMI: 0.005257372468456811\n",
      "CMI: 0.0010181331781174419\n",
      "CMI: 0.0001846023309917122\n",
      "CMI: 0.004612223058617609\n",
      "CMI: 0.010415654487417908\n",
      "CMI: 0.0033724591316095787\n",
      "CMI: 0.009344191869116836\n",
      "CMI: 0.0014907162796709283\n",
      "CMI: 0.003856427915671118\n",
      "CMI: 0.0045595782807902885\n",
      "CMI: 0.004890860720027229\n",
      "CMI: 0.0011282825505856131\n",
      "CMI: 0.0009835513138083674\n",
      "CMI: 0.002051249434811442\n",
      "CMI: 0.007000692487557969\n",
      "CMI: 0.005248576277873257\n",
      "CMI: 0.003473211045214336\n",
      "CMI: 0.004042481804649917\n",
      "CMI: 0.00017159246081654977\n",
      "CMI: 0.0042486479377382425\n",
      "CMI: 0.01583012019639074\n",
      "Highest CMI score: 0.01583012019639074\n",
      "Adding original feature: 491\n",
      "CMI: 0.0034204422705264026\n",
      "CMI: 0.0032640823788533946\n",
      "CMI: 0.004105256887681541\n",
      "CMI: 0.00420155489681906\n",
      "CMI: 0.0038526045395820274\n",
      "CMI: 0.0017344715223854834\n",
      "CMI: 0.0009534953835881321\n",
      "CMI: 0.004937148616328602\n",
      "CMI: 0.0010506577569672215\n",
      "CMI: 0.0037346872969094003\n",
      "CMI: 0.002794144337824267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMI: 0.0072298597779879015\n",
      "CMI: 0.010228696060808118\n",
      "CMI: 0.00436965418989449\n",
      "CMI: 6.515266162948619e-05\n",
      "CMI: 0.0017576839903602481\n",
      "CMI: 0.002927423152352615\n",
      "CMI: 0.009968049529583578\n",
      "CMI: 0.0027932095652657973\n",
      "CMI: 0.001412054083740899\n",
      "CMI: 0.019147207286820345\n",
      "CMI: 0.0080983631533183\n",
      "CMI: 0.015640622950444105\n",
      "CMI: 0.013483372010565653\n",
      "CMI: 0.017628139965900846\n",
      "CMI: 0.009316425520572491\n",
      "CMI: 0.010983192912190742\n",
      "CMI: 0.003770054413717583\n",
      "CMI: 0.019503950495072253\n",
      "CMI: 0.0002879823822212191\n",
      "CMI: 0.003425726650909011\n",
      "CMI: 0.008250567536926878\n",
      "CMI: 0.02256623715249212\n",
      "CMI: 0.017837010146138144\n",
      "CMI: 0.01659725091173031\n",
      "CMI: 0.024875487140057162\n",
      "CMI: 0.01478297967019676\n",
      "CMI: 0.016242833156358716\n",
      "CMI: 0.008700826813250018\n",
      "CMI: 0.017087881075416478\n",
      "CMI: 0.015237453390360423\n",
      "CMI: 0.02799426380568193\n",
      "CMI: 0.02435168526154846\n",
      "CMI: 0.020660611562666686\n",
      "CMI: 0.014715819372705385\n",
      "CMI: 0.006617595896907691\n",
      "CMI: 0.006095422209739798\n",
      "CMI: 0.0006926850861197487\n",
      "CMI: 0.019190997350469197\n",
      "CMI: 0.012058137831937654\n",
      "CMI: 0.008325865540086685\n",
      "CMI: 0.013035909139543278\n",
      "CMI: 0.0069486403142307585\n",
      "CMI: 0.01087190057108961\n",
      "CMI: 0.016243356960125577\n",
      "CMI: 0.008669478390011587\n",
      "CMI: 0.011059815099540737\n",
      "CMI: 0.010211299382867634\n",
      "CMI: 0.0042420489866467626\n",
      "CMI: 0.015310376682607374\n",
      "CMI: 0.01095894306551115\n",
      "CMI: 0.01356201732511314\n",
      "CMI: 0.0013370170130028725\n",
      "CMI: 0.006065480936381928\n",
      "CMI: 0.008862499506805566\n",
      "CMI: 0.009514780381833954\n",
      "CMI: 0.003143081982810436\n",
      "CMI: 0.007112962602103312\n",
      "CMI: 0.009400727893463523\n",
      "CMI: 0.01168234572244109\n",
      "CMI: 0.018848278507857308\n",
      "CMI: 0.009809942440061004\n",
      "CMI: 0.01634328146364944\n",
      "CMI: 0.004509376660613185\n",
      "CMI: 0.012233051170399523\n",
      "CMI: 0.00895329100319564\n",
      "CMI: 0.0021575635243172298\n",
      "CMI: 0.006510332925509066\n",
      "CMI: 0.005734145527232726\n",
      "CMI: 0.0011013339574069692\n",
      "CMI: 0.01046514198900228\n",
      "CMI: 0.0019358324898506307\n",
      "CMI: 5.2880989996395567e-05\n",
      "CMI: 0.005099430699598284\n",
      "CMI: 0.009475171332374799\n",
      "CMI: 0.003737971626866343\n",
      "CMI: 0.006851680763909296\n",
      "CMI: 0.007325262868512872\n",
      "CMI: 0.007134068068677002\n",
      "CMI: 0.0004961237378294792\n",
      "CMI: 0.007363100051622995\n",
      "CMI: 0.003692364894107958\n",
      "CMI: 0.002584847101447074\n",
      "CMI: 0.00831403792866997\n",
      "CMI: 0.013144644083230905\n",
      "CMI: 0.0026425167438697827\n",
      "CMI: 0.0027062705180431745\n",
      "CMI: 0.0013597337837917833\n",
      "CMI: 0.004079722472947411\n",
      "CMI: 0.0005891626870349609\n",
      "CMI: 0.0011817515180530536\n",
      "CMI: 0.00040745882518195\n",
      "CMI: 0.0073552361518861575\n",
      "CMI: 0.007481138535804788\n",
      "CMI: 0.0014437681748572517\n",
      "CMI: 0.0006412484097973459\n",
      "Highest CMI score: 0.02799426380568193\n",
      "Adding original feature: 191\n",
      "CMI: 0.002122505706276978\n",
      "CMI: 0.00021739569493905986\n",
      "CMI: 0.001373814601113632\n",
      "CMI: 0.002199001378039911\n",
      "CMI: 1.2546113348221866e-05\n",
      "CMI: 0.001826310537952458\n",
      "CMI: 0.0019961810498232424\n",
      "CMI: 0.0018437063820958555\n",
      "CMI: 0.0015505181972662596\n",
      "Highest CMI score: 0.002199001378039911\n",
      "Adding original feature: 151\n",
      "CMI: 0.0016116395738449696\n",
      "CMI: 0.00014095340007691526\n",
      "CMI: 0.002129701518516547\n",
      "CMI: 0.004872538399390169\n",
      "CMI: 0.0014183161142237166\n",
      "CMI: 0.004734590344520895\n",
      "CMI: 0.011839930568480539\n",
      "CMI: 0.008249445047591286\n",
      "CMI: 0.0007397846865166979\n",
      "CMI: 0.001657920987227668\n",
      "Highest CMI score: 0.011839930568480539\n",
      "Adding original feature: 397\n",
      "CMI: 0.0005361458978559441\n",
      "CMI: 0.0013249953266117886\n",
      "CMI: 0.0014202111038905674\n",
      "CMI: 0.0013662131789666798\n",
      "Highest CMI score: 0.0014202111038905674\n",
      "Adding original feature: 368\n",
      "CMI: 0.0014117509623412516\n",
      "Highest CMI score: 0.0014117509623412516\n",
      "Adding original feature: 364\n",
      "CMI: 0.0007189752092865431\n",
      "CMI: 0.0004875528082796676\n",
      "Highest CMI score: 0.0007189752092865431\n",
      "Adding original feature: 125\n",
      "CMI: 8.114375318984957e-05\n",
      "Highest CMI score: 8.114375318984957e-05\n",
      "Adding original feature: 149\n",
      "CMI: 0.0005547059450731751\n",
      "CMI: 1.3022775060933522e-05\n",
      "Highest CMI score: 0.0005547059450731751\n",
      "Adding original feature: 143\n",
      "Highest CMI score: -0.0005712786574875728\n",
      "\n",
      "[93, 325, 403, 491, 191, 151, 397, 368, 364, 125, 149, 143]\n",
      "\n",
      "Full aggregate regression train score: 0.9180110159940696, test score: -107.58500924872416\n",
      "Aggregate regression train score with FS: 0.24999443021500034, test score: 0.22622904562445512\n"
     ]
    }
   ],
   "source": [
    "### what happens without considering the last years?\n",
    "target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target('',max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01')\n",
    "\n",
    "path='/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/features/csv_allvalues/temporal_aggreg/Emiliani2_aggreg.csv'\n",
    "\n",
    "output,aggregate_trainVal,aggregate_test = aggregate_unfolded_data(path,['cyclostationary_mean_tg',\n",
    "       'cyclostationary_mean_rr', 'cyclostationary_mean_tg_1w',\n",
    "       'cyclostationary_mean_tg_4w', 'cyclostationary_mean_tg_8w',\n",
    "       'cyclostationary_mean_tg_12w', 'cyclostationary_mean_tg_16w',\n",
    "       'cyclostationary_mean_tg_24w', 'cyclostationary_mean_rr_1w',\n",
    "       'cyclostationary_mean_rr_4w', 'cyclostationary_mean_rr_8w',\n",
    "       'cyclostationary_mean_rr_12w', 'cyclostationary_mean_rr_16w',\n",
    "       'cyclostationary_mean_rr_24w'],target_df_trainVal, max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01')\n",
    "\n",
    "res = {\n",
    "    \"delta\" : [], # list with all deltas\n",
    "    \"numSelected\" : [], #\n",
    "    \"selectedFeatures\" : [] \n",
    "#    \"accuracy\" : [] # list of scores associated with the reduced problem\n",
    "}\n",
    "\n",
    "res['selectedFeatures'] = forwardFeatureSelection(10,np.array(aggregate_trainVal),np.array(target_df_trainVal.mean_std),res,10,1)\n",
    "selectedFeatures='selectedFeatures'\n",
    "print(f'\\n{res[selectedFeatures]}\\n')\n",
    "selected_colnames = aggregate_trainVal.columns[res['selectedFeatures']]\n",
    "compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7a48f7f8",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "6\n",
      "8\n",
      "9\n",
      "18\n",
      "20\n",
      "25\n",
      "26\n",
      "----- MI Scores -----\n",
      "[(0, 0.12455630733277606), (3, 0.1191326366947945), (9, 0.10639343474232596), (8, 0.09837955367460148), (1, 0.09501019884305828), (4, 0.0946340510559481), (2, 0.08785533209619939), (7, 0.08246163579244427), (6, 0.07671004309464893), (5, 0.05583991557037529)]\n",
      "Best MI score: 0.12455630733277606\n",
      "Adding first best original feature: 0\n",
      "CMI: 0.008919094917099996\n",
      "Highest CMI score: 0.008919094917099996\n",
      "Adding original feature: 3\n",
      "CMI: 0.001212057237399422\n",
      "CMI: 0.002583437635593183\n",
      "Highest CMI score: 0.002583437635593183\n",
      "Adding original feature: 8\n",
      "Highest CMI score: -0.001627961533766209\n",
      "\n",
      "[0, 3, 8]\n",
      "\n",
      "Full aggregate regression train score: 0.15939084618066446, test score: 0.05143212556246268\n",
      "Aggregate regression train score with FS: 0.13870957128874928, test score: 0.07089426171710611\n"
     ]
    }
   ],
   "source": [
    "### repeat keeping features with at least three cells and excluding last years\n",
    "ii = []\n",
    "for i in range(len(output)):\n",
    "    if (len(output[i]))>=3: \n",
    "        print(i)\n",
    "        ii.append(i)\n",
    "\n",
    "res = {\n",
    "    \"delta\" : [], # list with all deltas\n",
    "    \"numSelected\" : [], #\n",
    "    \"selectedFeatures\" : [] \n",
    "}\n",
    "\n",
    "res['selectedFeatures'] = forwardFeatureSelection(10,np.array(aggregate_trainVal.iloc[:,ii]),np.array(target_df_trainVal.mean_std),res,10,1)\n",
    "selectedFeatures='selectedFeatures'\n",
    "print(f'\\n{res[selectedFeatures]}\\n')\n",
    "selected_colnames = aggregate_trainVal.iloc[:,ii].columns[res['selectedFeatures']]\n",
    "compare_methods(aggregate_trainVal.iloc[:,ii], aggregate_test.iloc[:,ii], target_df_trainVal, target_df_test, selected_colnames)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
